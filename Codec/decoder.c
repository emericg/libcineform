/*! @file

*  @brief
*
*  @version 1.0.0
*
*  (C) Copyright 2017 GoPro Inc (http://gopro.com/).
*
*  Licensed under the Apache License, Version 2.0 (the "License");
*  you may not use this file except in compliance with the License.
*  You may obtain a copy of the License at
*
*      http://www.apache.org/licenses/LICENSE-2.0
*
*  Unless required by applicable law or agreed to in writing, software
*  distributed under the License is distributed on an "AS IS" BASIS,
*  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*  See the License for the specific language governing permissions and
*  limitations under the License.
*
*/

#include "config.h"
#include "timing.h"
#include <stddef.h>
#include <math.h>
#include <memory.h>
#include <time.h>

#ifndef DEBUG
#define DEBUG  (1 && _DEBUG)
#endif
#ifndef TIMING
#define TIMING (1 && _TIMING)
#endif
#ifndef XMMOPT
#define XMMOPT (1 && _XMMOPT)
#endif

#ifdef _WIN32
#include <windows.h>
#elif __APPLE__
#include "macdefs.h"
#else
#ifndef ZeroMemory
#define ZeroMemory(p,s)		memset(p,0,s)
#endif
#endif

#include <stdio.h>
#include <assert.h>
#include <emmintrin.h>			// Intel aligned alloc and free

#include "decoder.h"
#include "codec.h"
#include "vlc.h"
#include "codebooks.h"			// References to the codebooks
#include "color.h"				// Color formats supported by image processing routines
#include "image.h"
#include "filter.h"
#include "spatial.h"
#include "temporal.h"
#include "convert.h"
#include "wavelet.h"
#include "bitstream.h"
#include "frame.h"
#include "cpuid.h"
#include "bayer.h"
#include "metadata.h"
#include "demosaicframes.h"
#include "swap.h"
#include "RGB2YUV.h"
#include "lutpath.h"

extern void FastVignetteInplaceWP13(DECODER *decoder, int displayWidth, int width, int height, int y, float r1, float r2, float gain,
                                    int16_t *sptr, int resolution, int pixelsize);
extern void FastSharpeningBlurHinplaceWP13(int width, int16_t *sptr, float sharpness, int resolution, int pixelsize);
extern void FastSharpeningBlurVWP13(short *Aptr,
                                    short *Bptr,
                                    short *Cptr,
                                    short *Dptr,
                                    short *Eptr,
                                    int pitch,
                                    int edgenear,
                                    short *output,
                                    int pixels,
                                    float sharpness,
                                    int resolution,
                                    int channel_blend_type);
extern void FastSharpeningBlurVW13A(short *Aptr,
                                    short *Bptr,
                                    short *Cptr,
                                    short *Dptr,
                                    short *Eptr,
                                    int pitch,
                                    int edgenear,
                                    short *output,
                                    int pixels,
                                    float sharpness,
                                    int resolution,
                                    int channel_blend_type);

#define ERROR_TOLERANT			1

#if defined(_WIN32) && DEBUG
#include <tchar.h>				// For printing debug string in the console window
#endif

#define _DECODE_TRANSFORM		1	// Enable concurrent decoding and inverse transform
#define _TRANSFORM_FIELDPLUS	1	// Use the field plus transform

#if _SIF							// In SIF resolution, enable the _DECODE_TRANSFORM switch
#if _DECODE_TRANSFORM == 0
#define _DECODE_TRANSFORM		1
#endif
#endif

#ifndef _FSMBUFFER
#define _FSMBUFFER	0
#endif

// Turn off saturation in this file
#ifdef SATURATE
#undef SATURATE
#endif
#define SATURATE(x)			(assert(PIXEL_MIN <= (x) && (x) <= PIXEL_MAX), (x))
#define SATURATE8S(x)		(assert(PIXEL8S_MIN <= (x) && (x) <= PIXEL8S_MAX), (x))
//#define SATURATE8S(x)		SATURATE_8S(x)
//#define SATURATE(x) (x)

// Enable or disable function inlining
#if 1	//DEBUG
#define inline
#else
#define inline __forceinline
#endif

// Pixel size used for computing the compression ratio
#define BITS_PER_PIXEL 8

// Default processor capabilities
#define DEFAULT_FEATURES (_CPU_FEATURE_MMX )

#define DEMOSAIC_DELAYLINES	4

// Forward references
void AllocDecoderGroup(DECODER *decoder);
bool AllocDecoderBuffer(DECODER *decoder, int width, int height, int format);
void EraseDecoderFrames(DECODER *decoder);
TRANSFORM *AllocGroupTransform(GROUP *group, int channel);
void EraseOutputBuffer(uint8_t *buffer, int width, int height, int32_t pitch, int format);
#if _DEBUG
bool DecodeBandFSM16sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch, FILE *logfile);
#else
bool DecodeBandFSM16sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch);
#endif
bool DecodeBandFSM16sNoGapHighByte(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch, int quant);
bool DecodeBandFSM16sNoGap2Pass(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch, int quant);
void CopyLowpassRGB444ToBuffer(DECODER *decoder, IMAGE *image_array[], int num_channels,
                               uint8_t *output_buffer, int32_t output_pitch,
                               FRAME_INFO *info, int chroma_offset,
                               int precision);

extern void Row16uQuarter2OutputFormat(DECODER *decoder, FRAME_INFO *info, int thread_index,
                                       uint8_t *output, int pitch, int frame, void *scratch, size_t scratch_size, int threading,
                                       uint8_t *channeldata[TRANSFORM_MAX_CHANNELS], // used in quarter res decodes
                                       int channelpitch[TRANSFORM_MAX_CHANNELS]); // used in quarter res decodes);
//extern void ComputeCube(DECODER *decoder);
extern bool NeedCube(DECODER *decoder);

//extern int g_topdown;
//extern int g_bottomup;

// Performance measurements
#if _TIMING

extern TIMER tk_decompress;				// Timers
extern TIMER tk_decoding;
extern TIMER tk_convert;
extern TIMER tk_inverse;

extern COUNTER decode_byte_count;		// Counters
extern COUNTER sample_byte_count;
extern COUNTER alloc_group_count;
extern COUNTER alloc_transform_count;
extern COUNTER alloc_buffer_count;
extern COUNTER spatial_decoding_count;
extern COUNTER temporal_decoding_count;
extern COUNTER progressive_decode_count;

#endif

#if 0

// Table that maps from decoded format to pixel size
static const int PixelSize[] =
{
    0,		// DECODED_FORMAT_UNSUPPORTED
    2,		// DECODED_FORMAT_YUYV
    2,		// DECODED_FORMAT_UYVY
    2,		// DECODED_FORMAT_420
    4,		// DECODED_FORMAT_RGB32
    3,		// DECODED_FORMAT_RGB24
    2,		// DECODED_FORMAT_RGB555
    2,		// DECODED_FORMAT_RGB565

#if 0
    2,		// DECODED_FORMAT_YUYV_INVERTED
    2,		// DECODED_FORMAT_UYVY_INVERTED
    2,		// DECODED_FORMAT_420_INVERTED
#endif

    4,		// DECODED_FORMAT_RGB32_INVERTED
    3,		// DECODED_FORMAT_RGB24_INVERTED
    2,		// DECODED_FORMAT_RGB555_INVERTED
    2,		// DECODED_FORMAT_RGB565_INVERTED

    3,		// DECODED_FORMAT_V210,
    4,		// DECODED_FORMAT_YU64,			// Custom 16 bits per channel (all data scaled up) YUYV format.
    4,		// DECODED_FORMAT_YR16		// Rows of YUV with 16 bits per channel
};

#if _DEBUG
char *decoded_format_string[] =
{
    "Unsupported",
    "YUYV",
    "UYUV",
    "420",
    "RGB32",
    "RGB24",
    "RGB555",
    "RGB565",
#if 0
    "YUYV Inverted",
    "UYVY Inverted",
    "420 Inverted",
#endif
    //#if BUILD_PROSPECT
    "RGB32 Inverted",
    "RGB24 Inverted",
    "RGB555 Inverted",
    "RGB565 Inverted",
    "V210"
    //#endif
};
#endif

#else

static const int pixel_size_table[] =
{
    0,		// COLOR_FORMAT_UNKNOWN
    2,		// COLOR_FORMAT_UYVY
    2,		// COLOR_FORMAT_YUYV
    2,		// COLOR_FORMAT_YVYU
    0,		// COLOR_FORMAT_YV12
    0,		// COLOR_FORMAT_I420
    2,		// COLOR_FORMAT_RGB16
    3,		// COLOR_FORMAT_RGB24
    4,		// COLOR_FORMAT_RGB32
    0,
    3,		// COLOR_FORMAT_V210
    0,		// COLOR_FORMAT_RGB10
    4,		// COLOR_FORMAT_YU64
    4,		// COLOR_FORMAT_YR16
    4,		// COLOR_FORMAT_YUVA
};

static const int pixel_size_table_length = sizeof(pixel_size_table) / sizeof(pixel_size_table[0]);


static int PixelSize(int format)
{
    int pixel_size = 0;

    // Mask off the other fields in the format descriptor
    // Use the lookup table to determine the pixel size (if possible)
    if (0 <= format && format < pixel_size_table_length)
    {
        pixel_size = pixel_size_table[format];
        //return pixel_size;
    }

    //TODO: Change the rest of this routine into one big switch statement

    // Is this an Avid format?
    else if (COLOR_FORMAT_AVID <= format && format <= COLOR_FORMAT_AVID_END)
    {
        switch (format)
        {
            case COLOR_FORMAT_CbYCrY_8bit:
            case COLOR_FORMAT_CbYCrY_10bit_2_8:		// Only valid for the lower plane
                pixel_size = 1;
                break;

            case COLOR_FORMAT_CbYCrY_16bit:
            case COLOR_FORMAT_CbYCrY_16bit_2_14:
            case COLOR_FORMAT_CbYCrY_16bit_10_6:
                pixel_size = 2;
                break;

            default:
                assert(0);
                pixel_size = 2;		// Assume 16 bits per pixel if the format is unknown
                break;
        }
    }

    // Is this a Bayer format?
    else if (COLOR_FORMAT_BAYER <= format && format <= COLOR_FORMAT_BAYER_END)
    {
        pixel_size = (format - 100);
        if (pixel_size > 2)
            pixel_size = 2;
    }
    else if (format == COLOR_FORMAT_RG48)
        pixel_size = 6;
    else if (format == COLOR_FORMAT_RG64)
        pixel_size = 8;
    else if (format == COLOR_FORMAT_B64A)
    {
        pixel_size = 8;
    }

    return pixel_size;
}

#endif

int DecodedPixelSize(DECODED_FORMAT format)
{
    int pixel_size = 0;

    // Compute the pixel size
    switch (format)
    {
        case DECODED_FORMAT_YUYV:
            pixel_size = 2;
            break;

        case DECODED_FORMAT_RGB32:
            pixel_size = 4;
            break;

        case DECODED_FORMAT_RG48:
            pixel_size = 6;
            break;

        case DECODED_FORMAT_CT_UCHAR:
            pixel_size = 2;
            break;

        case DECODED_FORMAT_CT_SHORT:
        case DECODED_FORMAT_CT_SHORT_2_14:
        case DECODED_FORMAT_CT_USHORT_10_6:
            pixel_size = 4;
            break;

        case DECODED_FORMAT_CT_10Bit_2_8:
        case DECODED_FORMAT_V210:
            // This routine should not be called to compute the pixel sizes for these formats
            assert(0);
            return 0;
            break;

        case DECODED_FORMAT_ROW16U:
            pixel_size = 4;
            break;

        default:
            assert(0);
            return 0;
            break;
    }

    return pixel_size;
}

#if 0
// Convert FOURCC code to a string
static void str4cc(char *string, uint32_t  marker)
{
    char *p = (char *)&marker + 3;
    char *s = string;
    int i;
    for (i = 0; i < 4; i++)
        *(s++) = *(p--);
    *s = '\0';
}
#endif


void GetDisplayAspectRatio(DECODER *decoder, int *w, int *h)
{
    int origw, origh, guess = 0;

    origw = decoder->frame.width;
    origh = decoder->frame.height;

    switch (decoder->frame.resolution)
    {
        case DECODED_RESOLUTION_FULL:
            break;
        case DECODED_RESOLUTION_HALF:
            origw *= 2;
            origh *= 2;
            break;
        case DECODED_RESOLUTION_QUARTER:
            origw *= 4;
            origh *= 4;
            break;
        case DECODED_RESOLUTION_LOWPASS_ONLY:
            origw *= 8;
            origh *= 8;
            break;
        case DECODED_RESOLUTION_FULL_DEBAYER:
            break;
        case DECODED_RESOLUTION_HALF_NODEBAYER:
            origw *= 2;
            origh *= 2;
            break;
        case DECODED_RESOLUTION_QUARTER_NODEBAYER_SCALED:
            origw *= 4;
            origh *= 4;
            break;
        case DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER:
            //origw *= 2; //DAN20110129 -- seems the width has been corrected elsewhere or was never halved.
            break;
        case DECODED_RESOLUTION_HALF_HORIZONTAL:
            origw *= 2;
            break;
        case DECODED_RESOLUTION_HALF_VERTICAL:
            origh *= 2;
            break;
    }

    if (decoder->codec.picture_aspect_x <= 0 ||  decoder->codec.picture_aspect_y <= 0)
        guess = 1;

    // if guess default values, we can't trust them
    if (decoder->codec.picture_aspect_x == 16 && decoder->codec.picture_aspect_y == 9)
        guess = 1;

    if (decoder->pixel_aspect_x && decoder->pixel_aspect_y)
    {
        int j, den, num;
        decoder->codec.picture_aspect_x = num = (origw * decoder->pixel_aspect_x) / decoder->pixel_aspect_y;
        decoder->codec.picture_aspect_y = den = origh;

        for (j = 2; j < num + den; j++)
        {
            while (num == (num / j)*j && den == (den / j)*j)
            {
                num /= j;
                den /= j;
            }
        }
        decoder->codec.picture_aspect_x = num;
        decoder->codec.picture_aspect_y = den;
        guess = 0;
    }

    if (guess)
    {
        if (origw > 720) //HD.
        {
            if (origh == 1080)
            {
                if (origw == 2048)
                    *w = origw, *h = origh;
                else
                    *w = 16, *h = 9; // assume 16x9
            }
            else if (origh == 720)
            {
                *w = 16, *h = 9; // assume 16x9
            }
            else
            {
                *w = origw, *h = origh; // assume square pixel.
            }
        }
        else
        {
            if (origh == 720)
            {
                *w = 16, *h = 9; // assume 16x9
            }
            else
            {
                *w = origw, *h = origh; // assume square pixel.
            }
        }
    }
    else
    {
        *w = decoder->codec.picture_aspect_x;
        *h = decoder->codec.picture_aspect_y;
    }
}


bool IsValidFrameResolution(int resolution)
{
    switch (resolution)
    {
        case DECODED_RESOLUTION_FULL:
        case DECODED_RESOLUTION_HALF:
        case DECODED_RESOLUTION_QUARTER:
        case DECODED_RESOLUTION_LOWPASS_ONLY:
        case DECODED_RESOLUTION_HALF_HORIZONTAL:
        case DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER:
            return true;

        default:
            return false;
    }
}

// Return true if this decoder can decode to quarter resolution
bool IsQuarterResolutionEnabled(DECODER *decoder)
{
    return true;
}
size_t DecoderSize()
{
    return sizeof(DECODER);
}
void InitDecoder(DECODER *decoder, FILE *logfile, CODESET *cs)
{
#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "InitDecoder, decoder: 0x%p\n", decoder);
    }
#endif

    {
        //TODO: Clear the decoder before setting the CPU limit and affinity

        int i;
        //int thread_limit=0, thread_affinity=0, set_thread_params=0, capabilities=0;

        //save key params
        Thread_cntrl saved_params = decoder->thread_cntrl;

        // Clear everything
        memset(decoder, 0, sizeof(DECODER));

        //restore key params
        if (saved_params.set_thread_params == 1) // used by the DShow Interface
        {
            decoder->thread_cntrl = saved_params;
        }

#if _TIMING
        InitTiming();
#endif
        // Set the file for status information during decoding
        decoder->logfile = logfile;

        // Initialize the decoding error to no error
        decoder->error = CODEC_ERROR_OKAY;

        // Most recent marker found during decoding
        decoder->marker = 0;

        // Count of frames decoded
        decoder->frame_count = 0;

        // Set the codebooks that will be used for decoding
        if (cs != NULL)
        {
            // Use the codeset provided in the call
            for (i = 0; i < CODEC_NUM_CODESETS; i++)
            {

                // Codebook for decoding highpass coefficients
                decoder->magsbook[i] = cs[i].magsbook;

                // Codebook for decoding runs of coefficients
                decoder->runsbook[i] = cs[i].runsbook;

                // Lookup table for fast codebook search
                decoder->fastbook[i] = cs[i].fastbook;
            }
        }
        else
        {
            // Use the default codeset
            decoder->magsbook[0] = cs9.magsbook;
            decoder->runsbook[0] = cs9.runsbook;
            decoder->fastbook[0] = cs9.fastbook;
        }

        // Initialize the codec state
        InitCodecState(&decoder->codec);

        InitScratchBuffer(&decoder->scratch, NULL, 0);
    }

#if _ALLOCATOR
    decoder->allocator = NULL;
#endif

    decoder->initialized = 1; //DAN20060912
}

// Free data allocated within the decoder
void ClearDecoder(DECODER *decoder)
{
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

#if _ALLOCATOR
    ALLOCATOR *allocator = decoder->allocator;
#endif

    // Free the transforms allocated in the decoder
    int i;

    if (decoder->initialized == 0)
        return;

    if (decoder->sqrttable)
    {
#if _ALLOCATOR
        Free(decoder->allocator, decoder->sqrttable);
#else
        MEMORY_FREE(decoder->sqrttable);
#endif
        decoder->sqrttable = NULL;
    }

    for (i = 0; i < TRANSFORM_MAX_CHANNELS; i++)
    {
#if _ALLOCATOR
        FreeTransform(allocator, decoder->transform[i]);
#else
        FreeTransform(decoder->transform[i]);
#endif
        decoder->transform[i] = NULL;
    }

    if (decoder->aligned_sample_buffer)
    {
#if _ALLOCATOR
        FreeAligned(decoder->allocator, decoder->aligned_sample_buffer);
#else
        MEMORY_ALIGNED_FREE(decoder->aligned_sample_buffer);
#endif
        decoder->aligned_sample_buffer = NULL;
        decoder->aligned_sample_buffer_size = 0;
    }

    if (decoder->tools)
    {
#if _ALLOCATOR
        Free(decoder->allocator, decoder->tools);
#else
        MEMORY_FREE(decoder->tools);
#endif
        decoder->tools = NULL;
    }

    // Free the buffer allocated for decoding
    if (decoder->buffer != NULL)
    {
#if _ALLOCATOR
        FreeAligned(allocator, decoder->buffer);
#else
        MEMORY_ALIGNED_FREE(decoder->buffer);
#endif
        decoder->buffer = NULL;
        decoder->buffer_size = 0;

        // Clear the fields in the scratch buffer descriptor
        memset(&decoder->scratch, 0, sizeof(SCRATCH));

        // Eventually the buffer and buffer size fields will be obsolete
    }

    for (i = 0; i < _MAX_CPUS; i++)
    {
        if (decoder->threads_buffer[i])
        {
#if _ALLOCATOR
            FreeAligned(decoder->allocator, decoder->threads_buffer[i]);
#else
            MEMORY_ALIGNED_FREE(decoder->threads_buffer[i]);
#endif

            decoder->threads_buffer[i] = NULL;
        }
    }
    decoder->threads_buffer_size = 0;

    // Do not attempt to free the codebooks since the
    // codebook pointers are references to static tables

    // Can free some of the data structures allocated by the decoder
    FreeCodebooks(decoder);

#if _INTERLACED_WORKER_THREADS
    if (decoder->interlaced_worker.lock_init) // threads started
    {
        int i;

        // Signal this thread to stop
        SetEvent(decoder->interlaced_worker.stop_event);

        // Free all handles used by the worker threads
        for (i = 0; i < THREADS_IN_LAST_WAVELET; i++)
        {
            WaitForSingleObject(decoder->interlaced_worker.handle[i], INFINITE); //JY20080307

            CloseHandle(decoder->interlaced_worker.handle[i]);
            CloseHandle(decoder->interlaced_worker.start_event[i]);
            CloseHandle(decoder->interlaced_worker.done_event[i]);
        }
        CloseHandle(decoder->interlaced_worker.row_semaphore);
        CloseHandle(decoder->interlaced_worker.stop_event);

        for (i = 0; i < THREADS_IN_LAST_WAVELET; i++)
        {
            decoder->interlaced_worker.handle[i] = 0;
            decoder->interlaced_worker.start_event[i] = 0;
            decoder->interlaced_worker.done_event[i] = 0;
        }
        decoder->interlaced_worker.row_semaphore = 0;
        decoder->interlaced_worker.stop_event = 0;
    }

    // Free the critical section used by the worker threads
    DeleteCriticalSection(&decoder->interlaced_worker.lock);
    decoder->interlaced_worker.lock_init = 0;
#endif

#if _THREADED
    if (decoder->entropy_worker_new.pool.thread_count)
    {
        ThreadPoolDelete(&decoder->entropy_worker_new.pool);
        DeleteLock(&decoder->entropy_worker_new.lock);
    }

    if (decoder->worker_thread.pool.thread_count)
    {
        ThreadPoolDelete(&decoder->worker_thread.pool);
        DeleteLock(&decoder->worker_thread.lock);
    }

    if (decoder->draw_thread.pool.thread_count)
    {
        ThreadPoolDelete(&decoder->draw_thread.pool);
        DeleteLock(&decoder->draw_thread.lock);
    }
    /*
    if(decoder->qt_convert_worker.pool.thread_count)
    {
    	ThreadPoolDelete(&decoder->qt_convert_worker.pool);
    	DeleteLock(&decoder->qt_convert_worker.lock);
    }

    if(decoder->qt_scale_worker.pool.thread_count)
    {
    	ThreadPoolDelete(&decoder->qt_scale_worker.pool);
    	DeleteLock(&decoder->qt_scale_worker.lock);
    }
     */

    if (decoder->parallelDecoder)
    {
        if (decoder->parallelDecoder->decoder_thread.pool.thread_count)
        {
            ThreadPoolDelete(&decoder->parallelDecoder->decoder_thread.pool);
            DeleteLock(&decoder->parallelDecoder->decoder_thread.lock);
            decoder->parallelDecoder->decoder_thread.pool.thread_count = 0;
        }

        ClearDecoder(decoder->parallelDecoder);

#if _ALLOCATOR
        Free(decoder->allocator, decoder->parallelDecoder);
#else
        MEMORY_FREE(decoder->parallelDecoder);
#endif
        decoder->parallelDecoder = NULL;
    }
#endif // _THREADED


#if _ALLOCATOR
    if (decoder->RGBFilterBuffer16)
    {
        FreeAligned(decoder->allocator, decoder->RGBFilterBuffer16);
        decoder->RGBFilterBuffer16 = 0;
        decoder->RGBFilterBufferSize = 0;
    }
    if (decoder->RawBayer16)
    {
        FreeAligned(decoder->allocator, decoder->RawBayer16);
        decoder->RawBayer16 = 0;
        decoder->RawBayerSize = 0;
    }
    if (decoder->StereoBuffer)
    {
        FreeAligned(decoder->allocator, decoder->StereoBuffer);
        decoder->StereoBuffer = 0;
        decoder->StereoBufferSize = 0;
    }
    if (decoder->RawCube)
    {
        FreeAligned(decoder->allocator, decoder->RawCube);
        decoder->RawCube = 0;
    }
    if (decoder->Curve2Linear)
    {
        FreeAligned(decoder->allocator, decoder->Curve2Linear);
        decoder->Curve2Linear = 0;
    }
    if (decoder->Linear2CurveRed)
    {
        FreeAligned(decoder->allocator, decoder->Linear2CurveRed);
        decoder->Linear2CurveRed = NULL;
    }
    if (decoder->Linear2CurveGrn)
    {
        FreeAligned(decoder->allocator, decoder->Linear2CurveGrn);
        decoder->Linear2CurveGrn = NULL;
    }
    if (decoder->Linear2CurveBlu)
    {
        FreeAligned(decoder->allocator, decoder->Linear2CurveBlu);
        decoder->Linear2CurveBlu = NULL;
    }
    if (decoder->BYR4LinearRestore)
    {
        FreeAligned(decoder->allocator, decoder->BYR4LinearRestore);
        decoder->BYR4LinearRestore = NULL;
    }
    if (decoder->GammaContrastRed)
    {
        FreeAligned(decoder->allocator, decoder->GammaContrastRed);
        decoder->GammaContrastRed = NULL;
    }
    if (decoder->GammaContrastGrn)
    {
        FreeAligned(decoder->allocator, decoder->GammaContrastGrn);
        decoder->GammaContrastGrn = NULL;
    }
    if (decoder->GammaContrastBlu)
    {
        FreeAligned(decoder->allocator, decoder->GammaContrastBlu);
        decoder->GammaContrastBlu = NULL;
    }

    //3d LUT
    {
        if (decoder->LUTcache)
            Free(decoder->allocator, decoder->LUTcache);
        decoder->LUTcache = NULL;
        decoder->LUTcacheCRC = 0;
    }

    for (i = 0; i < 64; i++)
    {
        if (decoder->mdc[i])
            Free(decoder->allocator, decoder->mdc[i]);
        decoder->mdc[i] = NULL;
        decoder->mdc_size[i] = 0;
    }
#else // _ALLOCATOR
    if (decoder->RGBFilterBuffer16)
    {
        MEMORY_ALIGNED_FREE(decoder->RGBFilterBuffer16);
        decoder->RGBFilterBuffer16 = NULL;
    }
    if (decoder->RawBayer16)
    {
        MEMORY_ALIGNED_FREE(decoder->RawBayer16);
        decoder->RawBayer16 = NULL;
    }
    if (decoder->StereoBuffer)
    {
        MEMORY_ALIGNED_FREE(decoder->StereoBuffer);
        decoder->StereoBuffer = NULL;
        decoder->StereoBufferSize = 0;
    }
    if (decoder->RawCube)
    {
        MEMORY_ALIGNED_FREE(decoder->RawCube);
        decoder->RawCube = NULL;
    }
    if (decoder->Curve2Linear)
    {
        MEMORY_ALIGNED_FREE(decoder->Curve2Linear);
        decoder->Curve2Linear = NULL;
    }
    if (decoder->BYR4LinearRestore)
    {
        MEMORY_ALIGNED_FREE(decoder->BYR4LinearRestore);
        decoder->BYR4LinearRestore = NULL;
    }
    if (decoder->Linear2CurveRed)
    {
        MEMORY_ALIGNED_FREE(decoder->Linear2CurveRed);
        decoder->Linear2CurveRed = NULL;
    }
    if (decoder->Linear2CurveGrn)
    {
        MEMORY_ALIGNED_FREE(decoder->Linear2CurveGrn);
        decoder->Linear2CurveGrn = NULL;
    }
    if (decoder->Linear2CurveBlu)
    {
        MEMORY_ALIGNED_FREE(decoder->Linear2CurveBlu);
        decoder->Linear2CurveBlu = NULL;
    }
    if (decoder->GammaContrastRed)
    {
        MEMORY_ALIGNED_FREE(decoder->GammaContrastRed);
        decoder->GammaContrastRed = NULL;
    }
    if (decoder->GammaContrastGrn)
    {
        MEMORY_ALIGNED_FREE(decoder->GammaContrastGrn);
        decoder->GammaContrastGrn = NULL;
    }
    if (decoder->GammaContrastBlu)
    {
        MEMORY_ALIGNED_FREE(decoder->GammaContrastBlu);
        decoder->GammaContrastBlu = NULL;
    }

    //3d LUT
    {
        if (decoder->LUTcache)
            MEMORY_FREE(decoder->LUTcache);
        decoder->LUTcache = NULL;
        decoder->LUTcacheCRC = 0;
    }

    if (decoder->overrideData)
    {
        MEMORY_FREE(decoder->overrideData);
        decoder->overrideData = NULL;
        decoder->overrideSize = 0;
    }

    for (i = 0; i < 64; i++)
    {
        if (decoder->mdc[i])
            MEMORY_FREE(decoder->mdc[i]);
        decoder->mdc[i] = NULL;
        decoder->mdc_size[i] = 0;
    }
#endif // _ALLOCATOR

    decoder->initialized = 0;// cleared
}

void ExitDecoder(DECODER *decoder)
{
    // Let the caller keep the logfile open or choose to close it
    //if (logfile) fclose(logfile);

    // Free data allocated within the decoder
    ClearDecoder(decoder);
}

// Allocate the data structures for decoding a group
void AllocDecoderGroup(DECODER *decoder)
{
#if _ALLOCATOR
    ALLOCATOR *allocator = decoder->allocator;
#endif

    //CODEC_STATE *codec = &decoder->codec;
    //int num_channels = codec->num_channels;//DAN07022004
    int channel;

    assert(decoder->codec.num_channels <= TRANSFORM_MAX_CHANNELS); //DAN07022004

    for (channel = 0; channel < TRANSFORM_MAX_CHANNELS; channel++)//DAN07022004
    {
        TRANSFORM *transform = decoder->transform[channel];

        // Need to allocate a transform data structure?
        if (transform == NULL)
        {
#if _ALLOCATOR
            transform = (TRANSFORM *)Alloc(allocator, sizeof(TRANSFORM));
#else
            transform = (TRANSFORM *)MEMORY_ALLOC(sizeof(TRANSFORM));
#endif
            assert(transform != NULL);
            if (transform == NULL)
            {
                decoder->error = CODEC_ERROR_TRANSFORM_MEMORY;
                return;
            }
            memset(transform, 0, sizeof(TRANSFORM));
            decoder->transform[channel] = transform;

#if _TIMING
            alloc_transform_count++;
#endif
        }
    }
}

// Allocate the buffer used for intermediate results during decoding
bool AllocDecoderBuffer(DECODER *decoder, int width, int height, int format)
{
    int cpus;
    size_t size;
    size_t row_size;
    char *buffer;

#if 0
    // Allocate a buffer large enough for six rows of cache lines
    size = width * sizeof(PIXEL);
    size = ALIGN(size, _CACHE_LINE_SIZE);
    size = 2 * TRANSFORM_MAX_CHANNELS * size;
#else
    // Allocate a buffer large enough for nine rows of cache lines
    size = width * sizeof(PIXEL) * 4;
    size = ALIGN(size, _CACHE_LINE_SIZE);
    size = 3 * TRANSFORM_MAX_CHANNELS * size;
#endif

    switch (format)
    {
        case DECODED_FORMAT_V210:
        case DECODED_FORMAT_YU64:
            // Increase the buffer size for decoding to the V210 format
            row_size = 4 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 4 * 2 * row_size;
            break;

        case DECODED_FORMAT_YR16:
        case DECODED_FORMAT_CbYCrY_10bit_2_8:
        case DECODED_FORMAT_CbYCrY_16bit_2_14:
        case DECODED_FORMAT_CbYCrY_16bit_10_6:
            // Increase the buffer size for decoding to the YUV16 format
            row_size = 4 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 8 * 2 * row_size;
            break;

        case DECODED_FORMAT_RG48:
        case DECODED_FORMAT_WP13:
            // Increase the buffer size for decoding to the YUV16 format
            row_size = 6 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 12 * 2 * row_size;
            break;

        case DECODED_FORMAT_RG64:
            // Increase the buffer size for decoding to the YUV16 format
            row_size = 8 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 16 * 2 * row_size;
            break;

        case DECODED_FORMAT_BYR3:
            // Increase the buffer size for decoding to the YUV16 format
            row_size = 2 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 4 * 2 * row_size;
            break;

        case DECODED_FORMAT_BYR4:
            // Increase the buffer size for decoding to the YUV16 format
            row_size = 2 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 4 * 2 * row_size;
            break;

        case DECODED_FORMAT_B64A:
        case DECODED_FORMAT_W13A:
            // Increase the buffer size for decoding to the B64A format
            row_size = 8 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 16 * 2 * row_size;
            break;

        default:
            // Increase the buffer size for YUV to RGB conversion
            row_size = 3 * width * sizeof(PIXEL);
            row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
            size += 2 * 2 * row_size;
            break;
    }

    cpus = decoder->thread_cntrl.capabilities >> 16;
    if (cpus > 4)
        size *= 4;
    if (cpus > 16) //DAN20120803 -- 4444 clips
        size *= 2;

    // Has a buffer already been allocated?
    if (decoder->buffer != NULL)
    {
        // Is the buffer large enough?
        if (decoder->buffer_size < size)
        {
            // Free the previous buffer
#if _ALLOCATOR
            FreeAligned(decoder->allocator, decoder->buffer);
#else
            MEMORY_ALIGNED_FREE(decoder->buffer);
#endif
            decoder->buffer = NULL;
            decoder->buffer_size = 0;
        }
        else
        {
            return true;
        }
    }

    buffer = decoder->buffer;
    if (buffer == NULL)
    {
        // Allocate the decoding buffer
#if _ALLOCATOR
        buffer = (char *)AllocAligned(decoder->allocator, size, _CACHE_LINE_SIZE);
#else
        buffer = (char *)MEMORY_ALIGNED_ALLOC(size, _CACHE_LINE_SIZE);
#endif
        if (buffer == NULL)
        {
            return false;
        }
    }

    // Save the buffer and its size in the decoder
    decoder->buffer = buffer;
    decoder->buffer_size = size;

    // Initialize the scratch space descriptor
    InitScratchBuffer(&decoder->scratch, buffer, size);

    // allocate buffer for each debayer/color formating thread
    {
        int i;

        size = (width + 16) * 3 * 2 * 4 * 2 * 4; // sixteen lines

        if (height * 4 > width * 3) //square or tall images where running out of scratch space for zooms.
            size *= 1 + ((height + (width / 2)) / width);

        if (decoder->threads_buffer_size < size)
        {
            for (i = 0; i < _MAX_CPUS; i++)
            {
                if (decoder->threads_buffer[i])
                {
#if _ALLOCATOR
                    FreeAligned(decoder->allocator, decoder->threads_buffer[i]);
#else
                    MEMORY_ALIGNED_FREE(decoder->threads_buffer[i]);
#endif

                    decoder->threads_buffer[i] = NULL;
                }
            }
            decoder->threads_buffer_size = 0;
        }

        for (i = 0; i < cpus; i++)
        {
            if (decoder->threads_buffer[i] == NULL)
            {
#if _ALLOCATOR
                decoder->threads_buffer[i] = (char *)AllocAligned(decoder->allocator, size, _CACHE_LINE_SIZE);
#else
                decoder->threads_buffer[i] = (char *)MEMORY_ALIGNED_ALLOC(size, _CACHE_LINE_SIZE);
#endif

                if (decoder->threads_buffer[i] == NULL)
                {
                    return false;
                }
            }
        }

        decoder->threads_buffer_size = size;
    }

    // Eventually the scratch space descriptor will replace the buffer and buffer_size fields
    return true;
}

bool ResizeDecoderBuffer(DECODER *decoder, int width, int height, int format)
{
    // Check that the dimensions are valid
    assert(width > 0);
    assert(height > 0);

    // Just call the allocation routine
    return AllocDecoderBuffer(decoder, width, height, format);
}

void ClearTransformFlags(DECODER *decoder)
{
    TRANSFORM **transform_array = decoder->transform;
    int channel;

    for (channel = 0; channel < TRANSFORM_MAX_CHANNELS; channel++)
    {
        TRANSFORM *transform = transform_array[channel];
        int index;

        if (transform == NULL) break;

        for (index = 0; index < TRANSFORM_MAX_WAVELETS; index++)
        {
            IMAGE *wavelet = transform->wavelet[index];
            if (wavelet != NULL)
            {
                wavelet->band_valid_flags = 0;
                wavelet->band_started_flags = 0;
            }
        }
    }
}

// Initialize the tables for decoding the wavelet transforms
void InitWaveletDecoding(DECODER *decoder, int subband_wavelet_index[], int subband_band_index[], int num_subbands)
{
    size_t subband_table_size = num_subbands * sizeof(int);

    memset(decoder->subband_wavelet_index, 0, sizeof(decoder->subband_wavelet_index));
    memcpy(decoder->subband_wavelet_index, subband_wavelet_index, subband_table_size);

    memset(decoder->subband_band_index, 0, sizeof(decoder->subband_band_index));
    memcpy(decoder->subband_band_index, subband_band_index, subband_table_size);
}

#if 0
static bool IsValidFormat(int format)
{
    bool valid_format = true;

    //TODO: Change this routine into a switch statement

    if (format == COLOR_FORMAT_BYR5)
        return true; // can decode to BYR5
    if (format == COLOR_FORMAT_BYR4)
        return true; // can decode to BYR4
    if (format == COLOR_FORMAT_BYR3)
        return true; // can decode to BYR3
    if (format == COLOR_FORMAT_BYR2)
        return true; // can decode to BYR2
    if (format == COLOR_FORMAT_RG48)
        return true; // can decode to RGB48
    if (format == COLOR_FORMAT_RG64)
        return true; // can decode to RGBA64

    if (format == COLOR_FORMAT_B64A)
    {
        return true;	// Can decode to B64A
    }

    if (!(COLOR_FORMAT_UNKNOWN < format && format <= MAX_DECODED_COLOR_FORMAT))
    {
        valid_format = false;
    }

    return valid_format;
}
#endif

#if _INTERLACED_WORKER_THREADS
void StartInterlaceWorkerThreads(DECODER *decoder)
{
    int i;
    if (decoder->interlaced_worker.lock_init == 0)
    {
        // Create events for starting the worker threads
        for (i = 0; i < THREADS_IN_LAST_WAVELET; i++)
        {
            decoder->interlaced_worker.start_event[i] = CreateEvent(NULL, false, false, NULL);
        }

        // Create a semaphore to signal the worker threads to process rows
        decoder->interlaced_worker.row_semaphore = CreateSemaphore(NULL, 0, LONG_MAX, NULL);

        // Create an event for each worker thread to signal that it has finished
        for (i = 0; i < THREADS_IN_LAST_WAVELET; i++)
        {
            decoder->interlaced_worker.done_event[i] = CreateEvent(NULL, false, false, NULL);
        }

        // Create an event for forcing the worker threads to terminate
        decoder->interlaced_worker.stop_event = CreateEvent(NULL, true, false, NULL);

        // Zero the count of worker threads that are active
        decoder->interlaced_worker.thread_count = 0;

        // Initialize the lock for controlling access to the worker thread data
        InitializeCriticalSection(&decoder->interlaced_worker.lock);
        decoder->interlaced_worker.lock_init = 1;

        for (i = 0; i < THREADS_IN_LAST_WAVELET; i++)
        {
            decoder->interlaced_worker.id[i] = 0;
            decoder->interlaced_worker.handle[i] = CreateThread(NULL, 0, InterlacedWorkerThreadProc, decoder, 0, &decoder->interlaced_worker.id[i]);
            assert(decoder->interlaced_worker.handle[i] != NULL);
        }
    }
}
#endif

#if 0
int TestException(int x)
{
    static volatile int y1 = 100;
    volatile int x1 = x;
    return y1 / x1;
}
#endif

// Process device driver request to initialize the decoder
#if _ALLOCATOR
bool DecodeInit(ALLOCATOR *allocator, DECODER *decoder, int width, int height, int format, int resolution, FILE *logfile)
#else
bool DecodeInit(DECODER *decoder, int width, int height, int format, int resolution, FILE *logfile)
#endif
{
    CODESET codesets[CODEC_NUM_CODESETS];
    int i;
    int cpus;

    //int x = 0;

#if CODEC_NUM_CODESETS == 3
    memcpy(&codesets[0], &CURRENT_CODESET, sizeof(CODESET));
    memcpy(&codesets[1], &SECOND_CODESET, sizeof(CODESET));
    memcpy(&codesets[2], &THIRD_CODESET, sizeof(CODESET));
#elif CODEC_NUM_CODESETS == 2
    memcpy(&codesets[0], &CURRENT_CODESET, sizeof(CODESET));
    memcpy(&codesets[1], &SECOND_CODESET, sizeof(CODESET));
#else
    memcpy(&codesets[0], &CURRENT_CODESET, sizeof(CODESET));
#endif

    // Clear all decoder fields except the logfile and set the codebooks for decoding
    InitDecoder(decoder, logfile, &codesets[0]);

#if _ALLOCATOR
    decoder->allocator = allocator;
#endif

    if (decoder->thread_cntrl.capabilities == 0)
    {
        // Determine the processor capabilities
        SetDecoderCapabilities(decoder);
    }
    cpus = decoder->thread_cntrl.capabilities >> 16;
    assert(cpus > 0 && cpus <= _MAX_CPUS);

    // Decode to half resolution?
    if (resolution == DECODED_RESOLUTION_HALF)
    {
        // Reduce the frame size by half in each dimension
        width = width / 2;
        height = height / 2;
    }
    else if (resolution == DECODED_RESOLUTION_QUARTER)
    {
        // Reduce the frame size by one fourth in each dimension
        width = width / 4;
        height = height / 4;
    }

    // Initialize the codebooks
#if _ALLOCATOR
    if (!InitCodebooks(decoder->allocator, codesets))
    {
        //decoder->error = CODEC_ERROR_INIT_CODEBOOKS;
        // The subroutine has already set the error code
        return false;
    }
#else
    if (!InitCodebooks(codesets))
    {
        //decoder->error = CODEC_ERROR_INIT_CODEBOOKS;
        // The subroutine has already set the error code
        return false;
    }
#endif
    // Initize the FSM
    InitDecoderFSM(decoder, &codesets[0]);

    // Check the frame dimensions and format
    //assert(width > 0);
    //assert(height > 0);
    //	assert(IsValidFormat(format));


#if _THREADED_DECODER
    // Create a semaphore to signal the transform thread to begin processing
    // Initialize the transform queue

    decoder->transform_queue.started = 0;
    decoder->transform_queue.num_entries = 0;
    decoder->transform_queue.next_entry = 0;
    decoder->transform_queue.free_entry = 0;

    memset(decoder->transform_queue.queue, 0, sizeof(decoder->transform_queue.queue));
#endif

#if _INTERLACED_WORKER_THREADS && _DELAY_THREAD_START==0
    StartInterlaceWorkerThreads(decoder);
#endif

#if _THREADED
#if !_DELAY_THREAD_START  //start threads now if not _DELAY_THREAD_START
    if (cpus > 1)
    {
        int threads = cpus;
        if (threads > 4)
            threads = 4;

        CreateLock(&decoder->entropy_worker_new.lock);

        // Initialize the pool of transform worker threads
        ThreadPoolCreate(&decoder->entropy_worker_new.pool,
                         threads,
                         EntropyWorkerThreadProc,
                         decoder);
    }

    // Initialize the lock that controls access to the generic worker thread data
    CreateLock(&decoder->worker_thread.lock);
    // Initialize the pool of transform worker threads
    ThreadPoolCreate(&decoder->worker_thread.pool,
                     cpus,
                     WorkerThreadProc,
                     decoder);
#endif
#endif

    // Set the frame dimensions and format
    SetDecoderFormat(decoder, width, height, format, resolution);

    // Allocate the data structure for decoding the samples
    AllocDecoderGroup(decoder);

    // Note that this code assumes that the samples to decode are groups
    // as opposed to isolated frames which are not supported in this code

    // Allocate a buffer for storing intermediate results during decoding
    if (!AllocDecoderBuffer(decoder, width, height, format))
    {
        return false;
    }

    // Should check that the finite state machine tables were initialized
    assert(decoder->fsm[0].table.flags < 0);

    // Initialize the finite state machine for this decoder

    for (i = 0; i < CODEC_NUM_CODESETS; i++)
    {
        InitFSM(&decoder->fsm[i], codesets[i].fsm_table);

#if _COMPANDING
        // Scale the values in the finite state machine entries for companding
        ScaleFSM(&decoder->fsm[i].table);
#endif
    }

    // Indicate that the decoder has been initialized
    decoder->state = DECODER_STATE_INITIALIZED;

#if _TIMING
    // Initialize the global timers and counters
    InitTiming();
#endif

    //DAN20160203 Fix for a memory leak in InitCookbooks
    for (i = 0; i < CODEC_NUM_CODESETS; i++)
    {
#if _ALLOCATOR
        Free(allocator, codesets[i].codebook_runbook);
        codesets[i].codebook_runbook = NULL;
        Free(allocator, codesets[i].fastbook);
        codesets[i].fastbook = NULL;
        Free(allocator, codesets[i].valuebook);
        codesets[i].valuebook = NULL;
#else
        MEMORY_FREE(codesets[i].codebook_runbook);
        codesets[i].codebook_runbook = NULL;
        MEMORY_FREE(codesets[i].fastbook);
        codesets[i].fastbook = NULL;
        MEMORY_FREE(codesets[i].valuebook);
        codesets[i].valuebook = NULL;
#endif
    }

    // The decoder has been initialized successfully
    return true;
}


void DecodeEntropyInit(DECODER *decoder)
{
    int cpus = 1;
    if (decoder->thread_cntrl.capabilities == 0)
    {
        // Determine the processor capabilities
        SetDecoderCapabilities(decoder);
    }
    cpus = decoder->thread_cntrl.capabilities >> 16;
    if (cpus > (int)decoder->cfhddata.cpu_limit && decoder->cfhddata.cpu_limit)
    {
        cpus = decoder->cfhddata.cpu_limit;
        decoder->thread_cntrl.limit = cpus;
        decoder->thread_cntrl.set_thread_params = 1;
        decoder->thread_cntrl.capabilities &= 0xffff;
        decoder->thread_cntrl.capabilities |= cpus << 16;
    }
    assert(cpus > 0 && cpus <= _MAX_CPUS);

#if _THREADED
#if _DELAY_THREAD_START  //start threads now if not _DELAY_THREAD_START
    if (cpus > 1 && decoder->entropy_worker_new.pool.thread_count == 0)
    {
        int threads = cpus;
        if (threads > 4)
            threads = 4;

        CreateLock(&decoder->entropy_worker_new.lock);

        // Initialize the pool of transform worker threads
        ThreadPoolCreate(&decoder->entropy_worker_new.pool,
                         threads,
                         EntropyWorkerThreadProc,
                         decoder);
    }
#endif
#endif
}


TRANSFORM *AllocGroupTransform(GROUP *group, int channel)
{
#if _ALLOCATOR
    //TODO:ALLOC Change this routine to take an allocator as the first argument
    ALLOCATOR *allocator = NULL;
#endif

    TRANSFORM *transform;

    // Channel zero is a special case because it may mean
    // that the group header has not been decoded yet
    if (channel != 0)
    {
        // Make sure that the channel number is in range
        assert(0 <= channel && channel < group->header.num_channels);
        if (!(0 <= channel && channel < group->header.num_channels))
            return NULL;
    }

    transform = group->transform[channel];

    // Need to allocate a transform data structure?
    if (transform == NULL)
    {
#if _ALLOCATOR
        transform = (TRANSFORM *)Alloc(allocator, sizeof(TRANSFORM));
#else
        transform = (TRANSFORM *)MEMORY_ALLOC(sizeof(TRANSFORM));
#endif
        assert(transform != NULL);
        if (transform == NULL) return NULL;
        memset(transform, 0, sizeof(TRANSFORM));
        group->transform[channel] = transform;

#if _TIMING
        alloc_transform_count++;
#endif
    }

    return transform;
}

//extern FILE *logfile;

void EraseOutputBuffer(uint8_t *buffer, int width, int height, int32_t pitch, int format)
{
    size_t size = height * pitch;

    union
    {
        uint8_t byte[4];
        uint32_t word;
    } output;

    switch (format)
    {
        case DECODED_FORMAT_YUYV:
            output.byte[0] = COLOR_LUMA_BLACK;
            output.byte[1] = COLOR_CHROMA_ZERO;
            output.byte[2] = COLOR_LUMA_BLACK;
            output.byte[3] = COLOR_CHROMA_ZERO;
            break;

        default:
            //if (logfile) fprintf(logfile,"**Unknown format: %d\n", format);
            //assert(0);
            output.word = 0;
            break;
    }

    memset(buffer, output.word, size);
}


// Decode the coefficients in a subband
bool DecodeSampleSubband(DECODER *decoder, BITSTREAM *input, int subband);

// Decode the coefficients in a lowpass band
bool DecodeSampleLowPassBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet);

// Decode the coefficients in a highpass band
bool DecodeSampleHighPassBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int band, int threading);

// Decode an empty band
bool DecodeSampleEmptyBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int band);

bool DecodeBand16s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                   int band_index, int width, int height);

bool DecodeBand16sLossless(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                           int band_index, int width, int height);

// Decode a sample channel header
bool DecodeSampleChannelHeader(DECODER *decoder, BITSTREAM *input);

// Apply the inverse horizontal-temporal transform to reconstruct the output frame
void ReconstructSampleFrameToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch);

#if 0
// Reconstruct the frame to quarter resolution at full frame rate
void ReconstructQuarterFrame(DECODER *decoder, int num_channels,
                             uint8_t *frame1, uint8_t *frame2, int output_pitch,
                             FRAME_INFO *info, char *buffer, size_t buffer_size);
#else
// Reconstruct the frame to quarter resolution at full frame rate
void ReconstructQuarterFrame(DECODER *decoder, int num_channels,
                             int frame_index, uint8_t *output, int output_pitch,
                             FRAME_INFO *info, const SCRATCH *scratch, int precision);
#endif

// Copy the quarter resolution lowpass channels from the spatial transform
void CopyQuarterFrameToBuffer(TRANSFORM **transform_array, int num_channels,
                              uint8_t *output, int output_pitch,
                              FRAME_INFO *info, int precision);

// Convert the quarter resolution lowpass channels to the specified output format
void ConvertQuarterFrameToBuffer(DECODER *decoder, TRANSFORM **transform_array, int num_channels,
                                 uint8_t *output, int output_pitch,
                                 FRAME_INFO *info, int precision);

// Routines for converting the new encoded formats to the requested output format
CODEC_ERROR ReconstructSampleFrameRGB444ToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch);

CODEC_ERROR ReconstructSampleFrameRGBA4444ToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch);

CODEC_ERROR ReconstructSampleFrameYUVA4444ToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch);

// The first Bayer routine calls the other Bayer routines for the decoded resolution
CODEC_ERROR ReconstructSampleFrameBayerToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch);
CODEC_ERROR ReconstructSampleFrameDeBayerFullToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch);
CODEC_ERROR ReconstructSampleFrameBayerFullToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch);
CODEC_ERROR ReconstructSampleFrameBayerHalfToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch);
CODEC_ERROR ReconstructSampleFrameBayerQuarterToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch);

CODEC_ERROR UncompressedSampleFrameBayerToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch);
CODEC_ERROR UncompressedSampleFrameYUVToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch);
CODEC_ERROR UncompressedSampleFrameRGBToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch);

// New code for handling the original YUV 4:2:2 encoded format
CODEC_ERROR ReconstructSampleFrameYUV422ToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch);


// Return true if the rest of the channel does not have to be decoded
static bool CanSkipChannel(DECODER *decoder, int resolution)
{
    CODEC_STATE *codec = &decoder->codec;
    int channel = codec->channel;
    TRANSFORM *transform = decoder->transform[channel];
    int transform_type = transform->type;

    // Can the rest of the channel be skipped?
    if (transform_type == TRANSFORM_TYPE_FIELDPLUS)
    {
        switch (resolution)
        {
            case DECODED_RESOLUTION_HALF:
                if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
                    return ((codec->decoded_subband_flags & DECODED_SUBBAND_MASK_HALF) == DECODED_SUBBAND_MASK_HALF);
                break;

            case DECODED_RESOLUTION_QUARTER:
                if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
                    return ((codec->decoded_subband_flags & DECODED_SUBBAND_MASK_QUARTER) == DECODED_SUBBAND_MASK_QUARTER);
                break;

            case DECODED_RESOLUTION_LOWPASS_ONLY:
                return (codec->decoded_subband_flags & 1);
                break;

            default:
                if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
                {
                    if (decoder->frame.format == DECODED_FORMAT_YUYV || decoder->frame.format == DECODED_FORMAT_UYVY)
                    {
                        // If we are requesting a YUV decode we don't need the 4th channel
                        if (codec->channel == 3)
                        {
                            return true;
                        }
                    }
                }
                break;
        }
    }
    else
    {
        const uint32_t decoded_subband_mask_half = 0x7F;
        const uint32_t decoded_subband_mask_quarter = 0x0F;

        assert(transform_type == TRANSFORM_TYPE_SPATIAL);

        switch (resolution)
        {
            case DECODED_RESOLUTION_HALF:
                if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
                    return ((codec->decoded_subband_flags & decoded_subband_mask_half) == decoded_subband_mask_half);
                break;

            case DECODED_RESOLUTION_QUARTER:
                if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
                    return ((codec->decoded_subband_flags & decoded_subband_mask_quarter) == decoded_subband_mask_quarter);
                break;

            case DECODED_RESOLUTION_LOWPASS_ONLY:
                return (codec->decoded_subband_flags & 1);
                break;

            default:
                if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
                {
                    if (decoder->frame.format == DECODED_FORMAT_YUYV || decoder->frame.format == DECODED_FORMAT_UYVY)
                    {
                        // If we are requesting a YUV decode we don't need the 4th channel
                        if (codec->channel == 3)
                        {
                            return true;
                        }
                    }
                }
                break;
        }
    }

    // Cannot skip the rest of the channel
    return false;
}

#if 0
static bool CanSkipSubband(DECODER *decoder, int subband)
{
    // Bitmask indicates which subbands must be decoded for quarter resolution
    static uint32_t quarter_resolution_mask = 0x008F;

    // Convert the subband number into a bitmask (could use a lookup table)
    uint32_t subband_mask = SUBBAND_MASK(subband);

    // Select the resolution of the fully decoded frames
    int resolution = decoder->frame.resolution;

    switch (resolution)
    {
        case DECODED_RESOLUTION_QUARTER:
            //if (4 <= subband && subband <= 6)
            if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
            {
                if ((subband_mask & quarter_resolution_mask) == 0)
                {
                    return true;
                }
            }
            break;

        default:
            // Assume that the subband must be decoded
            break;
    }

    return false;
}
#endif

// Return true if the wavelet exists and all bands are valid
static bool AllBandsValid(IMAGE *wavelet)
{
    return (wavelet != NULL && BANDS_ALL_VALID(wavelet));
}

#if DEBUG
static bool AllTransformBandsValid(TRANSFORM *transform_array[], int num_channels, int frame_index)
{
    int channel;

    if (!(1 <= num_channels && num_channels <= TRANSFORM_MAX_CHANNELS))
    {
        assert(0);
        return false;
    }

    if (!(0 <= frame_index && frame_index < TRANSFORM_MAX_FRAMES))
    {
        assert(0);
        return false;
    }

    for (channel = 0; channel < num_channels; channel++)
    {
        IMAGE *wavelet = transform_array[channel]->wavelet[frame_index];
        if (!AllBandsValid(wavelet))
        {
            return false;
        }
    }

    // All wavelet bands in all channels are valid
    return true;
}

static bool AllLowpassBandsValid(TRANSFORM *transform_array[], int num_channels, int frame_index)
{
    int channel;

    if (!(0 < num_channels && num_channels <= TRANSFORM_MAX_CHANNELS))
    {
        return false;
    }

    if (!(0 <= frame_index && frame_index < TRANSFORM_MAX_FRAMES))
    {
        return false;
    }

    for (channel = 0; channel < num_channels; channel++)
    {
        IMAGE *wavelet = transform_array[channel]->wavelet[frame_index];
        if (!(wavelet != NULL && wavelet->band_valid_flags & BAND_VALID_MASK(0)))
        {
            return false;
        }
    }

    // All lowpass bands in all channels are valid
    return true;
}
#endif

static bool
ComputeFrameDimensionsFromFirstWavelet(int transform_type,
                                       int first_wavelet_width,
                                       int first_wavelet_height,
                                       int *frame_width_out,
                                       int *frame_height_out)
{
    int frame_width;
    int frame_height;

    int expansion = 8;

    switch (transform_type)
    {
        case TRANSFORM_TYPE_SPATIAL:
            frame_width = first_wavelet_width * expansion;
            frame_height = first_wavelet_height * expansion;
            break;

        case TRANSFORM_TYPE_FIELDPLUS:
            frame_width = first_wavelet_width * expansion;
            frame_height = first_wavelet_height * expansion;
            break;

        default:
            assert(0);
            return false;
    }

    // Return the frame dimensions
    *frame_width_out = frame_width;
    *frame_height_out = frame_height;

    return true;
}

// Decode the sample header to determine the type of sample and other parameters
bool ParseSampleHeader(BITSTREAM *input, SAMPLE_HEADER *header)
{
    TAGVALUE segment;
    int sample_type;
    int sample_size = 0;

    // Group index
    uint32_t channel_size[TRANSFORM_MAX_CHANNELS];

    // Number of channels in the group index
    int channel_count;

    // Values used for computing the frame width and height (if necessary)
    int transform_type = -1;
    int first_wavelet_width = 0;
    int first_wavelet_height = 0;
    int display_height = 0;
    int current_channel = 0;
    int currentVideoChannel = header->videoChannels;
    int find_lowpass_bands = header->find_lowpass_bands & 1;
    int find_uncompressed = header->find_lowpass_bands & 2 ? 1 : 0;
    int find_header_info_only = header->find_lowpass_bands & 4 ? 1 : 0;

    if (header == NULL)
    {
        return false;
    }
    if (currentVideoChannel == 0)
        currentVideoChannel = 1;

    // Clear the entire sample header to prevent early return from this routine
    memset(header, 0, sizeof(SAMPLE_HEADER));

    // Clear the error code
    header->error = CODEC_ERROR_OKAY;

    // Initialize the frame dimensions to unknown
    header->width = 0;
    header->height = 0;
    header->videoChannels = 1;

    // Initialize the original pixel format to unknown
    header->input_format = COLOR_FORMAT_UNKNOWN;

    // Initialize the encoded format to unknown
    header->encoded_format = ENCODED_FORMAT_UNKNOWN;

    // Clear the frame number in case it is not present in the sample
    header->frame_number = 0;

    // The video is not progressive if the sample flags are not present
    header->hdr_progressive = false;

#if _BITSTREAM_UNALIGNED
    // Record the alignment of the bitstream within the sample
    SetBitstreamAlignment(input, 0);
#endif

    sample_size = input->nWordsUsed;

    // Get the type of sample (should be the first tag value pair)
    segment = GetTagValue(input);
    assert(segment.tuple.tag == CODEC_TAG_SAMPLE);
    if (!IsValidSegment(input, segment, CODEC_TAG_SAMPLE))
    {
        header->error = CodecErrorBitstream(input);
        return false;
    }
    sample_type = segment.tuple.value;

    switch (sample_type)
    {
        case SAMPLE_TYPE_GROUP:		// Group of frames
            header->key_frame = true;
            header->difference_frame = false;
            header->droppable_frame = false;
            break;

        case SAMPLE_TYPE_FRAME:		// The second or later frame in a group
            header->key_frame = false;
            header->difference_frame = true;
            header->droppable_frame = true;
            break;

        case SAMPLE_TYPE_IFRAME:	// One frame in the group
            header->key_frame = true;
            header->difference_frame = false;
            header->droppable_frame = true;
            break;

        case SAMPLE_TYPE_SEQUENCE_HEADER:
            // Treat the video sequence header like a keyframe that can be dropped
            header->key_frame = true;
            header->difference_frame = false;
            header->droppable_frame = true;
            break;

        default:
            // Unknown type of sample
            header->error = CODEC_ERROR_SAMPLE_TYPE;
            return false;
            break;
    }

    // Continue parsing the sample header until all of the information has been found
    while (	(find_lowpass_bands == 1 && current_channel < 3) || //parse all
            (find_uncompressed == 1 && current_channel < 1) ||
            display_height == 0 ||
            header->width == 0 ||
            header->height == 0 ||
            header->input_format == COLOR_FORMAT_UNKNOWN ||
            header->frame_number == 0 ||
            (header->interlaced_flags == 0 && header->hdr_progressive == 0))
    {
        int chunksize = 0;
        // Get the next tag value pair from the bitstream
        segment = GetSegment(input);

        // Did the bitstream end before the last tag was found?
        if (input->error == BITSTREAM_ERROR_UNDERFLOW)
        {
            break;
        }

        // Did an error occur while reading the bitstream?
        if (input->error != BITSTREAM_ERROR_OKAY)
        {
            header->error = CodecErrorBitstream(input);
            return false;
        }

        // Is this an optional tag?
        if (segment.tuple.tag < 0)
        {
            segment.tuple.tag = NEG(segment.tuple.tag);
        }

        if (segment.tuple.tag & 0x2000)
        {
            chunksize = segment.tuple.value;
            chunksize &= 0xffff;
            chunksize += ((segment.tuple.tag & 0xff) << 16);
        }
        else if (segment.tuple.tag & 0x4000)
        {
            chunksize = segment.tuple.value;
            chunksize &= 0xffff;
        }
        //	else if(tag == CODEC_TAG_INDEX) // handled below
        //	{
        //		chunksize = value;
        //		chunksize &= 0xffff;
        //	}
        else
        {
            chunksize = 0;
        }

        if ((int)(segment.tuple.tag) <= ((int)CODEC_TAG_LAST_NON_SIZED) || segment.tuple.tag & 0x6000)
        {
            int skip = 1;

            if ((segment.tuple.tag & 0xff00) == 0x2200) //sample size
            {
                if (sample_size < chunksize * 4)
                    find_header_info_only = 1;

                skip = find_header_info_only;

                if (currentVideoChannel <= 1 && header->videoChannels == 2 && !find_header_info_only)
                {
                    BITSTREAM input2;
                    SAMPLE_HEADER header2;
                    BITWORD *eye2 = (BITWORD *)(input->lpCurrentWord + chunksize * 4);
                    int eye_offset = sample_size - input->nWordsUsed + chunksize * 4; //approx
                    int eye_sample_size =  input->nWordsUsed - eye_offset;

                    // Search for first sample of the next frame
                    while ((eye2[1] != (uint8_t)CODEC_TAG_SAMPLE || eye2[0] != 0 || eye2[2] != 0) && eye_sample_size > 0)
                    {
                        eye2 += 4;
                        chunksize ++;
                        eye_offset += 4;
                        eye_sample_size -= 4;
                    }

                    // Save the offset to the right stereo sample
                    header->left_sample_size = eye_offset;

                    {
                        InitBitstreamBuffer(&input2, eye2, eye_sample_size, BITSTREAM_ACCESS_READ);


                        memset(&header2, 0, sizeof(SAMPLE_HEADER));
                        header2.find_lowpass_bands = 1;

                        currentVideoChannel++;
                        header2.videoChannels = currentVideoChannel;

                        if (ParseSampleHeader(&input2, &header2))
                        {
                            int i;
                            for (i = 0; i < 4; i++)
                            {
                                if (header2.thumbnail_channel_offsets[i])
                                    header->thumbnail_channel_offsets_2nd_Eye[i] = eye_offset + header2.thumbnail_channel_offsets[i];
                            }
                        }
                    }
                }
            }
            if ((segment.tuple.tag & 0xff00) == 0x2300) //uncompressed sample size
            {
                header->hdr_uncompressed = 1;
                skip = 1;
                if (find_lowpass_bands != 1)
                    break;
            }
            if ((segment.tuple.tag & 0xff00) == 0x2100) //level
            {
                if (find_lowpass_bands == 1)
                {
                    skip = 0;
                }
                else
                {
                    skip = 1; // no header data after the fix level
                    break;
                }
            }


            if (chunksize)
            {
                if (skip)
                {
                    input->lpCurrentWord += chunksize * 4;
                    input->nWordsUsed -= chunksize * 4;
                }
            }
            else
            {
                switch (segment.tuple.tag)
                {
                    case CODEC_TAG_VERSION:			// Version number of the encoder used in each GOP.
                        header->encoder_version =	(((segment.tuple.value >> 12) & 0xf) << 16) |
                                                    (((segment.tuple.value >> 8) & 0xf) << 8) |
                                                    ((segment.tuple.value) & 0xff);
                        break;
                    case CODEC_TAG_INDEX:
                        // Get the number of channels in the index to skip
                        channel_count = segment.tuple.value;
                        DecodeGroupIndex(input, (uint32_t *)&channel_size[0], channel_count);
                        break;

                    case CODEC_TAG_FRAME_WIDTH:
                        // Record the frame width in the sample header
                        header->width = segment.tuple.value;
                        break;

                    case CODEC_TAG_FRAME_HEIGHT:
                        // Record the frame height in the sample header
                        header->height = segment.tuple.value;
                        break;

                    case CODEC_TAG_FRAME_DISPLAY_HEIGHT:
                        display_height = segment.tuple.value;
                        break;

                    case CODEC_TAG_LOWPASS_WIDTH:
                        // Save the width of the smallest wavelet for computing the frame dimensions
                        first_wavelet_width = segment.tuple.value;
                        break;

                    case CODEC_TAG_LOWPASS_HEIGHT:
                        // Save the height of the smallest wavelet for computing the frame dimensions
                        first_wavelet_height = segment.tuple.value;
                        break;

                    case CODEC_TAG_TRANSFORM_TYPE:
                        // Save the type of transform for computing the frame dimensions (if necessary)
                        transform_type = segment.tuple.value;
                        break;

                    case CODEC_TAG_INPUT_FORMAT:
                        // Record the original format of the encoded frames
                        header->input_format = (COLOR_FORMAT)segment.tuple.value;
                        break;

                    case CODEC_TAG_ENCODED_FORMAT:
                    case CODEC_TAG_OLD_ENCODED_FORMAT:
                        // Record the encoded format (internal representation)
                        header->encoded_format = (ENCODED_FORMAT)segment.tuple.value;
                        if (header->encoded_format == ENCODED_FORMAT_RGBA_4444 && channel_count == 3)
                            header->encoded_format = ENCODED_FORMAT_RGB_444;
                        break;

                    case CODEC_TAG_FRAME_NUMBER:
                        // Record the frame number for debugging
                        header->frame_number = segment.tuple.value;
                        break;

                    case CODEC_TAG_INTERLACED_FLAGS:
                        // Record the flags that indicate the field type
                        header->interlaced_flags = segment.tuple.value;
                        break;

                    case CODEC_TAG_SAMPLE_FLAGS:
                        // The sample flags specify progressive versus interlaced decoding
                        header->hdr_progressive = !!(segment.tuple.value & SAMPLE_FLAGS_PROGRESSIVE);
                        if (header->hdr_progressive)
                        {
                            // Clear the interlaced flags
                            header->interlaced_flags = 0;
                        }
                        break;

                    case CODEC_TAG_LOWPASS_SUBBAND:
                        if (segment.tuple.value == 0) // low pass band
                        {
                            int count = 8;
                            uint32_t *lptr = (uint32_t *)input->lpCurrentWord;
                            do
                            {
                                uint32_t longword = SwapInt32(lptr[count]);
                                unsigned short t, v;
                                t = (longword >> 16) & 0xffff;
                                v = (longword) & 0xffff;
                                if (t == CODEC_TAG_MARKER && IsLowPassBandMarker(v) && current_channel < 4)
                                {
                                    header->thumbnail_channel_offsets[current_channel] = (sample_size - input->nWordsUsed) + count * 4 + 4;
                                    break;
                                }

                                count++;
                            } while (count < 32);

                            current_channel++;
                        }
                        break;

                    case CODEC_TAG_ENCODED_CHANNELS:
                        if (header->videoChannels == 1)
                        {
                            header->videoChannels = segment.tuple.value;
                            if (header->videoChannels < 1)
                                header->videoChannels = 1;
                        }
                        break;


                    case CODEC_TAG_QUALITY_L:		//
                        header->encode_quality &= 0xffff0000;
                        header->encode_quality |= segment.tuple.value;
                        break;

                    case CODEC_TAG_QUALITY_H:		//
                        header->encode_quality &= 0xffff;
                        header->encode_quality |= segment.tuple.value << 16;
                        break;

                }

                // Have the encoded frame dimensions been computed?
                if (header->width == 0 || header->height == 0)
                {
                    // Found the first wavelet in the bitstream?
                    if (transform_type >= 0 && first_wavelet_width > 0 && first_wavelet_height > 0)
                    {
                        // The group header did not contain tags for the frame dimensions
                        // prior to the release of support for RGB 4:4:4, so must attempt to
                        // compute the frame dimensions from the dimensions of the lowpass band.
                        int frame_width = 0;
                        int frame_height = 0;

                        // Use the dimensions of the first wavelet to compute the frame width and height
                        if (!ComputeFrameDimensionsFromFirstWavelet(transform_type,
                                first_wavelet_width,
                                first_wavelet_height,
                                &frame_width,
                                &frame_height))
                        {

                            // Could not compute the frame dimensions
                            header->error = CODEC_ERROR_FRAME_DIMENSIONS;
                            return false;
                        }

                        // Save the frame dimensions in the sample header
                        header->width = frame_width;
                        header->height = frame_height;

                        // No more header information after finding the lowpass band
                        break;
                    }
                }

                if (find_lowpass_bands != 1 && find_uncompressed != 1)
                {
                    // No more header information after the first encoded band
                    if (segment.tuple.tag == CODEC_TAG_BAND_NUMBER)
                    {
                        // Stop looking for header information
                        break;
                    }

                    // No more header information after the frame index
                    if (segment.tuple.tag == CODEC_TAG_FRAME_INDEX)
                    {
                        // Stop looking for header information
                        break;
                    }

                    // No more header information after the lowpass band header
                    if (segment.tuple.tag == CODEC_TAG_PIXEL_DEPTH)
                    {
                        // Stop looking for header information
                        break;
                    }
                }
            }
        }
    }

    if (header->width == 0 || header->height == 0)
    {
        assert(0);
    }

    // Fill in the encoded format if it was not present in the header
    if (header->encoded_format == ENCODED_FORMAT_UNKNOWN)
    {
        header->encoded_format = GetEncodedFormat(header->input_format, header->encode_quality, channel_count);
    }

    if (display_height > 0)
    {
        header->height = display_height;
    }

    if (header->encoded_format == ENCODED_FORMAT_BAYER)
    {
        header->width *= 2;
        header->height *= 2;

        if (display_height == 0)
        {
            if (header->height == 1088)
                header->height = 1080;
        }
    }

    // Return true if the header was parsed completely and correctly
    return (header->width > 0 &&
            header->height > 0 &&
            ((sample_type == SAMPLE_TYPE_FRAME) ||
             (header->input_format != COLOR_FORMAT_UNKNOWN &&
              header->encoded_format != ENCODED_FORMAT_UNKNOWN)));

    // It is not an error if the frame number was not found in the sample header
}

bool DumpSampleHeader(BITSTREAM *input, FILE *logfile)
{
    TAGVALUE segment;

    int lowpass_width = 0;
    int lowpass_height = 0;

    // Parse the sample header until the lowpass band is found
    while (lowpass_width == 0 && lowpass_height == 0)
    {
        // Get the next tag value pair from the bitstream
        segment = GetSegment(input);

        // Did an error occur while reading the bitstream?
        if (input->error != BITSTREAM_ERROR_OKAY)
        {
            return false;
        }

        // Is this an optional tag?
        if (segment.tuple.tag < 0)
        {
            segment.tuple.tag = NEG(segment.tuple.tag);
        }

        // Check that the tag is valid
        assert(CODEC_TAG_ZERO < segment.tuple.tag && segment.tuple.tag <= CODEC_TAG_LAST_NON_SIZED);

        switch (segment.tuple.tag)
        {
            case CODEC_TAG_SAMPLE:
                fprintf(logfile, "Sample type: %d\n", segment.tuple.value);
                break;

            case CODEC_TAG_FRAME_WIDTH:
                fprintf(logfile, "Frame width: %d\n", segment.tuple.value);
                break;

            case CODEC_TAG_FRAME_HEIGHT:
                fprintf(logfile, "Frame height: %d\n", segment.tuple.value);
                break;

            case CODEC_TAG_LOWPASS_WIDTH:
                lowpass_width = segment.tuple.value;
                fprintf(logfile, "Lowpass width: %d\n", lowpass_width);
                break;

            case CODEC_TAG_LOWPASS_HEIGHT:
                lowpass_height = segment.tuple.value;
                fprintf(logfile, "Lowpass height: %d\n", lowpass_height);
                break;

            case CODEC_TAG_TRANSFORM_TYPE:
                fprintf(logfile, "Transform type: %d\n", segment.tuple.value);
                break;

            case CODEC_TAG_INPUT_FORMAT:
                fprintf(logfile, "Input format: %d\n", segment.tuple.value);
                break;

            case CODEC_TAG_ENCODED_FORMAT:
            case CODEC_TAG_OLD_ENCODED_FORMAT:
                fprintf(logfile, "Encoded format: %d\n", segment.tuple.value);
                break;

            case CODEC_TAG_FRAME_NUMBER:
                fprintf(logfile, "Frame number: %d\n", segment.tuple.value);
                break;
        }
    }

    return true;
}

int SkipVideoChannel(DECODER *decoder, BITSTREAM *input, int skip_to_channel) // 3D work
{
    TAGWORD tag, value = 1;
    unsigned char *pos = NULL;
    int readsize =  input->nWordsUsed;
    if (readsize > 4096) // only need to scan the first few tuplets
    {
        readsize = 4096;
    }
    else
    {
        //Tiny therefore P-frame, nothing to be read so:
        value = decoder->real_channels; // return the last value.
        return value;
    }


    pos = GetTupletAddr(input->lpCurrentBuffer, readsize, CODEC_TAG_ENCODED_CHANNELS, &value);

    if (pos && value > 1 && skip_to_channel > 1)
    {
        int chunksize = 0;
        intptr_t offset;
        int count = 0;

        do
        {
            tag = *pos++ << 8;
            tag |= *pos++;
            value = *pos++ << 8;
            value |= *pos++;

            if (tag < 0)
            {
                tag = NEG(tag);
            }
        } while ((tag & 0xff00) != CODEC_TAG_SAMPLE_SIZE && count++ < 10);

        if ((tag & 0xff00) == CODEC_TAG_SAMPLE_SIZE)
        {
            chunksize = value;
            chunksize &= 0xffff;
            chunksize += ((tag & 0xff) << 16);

            offset = ((intptr_t)pos - (intptr_t)input->lpCurrentWord) + chunksize * 4;

            input->lpCurrentWord += offset;
            input->nWordsUsed -= (int)offset;

            {
                uint8_t *tag = (uint8_t *)input->lpCurrentWord;

                // Search for first sample of the next frame
                while ((tag[1] != (uint8_t)CODEC_TAG_SAMPLE || tag[0] != 0 || tag[2] != 0) && input->nWordsUsed > 0)
                {
                    input->lpCurrentWord += 4;
                    input->nWordsUsed -= 4;
                    tag += 4;
                }

            }
        }
    }

    //if(value == 0) value = 1; // old non-stereo file
    return value;
}


#define SUBPIXEL	64


static short gains[SUBPIXEL + 1][4] =
{
    {0 * 128, 0 * 128, 0x7fff, 0 * 128},
    {0 * 128, 2 * 128, 0x7fff, -2 * 128},
    {0 * 128, 5 * 128, 255 * 128, -4 * 128},
    {0 * 128, 8 * 128, 254 * 128, -6 * 128},
    {0 * 128, 11 * 128, 253 * 128, -8 * 128},
    {0 * 128, 14 * 128, 252 * 128, -10 * 128},
    {0 * 128, 18 * 128, 250 * 128, -12 * 128},
    {0 * 128, 21 * 128, 248 * 128, -13 * 128},
    {-1 * 128, 25 * 128, 247 * 128, -15 * 128},
    {-1 * 128, 29 * 128, 244 * 128, -16 * 128},
    {-1 * 128, 33 * 128, 241 * 128, -17 * 128},
    {-2 * 128, 37 * 128, 239 * 128, -18 * 128},
    {-2 * 128, 41 * 128, 236 * 128, -19 * 128},
    {-3 * 128, 46 * 128, 233 * 128, -20 * 128},
    {-3 * 128, 50 * 128, 229 * 128, -20 * 128},
    {-4 * 128, 55 * 128, 226 * 128, -21 * 128},
    {-4 * 128, 60 * 128, 221 * 128, -21 * 128},
    {-5 * 128, 65 * 128, 217 * 128, -21 * 128},
    {-5 * 128, 70 * 128, 213 * 128, -22 * 128},
    {-6 * 128, 75 * 128, 209 * 128, -22 * 128},
    {-7 * 128, 80 * 128, 205 * 128, -22 * 128},
    {-7 * 128, 85 * 128, 199 * 128, -21 * 128},
    {-8 * 128, 91 * 128, 194 * 128, -21 * 128},
    {-9 * 128, 96 * 128, 190 * 128, -21 * 128},
    {-10 * 128, 102 * 128, 185 * 128, -21 * 128},
    {-10 * 128, 107 * 128, 179 * 128, -20 * 128},
    {-11 * 128, 113 * 128, 174 * 128, -20 * 128},
    {-12 * 128, 118 * 128, 169 * 128, -19 * 128},
    {-13 * 128, 124 * 128, 164 * 128, -19 * 128},
    {-14 * 128, 129 * 128, 159 * 128, -18 * 128},
    {-14 * 128, 135 * 128, 152 * 128, -17 * 128},
    {-15 * 128, 141 * 128, 147 * 128, -17 * 128},
    {-16 * 128, 144 * 128, 144 * 128, -16 * 128},
    {-17 * 128, 147 * 128, 141 * 128, -15 * 128},
    {-17 * 128, 152 * 128, 135 * 128, -14 * 128},
    {-18 * 128, 159 * 128, 129 * 128, -14 * 128},
    {-19 * 128, 164 * 128, 124 * 128, -13 * 128},
    {-19 * 128, 169 * 128, 118 * 128, -12 * 128},
    {-20 * 128, 174 * 128, 113 * 128, -11 * 128},
    {-20 * 128, 179 * 128, 107 * 128, -10 * 128},
    {-21 * 128, 185 * 128, 102 * 128, -10 * 128},
    {-21 * 128, 190 * 128, 96 * 128, -9 * 128},
    {-21 * 128, 194 * 128, 91 * 128, -8 * 128},
    {-21 * 128, 199 * 128, 85 * 128, -7 * 128},
    {-22 * 128, 205 * 128, 80 * 128, -7 * 128},
    {-22 * 128, 209 * 128, 75 * 128, -6 * 128},
    {-22 * 128, 213 * 128, 70 * 128, -5 * 128},
    {-21 * 128, 217 * 128, 65 * 128, -5 * 128},
    {-21 * 128, 221 * 128, 60 * 128, -4 * 128},
    {-21 * 128, 226 * 128, 55 * 128, -4 * 128},
    {-20 * 128, 229 * 128, 50 * 128, -3 * 128},
    {-20 * 128, 233 * 128, 46 * 128, -3 * 128},
    {-19 * 128, 236 * 128, 41 * 128, -2 * 128},
    {-18 * 128, 239 * 128, 37 * 128, -2 * 128},
    {-17 * 128, 241 * 128, 33 * 128, -1 * 128},
    {-16 * 128, 244 * 128, 29 * 128, -1 * 128},
    {-15 * 128, 247 * 128, 25 * 128, -1 * 128},
    {-13 * 128, 248 * 128, 21 * 128, 0 * 128},
    {-12 * 128, 250 * 128, 18 * 128, 0 * 128},
    {-10 * 128, 252 * 128, 14 * 128, 0 * 128},
    {-8 * 128, 253 * 128, 11 * 128, 0 * 128},
    {-6 * 128, 254 * 128, 8 * 128, 0 * 128},
    {-4 * 128, 255 * 128, 5 * 128, 0 * 128},
    {-2 * 128, 0x7fff, 2 * 128, 0 * 128},
    {0 * 128, 0 * 128, 0x7fff, 0 * 128}
};


static int lanczos[256] =
{
    0,
    -2,
    -8,
    -18,
    -33,
    -53,
    -77,
    -106,
    -141,
    -179,
    -223,
    -272,
    -325,
    -384,
    -447,
    -514,
    -586,
    -662,
    -742,
    -826,
    -913,
    -1004,
    -1097,
    -1193,
    -1290,
    -1389,
    -1490,
    -1591,
    -1692,
    -1792,
    -1892,
    -1990,
    -2086,
    -2179,
    -2269,
    -2355,
    -2436,
    -2511,
    -2580,
    -2643,
    -2697,
    -2744,
    -2781,
    -2809,
    -2826,
    -2832,
    -2826,
    -2808,
    -2776,
    -2730,
    -2670,
    -2594,
    -2503,
    -2395,
    -2271,
    -2129,
    -1969,
    -1790,
    -1593,
    -1377,
    -1141,
    -886,
    -611,
    -315,
    0,
    336,
    692,
    1069,
    1466,
    1884,
    2321,
    2778,
    3255,
    3750,
    4265,
    4797,
    5347,
    5914,
    6498,
    7097,
    7711,
    8340,
    8982,
    9636,
    10301,
    10977,
    11663,
    12357,
    13058,
    13765,
    14477,
    15192,
    15910,
    16630,
    17349,
    18066,
    18781,
    18871,
    19580,
    20285,
    20986,
    21678,
    22361,
    23035,
    23697,
    24348,
    24983,
    25604,
    26206,
    26790,
    27354,
    27898,
    28419,
    28915,
    29387,
    29832,
    30249,
    30638,
    30997,
    31326,
    31623,
    31886,
    32117,
    32314,
    32476,
    32603,
    32695,
    32749,
    32767,	//was 32768, issue for SSE2
    32749,
    32695,
    32603,
    32476,
    32314,
    32117,
    31886,
    31623,
    31326,
    30997,
    30638,
    30249,
    29832,
    29387,
    28915,
    28419,
    27898,
    27354,
    26790,
    26206,
    25604,
    24983,
    24348,
    23697,
    23035,
    22361,
    21678,
    20986,
    20285,
    19580,
    18871,
    18159,
    18066,
    17349,
    16630,
    15910,
    15192,
    14477,
    13765,
    13058,
    12357,
    11663,
    10977,
    10301,
    9636,
    8982,
    8340,
    7711,
    7097,
    6498,
    5914,
    5347,
    4797,
    4265,
    3750,
    3255,
    2778,
    2321,
    1884,
    1466,
    1069,
    692,
    336,
    0,
    -315,
    -611,
    -886,
    -1141,
    -1377,
    -1593,
    -1790,
    -1969,
    -2129,
    -2271,
    -2395,
    -2503,
    -2594,
    -2670,
    -2730,
    -2776,
    -2808,
    -2826,
    -2832,
    -2826,
    -2809,
    -2781,
    -2744,
    -2697,
    -2643,
    -2580,
    -2511,
    -2436,
    -2355,
    -2269,
    -2179,
    -2086,
    -1990,
    -1892,
    -1792,
    -1692,
    -1591,
    -1490,
    -1389,
    -1290,
    -1193,
    -1097,
    -1004,
    -913,
    -826,
    -742,
    -662,
    -586,
    -514,
    -447,
    -384,
    -325,
    -272,
    -223,
    -179,
    -141,
    -106,
    -77,
    -53,
    -33,
    -18,
    -8,
    -2,
};


void RGB48VerticalShiftZoom(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer,
                            int widthbytes, int height, int pitch, float offset,
                            float zoom)
{
    float yposf, ystepf;
    int x;
    //int endofSSEline = 0;
    unsigned short *scanline[4];
    //int spitch = pitch/2;
    int neg = 0, step;

    __m128i lA, lB, lC, lD, gA, gB, gC, gD, o128, t1;
    __m128i *lineA, *lineB, *lineC, *lineD, *outline128;

    offset = -offset;

    yposf = height * offset;
    yposf = (float)height * (0.5f - 1.0f / (2.0f * zoom) - offset);
    ystepf = 1.0f / zoom;

    if (yposf < 0.0)
        neg = 1;

    if (pitch < 0)
        yposf -= ystepf;

    /*	yposi = floor(yposf);

    	remainf = yposf - (float)yposi;
    	tablepos = (remainf*(float)SUBPIXEL);

    	yposi = abs(yposi);

    	if(yposi==0 && tablepos == 0)
    		return; // no move required
    */
    // -3 , 0 best small notch at zero?
    //

    switch (decoder->StereoBufferFormat)
    {
        case DECODED_FORMAT_RGB32:
        case DECODED_FORMAT_RGB24:
        case DECODED_FORMAT_YUYV:
            step = 16;
            break;
        case DECODED_FORMAT_W13A:
        case DECODED_FORMAT_RG64:
        case DECODED_FORMAT_WP13:
        case DECODED_FORMAT_RG48:
        default:
            step = 32;
            break;
    }

    {
        static char zeroline[1024] = {0};
        int y, yoffset = ((int)(yposf - 2.0)), yend = ((int)(yposf + 2.0 + ystepf * height));
        unsigned char *src = (unsigned char *)RGB48;
        unsigned char *dst = (unsigned char *)RGB48;
        unsigned char *ptr = (unsigned char *)buffer;

        if (yoffset < 0) yoffset = 0;
        if (yend > height) yend = height;

        src += pitch * yoffset;

        for (y = yoffset; y < yend; y++)
        {
            memcpy(ptr, src, widthbytes);

            ptr += widthbytes;
            src += pitch;
        }

        ptr = (unsigned char *)buffer;
        for (y = 0; y < height; y++)
        {
            int i, t, yp = ((int)yposf);
            int rmdr = 63 - ((int)(yposf * 64.0) & 63);
            int gains[4];

            yp -= 1; // use -2 cause a image down shift //DAN20100225
            t = 0;
            for (i = 0; i < 4; i++)
            {
                if (yp < 0 || yp >= height) // skip 0 line as the top line was zagged
                {
                    t += gains[i] = lanczos[rmdr];
                    scanline[i] = (unsigned short *)zeroline;
                }
                else
                {
                    t += gains[i] = lanczos[rmdr];
                    scanline[i] = (unsigned short *)&ptr[widthbytes * (yp - yoffset)];
                }

                yp++;
                rmdr += 64;
            }

            if (t)
            {
                __m128i half;

                gA = _mm_set1_epi16(gains[0]);
                gB = _mm_set1_epi16(gains[1]);
                gC = _mm_set1_epi16(gains[2]);
                gD = _mm_set1_epi16(gains[3]);

                outline128 = (__m128i *)dst;

                lineA = (__m128i *)scanline[0];
                lineB = (__m128i *)scanline[1];
                lineC = (__m128i *)scanline[2];
                lineD = (__m128i *)scanline[3];

                switch (decoder->StereoBufferFormat)
                {
                    case DECODED_FORMAT_W13A:
                    case DECODED_FORMAT_WP13:
                        for (x = 0; x < widthbytes; x += step)
                        {
                            lA =  _mm_loadu_si128(lineA++);
                            lB =  _mm_loadu_si128(lineB++);
                            lC =  _mm_loadu_si128(lineC++);
                            lD =  _mm_loadu_si128(lineD++);

                            o128 = _mm_mulhi_epi16(lA, gA);

                            t1 = _mm_mulhi_epi16(lB, gB);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lC, gC);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lD, gD);
                            o128 = _mm_adds_epi16(o128, t1);


                            // upper limit to 32767
                            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                            o128 = _mm_slli_epi16(o128, 1);
                            _mm_storeu_si128(outline128++, o128);

                            lA =  _mm_loadu_si128(lineA++);
                            lB =  _mm_loadu_si128(lineB++);
                            lC =  _mm_loadu_si128(lineC++);
                            lD =  _mm_loadu_si128(lineD++);


                            o128 = _mm_mulhi_epi16(lA, gA);

                            t1 = _mm_mulhi_epi16(lB, gB);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lC, gC);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lD, gD);
                            o128 = _mm_adds_epi16(o128, t1);


                            // upper limit to 32767
                            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                            o128 = _mm_slli_epi16(o128, 1);

                            _mm_storeu_si128(outline128++, o128);
                        }
                        break;


                    case DECODED_FORMAT_RG64:
                    case DECODED_FORMAT_RG48:
                        for (x = 0; x < widthbytes; x += step)
                        {
                            lA =  _mm_loadu_si128(lineA++);
                            lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                            lB =  _mm_loadu_si128(lineB++);
                            lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                            lC =  _mm_loadu_si128(lineC++);
                            lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                            lD =  _mm_loadu_si128(lineD++);
                            lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                            o128 = _mm_mulhi_epi16(lA, gA);

                            t1 = _mm_mulhi_epi16(lB, gB);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lC, gC);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lD, gD);
                            o128 = _mm_adds_epi16(o128, t1);


                            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_slli_epi16(o128, 4);
                            _mm_storeu_si128(outline128++, o128);

                            lA =  _mm_loadu_si128(lineA++);
                            lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                            lB =  _mm_loadu_si128(lineB++);
                            lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                            lC =  _mm_loadu_si128(lineC++);
                            lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                            lD =  _mm_loadu_si128(lineD++);
                            lD = _mm_srli_epi16(lD, 3); //13-bit unsigned


                            o128 = _mm_mulhi_epi16(lA, gA);

                            t1 = _mm_mulhi_epi16(lB, gB);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lC, gC);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lD, gD);
                            o128 = _mm_adds_epi16(o128, t1);

                            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_slli_epi16(o128, 4);
                            _mm_storeu_si128(outline128++, o128);
                        }
                        break;
                    case DECODED_FORMAT_RGB32:
                    case DECODED_FORMAT_RGB24:
                    case DECODED_FORMAT_YUYV:
                        for (x = 0; x < widthbytes; x += step)
                        {

                            lA =  _mm_loadu_si128(lineA);
                            lA = _mm_unpackhi_epi8 (_mm_setzero_si128(), lA);
                            lB =  _mm_loadu_si128(lineB);
                            lB = _mm_unpackhi_epi8 (_mm_setzero_si128(), lB);
                            lC =  _mm_loadu_si128(lineC);
                            lC = _mm_unpackhi_epi8 (_mm_setzero_si128(), lC);
                            lD =  _mm_loadu_si128(lineD);
                            lD = _mm_unpackhi_epi8 (_mm_setzero_si128(), lD);

                            lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                            lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                            lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                            lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                            o128 = _mm_mulhi_epi16(lA, gA);

                            t1 = _mm_mulhi_epi16(lB, gB);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lC, gC);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lD, gD);
                            o128 = _mm_adds_epi16(o128, t1);


                            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_slli_epi16(o128, 4);
                            half = o128;

                            lA =  _mm_loadu_si128(lineA++);
                            lA = _mm_unpacklo_epi8 (_mm_setzero_si128(), lA);
                            lB =  _mm_loadu_si128(lineB++);
                            lB = _mm_unpacklo_epi8 (_mm_setzero_si128(), lB);
                            lC =  _mm_loadu_si128(lineC++);
                            lC = _mm_unpacklo_epi8 (_mm_setzero_si128(), lC);
                            lD =  _mm_loadu_si128(lineD++);
                            lD = _mm_unpacklo_epi8 (_mm_setzero_si128(), lD);

                            lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                            lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                            lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                            lD = _mm_srli_epi16(lD, 3); //13-bit unsigned


                            o128 = _mm_mulhi_epi16(lA, gA);

                            t1 = _mm_mulhi_epi16(lB, gB);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lC, gC);
                            o128 = _mm_adds_epi16(o128, t1);

                            t1 = _mm_mulhi_epi16(lD, gD);
                            o128 = _mm_adds_epi16(o128, t1);

                            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                            o128 = _mm_slli_epi16(o128, 4);

                            half = _mm_srli_epi16(half, 8);
                            o128 = _mm_srli_epi16(o128, 8);
                            o128 = _mm_packus_epi16(o128, half);
                            _mm_storeu_si128(outline128++, o128);
                        }
                        break;
                }
            }
            else
            {
                if (decoder->StereoBufferFormat == DECODED_FORMAT_YUYV)
                {
                    memset(dst, 0x10801080, widthbytes);
                }
                else
                {
                    memset(dst, 0, widthbytes);
                }
            }

            yposf += ystepf;
            dst += pitch;
        }
        /*ptr = (unsigned char *)buffer;
        for(y=0;y<height; y++)
        {
        	int r,g,b,yp = ((int)yposf);

        	yposf += ystepf;

        	if(yp<0 || yp>= height)
        	{
        		memset(dst, 0, widthbytes);
        	}
        	else
        	{
        		memcpy(dst, &ptr[widthbytes*yp], widthbytes);
        	}
        	dst += pitch;
        }*/
    }
}



void RGB48VerticalShiftZoomFine(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer,
                                int widthbytes, int height, int pitch, float offset,
                                float zoom, int xx)
{
    float yposf, ystepf;
    //int endofSSEline = 0;
    unsigned short *scanline[4];
    //int spitch = pitch/2;
    int neg = 0, step;

    __m128i lA, lB, lC, lD, gA, gB, gC, gD, o128, t1;
    uint8_t *lineAPos, *lineBPos, *lineCPos, *lineDPos;
    uint8_t *outlinePos8;
    uint16_t *outlinePos16;

    offset = -offset;

    //yposf = height * offset;
    yposf = (float)height * (0.5f - 1.0f / (2.0f * zoom) - offset);
    ystepf = 1.0f / zoom;

    if (yposf < 0.0)
        neg = 1;

    if (pitch < 0)
        yposf -= ystepf;

    /*	yposi = floor(yposf);

    	remainf = yposf - (float)yposi;
    	tablepos = (remainf*(float)SUBPIXEL);

    	yposi = abs(yposi);

    	if(yposi==0 && tablepos == 0)
    		return; // no move required
    */
    // -3 , 0 best small notch at zero?
    //

    switch (decoder->StereoBufferFormat)
    {
        case DECODED_FORMAT_RGB32:
            step = 4;
            break;
        case DECODED_FORMAT_RGB24:
            step = 3;
            break;
        case DECODED_FORMAT_YUYV:
            step = 4;
            break;
        case DECODED_FORMAT_W13A:
        case DECODED_FORMAT_RG64:
            step = 8;
            break;
        case DECODED_FORMAT_WP13:
        case DECODED_FORMAT_RG48:
            step = 6;
            break;
        default:
            assert(0);
            break;
    }

    {
        static char zeroline[1024] = {0};
        int y, yoffset = ((int)(yposf - 2.0)), yend = ((int)(yposf + 2.0 + ystepf * height));
        unsigned char *src = (unsigned char *)RGB48;
        unsigned char *dst = (unsigned char *)RGB48;
        unsigned char *ptr = (unsigned char *)buffer;

        if (yoffset < 0) yoffset = 0;
        if (yend > height) yend = height;

        src += pitch * yoffset;

        for (y = yoffset; y < yend; y++)
        {
            memcpy(ptr, src, widthbytes);

            ptr += widthbytes;
            src += pitch;
        }

        ptr = (unsigned char *)buffer;
        for (y = 0; y < height; y++)
        {
            int i, t, yp = ((int)yposf);
            int rmdr = 63 - ((int)(yposf * 64.0) & 63);
            int gains[4];

            yp -= 1; // use -2 cause a image down shift //DAN20100225
            t = 0;
            for (i = 0; i < 4; i++)
            {
                if (yp < 0 || yp >= height) // skip 0 line as the top line was zagged
                {
                    t += gains[i] = lanczos[rmdr];
                    scanline[i] = (unsigned short *)zeroline;
                }
                else
                {
                    t += gains[i] = lanczos[rmdr];
                    scanline[i] = (unsigned short *)&ptr[widthbytes * (yp - yoffset)];
                }

                yp++;
                rmdr += 64;
            }

            if (t)
            {
                gA = _mm_set1_epi16(gains[0]);
                gB = _mm_set1_epi16(gains[1]);
                gC = _mm_set1_epi16(gains[2]);
                gD = _mm_set1_epi16(gains[3]);

                outlinePos8 = (uint8_t *)dst;
                outlinePos16 = (uint16_t *)dst;

                lineAPos = (uint8_t *)scanline[0];
                lineBPos = (uint8_t *)scanline[1];
                lineCPos = (uint8_t *)scanline[2];
                lineDPos = (uint8_t *)scanline[3];

                switch (decoder->StereoBufferFormat)
                {
                    case DECODED_FORMAT_W13A:
                        lA =  _mm_loadu_si128((__m128i *)lineAPos);
                        lineAPos += 8;
                        lB =  _mm_loadu_si128((__m128i *)lineBPos);
                        lineBPos += 8;
                        lC =  _mm_loadu_si128((__m128i *)lineCPos);
                        lineCPos += 8;
                        lD =  _mm_loadu_si128((__m128i *)lineDPos);
                        lineDPos += 8;

                        o128 = _mm_mulhi_epi16(lA, gA);

                        t1 = _mm_mulhi_epi16(lB, gB);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lC, gC);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lD, gD);
                        o128 = _mm_adds_epi16(o128, t1);

                        // upper limit to 32767
                        o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                        o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                        o128 = _mm_slli_epi16(o128, 1);

                        //_mm_storeu_si128((__m128i *)outlinePos, o128);
                        outlinePos16[0] = _mm_extract_epi16(o128, 0);
                        outlinePos16[1] = _mm_extract_epi16(o128, 1);
                        outlinePos16[2] = _mm_extract_epi16(o128, 2);
                        outlinePos16[3] = _mm_extract_epi16(o128, 3);
                        outlinePos16 += 4;
                        break;

                    case DECODED_FORMAT_WP13:
                        lA =  _mm_loadu_si128((__m128i *)lineAPos);
                        lineAPos += 6;
                        lB =  _mm_loadu_si128((__m128i *)lineBPos);
                        lineBPos += 6;
                        lC =  _mm_loadu_si128((__m128i *)lineCPos);
                        lineCPos += 6;
                        lD =  _mm_loadu_si128((__m128i *)lineDPos);
                        lineDPos += 6;

                        o128 = _mm_mulhi_epi16(lA, gA);

                        t1 = _mm_mulhi_epi16(lB, gB);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lC, gC);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lD, gD);
                        o128 = _mm_adds_epi16(o128, t1);

                        // upper limit to 32767
                        o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                        o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                        o128 = _mm_slli_epi16(o128, 1);

                        //_mm_storeu_si128((__m128i *)outlinePos, o128);
                        outlinePos16[0] = _mm_extract_epi16(o128, 0);
                        outlinePos16[1] = _mm_extract_epi16(o128, 1);
                        outlinePos16[2] = _mm_extract_epi16(o128, 2);
                        outlinePos16 += 3;
                        break;

                    case DECODED_FORMAT_RG64:
                        lA =  _mm_loadu_si128((__m128i *)lineAPos);
                        lineAPos += 8;
                        lB =  _mm_loadu_si128((__m128i *)lineBPos);
                        lineBPos += 8;
                        lC =  _mm_loadu_si128((__m128i *)lineCPos);
                        lineCPos += 8;
                        lD =  _mm_loadu_si128((__m128i *)lineDPos);
                        lineDPos += 8;

                        lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                        lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                        lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                        lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                        o128 = _mm_mulhi_epi16(lA, gA);

                        t1 = _mm_mulhi_epi16(lB, gB);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lC, gC);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lD, gD);
                        o128 = _mm_adds_epi16(o128, t1);


                        o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_slli_epi16(o128, 4);


                        //_mm_storeu_si128((__m128i *)outlinePos, o128);
                        outlinePos16[0] = _mm_extract_epi16(o128, 0);
                        outlinePos16[1] = _mm_extract_epi16(o128, 1);
                        outlinePos16[2] = _mm_extract_epi16(o128, 2);
                        outlinePos16[3] = _mm_extract_epi16(o128, 3);
                        outlinePos16 += 4;
                        break;

                    case DECODED_FORMAT_RG48:
                        lA =  _mm_loadu_si128((__m128i *)lineAPos);
                        lineAPos += 6;
                        lB =  _mm_loadu_si128((__m128i *)lineBPos);
                        lineBPos += 6;
                        lC =  _mm_loadu_si128((__m128i *)lineCPos);
                        lineCPos += 6;
                        lD =  _mm_loadu_si128((__m128i *)lineDPos);
                        lineDPos += 6;

                        lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                        lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                        lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                        lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                        o128 = _mm_mulhi_epi16(lA, gA);

                        t1 = _mm_mulhi_epi16(lB, gB);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lC, gC);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lD, gD);
                        o128 = _mm_adds_epi16(o128, t1);


                        o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_slli_epi16(o128, 4);


                        //_mm_storeu_si128((__m128i *)outlinePos, o128);
                        outlinePos16[0] = _mm_extract_epi16(o128, 0);
                        outlinePos16[1] = _mm_extract_epi16(o128, 1);
                        outlinePos16[2] = _mm_extract_epi16(o128, 2);
                        outlinePos16 += 3;
                        break;

                    case DECODED_FORMAT_RGB32:
                    case DECODED_FORMAT_YUYV:
                        lA =  _mm_loadu_si128((__m128i *)lineAPos);
                        lineAPos += 4;
                        lA = _mm_unpackhi_epi8 (_mm_setzero_si128(), lA);
                        lB =  _mm_loadu_si128((__m128i *)lineBPos);
                        lineBPos += 4;
                        lB = _mm_unpackhi_epi8 (_mm_setzero_si128(), lB);
                        lC =  _mm_loadu_si128((__m128i *)lineCPos);
                        lineCPos += 4;
                        lC = _mm_unpackhi_epi8 (_mm_setzero_si128(), lC);
                        lD =  _mm_loadu_si128((__m128i *)lineDPos);
                        lineDPos += 4;
                        lD = _mm_unpackhi_epi8 (_mm_setzero_si128(), lD);

                        lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                        lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                        lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                        lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                        o128 = _mm_mulhi_epi16(lA, gA);

                        t1 = _mm_mulhi_epi16(lB, gB);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lC, gC);
                        o128 = _mm_adds_epi16(o128, t1);

                        t1 = _mm_mulhi_epi16(lD, gD);
                        o128 = _mm_adds_epi16(o128, t1);


                        o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_srli_epi16(o128, 4);
                        outlinePos8[0] = _mm_extract_epi16(o128, 0);
                        outlinePos8[1] = _mm_extract_epi16(o128, 1);
                        outlinePos8[2] = _mm_extract_epi16(o128, 2);
                        outlinePos8[3] = _mm_extract_epi16(o128, 3);
                        outlinePos8 += 4;
                        break;

                    case DECODED_FORMAT_RGB24:
                    {
                        int r, g, b;

                        b = ((lineAPos[0] * gains[0]) >> 7) +
                            ((lineBPos[0] * gains[1]) >> 7) +
                            ((lineCPos[0] * gains[2]) >> 7) +
                            ((lineDPos[0] * gains[3]) >> 7); //16-bit

                        g = ((lineAPos[1] * gains[0]) >> 7) +
                            ((lineBPos[1] * gains[1]) >> 7) +
                            ((lineCPos[1] * gains[2]) >> 7) +
                            ((lineDPos[1] * gains[3]) >> 7); //16-bit

                        r = ((lineAPos[2] * gains[0]) >> 7) +
                            ((lineBPos[2] * gains[1]) >> 7) +
                            ((lineCPos[2] * gains[2]) >> 7) +
                            ((lineDPos[2] * gains[3]) >> 7); //16-bit

                        if (r < 0) r = 0;
                        if (r > 65535) r = 65535;
                        if (g < 0) g = 0;
                        if (g > 65535) g = 65535;
                        if (b < 0) b = 0;
                        if (b > 65535) b = 65535;

                        lineAPos += 3;
                        lineBPos += 3;
                        lineCPos += 3;
                        lineDPos += 3;

                        outlinePos8[0] = b >> 8; //b
                        outlinePos8[1] = g >> 8; //g
                        outlinePos8[2] = r >> 8; //r
                        outlinePos8 += 3;

                        /* SSE2 can't load byte alligned
                        lA =  _mm_loadu_si128((__m128i *)lineAPos);	lineAPos+=3;
                        lA = _mm_unpackhi_epi8 (_mm_setzero_si128(), lA);
                        lB =  _mm_loadu_si128((__m128i *)lineBPos);	lineBPos+=3;
                        lB = _mm_unpackhi_epi8 (_mm_setzero_si128(), lB);
                        lC =  _mm_loadu_si128((__m128i *)lineCPos);	lineCPos+=3;
                        lC = _mm_unpackhi_epi8 (_mm_setzero_si128(), lC);
                        lD =  _mm_loadu_si128((__m128i *)lineDPos);	lineDPos+=3;
                        lD = _mm_unpackhi_epi8 (_mm_setzero_si128(), lD);

                        lA = _mm_srli_epi16(lA,3); //13-bit unsigned
                        lB = _mm_srli_epi16(lB,3); //13-bit unsigned
                        lC = _mm_srli_epi16(lC,3); //13-bit unsigned
                        lD = _mm_srli_epi16(lD,3); //13-bit unsigned

                        o128 = _mm_mulhi_epi16(lA, gA);

                        t1 = _mm_mulhi_epi16(lB, gB);
                        o128 = _mm_adds_epi16(o128,t1);

                        t1 = _mm_mulhi_epi16(lC, gC);
                        o128 = _mm_adds_epi16(o128,t1);

                        t1 = _mm_mulhi_epi16(lD, gD);
                        o128 = _mm_adds_epi16(o128,t1);


                        o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                        o128 = _mm_srli_epi16(o128,4);
                        outlinePos8[0] = _mm_extract_epi16(o128, 0); //b
                        outlinePos8[1] = _mm_extract_epi16(o128, 1); //g
                        outlinePos8[2] = _mm_extract_epi16(o128, 2); //r
                        outlinePos8+=3;
                        */
                    }
                    break;
                }
            }
            else
            {
                if (decoder->StereoBufferFormat == DECODED_FORMAT_YUYV)
                {
                    memset(dst, 0x10801080, widthbytes);
                }
                else
                {
                    memset(dst, 0, widthbytes);
                }
            }

            yposf += ystepf;
            dst += pitch;
        }
    }
}



void RGB48VerticalShift(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer,
                        int widthbytes, int height, int pitch, float offset)
{
    float yposf, remainf;
    int yposi, tablepos, x, y;
    int gainA, gainB, gainC, gainD;
    //int endofSSEline = 0;
    unsigned short *scanline[4], *tline;
    int spitch = pitch / 2;
    int neg = 0, shift = 0, skip, step;
    int origwidthbytes = widthbytes;
    int origwidthextra;

    __m128i lA, lB, lC, lD, gA, gB, gC, gD, o128, t1;
    __m128i *lineA, *lineB, *lineC, *lineD, *outline128;

    //	offset = -offset;

    if (offset < 0.0)
        neg = 1;

    yposf = height * offset;
    yposi = (int)floor(yposf);

    remainf = yposf - (float)yposi;
    tablepos = (int)(remainf * (float)SUBPIXEL);

    yposi = abs(yposi);

    if (yposi == 0 && tablepos == 0)
        return; // no move required

    // -3 , 0 best small notch at zero?
    //

    if (neg)
    {
        yposi -= 2;
        gainA = gains[tablepos][0];
        gainB = gains[tablepos][1];
        gainC = gains[tablepos][2];
        gainD = gains[tablepos][3];
    }
    else
    {
        yposi -= 1; //offset inherent in the table
        gainD = gains[tablepos][0];
        gainC = gains[tablepos][1];
        gainB = gains[tablepos][2];
        gainA = gains[tablepos][3];
    }

    gA = _mm_set1_epi16(gainA);
    gB = _mm_set1_epi16(gainB);
    gC = _mm_set1_epi16(gainC);
    gD = _mm_set1_epi16(gainD);


    switch (decoder->StereoBufferFormat)
    {
        case DECODED_FORMAT_RGB32:
            skip = 4;
            step = 16;
            break;
        case DECODED_FORMAT_RGB24:
            skip = 3;
            step = 16;
            break;
        case DECODED_FORMAT_YUYV:
            skip = 2;
            step = 16;
            break;
        case DECODED_FORMAT_WP13:
        case DECODED_FORMAT_RG48:
        case DECODED_FORMAT_W13A:
        case DECODED_FORMAT_RG64:
        default:
            skip = 6;
            step = 32;
            break;
    }


    //	scanline[0] = buffer;
    //	scanline[1] = buffer + width*skip/2;
    //	scanline[2] = buffer + width*skip/2*2;
    //	scanline[3] = buffer + width*skip/2*3;

    widthbytes += (step - 1);
    widthbytes -= (widthbytes % step);
    origwidthextra = (origwidthbytes % step);

    scanline[0] = buffer;
    scanline[1] = buffer + widthbytes / 2;
    scanline[2] = buffer + widthbytes / 2 * 2;
    scanline[3] = buffer + widthbytes / 2 * 3;


    for (y = 0; y < 4; y++)
    {
        if (yposi + y >= 0 && yposi + y < height)
        {
            unsigned short *ptr = RGB48;
            if (neg)
                ptr += (height - 1 - yposi - y) * spitch;
            else
                ptr += (yposi + y) * spitch;
            memcpy(scanline[y], ptr, origwidthbytes);
        }
        else
        {
            memset(scanline[y], 0, origwidthbytes);
        }
    }

    {


        for (y = 0; y < height; y++)
        {
            unsigned short *ptr = RGB48;

            if (neg)
                ptr += (height - y - 1) * spitch;
            else
                ptr += y * spitch;
            outline128 = (__m128i *)ptr;

            lineA = (__m128i *)scanline[0];
            lineB = (__m128i *)scanline[1];
            lineC = (__m128i *)scanline[2];
            lineD = (__m128i *)scanline[3];

            //for(x=0;x<width*skip/2; x+=step)
            for (x = 0; x < widthbytes; x += step)
            {
                __m128i half;

                switch (decoder->StereoBufferFormat)
                {
                    case DECODED_FORMAT_W13A:
                    case DECODED_FORMAT_WP13:
                    {
                        lA =  _mm_loadu_si128(lineA++);
                        lB =  _mm_loadu_si128(lineB++);
                        lC =  _mm_loadu_si128(lineC++);
                        lD =  _mm_loadu_si128(lineD++);

                        shift = 0;
                    }
                    break;
                    case DECODED_FORMAT_RG64:
                    case DECODED_FORMAT_RG48:
                    {
                        lA =  _mm_loadu_si128(lineA++);
                        lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                        lB =  _mm_loadu_si128(lineB++);
                        lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                        lC =  _mm_loadu_si128(lineC++);
                        lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                        lD =  _mm_loadu_si128(lineD++);
                        lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                        shift = 3;
                    }
                    break;
                    case DECODED_FORMAT_RGB32:
                    case DECODED_FORMAT_RGB24:
                    case DECODED_FORMAT_YUYV:

                        lA =  _mm_loadu_si128(lineA);
                        lA = _mm_unpackhi_epi8 (_mm_setzero_si128(), lA);
                        lB =  _mm_loadu_si128(lineB);
                        lB = _mm_unpackhi_epi8 (_mm_setzero_si128(), lB);
                        lC =  _mm_loadu_si128(lineC);
                        lC = _mm_unpackhi_epi8 (_mm_setzero_si128(), lC);
                        lD =  _mm_loadu_si128(lineD);
                        lD = _mm_unpackhi_epi8 (_mm_setzero_si128(), lD);

                        lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                        lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                        lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                        lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                        shift = 3;

                        break;
                }

                o128 = _mm_mulhi_epi16(lA, gA);

                t1 = _mm_mulhi_epi16(lB, gB);
                o128 = _mm_adds_epi16(o128, t1);

                t1 = _mm_mulhi_epi16(lC, gC);
                o128 = _mm_adds_epi16(o128, t1);

                t1 = _mm_mulhi_epi16(lD, gD);
                o128 = _mm_adds_epi16(o128, t1);

                if (shift)
                {
                    o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                    o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                    o128 = _mm_slli_epi16(o128, 4);
                }
                else
                {
                    // upper limit to 32767
                    o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                    o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                    o128 = _mm_slli_epi16(o128, 1);
                }

                if (skip == 6) //RGB48 || WP13
                {
                    if (widthbytes == origwidthbytes || x + 16 < origwidthbytes)
                        _mm_storeu_si128(outline128++, o128);
                    else
                    {
                        //if(x < origwidthbytes+16/*bytes in an SSE2 reg*/)
                        _mm_storeu_si128((__m128i *)scanline[0], o128);
                        memcpy((char *)outline128, (char *)scanline[0], origwidthextra);
                        outline128++;
                    }
                }
                else
                {
                    half = o128;
                }





                switch (decoder->StereoBufferFormat)
                {
                    case DECODED_FORMAT_W13A:
                    case DECODED_FORMAT_WP13:
                    {
                        lA =  _mm_loadu_si128(lineA++);
                        lB =  _mm_loadu_si128(lineB++);
                        lC =  _mm_loadu_si128(lineC++);
                        lD =  _mm_loadu_si128(lineD++);

                        shift = 0;
                    }
                    break;
                    case DECODED_FORMAT_RG64:
                    case DECODED_FORMAT_RG48:
                    {
                        lA =  _mm_loadu_si128(lineA++);
                        lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                        lB =  _mm_loadu_si128(lineB++);
                        lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                        lC =  _mm_loadu_si128(lineC++);
                        lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                        lD =  _mm_loadu_si128(lineD++);
                        lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                        shift = 3;
                    }
                    break;
                    case DECODED_FORMAT_RGB32:
                    case DECODED_FORMAT_RGB24:
                    case DECODED_FORMAT_YUYV:

                        lA =  _mm_loadu_si128(lineA++);
                        lA = _mm_unpacklo_epi8 (_mm_setzero_si128(), lA);
                        lB =  _mm_loadu_si128(lineB++);
                        lB = _mm_unpacklo_epi8 (_mm_setzero_si128(), lB);
                        lC =  _mm_loadu_si128(lineC++);
                        lC = _mm_unpacklo_epi8 (_mm_setzero_si128(), lC);
                        lD =  _mm_loadu_si128(lineD++);
                        lD = _mm_unpacklo_epi8 (_mm_setzero_si128(), lD);

                        lA = _mm_srli_epi16(lA, 3); //13-bit unsigned
                        lB = _mm_srli_epi16(lB, 3); //13-bit unsigned
                        lC = _mm_srli_epi16(lC, 3); //13-bit unsigned
                        lD = _mm_srli_epi16(lD, 3); //13-bit unsigned

                        shift = 3;

                        break;
                }

                o128 = _mm_mulhi_epi16(lA, gA);

                t1 = _mm_mulhi_epi16(lB, gB);
                o128 = _mm_adds_epi16(o128, t1);

                t1 = _mm_mulhi_epi16(lC, gC);
                o128 = _mm_adds_epi16(o128, t1);

                t1 = _mm_mulhi_epi16(lD, gD);
                o128 = _mm_adds_epi16(o128, t1);

                if (shift)
                {
                    o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                    o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
                    o128 = _mm_slli_epi16(o128, 4);
                }
                else
                {
                    // upper limit to 32767
                    o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                    o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
                    o128 = _mm_slli_epi16(o128, 1);
                }

                if (skip != 6) //!RGB48 || !WP13
                {
                    half = _mm_srli_epi16(half, 8);
                    o128 = _mm_srli_epi16(o128, 8);
                    o128 = _mm_packus_epi16(o128, half);
                }

                if (widthbytes == origwidthbytes || x + 32 < origwidthbytes)
                {
                    _mm_storeu_si128(outline128++, o128);
                }
                else
                {
                    //if(x+16 < origwidthbytes+16)

                    if (origwidthextra > 16)
                    {
                        _mm_storeu_si128((__m128i *)scanline[0], o128);
                        memcpy((char *)outline128, (char *)scanline[0], origwidthextra - 16);
                    }
                    outline128++;
                }
            }

            tline = scanline[0];
            scanline[0] = scanline[1];
            scanline[1] = scanline[2];
            scanline[2] = scanline[3];
            scanline[3] = tline;

            if (yposi + y + 4 >= 0 && yposi + y + 4 < height)
            {
                unsigned short *ptr = RGB48;
                if (neg)
                    ptr += (height - 1 - (yposi + y + 4)) * spitch;
                else
                    ptr += (yposi + y + 4) * spitch;
                memcpy(scanline[3], ptr, origwidthbytes);
            }
            else
            {
                memset(scanline[3], 0, origwidthbytes);
            }
        }
    }
}




void RGB48HoriShiftZoom(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer, int width, int height, int line, float hoffset, float roffset, float zoom, int flip, float frameTilt, int eye)
{
    float xposf, xstepf;
    int x;
    //int endofSSEline = 0;
    unsigned short *scanline = (unsigned short *)buffer;
    short *sscanline = (short *)buffer;
    int neg = 0;
    float offset = hoffset;

    if (flip)
    {
        unsigned short *ptrL = RGB48;
        unsigned short *ptrR = RGB48;
        ptrR += (width * 3) - 3;
        for (x = 0; x < width / 2; x++)
        {
            int t;

            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            ptrR -= 6;
        }
    }


    if (eye > 0)
    {
        zoom *= 1.0f + frameTilt;
    }
    else
    {
        zoom /= 1.0f + frameTilt;
    }


    xposf = (float)width * (0.5f - 1.0f / (2.0f * zoom) - offset);
    xposf -= width * roffset * 0.5f / zoom;
    xposf += (float)line * ((float)width * roffset / ((float)height * zoom));

    if (xposf < 0.0)
        neg = 1;

    xstepf = 1.0f / zoom;


    memcpy(scanline, RGB48, width * 3 * 2);
    {
        //unsigned short zeroline[3] = {0};
        int xx = 0;
        int ixpos = (int)(xposf * 65536.0f);
        int ixstep = (int)(xstepf * 65536.0f);
        float xbase = xposf / (float)width;
        float xstep = xstepf / (float)width;
        float z = (decoder->cfhddata.FrameHDynamic - 1.0f) * 2.0f;
        //	int holdstart = width*5/10; // Use to specify a area of uniform stretch
        //	int holdend = width*5/10;
        int holdstart = (int)((decoder->cfhddata.FrameHDynCenter - decoder->cfhddata.FrameHDynWidth * 0.125) * (float)width);
        int holdend = (int)((decoder->cfhddata.FrameHDynCenter + decoder->cfhddata.FrameHDynWidth * 0.125) * (float)width);
        float flatxstep;
        float modified_xstep_avg;
        float bottomxstep;
        float basexstepstart;
        float basexstepend;
        float range;
#if MMXSUPPORTED //TODO DANREMOVE
        __m64 overflowprotect = _mm_set1_pi16(0x7fff - 0x3fff);
#endif

        if (holdstart < 0) holdstart = 0, holdend = (int)((decoder->cfhddata.FrameHDynWidth * 0.5) * (float)width);
        if (holdend > width) holdend = width, holdstart = (int)((1.0 - decoder->cfhddata.FrameHDynWidth * 0.5) * (float)width);

        range = (float)(holdend - holdstart);

        flatxstep = xstep - z * 0.5f * xstep;
        modified_xstep_avg = (xstep * (float)width - range * flatxstep) / ((float)width - range);
        bottomxstep = modified_xstep_avg - (flatxstep - modified_xstep_avg);

        if (holdstart == (width - holdend))
        {
            basexstepstart = bottomxstep;
            basexstepend = bottomxstep;
        }
        else if (holdstart < (width - holdend))
        {
            float a = (float)holdstart / (float)(width - holdend);
            float startavg = a * modified_xstep_avg + (1.0f - a) * flatxstep;
            float endavg = (modified_xstep_avg * ((float)width - range) - startavg * (float)holdstart) / (float)(width - holdend);

            basexstepstart = startavg - (flatxstep - startavg);
            basexstepend = endavg - (flatxstep - endavg);

        }
        else
        {
            float a = (float)(width - holdend) / (float)holdstart;
            float endavg = a * modified_xstep_avg + (1.0f - a) * flatxstep;
            float startavg = (modified_xstep_avg * ((float)width - range) - endavg * (float)(width - holdend)) / (float)holdstart;

            basexstepstart = startavg - (flatxstep - startavg);
            basexstepend = endavg - (flatxstep - endavg);

        }


        if (decoder->StereoBufferFormat == DECODED_FORMAT_WP13)
        {
            float fxpos = xbase;

            for (x = 0; x < width; x++) //RGB
            {
                int gains = 0;
                int xp, rmdr;

                if (z != 0.0)
                {
                    if (x < holdstart)
                    {
                        fxpos += basexstepstart * ((float)(holdstart - x) / (float)holdstart) + flatxstep * ((float)x / (float)holdstart);
                    }
                    else if (x > holdend)
                    {
                        int diff = width - x;
                        int range = width - holdend;
                        fxpos += basexstepend * ((float)(range - diff) / (float)range) + flatxstep * ((float)(diff) / (float)range);
                    }
                    else
                    {
                        fxpos += flatxstep;
                    }

                    xp = (int)(fxpos * 65536.0f * (float)width);
                    rmdr = 63 - ((xp >> 10) & 63);
                    xp >>= 16;
                }
                else
                {
                    xp = ixpos >> 16;
                    rmdr = 63 - ((ixpos >> 10) & 63);
                    ixpos += ixstep;
                }

                xp -= 1;// was -2 causing a right shift //DAN20100225
#if MMXSUPPORTED //TODO DANREMOVE
                if (xp > 4 && xp < width - 4 && xx < (width - 1) * 3) //We need 3 values for RGB< yet we write 4, so the last pixel can't be done with MMX
                {
                    __m64 *src64;
                    __m64 *dst64;
                    __m64 sumx16;
                    __m64 rgbx16;
                    __m64 gain16;
                    int linepos = (xp - 1) * 3;

                    src64 = (__m64 *)&sscanline[linepos];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr]); //15-bit
                    sumx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit

                    src64 = (__m64 *)&sscanline[linepos + 3];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 64]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&sscanline[linepos + 6];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 128]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&sscanline[linepos + 9];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 192]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    sumx16 = _mm_adds_pi16(sumx16, overflowprotect);
                    sumx16 = _mm_subs_pu16(sumx16, overflowprotect);

                    sumx16 = _mm_slli_pi16(sumx16, 1);

                    dst64 = (__m64 *)&RGB48[xx];
                    *dst64 = sumx16;
                }
                else
#endif
                {
                    int i, r = 0, g = 0, b = 0;

                    for (i = 0; i < 4; i++)
                    {
                        if (xp <= 0 || xp >= width)
                        {
                            gains += lanczos[rmdr] >> 1;
                        }
                        else
                        {
                            gains += lanczos[rmdr] >> 1;
                            r += (gains * sscanline[xp * 3]);
                            g += (gains * sscanline[xp * 3 + 1]);
                            b += (gains * sscanline[xp * 3 + 2]);
                            gains = 0;
                        }

                        xp++;
                        rmdr += 64;
                    }
                    r >>= 14;
                    g >>= 14;
                    b >>= 14;
                    if (r < 0) r = 0;
                    else if (r > 65535) r = 65535;
                    if (g < 0) g = 0;
                    else if (g > 65535) g = 65535;
                    if (b < 0) b = 0;
                    else if (b > 65535) b = 65535;
                    RGB48[xx] = r;
                    RGB48[xx + 1] = g;
                    RGB48[xx + 2] = b;
                }
                xx += 3;
            }
        }
        else
        {
            float fxpos = xbase;

            for (x = 0; x < width; x++) //RGB
            {
                int gains = 0;
                int xp, rmdr;

                if (z != 0.0)
                {
                    if (x < holdstart)
                    {
                        fxpos += basexstepstart * ((float)(holdstart - x) / (float)holdstart) + flatxstep * ((float)x / (float)holdstart);
                    }
                    else if (x > holdend)
                    {
                        int diff = width - x;
                        int range = width - holdend;
                        fxpos += basexstepend * ((float)(range - diff) / (float)range) + flatxstep * ((float)(diff) / (float)range);
                    }
                    else
                    {
                        fxpos += flatxstep;
                    }

                    xp = (int)(fxpos * 65536.0f * (float)width);
                    rmdr = 63 - ((xp >> 10) & 63);
                    xp >>= 16;
                }
                else
                {
                    xp = ixpos >> 16;
                    rmdr = 63 - ((ixpos >> 10) & 63);
                    ixpos += ixstep;
                }

                xp -= 1; // was -2 causing a right shift //DAN20100225
#if MMXSUPPORTED //TODO DANREMOVE
                if (xp > 4 && xp < width - 4)
                {
                    __m64 *src64;
                    __m64 *dst64;
                    __m64 sumx16;
                    __m64 rgbx16;
                    __m64 gain16;
                    int linepos = (xp - 0) * 3; //DAN20102602 -- fix left edge error.

                    src64 = (__m64 *)&scanline[linepos];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    sumx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit

                    src64 = (__m64 *)&scanline[linepos + 3];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 64]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&scanline[linepos + 6];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 128]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&scanline[linepos + 9];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 192]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    sumx16 = _mm_adds_pi16(sumx16, overflowprotect);
                    sumx16 = _mm_subs_pu16(sumx16, overflowprotect);

                    sumx16 = _mm_slli_pi16(sumx16, 2);

                    dst64 = (__m64 *)&RGB48[xx];
                    *dst64 = sumx16;
                }
                else
#endif
                {
                    int i, r = 0, g = 0, b = 0;

                    for (i = 0; i < 4; i++)
                    {
                        if (xp <= 0 || xp >= width)
                        {
                            gains += lanczos[rmdr] >> 1;
                        }
                        else
                        {
                            gains += lanczos[rmdr] >> 1;
                            r += (gains * scanline[xp * 3]);
                            g += (gains * scanline[xp * 3 + 1]);
                            b += (gains * scanline[xp * 3 + 2]);
                            gains = 0;
                        }

                        xp++;
                        rmdr += 64;
                    }
                    r >>= 14;
                    g >>= 14;
                    b >>= 14;
                    if (r < 0) r = 0;
                    else if (r > 65535) r = 65535;
                    if (g < 0) g = 0;
                    else if (g > 65535) g = 65535;
                    if (b < 0) b = 0;
                    else if (b > 65535) b = 65535;
                    RGB48[xx] = r;
                    RGB48[xx + 1] = g;
                    RGB48[xx + 2] = b;
                }
                xx += 3;
            }
        }
    }

#if MMXSUPPORTED //TODO DANREMOVE
    //_mm_empty();
#endif
}


#if 0 //Why is this not used? 
void RGB48HoriShiftZoomFine(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer, int width, int height, int line, float hoffset, float roffset, float zoom, int flip, float frameTilt, int eye)
{
    float xposf, remainf, xstepf;
    int xposi, tablepos, x;
    int Ra, Rb, Rc, Rd;
    int Ga, Gb, Gc, Gd;
    int Ba, Bb, Bc, Bd;
    int gainA, gainB, gainC, gainD;
    int endofSSEline = 0;
    unsigned short *scanline = (unsigned short *)buffer;
    short *sscanline = (short *)buffer;
    int neg = 0, shift = 0;
    float offset = hoffset;

    __m128i l1, l2, l3, gA, gB, gC, gD, o128, t1, t2;
    __m128i *line128, *outline128;

    if (flip)
    {
        unsigned short *ptrL = RGB48;
        unsigned short *ptrR = RGB48;
        ptrR += (width * 3) - 3;
        for (x = 0; x < width / 2; x++)
        {
            int t;

            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            ptrR -= 6;
        }
    }


    if (eye > 0)
    {
        zoom *= 1.0 + frameTilt;
    }
    else
    {
        zoom /= 1.0 + frameTilt;
    }


    xposf = (float)width * (0.5 - 1.0 / (2.0 * zoom) - offset);
    xposf -= width * roffset * 0.5 / zoom;
    xposf += (float)line * ((float)width * roffset / ((float)height * zoom));

    if (xposf < 0.0)
        neg = 1;

    xstepf = 1.0 / zoom;

    memcpy(scanline, RGB48, width * 3 * 2);
    {
        unsigned short zeroline[3] = {0};
        int xx = 0;
        int ixpos = xposf * 65536.0;
        int ixstep = xstepf * 65536.0;
        float xbase = xposf / (float)width;
        float xstep = xstepf / (float)width;
        float z = (decoder->cfhddata.FrameHDynamic - 1.0) * 2.0;
        int holdstart = width * 5 / 10; // Use to specify a area of uniform stretch
        int holdend = width * 5 / 10;
        float flatxstep = xstep - z * 0.5 * xstep;
        float modified_xstep_avg = (xstep * (float)width - (float)(holdend - holdstart) * flatxstep) / (float)(width - (holdend - holdstart));
        float bottomxstep = modified_xstep_avg - (flatxstep - modified_xstep_avg);
        __m64 overflowprotect = _mm_set1_pi16(0x7fff - 0x3fff);

        if (bottomxstep < 0.0)
        {
            bottomxstep = 0.0;
            flatxstep = modified_xstep_avg + modified_xstep_avg;
        }
        if (flatxstep < 0.0)
        {
            flatxstep = 0.0;
            bottomxstep = modified_xstep_avg - (flatxstep - modified_xstep_avg);
        }

        if (decoder->StereoBufferFormat == DECODED_FORMAT_WP13)
        {
            float fxpos = xbase;

            for (x = 0; x < width; x++) //RGB
            {
                int gains = 0;
                int xp, rmdr;

                if (z != 0.0)
                {
                    if (x < holdstart)
                    {
                        fxpos += bottomxstep * ((float)(holdstart - x) / (float)holdstart) + flatxstep * ((float)x / (float)holdstart);
                    }
                    else if (x > holdend)
                    {
                        int diff = width - x;
                        int range = width - holdend;
                        fxpos += bottomxstep * ((float)(range - diff) / (float)range) + flatxstep * ((float)(diff) / (float)range);
                    }
                    else
                    {
                        fxpos += flatxstep;
                    }
                    /*	fxpos = xbase + xstep * x;//(float)ixpos/(65536.0*(float)width);

                    	if(fxpos >= 0.0 && fxpos <= 1.0)
                    	{
                    		if(z > 0.0)
                    		{
                    			fxpos = 1.8*fxpos - 2.4*fxpos*fxpos + (1.6*fxpos*fxpos*fxpos);
                    			fxpos = fxpos * (z) + (xbase + xstep * x) * (1.0-z);
                    		}
                    		else
                    		{
                    			fxpos = 3.0*fxpos*fxpos - 2.0*fxpos*fxpos*fxpos;
                    			fxpos = fxpos * (-z) + (xbase + xstep * x) * (1.0+z);
                    		}
                    	}
                    */

                    xp = (fxpos * 65536.0 * (float)width);
                    rmdr = 63 - ((xp >> 10) & 63);
                    xp >>= 16;
                }
                else
                {
                    xp = ixpos >> 16;
                    rmdr = 63 - ((ixpos >> 10) & 63);
                    ixpos += ixstep;
                }

                xp -= 1;// was -2 causing a right shift //DAN20100225
                if (xp > 4 && xp < width - 4)
                {
                    __m64 *src64;
                    __m64 *dst64;
                    __m64 sumx16;
                    __m64 rgbx16;
                    __m64 gain16;
                    int linepos = (xp - 1) * 3;

                    src64 = (__m64 *)&sscanline[linepos];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr]); //15-bit
                    sumx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit

                    src64 = (__m64 *)&sscanline[linepos + 3];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 64]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&sscanline[linepos + 6];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 128]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&sscanline[linepos + 9];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 192]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    sumx16 = _mm_adds_pi16(sumx16, overflowprotect);
                    sumx16 = _mm_subs_pu16(sumx16, overflowprotect);

                    sumx16 = _mm_slli_pi16(sumx16, 1);

                    dst64 = (__m64 *)&RGB48[xx];
                    *dst64 = sumx16;
                }
                else
                {
                    int i, t, r = 0, g = 0, b = 0;

                    for (i = 0; i < 4; i++)
                    {
                        if (xp <= 0 || xp >= width)
                        {
                            /*	if(i == 3) //DAN20101112 this code was crashing disparity zoom
                            	{
                            		gains = lanczos[rmdr]>>1;
                            		r += (gains * sscanline[(xp-1)*3]);
                            		g += (gains * sscanline[(xp-1)*3+1]);
                            		b += (gains * sscanline[(xp-1)*3+2]);
                            	}
                            	else */
                            {
                                gains += lanczos[rmdr] >> 1;
                            }
                        }
                        else
                        {
                            gains += lanczos[rmdr] >> 1;
                            r += (gains * sscanline[xp * 3]);
                            g += (gains * sscanline[xp * 3 + 1]);
                            b += (gains * sscanline[xp * 3 + 2]);
                            gains = 0;
                        }

                        xp++;
                        rmdr += 64;
                    }
                    r >>= 14;
                    g >>= 14;
                    b >>= 14;
                    if (r < 0) r = 0;
                    else if (r > 65535) r = 65535;
                    if (g < 0) g = 0;
                    else if (g > 65535) g = 65535;
                    if (b < 0) b = 0;
                    else if (b > 65535) b = 65535;
                    RGB48[xx] = r;
                    RGB48[xx + 1] = g;
                    RGB48[xx + 2] = b;
                }
                xx += 3;
            }
        }
        else
        {
            float fxpos = xbase;

            for (x = 0; x < width; x++) //RGB
            {
                int gains = 0;
                int xp, rmdr;

                if (z != 0.0)
                {
                    if (x < holdstart)
                    {
                        fxpos += bottomxstep * ((float)(holdstart - x) / (float)holdstart) + flatxstep * ((float)x / (float)holdstart);
                    }
                    else if (x > holdend)
                    {
                        int diff = width - x;
                        int range = width - holdend;
                        fxpos += bottomxstep * ((float)(range - diff) / (float)range) + flatxstep * ((float)(diff) / (float)range);
                    }
                    else
                    {
                        fxpos += flatxstep;
                    }
                    /*	fxpos = xbase + xstep * x;//(float)ixpos/(65536.0*(float)width);

                    	if(fxpos >= 0.0 && fxpos <= 1.0)
                    	{
                    		if(z > 0.0)
                    		{
                    			fxpos = 1.8*fxpos - 2.4*fxpos*fxpos + (1.6*fxpos*fxpos*fxpos);
                    			fxpos = fxpos * (z) + (xbase + xstep * x) * (1.0-z);
                    		}
                    		else
                    		{
                    			fxpos = 3.0*fxpos*fxpos - 2.0*fxpos*fxpos*fxpos;
                    			fxpos = fxpos * (-z) + (xbase + xstep * x) * (1.0+z);
                    		}
                    	}
                    */

                    xp = (fxpos * 65536.0 * (float)width);
                    rmdr = 63 - ((xp >> 10) & 63);
                    xp >>= 16;
                }
                else
                {
                    xp = ixpos >> 16;
                    rmdr = 63 - ((ixpos >> 10) & 63);
                    ixpos += ixstep;
                }

                xp -= 1; // was -2 causing a right shift //DAN20100225
                if (xp > 4 && xp < width - 4)
                {
                    __m64 *src64;
                    __m64 *dst64;
                    __m64 sumx16;
                    __m64 rgbx16;
                    __m64 gain16;
                    int linepos = (xp - 0) * 3; //DAN20102602 -- fix left edge error.

                    src64 = (__m64 *)&scanline[linepos];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    sumx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit

                    src64 = (__m64 *)&scanline[linepos + 3];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 64]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&scanline[linepos + 6];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 128]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&scanline[linepos + 9];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 192]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    sumx16 = _mm_adds_pi16(sumx16, overflowprotect);
                    sumx16 = _mm_subs_pu16(sumx16, overflowprotect);

                    sumx16 = _mm_slli_pi16(sumx16, 2);

                    dst64 = (__m64 *)&RGB48[xx];
                    *dst64 = sumx16;
                }
                else
                {
                    int i, t, r = 0, g = 0, b = 0;

                    for (i = 0; i < 4; i++)
                    {
                        if (xp <= 0 || xp >= width)
                        {
                            /*	if(i == 3) //DAN20101112 this code was crashing disparity zoom
                            	{
                            		gains = lanczos[rmdr]>>1;
                            		r += (gains * scanline[(xp-1)*3]);
                            		g += (gains * scanline[(xp-1)*3+1]);
                            		b += (gains * scanline[(xp-1)*3+2]);
                            	}
                            	else */
                            {
                                gains += lanczos[rmdr] >> 1;
                            }
                        }
                        else
                        {
                            gains += lanczos[rmdr] >> 1;
                            r += (gains * scanline[xp * 3]);
                            g += (gains * scanline[xp * 3 + 1]);
                            b += (gains * scanline[xp * 3 + 2]);
                            gains = 0;
                        }

                        xp++;
                        rmdr += 64;
                    }
                    r >>= 14;
                    g >>= 14;
                    b >>= 14;
                    if (r < 0) r = 0;
                    else if (r > 65535) r = 65535;
                    if (g < 0) g = 0;
                    else if (g > 65535) g = 65535;
                    if (b < 0) b = 0;
                    else if (b > 65535) b = 65535;
                    RGB48[xx] = r;
                    RGB48[xx + 1] = g;
                    RGB48[xx + 2] = b;
                }
                xx += 3;
            }
        }
    }

    /*
    	memcpy(scanline, RGB48, width*3*2);
    	{
    		for(x=0;x<width*3; x+=3) //RGB
    		{
    			int r,g,b,xp = ((int)xposf)*3;

    			xposf += xstepf;

    			if(xp<0 || xp>= width*3)
    			{
    				RGB48[x] = 0;
    				RGB48[x+1] = 0;
    				RGB48[x+2] = 0;
    			}
    			else
    			{
    				r = scanline[xp];
    				g = scanline[xp+1];
    				b = scanline[xp+2];

    				RGB48[x] = r;
    				RGB48[x+1] = g;
    				RGB48[x+2] = b;
    			}
    		}
    	}
    */

    //_mm_empty();
}
#endif

void RGBA64HoriShiftZoom(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer, int width, int height, int line, float hoffset, float roffset, float zoom, int flip, float frameTilt, int eye)
{
    float xposf, xstepf;
    int x;
    //int endofSSEline = 0;
    unsigned short *scanline = (unsigned short *)buffer;
    short *sscanline = (short *)buffer;
    int neg = 0;
    float offset = hoffset;

    if (flip)
    {
        unsigned short *ptrL = RGB48;
        unsigned short *ptrR = RGB48;
        ptrR += (width * 4) - 4;
        for (x = 0; x < width / 2; x++)
        {
            int t;

            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            t = *ptrL;
            *ptrL++ = *ptrR;
            *ptrR++ = t;
            ptrR -= 4;
        }
    }


    if (eye > 0)
    {
        zoom *= 1.0f + frameTilt;
    }
    else
    {
        zoom /= 1.0f + frameTilt;
    }


    xposf = (float)width * (0.5f - 1.0f / (2.0f * zoom) - offset);
    xposf -= width * roffset * 0.5f;
    xposf += line * (width * roffset / ((float)height * zoom));

    if (xposf < 0.0)
        neg = 1;

    xstepf = 1.0f / zoom;


    memcpy(scanline, RGB48, width * 4 * 2);
    {
        //unsigned short zeroline[3] = {0};
        int xx = 0;
        int ixpos = (int)(xposf * 65536.0f);
        int ixstep = (int)(xstepf * 65536.0f);
        float xbase = xposf / (float)width;
        float xstep = xstepf / (float)width;
        float z = (decoder->cfhddata.FrameHDynamic - 1.0f) * 2.0f;
        int holdstart = width * 5 / 10; // Use to specify a area of uniform stretch
        int holdend = width * 5 / 10;
        float flatxstep = xstep - z * 0.5f * xstep;
        float modified_xstep_avg = (xstep * (float)width - (float)(holdend - holdstart) * flatxstep) / (float)(width - (holdend - holdstart));
        float bottomxstep = modified_xstep_avg - (flatxstep - modified_xstep_avg);
#if MMXSUPPORTED //TODO DANREMOVE
        __m64 overflowprotect = _mm_set1_pi16(0x7fff - 0x3fff);
#endif

        if (bottomxstep < 0.0)
        {
            bottomxstep = 0.0;
            flatxstep = modified_xstep_avg + modified_xstep_avg;
        }
        if (flatxstep < 0.0)
        {
            flatxstep = 0.0;
            bottomxstep = modified_xstep_avg - (flatxstep - modified_xstep_avg);
        }

        if (decoder->StereoBufferFormat == DECODED_FORMAT_W13A)
        {
            float fxpos = xbase;

            for (x = 0; x < width; x++) //RGB
            {
                int gains = 0;
                int xp, rmdr;

                if (z != 0.0)
                {
                    if (x < holdstart)
                    {
                        fxpos += bottomxstep * ((float)(holdstart - x) / (float)holdstart) + flatxstep * ((float)x / (float)holdstart);
                    }
                    else if (x > holdend)
                    {
                        int diff = width - x;
                        int range = width - holdend;
                        fxpos += bottomxstep * ((float)(range - diff) / (float)range) + flatxstep * ((float)(diff) / (float)range);
                    }
                    else
                    {
                        fxpos += flatxstep;
                    }

                    xp = (int)(fxpos * 65536.0f * (float)width);
                    rmdr = 63 - ((xp >> 10) & 63);
                    xp >>= 16;
                }
                else
                {
                    xp = ixpos >> 16;
                    rmdr = 63 - ((ixpos >> 10) & 63);
                    ixpos += ixstep;
                }

                xp -= 1;// was -2 causing a right shift //DAN20100225
#if MMXSUPPORTED //TODO DANREMOVE
                if (xp > 4 && xp < width - 4)
                {
                    __m64 *src64;
                    __m64 *dst64;
                    __m64 sumx16;
                    __m64 rgbx16;
                    __m64 gain16;
                    int linepos = (xp - 1) * 4;

                    src64 = (__m64 *)&sscanline[linepos];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr]); //15-bit
                    sumx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit

                    src64 = (__m64 *)&sscanline[linepos + 4];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 64]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&sscanline[linepos + 8];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 128]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&sscanline[linepos + 12];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 192]); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //13*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    sumx16 = _mm_adds_pi16(sumx16, overflowprotect);
                    sumx16 = _mm_subs_pu16(sumx16, overflowprotect);

                    sumx16 = _mm_slli_pi16(sumx16, 1);

                    dst64 = (__m64 *)&RGB48[xx];
                    *dst64 = sumx16;
                }
                else
#endif
                {
                    int i, r = 0, g = 0, b = 0, a = 0;

                    for (i = 0; i < 4; i++)
                    {
                        if (xp <= 0 || xp >= width)
                        {
                            gains += lanczos[rmdr] >> 1;
                        }
                        else
                        {
                            gains += lanczos[rmdr] >> 1;
                            r += (gains * sscanline[xp * 4]);
                            g += (gains * sscanline[xp * 4 + 1]);
                            b += (gains * sscanline[xp * 4 + 2]);
                            a += (gains * sscanline[xp * 4 + 3]);
                            gains = 0;
                        }

                        xp++;
                        rmdr += 64;
                    }
                    r >>= 14;
                    g >>= 14;
                    b >>= 14;
                    a >>= 14;
                    if (r < 0) r = 0;
                    else if (r > 65535) r = 65535;
                    if (g < 0) g = 0;
                    else if (g > 65535) g = 65535;
                    if (b < 0) b = 0;
                    else if (b > 65535) b = 65535;
                    if (a < 0) a = 0;
                    else if (a > 65535) a = 65535;
                    RGB48[xx] = r;
                    RGB48[xx + 1] = g;
                    RGB48[xx + 2] = b;
                    RGB48[xx + 3] = a;
                }
                xx += 4;
            }
        }
        else
        {
            float fxpos = xbase;

            for (x = 0; x < width; x++) //RGB
            {
                int gains = 0;
                int xp, rmdr;

                if (z != 0.0)
                {
                    if (x < holdstart)
                    {
                        fxpos += bottomxstep * ((float)(holdstart - x) / (float)holdstart) + flatxstep * ((float)x / (float)holdstart);
                    }
                    else if (x > holdend)
                    {
                        int diff = width - x;
                        int range = width - holdend;
                        fxpos += bottomxstep * ((float)(range - diff) / (float)range) + flatxstep * ((float)(diff) / (float)range);
                    }
                    else
                    {
                        fxpos += flatxstep;
                    }

                    xp = (int)(fxpos * 65536.0f * (float)width);
                    rmdr = 63 - ((xp >> 10) & 63);
                    xp >>= 16;
                }
                else
                {
                    xp = ixpos >> 16;
                    rmdr = 63 - ((ixpos >> 10) & 63);
                    ixpos += ixstep;
                }

                xp -= 1; // was -2 causing a right shift //DAN20100225
#if MMXSUPPORTED //TODO DANREMOVE
                if (xp > 4 && xp < width - 4)
                {
                    __m64 *src64;
                    __m64 *dst64;
                    __m64 sumx16;
                    __m64 rgbx16;
                    __m64 gain16;
                    int linepos = (xp - 0) * 4; //DAN20102602 -- fix left edge error.

                    src64 = (__m64 *)&scanline[linepos];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    sumx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit

                    src64 = (__m64 *)&scanline[linepos + 4];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 64]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&scanline[linepos + 8];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 128]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    src64 = (__m64 *)&scanline[linepos + 12];
                    rgbx16 = *src64;
                    gain16 = _mm_set1_pi16(lanczos[rmdr + 192]); //15-bit
                    rgbx16 = _mm_srli_pi16(rgbx16, 1); //15-bit
                    rgbx16 = _mm_mulhi_pi16(rgbx16, gain16); //15*15-bit
                    sumx16 = _mm_adds_pi16(sumx16, rgbx16);

                    sumx16 = _mm_adds_pi16(sumx16, overflowprotect);
                    sumx16 = _mm_subs_pu16(sumx16, overflowprotect);

                    sumx16 = _mm_slli_pi16(sumx16, 2);

                    dst64 = (__m64 *)&RGB48[xx];
                    *dst64 = sumx16;
                }
                else
#endif
                {
                    int i, r = 0, g = 0, b = 0, a = 0;

                    for (i = 0; i < 4; i++)
                    {
                        if (xp <= 0 || xp >= width)
                        {
                            gains += lanczos[rmdr] >> 1;
                        }
                        else
                        {
                            gains += lanczos[rmdr] >> 1;
                            r += (gains * scanline[xp * 4]);
                            g += (gains * scanline[xp * 4 + 1]);
                            b += (gains * scanline[xp * 4 + 2]);
                            a += (gains * scanline[xp * 4 + 3]);
                            gains = 0;
                        }

                        xp++;
                        rmdr += 64;
                    }
                    r >>= 14;
                    g >>= 14;
                    b >>= 14;
                    a >>= 14;
                    if (r < 0) r = 0;
                    else if (r > 65535) r = 65535;
                    if (g < 0) g = 0;
                    else if (g > 65535) g = 65535;
                    if (b < 0) b = 0;
                    else if (b > 65535) b = 65535;
                    if (a < 0) a = 0;
                    else if (a > 65535) a = 65535;
                    RGB48[xx] = r;
                    RGB48[xx + 1] = g;
                    RGB48[xx + 2] = b;
                    RGB48[xx + 3] = a;
                }
                xx += 4;
            }
        }
    }

#if MMXSUPPORTED //TODO DANREMOVE
    //_mm_empty();
#endif
}

void RGB48WindowMask(DECODER *decoder, unsigned short *RGB48, int width, int channel, float windowMask)
{
    float line = (float)width * fabsf(windowMask);
    int  pixelbytes = 6;
    float frac = (float)(line - (float)((int)line));

    switch (decoder->StereoBufferFormat)
    {
        case DECODED_FORMAT_RGB32:
        case DECODED_FORMAT_W13A:
        case DECODED_FORMAT_RG64:
            pixelbytes = 8;
            break;
    }
    if (decoder->StereoBufferFormat == DECODED_FORMAT_W13A ||
            decoder->StereoBufferFormat == DECODED_FORMAT_WP13) // signed math needed
    {
        short *ptrL = (short *)RGB48;
        short *ptrR = (short *)RGB48;

        if (windowMask < 0)
            channel = channel == 0 ? 1 : 0;

        if (pixelbytes == 6)
        {
            if (channel == 0)
            {
                memset(ptrL, 0, 6 * (int)line);
                ptrL += ((int)line * 3);
                ptrL[0] = (int)((float)ptrL[0] * (1.0 - frac));
                ptrL[1] = (int)((float)ptrL[1] * (1.0 - frac));
                ptrL[2] = (int)((float)ptrL[2] * (1.0 - frac));
            }
            else
            {
                ptrR += ((width - (int)line) * 3);
                memset(ptrR, 0, 6 * (int)line);
                ptrR[-1] = (int)((float)ptrR[-1] * (1.0 - frac));
                ptrR[-2] = (int)((float)ptrR[-2] * (1.0 - frac));
                ptrR[-3] = (int)((float)ptrR[-3] * (1.0 - frac));
            }
        }
        else
        {
            if (channel == 0)
            {
                memset(ptrL, 0, 8 * (int)line);
                ptrL += ((int)line * 4);
                ptrL[0] = (int)((float)ptrL[0] * (1.0 - frac));
                ptrL[1] = (int)((float)ptrL[1] * (1.0 - frac));
                ptrL[2] = (int)((float)ptrL[2] * (1.0 - frac));
                ptrL[3] = (int)((float)ptrL[3] * (1.0 - frac));
            }
            else
            {
                ptrR += ((width - (int)line) * 4);
                memset(ptrR, 0, 8 * (int)line);
                ptrR[-1] = (int)((float)ptrR[-1] * (1.0 - frac));
                ptrR[-2] = (int)((float)ptrR[-2] * (1.0 - frac));
                ptrR[-3] = (int)((float)ptrR[-3] * (1.0 - frac));
                ptrR[-4] = (int)((float)ptrR[-4] * (1.0 - frac));
            }
        }
    }
    else
    {
        unsigned short *ptrL = RGB48;
        unsigned short *ptrR = RGB48;

        if (windowMask < 0)
            channel = channel == 0 ? 1 : 0;

        if (pixelbytes == 6)
        {
            if (channel == 0)
            {
                memset(ptrL, 0, 6 * (int)line);
                ptrL += ((int)line * 3);
                ptrL[0] = (int)((float)ptrL[0] * (1.0 - frac));
                ptrL[1] = (int)((float)ptrL[1] * (1.0 - frac));
                ptrL[2] = (int)((float)ptrL[2] * (1.0 - frac));
            }
            else
            {
                ptrR += ((width - (int)line) * 3);
                memset(ptrR, 0, 6 * (int)line);
                ptrR[-1] = (int)((float)ptrR[-1] * (1.0 - frac));
                ptrR[-2] = (int)((float)ptrR[-2] * (1.0 - frac));
                ptrR[-3] = (int)((float)ptrR[-3] * (1.0 - frac));
            }
        }
        else
        {
            if (channel == 0)
            {
                memset(ptrL, 0, 8 * (int)line);
                ptrL += ((int)line * 4);
                ptrL[0] = (int)((float)ptrL[0] * (1.0 - frac));
                ptrL[1] = (int)((float)ptrL[1] * (1.0 - frac));
                ptrL[2] = (int)((float)ptrL[2] * (1.0 - frac));
                ptrL[3] = (int)((float)ptrL[3] * (1.0 - frac));
            }
            else
            {
                ptrR += ((width - (int)line) * 4);
                memset(ptrR, 0, 8 * (int)line);
                ptrR[-1] = (int)((float)ptrR[-1] * (1.0 - frac));
                ptrR[-2] = (int)((float)ptrR[-2] * (1.0 - frac));
                ptrR[-3] = (int)((float)ptrR[-3] * (1.0 - frac));
                ptrR[-4] = (int)((float)ptrR[-4] * (1.0 - frac));
            }
        }
    }
}


void RGB48HoriShift(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer, int width, float offset, int flip)
{
    float xposf, remainf;
    int xposi, tablepos, x;
    int gainA, gainB, gainC, gainD;
    //int endofSSEline = 0;
    unsigned short *scanline = (unsigned short *)buffer;
    int neg = 0, shift = 0;

    __m128i l1, l2, l3, gA, gB, gC, gD, o128, t1, t2;
    __m128i *line128, *outline128;

    if (flip)
    {
        unsigned short *ptrL = RGB48;
        unsigned short *ptrR = RGB48;
        ptrR += (width * 3) - 3;
        for (x = 0; x < width / 2; x++)
        {
            int t1, t2, t3;

            t1 = ptrL[0];
            ptrL[0] = ptrR[0];
            ptrR[0] = t1;
            t2 = ptrL[1];
            ptrL[1] = ptrR[1];
            ptrR[1] = t2;
            t3 = ptrL[2];
            ptrL[2] = ptrR[2];
            ptrR[2] = t3;
            ptrL += 3;
            ptrR -= 3;
        }
    }

    if (offset < 0.0)
        neg = 1;

    xposf = width * offset;
    xposi = (int)floorf(xposf);

    remainf = xposf - (float)xposi;
    tablepos = (int)(remainf * (float)SUBPIXEL);

    xposi = abs(xposi);

    if (xposi == 0 && tablepos == 0)
        return; // no move required

    gainA = gains[tablepos][0];
    gainB = gains[tablepos][1];
    gainC = gains[tablepos][2];
    gainD = gains[tablepos][3];


    if (neg == 0)
    {
        unsigned short *ptr = scanline;
        int nwidth = width - xposi + 16;
        if (nwidth > width)
            nwidth = width;

        for (x = 0; x < xposi + 2; x++)
        {
            *ptr++ = 0;//r
            *ptr++ = 0;//g
            *ptr++ = 0;//b
        }

        memcpy(ptr, RGB48, (nwidth) * 3 * 2);
        ptr += (nwidth) * 3;
        for (x = 0; x < 16; x++)
        {
            *ptr++ = 0;//r
            *ptr++ = 0;//g
            *ptr++ = 0;//b
        }
    }
    else
    {
        unsigned short *ptr = scanline;

        for (x = 0; x < 2; x++)
        {
            if (x + xposi - 2 >= 0)
            {
                *ptr++ = RGB48[(x + xposi - 2) * 3]; //r
                *ptr++ = RGB48[(x + xposi - 2) * 3 + 1]; //g
                *ptr++ = RGB48[(x + xposi - 2) * 3 + 2]; //b
            }
            else
            {
                *ptr++ = 0;//r
                *ptr++ = 0;//g
                *ptr++ = 0;//b
            }
        }

        memcpy(ptr, &RGB48[xposi * 3], (width - xposi) * 3 * 2);
        ptr += (width - xposi) * 3;
        for (x = 0; x < xposi + 16; x++)
        {
            *ptr++ = 0;//r
            *ptr++ = 0;//g
            *ptr++ = 0;//b
        }
    }

    gA = _mm_set1_epi16(gainA);
    gB = _mm_set1_epi16(gainB);
    gC = _mm_set1_epi16(gainC);
    gD = _mm_set1_epi16(gainD);

    line128 = (__m128i *)&scanline[0];
    //outline128 = line128;
    outline128 = (__m128i *)&RGB48[0];

    //l1 = load128;//r1,g1,b1,r2,g2,b2,r3,g3,
    //l2 = load128;//b3,r4,g4,b4,r5,g5,b5,r6
    //l3 = load128;//g6,b6,r7,g7,b7,r8,g8,b8


    if (decoder->StereoBufferFormat == DECODED_FORMAT_WP13)
    {
        l1 =  _mm_loadu_si128(line128++);
        l2 =  _mm_loadu_si128(line128++);
        l3 =  _mm_loadu_si128(line128++);

        shift = 0;
    }
    else
    {
        l1 =  _mm_loadu_si128(line128++);
        l1 = _mm_srli_epi16(l1, 3); //13-bit unsigned
        l2 =  _mm_loadu_si128(line128++);
        l2 = _mm_srli_epi16(l2, 3); //13-bit unsigned
        l3 =  _mm_loadu_si128(line128++);
        l3 = _mm_srli_epi16(l3, 3); //13-bit unsigned

        shift = 3;
    }



    for (x = 0; x < width * 3; x += 8)
    {
        //o=l1* gainA
        o128 = _mm_mulhi_epi16(l1, gA);

        //t1 = l1<<3*16	//t1 = r2,g2,b2,r3,g3, 0 0 0
        //t2 = l2>>16*5	//t2 = 0  0  0  0  0  b3,r4,g4
        //t1 += t2;		//t1 = r2,g2,b2,r3,g3,b3,r4,g4
        //l1 = t1			//l1 = r2,g2,b2,r3,g3,b3,r4,g4
        //t1 *= gainB
        //o  += t1
        t1 = _mm_srli_si128(l1, 3 * 2);
        t2 = _mm_slli_si128(l2, 5 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        l1 = t1;
        t1 = _mm_mulhi_epi16(t1, gB);
        o128 = _mm_adds_epi16(o128, t1);


        //t1 = l1<<3*16	//t1 = r3,g3,b3,r4,g4 0  0  0
        //t2 = l2<<3*16;	//t2 = b4,r5,g5,b5,r6 0  0  0
        //t2 >>= 5*16;	//t2 = 0  0  0  0  0  b4,r5,g5
        //t1 += t2		//t1 = r3,g3,b3,r4,g4,b4,r5,g5
        //l1 = t1			//l1 = r3,g3,b3,r4,g4,b4,r5,g5
        //t1 *= gainC
        //o  += t1
        t1 = _mm_srli_si128(l1, 3 * 2);
        t2 = _mm_srli_si128(l2, 3 * 2);
        t2 = _mm_slli_si128(t2, 5 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        l1 = t1;
        t1 = _mm_mulhi_epi16(t1, gC);
        o128 = _mm_adds_epi16(o128, t1);


        //t1 = l1<<3*16	//t1 = r4,g4,b4,r5,g5 0  0  0
        //t2 = l2<<6*16	//t2 = b5,r6 0  0  0  0  0  0
        //t2 >>= 5 * 16;	//t2 = 0  0  0  0  0  b5,r6 0
        //t1 += t2		//t1 = r4,g4,b4,r5,g5,b5,r6, 0
        //t2 = l3>>7*16	//t2 = 0  0  0  0  0  0  0  g6
        //t1 += t2		//t1 = r4,g4,b4,r5,g5,b5,r6,g6
        //t1 *= gainD
        //o  += t1
        t1 = _mm_srli_si128(l1, 3 * 2);
        t2 = _mm_srli_si128(l2, 6 * 2);
        t2 = _mm_slli_si128(t2, 5 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        t2 = _mm_slli_si128(l3, 7 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        t1 = _mm_mulhi_epi16(t1, gD);
        o128 = _mm_adds_epi16(o128, t1);

        l1 = l2;
        l2 = l3;
        l3 = _mm_loadu_si128(line128++);

        if (shift)
        {
            l3 = _mm_srli_epi16(l3, 3); //13-bit unsigned

            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
            o128 = _mm_slli_epi16(o128, 4);
        }
        else
        {
            // upper limit to 32767
            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
            o128 = _mm_slli_epi16(o128, 1);
        }
        _mm_storeu_si128(outline128++, o128);

    }
}


void RGBA64HoriShift(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer, int width, float offset, int flip)
{
    float xposf, remainf;
    int xposi, tablepos, x;
    int gainA, gainB, gainC, gainD;
    //int endofSSEline = 0;
    unsigned short *scanline = (unsigned short *)buffer;
    int neg = 0, shift = 0;

    __m128i l1, l2, l3, gA, gB, gC, gD, o128, t1, t2;
    __m128i *line128, *outline128;

    if (flip)
    {
        unsigned short *ptrL = RGB48;
        unsigned short *ptrR = RGB48;
        ptrR += (width * 4) - 4;
        for (x = 0; x < width / 2; x++)
        {
            int t1, t2, t3, t4;

            t1 = ptrL[0];
            ptrL[0] = ptrR[0];
            ptrR[0] = t1;
            t2 = ptrL[1];
            ptrL[1] = ptrR[1];
            ptrR[1] = t2;
            t3 = ptrL[2];
            ptrL[2] = ptrR[2];
            ptrR[2] = t3;
            t4 = ptrL[2];
            ptrL[3] = ptrR[3];
            ptrR[3] = t4;
            ptrL += 4;
            ptrR -= 4;
        }
    }

    if (offset < 0.0)
        neg = 1;

    xposf = width * offset;
    xposi = (int)floorf(xposf);

    remainf = xposf - (float)xposi;
    tablepos = (int)(remainf * (float)SUBPIXEL);

    xposi = abs(xposi);

    if (xposi == 0 && tablepos == 0)
        return; // no move required

    gainA = gains[tablepos][0];
    gainB = gains[tablepos][1];
    gainC = gains[tablepos][2];
    gainD = gains[tablepos][3];


    if (neg == 0)
    {
        unsigned short *ptr = scanline;
        int nwidth = width - xposi + 16;
        if (nwidth > width)
            nwidth = width;

        for (x = 0; x < xposi + 2; x++)
        {
            *ptr++ = 0;//r
            *ptr++ = 0;//g
            *ptr++ = 0;//b
            *ptr++ = 0;//a
        }

        memcpy(ptr, RGB48, (nwidth) * 4 * 2);
        ptr += (nwidth) * 4;
        for (x = 0; x < 16; x++)
        {
            *ptr++ = 0;//r
            *ptr++ = 0;//g
            *ptr++ = 0;//b
            *ptr++ = 0;//a
        }
    }
    else
    {
        unsigned short *ptr = scanline;

        for (x = 0; x < 2; x++)
        {
            if (x + xposi - 2 >= 0)
            {
                *ptr++ = RGB48[(x + xposi - 2) * 4]; //r
                *ptr++ = RGB48[(x + xposi - 2) * 4 + 1]; //g
                *ptr++ = RGB48[(x + xposi - 2) * 4 + 2]; //b
                *ptr++ = RGB48[(x + xposi - 2) * 4 + 3]; //a
            }
            else
            {
                *ptr++ = 0;//r
                *ptr++ = 0;//g
                *ptr++ = 0;//b
                *ptr++ = 0;//a
            }
        }

        memcpy(ptr, &RGB48[xposi * 4], (width - xposi) * 4 * 2);
        ptr += (width - xposi) * 4;
        for (x = 0; x < xposi + 16; x++)
        {
            *ptr++ = 0;//r
            *ptr++ = 0;//g
            *ptr++ = 0;//b
            *ptr++ = 0;//a
        }
    }

    gA = _mm_set1_epi16(gainA);
    gB = _mm_set1_epi16(gainB);
    gC = _mm_set1_epi16(gainC);
    gD = _mm_set1_epi16(gainD);

    line128 = (__m128i *)&scanline[0];
    //outline128 = line128;
    outline128 = (__m128i *)&RGB48[0];

    //l1 = load128;//r1,g1,b1,a1,r2,g2,b2,a2,
    //l2 = load128;//r3,g3,b3,a3,r4,g4,b4,a4,
    //l3 = load128;//r5,g5,b5,a5,r6,g6,b6,a6,
    //l4 = load128;//r7,g7,b7,a7,r8,g8,b8,a8,


    if (decoder->StereoBufferFormat == DECODED_FORMAT_WP13 || decoder->StereoBufferFormat == DECODED_FORMAT_W13A)
    {
        l1 =  _mm_loadu_si128(line128++);
        l2 =  _mm_loadu_si128(line128++);
        l3 =  _mm_loadu_si128(line128++);

        shift = 0;
    }
    else
    {
        l1 =  _mm_loadu_si128(line128++);
        l1 = _mm_srli_epi16(l1, 3); //13-bit unsigned
        l2 =  _mm_loadu_si128(line128++);
        l2 = _mm_srli_epi16(l2, 3); //13-bit unsigned
        l3 =  _mm_loadu_si128(line128++);
        l3 = _mm_srli_epi16(l3, 3); //13-bit unsigned

        shift = 3;
    }



    for (x = 0; x < width * 4; x += 8)
    {
        //o=l1* gainA
        o128 = _mm_mulhi_epi16(l1, gA);

        //t1 = l1<<4*16	//t1 = r2,g2,b2,a2,0, 0 0 0
        //t2 = l2>>4*16	//t2 = 0  0  0  0  r3,g3,b3,a4
        //t1 += t2;		//t1 = r2,g2,b2,a2,r3,g3,b3,a4
        //l1 = t1		//l1 = r2,g2,b2,a2,r3,g3,b3,a4
        //t1 *= gainB
        //o  += t1
        t1 = _mm_srli_si128(l1, 4 * 2);
        t2 = _mm_slli_si128(l2, 4 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        l1 = t1;
        t1 = _mm_mulhi_epi16(t1, gB);
        o128 = _mm_adds_epi16(o128, t1);


        //t1 = l1<<4*16	//t1 = r3,g3,b3,a3, 0  0  0  0
        //t2 = l2<<4*16;//t2 = r4,g4,b4,a4, 0  0  0  0
        //t2 >>= 4*16;	//t2 = 0  0  0  0  r4,g4,b4,a4
        //t1 += t2		//t1 = r3,g3,b3,a4,r4,g4,b4,a4
        //l1 = t1		//l1 = r3,g3,b3,a4,r4,g4,b4,a4
        //t1 *= gainC
        //o  += t1
        t1 = _mm_srli_si128(l1, 4 * 2);
        t2 = _mm_srli_si128(l2, 4 * 2);
        t2 = _mm_slli_si128(t2, 4 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        l1 = t1;
        t1 = _mm_mulhi_epi16(t1, gC);
        o128 = _mm_adds_epi16(o128, t1);


        //t1 = l1<<4*16	//t1 = r4,g4,b4,a4,0  0  0  0
        //t2 = l3>>4*16	//t2 = 0 0  0  0   r5,g5,b5,a5
        //t1 += t2		//t1 = r4,g4,b4,a4,r5,g5,b5,a5
        //t1 *= gainD
        //o  += t1
        t1 = _mm_srli_si128(l1, 4 * 2);
        t2 = _mm_slli_si128(l3, 4 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        t1 = _mm_mulhi_epi16(t1, gD);
        o128 = _mm_adds_epi16(o128, t1);

        l1 = l2;
        l2 = l3;
        l3 = _mm_loadu_si128(line128++);

        if (shift)
        {
            l3 = _mm_srli_epi16(l3, 3); //13-bit unsigned

            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
            o128 = _mm_slli_epi16(o128, 4);
        }
        else
        {
            // upper limit to 32767
            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
            o128 = _mm_slli_epi16(o128, 1);
        }
        _mm_storeu_si128(outline128++, o128);

    }
}



void RGB48HoriShiftAnaglyph(DECODER *decoder, unsigned short *RGB48, unsigned short *buffer, int width,
                            float offsetR, float offsetG, float offsetB,
                            int flipR, int flipG, int flipB)
{
    float Rxposf, Rremainf;
    int Rxposi, Rtablepos;
    float Gxposf, Gremainf;
    int Gxposi, Gtablepos;
    float Bxposf, Bremainf;
    int Bxposi, Btablepos;
    int x;
    int RgainA, RgainB, RgainC, RgainD;
    int GgainA, GgainB, GgainC, GgainD;
    int BgainA, BgainB, BgainC, BgainD;
    //int endofSSEline = 0;
    unsigned short *scanline = (unsigned short *)buffer;
    int negR = 0;
    int negG = 0;
    int negB = 0;
    int shift = 0;

    __m128i l1, l2, l3, o128, t1, t2;
    __m128i *line128, *outline128;
    __m128i gA1, gB1, gC1, gD1, gA2, gB2, gC2, gD2, gA3, gB3, gC3, gD3;

    if (flipR)
    {
        unsigned short *ptrL = RGB48;
        unsigned short *ptrR = RGB48;
        ptrR += (width * 3) - 3;
        for (x = 0; x < width / 2; x++)
        {
            int t;

            t = *ptrL;
            *ptrL = *ptrR;
            *ptrR = t;
            ptrL += 3;
            ptrR -= 3;
        }
    }

    if (flipG)
    {
        unsigned short *ptrL = &RGB48[1];
        unsigned short *ptrR = &RGB48[1];
        ptrR += (width * 3) - 3;
        for (x = 0; x < width / 2; x++)
        {
            int t;

            t = *ptrL;
            *ptrL = *ptrR;
            *ptrR = t;
            ptrL += 3;
            ptrR -= 3;
        }
    }

    if (flipB)
    {
        unsigned short *ptrL = &RGB48[2];
        unsigned short *ptrR = &RGB48[2];
        ptrR += (width * 3) - 3;
        for (x = 0; x < width / 2; x++)
        {
            int t;

            t = *ptrL;
            *ptrL = *ptrR;
            *ptrR = t;
            ptrL += 3;
            ptrR -= 3;
        }
    }

    if (offsetR < 0.0)
        negR = 1;
    if (offsetG < 0.0)
        negG = 1;
    if (offsetB < 0.0)
        negB = 1;

    Rxposf = width * offsetR;
    Rxposi = (int)floorf(Rxposf);
    Rremainf = Rxposf - (float)Rxposi;
    Rtablepos = (int)(Rremainf * (float)SUBPIXEL);

    Gxposf = width * offsetG;
    Gxposi = (int)floorf(Gxposf);
    Gremainf = Gxposf - (float)Gxposi;
    Gtablepos = (int)(Gremainf * (float)SUBPIXEL);

    Bxposf = width * offsetB;
    Bxposi = (int)floorf(Bxposf);
    Bremainf = Bxposf - (float)Bxposi;
    Btablepos = (int)(Bremainf * (float)SUBPIXEL);

    Rxposi = abs(Rxposi);
    Gxposi = abs(Gxposi);
    Bxposi = abs(Bxposi);

    if (Rxposi == 0 && Rtablepos == 0)
        return; // no move required

    RgainA = gains[Rtablepos][0];
    RgainB = gains[Rtablepos][1];
    RgainC = gains[Rtablepos][2];
    RgainD = gains[Rtablepos][3];

    GgainA = gains[Gtablepos][0];
    GgainB = gains[Gtablepos][1];
    GgainC = gains[Gtablepos][2];
    GgainD = gains[Gtablepos][3];

    BgainA = gains[Btablepos][0];
    BgainB = gains[Btablepos][1];
    BgainC = gains[Btablepos][2];
    BgainD = gains[Btablepos][3];

    if (negR == 0)
    {
        unsigned short *ptr = scanline;
        int nwidth = width - Rxposi + 16;
        if (nwidth > width)
            nwidth = width;

        for (x = 0; x < Rxposi + 2; x++)
        {
            *ptr++ = 0;//r
            ptr++;//g
            ptr++;//b
        }
        for (x = 0; x < nwidth; x++)
        {
            *ptr++ = RGB48[x * 3]; //r
            ptr++;//g
            ptr++;//b
        }
        for (x = 0; x < 16; x++)
        {
            *ptr++ = 0;//r
            ptr++;//g
            ptr++;//b
        }
    }
    else
    {
        unsigned short *ptr = scanline;

        for (x = 0; x < 2; x++)
        {
            if (x + Rxposi - 2 >= 0)
            {
                *ptr++ = RGB48[(x + Rxposi - 2) * 3]; //r
                ptr++;//g
                ptr++;//b
            }
            else
            {
                *ptr++ = 0;//r
                ptr++;//g
                ptr++;//b
            }
        }

        //memcpy(ptr, &RGB48[xposi*3], (width-xposi)*3*2);
        //ptr += (width-xposi)*3;

        for (x = Rxposi; x < width; x++)
        {
            *ptr++ = RGB48[x * 3]; //r
            ptr++;//g
            ptr++;//b
        }
        for (x = 0; x < Rxposi + 16; x++)
        {
            *ptr++ = 0;//r
            ptr++;//g
            ptr++;//b
        }
    }


    if (negG == 0)
    {
        unsigned short *ptr = scanline;
        int nwidth = width - Gxposi + 16;
        if (nwidth > width)
            nwidth = width;

        for (x = 0; x < Gxposi + 2; x++)
        {
            ptr++;//r
            *ptr++ = 0;//g
            ptr++;//b
        }
        for (x = 0; x < nwidth; x++)
        {
            ptr++;//r
            *ptr++ = RGB48[x * 3 + 1]; //g
            ptr++;//b
        }
        for (x = 0; x < 16; x++)
        {
            ptr++;//r
            *ptr++ = 0;//g
            ptr++;//b
        }
    }
    else
    {
        unsigned short *ptr = scanline;

        for (x = 0; x < 2; x++)
        {
            if (x + Gxposi - 2 >= 0)
            {
                ptr++;//r
                *ptr++ = RGB48[(x + Gxposi - 2) * 3 + 1]; //g
                ptr++;//b
            }
            else
            {
                ptr++;//r
                *ptr++ = 0;//g
                ptr++;//b
            }
        }

        //memcpy(ptr, &RGB48[xposi*3], (width-xposi)*3*2);
        //ptr += (width-xposi)*3;

        for (x = Gxposi; x < width; x++)
        {
            ptr++;//r
            *ptr++ = RGB48[x * 3 + 1]; //g
            ptr++;//b
        }
        for (x = 0; x < Gxposi + 16; x++)
        {
            ptr++;//r
            *ptr++ = 0;//g
            ptr++;//b
        }
    }


    if (negB == 0)
    {
        unsigned short *ptr = scanline;
        int nwidth = width - Bxposi + 16;
        if (nwidth > width)
            nwidth = width;

        for (x = 0; x < Bxposi + 2; x++)
        {
            ptr++;//r
            ptr++;//g
            *ptr++ = 0;//b
        }
        for (x = 0; x < nwidth; x++)
        {
            ptr++;//r
            ptr++;//g
            *ptr++ = RGB48[x * 3 + 2]; //b
        }
        for (x = 0; x < 16; x++)
        {
            ptr++;//r
            ptr++;//g
            *ptr++ = 0;//b
        }
    }
    else
    {
        unsigned short *ptr = scanline;

        for (x = 0; x < 2; x++)
        {
            if (x + Bxposi - 2 >= 0)
            {
                ptr++;//r
                ptr++;//g
                *ptr++ = RGB48[(x + Bxposi - 2) * 3 + 2]; //b
            }
            else
            {
                ptr++;//r
                ptr++;//g
                *ptr++ = 0;//b
            }
        }

        //memcpy(ptr, &RGB48[xposi*3], (width-xposi)*3*2);
        //ptr += (width-xposi)*3;

        for (x = Bxposi; x < width; x++)
        {
            ptr++;//r
            ptr++;//g
            *ptr++ = RGB48[x * 3 + 2]; //b
        }
        for (x = 0; x < Bxposi + 16; x++)
        {
            ptr++;//r
            ptr++;//g
            *ptr++ = 0;//b
        }
    }


    gA1 = _mm_set_epi16(RgainA, GgainA, BgainA, RgainA, GgainA, BgainA, RgainA, GgainA);
    gA2 = _mm_set_epi16(BgainA, RgainA, GgainA, BgainA, RgainA, GgainA, BgainA, RgainA);
    gA3 = _mm_set_epi16(GgainA, BgainA, RgainA, GgainA, BgainA, RgainA, GgainA, BgainA);

    gB1 = _mm_set_epi16(RgainB, GgainB, BgainB, RgainB, GgainB, BgainB, RgainB, GgainB);
    gB2 = _mm_set_epi16(BgainB, RgainB, GgainB, BgainB, RgainB, GgainB, BgainB, RgainB);
    gB3 = _mm_set_epi16(GgainB, BgainB, RgainB, GgainB, BgainB, RgainB, GgainB, BgainB);

    gC1 = _mm_set_epi16(RgainC, GgainC, BgainC, RgainC, GgainC, BgainC, RgainC, GgainC);
    gC2 = _mm_set_epi16(BgainC, RgainC, GgainC, BgainC, RgainC, GgainC, BgainC, RgainC);
    gC3 = _mm_set_epi16(GgainC, BgainC, RgainC, GgainC, BgainC, RgainC, GgainC, BgainC);

    gD1 = _mm_set_epi16(RgainD, GgainD, BgainD, RgainD, GgainD, BgainD, RgainD, GgainD);
    gD2 = _mm_set_epi16(BgainD, RgainD, GgainD, BgainD, RgainD, GgainD, BgainD, RgainD);
    gD3 = _mm_set_epi16(GgainD, BgainD, RgainD, GgainD, BgainD, RgainD, GgainD, BgainD);

    line128 = (__m128i *)&scanline[0];
    //outline128 = line128;
    outline128 = (__m128i *)&RGB48[0];

    //l1 = load128;//r1,g1,b1,r2,g2,b2,r3,g3,
    //l2 = load128;//b3,r4,g4,b4,r5,g5,b5,r6
    //l3 = load128;//g6,b6,r7,g7,b7,r8,g8,b8
    if (decoder->StereoBufferFormat == DECODED_FORMAT_WP13)
    {
        l1 =  _mm_loadu_si128(line128++);
        l2 =  _mm_loadu_si128(line128++);
        l3 =  _mm_loadu_si128(line128++);

        shift = 0;
    }
    else
    {
        l1 =  _mm_loadu_si128(line128++);
        l1 = _mm_srli_epi16(l1, 3); //13-bit unsigned
        l2 =  _mm_loadu_si128(line128++);
        l2 = _mm_srli_epi16(l2, 3); //13-bit unsigned
        l3 =  _mm_loadu_si128(line128++);
        l3 = _mm_srli_epi16(l3, 3); //13-bit unsigned

        shift = 3;
    }

    for (x = 0; x < width * 3; x += 8)
    {
        //o=l1* gainA
        o128 = _mm_mulhi_epi16(l1, gA1);

        //t1 = l1<<3*16	//t1 = r2,g2,b2,r3,g3, 0 0 0
        //t2 = l2>>16*5	//t2 = 0  0  0  0  0  b3,r4,g4
        //t1 += t2;		//t1 = r2,g2,b2,r3,g3,b3,r4,g4
        //l1 = t1			//l1 = r2,g2,b2,r3,g3,b3,r4,g4
        //t1 *= gainB
        //o  += t1
        t1 = _mm_srli_si128(l1, 3 * 2);
        t2 = _mm_slli_si128(l2, 5 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        l1 = t1;
        t1 = _mm_mulhi_epi16(t1, gB1);
        o128 = _mm_adds_epi16(o128, t1);


        //t1 = l1<<3*16	//t1 = r3,g3,b3,r4,g4 0  0  0
        //t2 = l2<<3*16;	//t2 = b4,r5,g5,b5,r6 0  0  0
        //t2 >>= 5*16;	//t2 = 0  0  0  0  0  b4,r5,g5
        //t1 += t2		//t1 = r3,g3,b3,r4,g4,b4,r5,g5
        //l1 = t1			//l1 = r3,g3,b3,r4,g4,b4,r5,g5
        //t1 *= gainC
        //o  += t1
        t1 = _mm_srli_si128(l1, 3 * 2);
        t2 = _mm_srli_si128(l2, 3 * 2);
        t2 = _mm_slli_si128(t2, 5 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        l1 = t1;
        t1 = _mm_mulhi_epi16(t1, gC1);
        o128 = _mm_adds_epi16(o128, t1);


        //t1 = l1<<3*16	//t1 = r4,g4,b4,r5,g5 0  0  0
        //t2 = l2<<6*16	//t2 = b5,r6 0  0  0  0  0  0
        //t2 >>= 5 * 16;	//t2 = 0  0  0  0  0  b5,r6 0
        //t1 += t2		//t1 = r4,g4,b4,r5,g5,b5,r6, 0
        //t2 = l3>>7*16	//t2 = 0  0  0  0  0  0  0  g6
        //t1 += t2		//t1 = r4,g4,b4,r5,g5,b5,r6,g6
        //t1 *= gainD
        //o  += t1
        t1 = _mm_srli_si128(l1, 3 * 2);
        t2 = _mm_srli_si128(l2, 6 * 2);
        t2 = _mm_slli_si128(t2, 5 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        t2 = _mm_slli_si128(l3, 7 * 2);
        t1 = _mm_adds_epi16(t1, t2);
        t1 = _mm_mulhi_epi16(t1, gD1);
        o128 = _mm_adds_epi16(o128, t1);


        t1 = gA1;
        gA1 = gA2;
        gA2 = gA3;
        gA3 = t1;

        t1 = gB1;
        gB1 = gB2;
        gB2 = gB3;
        gB3 = t1;

        t1 = gC1;
        gC1 = gC2;
        gC2 = gC3;
        gC3 = t1;

        t1 = gD1;
        gD1 = gD2;
        gD2 = gD3;
        gD3 = t1;


        l1 = l2;
        l2 = l3;
        l3 = _mm_loadu_si128(line128++);

        if (shift)
        {
            l3 = _mm_srli_epi16(l3, 3); //13-bit unsigned

            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x0fff));
            o128 = _mm_slli_epi16(o128, 4);
        }
        else
        {
            // upper limit to 32767
            o128 = _mm_adds_epi16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
            o128 = _mm_subs_epu16(o128, _mm_set1_epi16(0x7fff - 0x3fff));
            o128 = _mm_slli_epi16(o128, 1);
        }
        _mm_storeu_si128(outline128++, o128);

    }
}


void HistogramLine(DECODER *decoder, unsigned short *sbase, int width, int format, int whitepoint)
{
    int x, val, ypos = 0, upos = 1, vpos = 3;
    int step = 1, pos = 0;
    short *ssbase = (short *)sbase;
    uint32_t *lbase = (uint32_t *)sbase;
    ToolsHandle *tools = decoder->tools;
    int scaledvectorscope = 0;

    if (tools == NULL)
        return;

    if (whitepoint == 13)
    {
        if (format == DECODED_FORMAT_RG64)
            format = DECODED_FORMAT_W13A;
        else
            format = DECODED_FORMAT_WP13;
    }
    while (width / step > 360)
    {
        step *= 2;
    }

    tools->waveformWidth = width / step;
    decoder->tools->blurUVdone = 0;

    switch (format & 0xffffff)
    {
        case DECODED_FORMAT_WP13:
            decoder->tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                R = ssbase[0] >> 5;
                G = ssbase[1] >> 5;
                B = ssbase[2] >> 5;

                if (R > 255) R = 255;
                if (R < 0) R = 0;
                if (G > 255) G = 255;
                if (G < 0) G = 0;
                if (B > 255) B = 255;
                if (B < 0) B = 0;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;

                ssbase += step * 3;
            }
            break;

        case DECODED_FORMAT_W13A:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                R = ssbase[0] >> 5;
                G = ssbase[1] >> 5;
                B = ssbase[2] >> 5;

                if (R > 255) R = 255;
                if (R < 0) R = 0;
                if (G > 255) G = 255;
                if (G < 0) G = 0;
                if (B > 255) B = 255;
                if (B < 0) B = 0;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;

                ssbase += step * 4;
            }
            break;

        case DECODED_FORMAT_RG48:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                R = sbase[0] >> 8;
                G = sbase[1] >> 8;
                B = sbase[2] >> 8;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;

                sbase += step * 3;
            }
            break;


        case DECODED_FORMAT_AB10:
        case DECODED_FORMAT_RG30:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                val = lbase[x];

                R = (val >> 22) & 0xff;
                G = (val >> 12) & 0xff;
                B = (val >> 02) & 0xff;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case DECODED_FORMAT_AR10:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                val = lbase[x];

                B = (val >> 22) & 0xff;
                G = (val >> 12) & 0xff;
                R = (val >> 02) & 0xff;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case DECODED_FORMAT_R210:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                val = SwapInt32BtoN(lbase[x]);

                R = (val >> 22) & 0xff;
                G = (val >> 12) & 0xff;
                B = (val >> 02) & 0xff;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case DECODED_FORMAT_DPX0:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                val = SwapInt32BtoN(lbase[x]);

                R = (val >> 24) & 0xff;
                G = (val >> 14) & 0xff;
                B = (val >> 04) & 0xff;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case DECODED_FORMAT_RG64:
        case DECODED_FORMAT_B64A:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int32_t R, G, B, U, V;
                R = sbase[1] >> 8;
                G =	sbase[2] >> 8;
                B = sbase[3] >> 8;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;

                sbase += step * 4;
            }
            break;

        case COLOR_FORMAT_UYVY:
            ypos = 1, upos = 0, vpos = 2;
        case DECODED_FORMAT_CbYCrY_8bit:		// CMD: 20100109
        case COLOR_FORMAT_YUYV:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int Y, U, V, R, G, B;
                uint8_t *bptr = (uint8_t *)sbase;
                bptr +=  x * 2;

                Y = bptr[ypos] - 16;
                U = bptr[upos] - 128;
                Y += bptr[ypos + 2] - 16;
                Y >>= 1;
                V = bptr[vpos] - 128;

                R = (9535 * Y + 14688 * V) >> 13; //13-bit white
                G = (9535 * Y - 4375 * V - 1745 * U) >> 13;
                B = (9535 * Y + 17326 * U) >> 13;

                //TODO much -20 to 120 RGB range.
                if (R > 255) R = 255;
                if (R < 0) R = 0;
                if (G > 255) G = 255;
                if (G < 0) G = 0;
                if (B > 255) B = 255;
                if (B < 0) B = 0;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                if (scaledvectorscope)
                {
                    U *= 255;
                    U /= 314;
                    V *= 255;
                    V /= 244;
                }
                //* 255.0/314.0
                //* 255.0/244.0
                U += 128;
                V += 128;
                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case COLOR_FORMAT_YU64:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int Y, U, V, R, G, B;
                uint8_t *bptr = (uint8_t *)sbase;
                bptr +=  x * 4;
                bptr++; //read only the high byte out of the 16-bit

                Y = bptr[0] - 16;
                V = bptr[2] - 128;
                Y += bptr[4] - 16;
                Y >>= 1;
                U = bptr[6] - 128;

                R = (9535 * Y + 14688 * V) >> 13; //13-bit white
                G = (9535 * Y - 4375 * V - 1745 * U) >> 13;
                B = (9535 * Y + 17326 * U) >> 13;

                if (R > 255) R = 255;
                if (R < 0) R = 0;
                if (G > 255) G = 255;
                if (G < 0) G = 0;
                if (B > 255) B = 255;
                if (B < 0) B = 0;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                if (scaledvectorscope)
                {
                    U *= 255;
                    U /= 314;
                    V *= 255;
                    V /= 244;
                }
                U += 128;
                V += 128;
                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;



        case COLOR_FORMAT_V210:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int Y, U, V, R, G, B;
                uint32_t *lptr = (uint32_t *)sbase;
                lptr += (x / 6) * 4;

                switch (x % 6)
                {
                    case 0:
                        V = ((*lptr >> 02) & 0xff) - 128;
                        Y = ((*lptr >> 12) & 0xff) - 16;
                        U = ((*lptr >> 22) & 0xff) - 128;
                        lptr++;
                        Y += ((*lptr >> 02) & 0xff) - 16;
                        Y >>= 1;
                        break;
                    case 1:
                        lptr++;
                        Y = ((*lptr >> 02) & 0xff) - 16;
                        V = ((*lptr >> 12) & 0xff) - 128;
                        Y += ((*lptr >> 22) & 0xff) - 16;
                        Y >>= 1;
                        lptr--;
                        U = ((*lptr >> 22) & 0xff) - 128;
                        break;
                    case 2:
                        lptr++;
                        Y = ((*lptr >> 22) & 0xff) - 16;
                        lptr++;
                        U = ((*lptr >> 02) & 0xff) - 128;
                        Y += ((*lptr >> 12) & 0xff) - 16;
                        Y >>= 1;
                        V = ((*lptr >> 22) & 0xff) - 128;
                        break;
                    case 3:
                        lptr++;
                        V = ((*lptr >> 12) & 0xff) - 128;
                        lptr++;
                        U = ((*lptr >> 02) & 0xff) - 128;
                        Y = ((*lptr >> 12) & 0xff) - 16;
                        lptr++;
                        Y += ((*lptr >> 02) & 0xff) - 16;
                        Y >>= 1;
                        break;
                    case 4:
                        lptr += 2;
                        V = ((*lptr >> 22) & 0xff) - 128;
                        lptr++;
                        Y = ((*lptr >> 02) & 0xff) - 16;
                        U = ((*lptr >> 12) & 0xff) - 128;
                        Y += ((*lptr >> 22) & 0xff) - 16;
                        Y >>= 1;
                        break;
                    case 5:
                        lptr += 2;
                        V = ((*lptr >> 22) & 0xff) - 128;
                        lptr++;
                        U = ((*lptr >> 12) & 0xff) - 128;
                        Y = ((*lptr >> 22) & 0xff) - 16;
                        lptr++;
                        Y += ((*lptr >> 02) & 0xff) - 16;
                        Y >>= 1;
                        break;
                }

                R = (9535 * Y + 14688 * V) >> 13; //13-bit white
                G = (9535 * Y - 4375 * V - 1745 * U) >> 13;
                B = (9535 * Y + 17326 * U) >> 13;

                if (R > 255) R = 255;
                if (R < 0) R = 0;
                if (G > 255) G = 255;
                if (G < 0) G = 0;
                if (B > 255) B = 255;
                if (B < 0) B = 0;
                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                if (scaledvectorscope)
                {
                    U *= 255;
                    U /= 314;
                    V *= 255;
                    V /= 244;
                }
                U += 128;
                V += 128;
                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case COLOR_FORMAT_RGB24:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int R, G, B, U, V;
                uint8_t *bptr = (uint8_t *)sbase;
                bptr +=  x * 3;

                R = bptr[2];
                G = bptr[1];
                B = bptr[0];

                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case COLOR_FORMAT_RGB32:
            tools->histogram = 1;
            for (x = 0, pos = 0; x < width; x += step, pos++)
            {
                int R, G, B, U, V;
                uint8_t *bptr = (uint8_t *)sbase;
                bptr +=  x * 4;

                R = bptr[2];
                G = bptr[1];
                B = bptr[0];

                tools->histR[R]++;
                tools->histG[G]++;
                tools->histB[B]++;
                tools->waveR[pos][R]++;
                tools->waveG[pos][G]++;
                tools->waveB[pos][B]++;

                //Y = (((1499 * R) + (5030 * G) + (508 * B))>>13) + 16;
                if (scaledvectorscope)
                {
                    U = ((((-672 * R) - (2249 * G) + (2920 * B)) >> 13)) + 128;	//* 255.0/314.0
                    V = ((((3758 * R) - (3416 * G) - (343 * B)) >> 13)) + 128;	//* 255.0/244.0
                }
                else
                {
                    U = ((((-827 * R) - (2769 * G) + (3596 * B)) >> 13)) + 128;
                    V = ((((3596 * R) - (3269 * G) - (328 * B)) >> 13)) + 128;
                }

                if (U < 0) U = 0;
                if (U > 255) U = 255;
                if (V < 0) V = 0;
                if (V > 255) V = 255;
                tools->scopeUV[U][V]++;
            }
            break;

        case COLOR_FORMAT_BYR2:
        case COLOR_FORMAT_BYR4:
            //do nothing
            break;

        default:
            assert(0);
#if (0 && DEBUG)
            fprintf(stderr, "decoder.HistogramLine: Unsupported pixel format\n");
#endif
            break;

    }
}


void GhostBust(DECODER *decoder, unsigned short *sbaseL, unsigned short *sbaseR, int width, int ileakL, int ileakR)
{
#if 1
    int x, RL, GL, BL, RR, GR, BR;
    int nRL, nGL, nBL;
    int nRR, nGR, nBR;
    int max = 1024 * 1024 - 1;
    unsigned short *sqrttable = decoder->sqrttable;
    ileakL >>= 6;
    ileakR >>= 6;

    if (sqrttable == NULL)
        return;

    for (x = 0; x < width; x++)
    {
        RL = sbaseL[0] >> 6;
        GL = sbaseL[1] >> 6; //10-bit
        BL = sbaseL[2] >> 6;
        RL *= RL;
        GL *= GL;	//20-bit
        BL *= BL;

        RR = sbaseR[0] >> 6;
        GR = sbaseR[1] >> 6; //10-bit
        BR = sbaseR[2] >> 6;
        RR *= RR;
        GR *= GR;	//20-bit
        BR *= BR;

        nRL = RL * (1023 - ileakL) + ileakL * max - RR * ileakL; //30-bit
        nGL = GL * (1023 - ileakL) + ileakL * max - GR * ileakL;
        nBL = BL * (1023 - ileakL) + ileakL * max - BR * ileakL;

        nRL >>= 10; //20-bit
        nGL >>= 10;
        nBL >>= 10;

        if (nRL > max) nRL = max;
        if (nRL < 0) nRL = 0;
        if (nGL > max) nGL = max;
        if (nGL < 0) nGL = 0;
        if (nBL > max) nBL = max;
        if (nBL < 0) nBL = 0;

        if (sqrttable[nRL] == 65535)
            sqrttable[nRL] = (int)sqrt(nRL);
        if (sqrttable[nGL] == 65535)
            sqrttable[nGL] = (int)sqrt(nGL);
        if (sqrttable[nBL] == 65535)
            sqrttable[nBL] = (int)sqrt(nBL);
        sbaseL[0] = sqrttable[nRL] << 6;
        sbaseL[1] = sqrttable[nGL] << 6;
        sbaseL[2] = sqrttable[nBL] << 6;
        sbaseL += 3;


        nRR = RR * (1023 - ileakR) + ileakR * max - RL * ileakR; //30-bit
        nGR = GR * (1023 - ileakR) + ileakR * max - GL * ileakR;
        nBR = BR * (1023 - ileakR) + ileakR * max - BL * ileakR;

        nRR >>= 10; //20-bit
        nGR >>= 10;
        nBR >>= 10;

        if (nRR > max) nRR = max;
        if (nRR < 0) nRR = 0;
        if (nGR > max) nGR = max;
        if (nGR < 0) nGR = 0;
        if (nBR > max) nBR = max;
        if (nBR < 0) nBR = 0;

        if (sqrttable[nRR] == 65535)
            sqrttable[nRR] = (int)sqrt(nRR);
        if (sqrttable[nGR] == 65535)
            sqrttable[nGR] = (int)sqrt(nGR);
        if (sqrttable[nBR] == 65535)
            sqrttable[nBR] = (int)sqrt(nBR);
        sbaseR[0] = sqrttable[nRR] << 6;
        sbaseR[1] = sqrttable[nGR] << 6;
        sbaseR[2] = sqrttable[nBR] << 6;
        sbaseR += 3;

    }
#else // works and fast but has not image linearization, not as good
    __m128i *ptrL = (__m128i *)sbaseL;
    __m128i *ptrR = (__m128i *)sbaseR;

    __m128i t, L, R, nL, nR;

    int x, width8 = (width * 3) & ~7;
    __m128i white_epi16 = _mm_set1_epi16(32767);
    __m128i leak_epi16 = _mm_set1_epi16(ileak >> 1);
    __m128i oneNegLeak_epi16 = _mm_set1_epi16(32767 - (ileak >> 1));

    for (x = 0; x < width8; x += 8)
    {
        L = _mm_load_si128(ptrL);
        R = _mm_load_si128(ptrR);

        L = _mm_srli_epi16(L, 1); //15-bit
        R = _mm_srli_epi16(R, 1); //15-bit

        nL = _mm_mulhi_epi16(L, oneNegLeak_epi16);
        t  = _mm_mulhi_epi16(white_epi16, leak_epi16);
        nL = _mm_adds_epi16(nL, t);
        t  = _mm_mulhi_epi16(R, leak_epi16);
        nL = _mm_subs_epu16(nL, t);

        nR = _mm_mulhi_epi16(R, oneNegLeak_epi16);
        t  = _mm_mulhi_epi16(white_epi16, leak_epi16);
        nR = _mm_adds_epi16(nR, t);
        t  = _mm_mulhi_epi16(L, leak_epi16);
        nR = _mm_subs_epu16(nR, t);

        L = _mm_slli_epi16(nL, 2);
        R = _mm_slli_epi16(nR, 2);

        _mm_store_si128(ptrL++, L);
        _mm_store_si128(ptrR++, R);
    }
#endif
}


void GhostBustRC(DECODER *decoder, unsigned short *sbase, int width, int ileakL, int ileakR)
{
#if 1
    int x, R, G, B;
    int nR, nG, nB;
    int max = 1024 * 1024 - 1;
    unsigned short *sqrttable = decoder->sqrttable;
    ileakL >>= 6;
    ileakR >>= 6;

    if (sqrttable == NULL)
        return;

    for (x = 0; x < width; x++)
    {
        R = sbase[0] >> 6;
        G = sbase[1] >> 6; //10-bit
        B = sbase[2] >> 6;
        R *= R;
        G *= G;	//20-bit
        B *= B;

        nR = R * (1023 - ileakL) + ileakL * max - ((G + B) >> 1) * ileakL; //30-bit
        nG = G * (1023 - ileakR) + ileakR * max - R * ileakR;
        nB = B * (1023 - ileakR) + ileakR * max - R * ileakR;

        nR >>= 10; //20-bit
        nG >>= 10;
        nB >>= 10;

        if (nR > max) nR = max;
        if (nR < 0) nR = 0;
        if (nG > max) nG = max;
        if (nG < 0) nG = 0;
        if (nB > max) nB = max;
        if (nB < 0) nB = 0;

        if (sqrttable[nR] == 65535)
            sqrttable[nR] = (int)sqrt(nR);
        if (sqrttable[nG] == 65535)
            sqrttable[nG] = (int)sqrt(nG);
        if (sqrttable[nB] == 65535)
            sqrttable[nB] = (int)sqrt(nB);
        sbase[0] = sqrttable[nR] << 6;
        sbase[1] = sqrttable[nG] << 6;
        sbase[2] = sqrttable[nB] << 6;
        sbase += 3;
    }

#elif 0
    int x;
    float R, G, B;
    float nR, nG, nB;
    float fleakL = (float)ileakL / 65535.0;
    float fleakR = (float)ileakR / 65535.0;

    for (x = 0; x < width; x++)
    {
        R = sbase[0];
        G = sbase[1];
        B = sbase[2];
        R /= 65535.0;
        G /= 65535.0;
        B /= 65535.0;
        R *= R;
        G *= G;
        B *= B;

        nR = R * (1.0 - fleakL) + fleakL - (G + B) * 0.5 * fleakL;
        nG = G * (1.0 - fleakR) + fleakR - R * fleakR;
        nB = B * (1.0 - fleakR) + fleakR - R * fleakR;

        if (nR < 0) nR = 0;
        if (nG < 0) nG = 0;
        if (nB < 0) nB = 0;

        nR = sqrt(nR);
        nG = sqrt(nG);
        nB = sqrt(nB);

        sbase[0] = nR * 65535.0;
        sbase[1] = nG * 65535.0;
        sbase[2] = nB * 65535.0;
        sbase += 3;
    }
#elif 0
    __m128i RGBRGB, rgb_epi32, RGB1, RGB2;
    __m128i zero_epi128 = _mm_setzero_si128();

    int x, width6 = (width * 3) / 6 * 6;
    __m128 white_ps = _mm_set1_ps(1.0);
    __m128 mul_neg_leak_ps = _mm_set_ps(1.0 - ((float)ileakL / 65536.0), 1.0 - ((float)ileakR / 65536.0), 1.0 - ((float)ileakR / 65536.0), 1.0 - ((float)ileakL / 65536.0));
    __m128 leak_ps = _mm_set_ps((float)ileakL / 65536.0, (float)ileakR / 65536.0, (float)ileakR / 65536.0, (float)ileakL / 65536.0);
    __m128 scale_ps = _mm_set1_ps(65535.0);
    __m128 scalehalf_ps = _mm_set1_ps(32767.0);
    __m128 zero_ps = _mm_set1_ps(0.0);
    __m128 rgb_ps, alt_rgb_ps;
    __m128i sub_epi32;
    __m128 sub_ps;

    for (x = 0; x < width6; x += 6) // two RGB pairs
    {
        int R, G, B;
        RGBRGB = _mm_loadu_si128((__m128i *)sbase);

        R = _mm_extract_epi16(RGBRGB, 0);
        G = _mm_extract_epi16(RGBRGB, 1);
        B = _mm_extract_epi16(RGBRGB, 2);
        G += B;
        G >>= 1;

        sub_epi32 = _mm_set_epi32(G, R, R, G);
        sub_ps = _mm_cvtepi32_ps(sub_epi32); // range 0 to 65535.0
        sub_ps = _mm_div_ps(sub_ps, scale_ps); // range 0 to 1.0
        sub_ps = _mm_mul_ps(sub_ps, sub_ps); // square

        rgb_epi32 = _mm_unpacklo_epi16(RGBRGB, zero_epi128);
        rgb_ps = _mm_cvtepi32_ps(rgb_epi32); // range 0 to 65535.0
        rgb_ps = _mm_div_ps(rgb_ps, scale_ps); // range 0 to 1.0
        rgb_ps = _mm_mul_ps(rgb_ps, rgb_ps); // square
        rgb_ps = _mm_mul_ps(rgb_ps, mul_neg_leak_ps); // [R*(1.0-fleakL)] + fleakL - (G+B)*0.5*fleakL;
        rgb_ps = _mm_add_ps(rgb_ps, leak_ps); // R*(1.0-fleakL) [+ fleakL] - (G+B)*0.5*fleakL;
        sub_ps = _mm_mul_ps(sub_ps, leak_ps); // R*(1.0-fleakL) + fleakL - [(G+B)*0.5*fleakL;]
        rgb_ps = _mm_sub_ps(rgb_ps, sub_ps); // R*(1.0-fleakL) + fleakL] [- (G+B)*0.5*fleakL;]

        rgb_ps = _mm_max_ps(rgb_ps, zero_ps);	// if(x < 0) x= 0;
        rgb_ps = _mm_sqrt_ps(rgb_ps);			// sqrt()
        rgb_ps = _mm_mul_ps(rgb_ps, scalehalf_ps); // range 0 to 32767
        RGB1 = _mm_cvtps_epi32(rgb_ps);
        RGB1 = _mm_packs_epi32 (RGB1, zero_epi128);
        RGB1 = _mm_slli_si128(RGB1, 10);
        RGB1 = _mm_srli_si128(RGB1, 10);


        RGBRGB = _mm_srli_si128(RGBRGB, 6);

        R = _mm_extract_epi16(RGBRGB, 0);
        G = _mm_extract_epi16(RGBRGB, 1);
        B = _mm_extract_epi16(RGBRGB, 2);
        G += B;
        G >>= 1;

        sub_epi32 = _mm_set_epi32(G, R, R, G);
        sub_ps = _mm_cvtepi32_ps(sub_epi32); // range 0 to 65535.0
        sub_ps = _mm_div_ps(sub_ps, scale_ps); // range 0 to 1.0
        sub_ps = _mm_mul_ps(sub_ps, sub_ps); // square

        rgb_epi32 = _mm_unpacklo_epi16(RGBRGB, zero_epi128);
        rgb_ps = _mm_cvtepi32_ps(rgb_epi32); // range 0 to 65535.0
        rgb_ps = _mm_div_ps(rgb_ps, scale_ps); // range 0 to 1.0
        rgb_ps = _mm_mul_ps(rgb_ps, rgb_ps); // square
        rgb_ps = _mm_mul_ps(rgb_ps, mul_neg_leak_ps); // [R*(1.0-fleakL)] + fleakL - (G+B)*0.5*fleakL;
        rgb_ps = _mm_add_ps(rgb_ps, leak_ps); // R*(1.0-fleakL) [+ fleakL] - (G+B)*0.5*fleakL;
        sub_ps = _mm_mul_ps(sub_ps, leak_ps); // R*(1.0-fleakL) + fleakL - [(G+B)*0.5*fleakL;]
        rgb_ps = _mm_sub_ps(rgb_ps, sub_ps); // R*(1.0-fleakL) + fleakL] [- (G+B)*0.5*fleakL;]

        rgb_ps = _mm_max_ps(rgb_ps, zero_ps);	// if(x < 0) x= 0;
        rgb_ps = _mm_sqrt_ps(rgb_ps);			// sqrt()
        rgb_ps = _mm_mul_ps(rgb_ps, scalehalf_ps); // range 0 to 32767
        RGB2 = _mm_cvtps_epi32(rgb_ps);
        RGB2 = _mm_packs_epi32 (RGB2, zero_epi128);
        RGB2 = _mm_slli_si128(RGB2, 6);

        RGB1 = _mm_adds_epi16(RGB1, RGB2);
        RGB1 = _mm_slli_epi16(RGB1, 1);
        RGB1 = _mm_slli_si128(RGB1, 4);
        RGB1 = _mm_srli_si128(RGB1, 4);

        RGBRGB = _mm_srli_si128(RGBRGB, 6);
        RGBRGB = _mm_slli_si128(RGBRGB, 12);
        RGBRGB = _mm_adds_epi16(RGB1, RGBRGB);

        _mm_storeu_si128((__m128i *)sbase, RGBRGB);
        sbase += 6;
    }
#endif
}

void GhostBustAB(DECODER *decoder, unsigned short *sbase, int width, int ileakL, int ileakR)
{
    int x, R, G, B;
    int nR, nG, nB;
    int max = 1024 * 1024 - 1;
    unsigned short *sqrttable = decoder->sqrttable;
    ileakL >>= 6;
    ileakR >>= 6;

    if (sqrttable == NULL)
        return;

    for (x = 0; x < width; x++)
    {
        R = sbase[0] >> 6;
        G = sbase[1] >> 6; //10-bit
        B = sbase[2] >> 6;
        R *= R;
        G *= G;	//20-bit
        B *= B;

        nR = R * (1023 - ileakL) + ileakL * max - B * ileakL;
        nG = G * (1023 - ileakL) + ileakL * max - B * ileakL;
        nB = B * (1023 - ileakR) + ileakR * max - ((R + G) >> 1) * ileakR;

        nR >>= 10; //20-bit
        nG >>= 10;
        nB >>= 10;

        if (nR > max) nR = max;
        if (nR < 0) nR = 0;
        if (nG > max) nG = max;
        if (nG < 0) nG = 0;
        if (nB > max) nB = max;
        if (nB < 0) nB = 0;

        if (sqrttable[nR] == 65535)
            sqrttable[nR] = (int)sqrt(nR);
        if (sqrttable[nG] == 65535)
            sqrttable[nG] = (int)sqrt(nG);
        if (sqrttable[nB] == 65535)
            sqrttable[nB] = (int)sqrt(nB);
        sbase[0] = sqrttable[nR] << 6;
        sbase[1] = sqrttable[nG] << 6;
        sbase[2] = sqrttable[nB] << 6;
        sbase += 3;
    }
}

void GhostBustGM(DECODER *decoder, unsigned short *sbase, int width, int ileakL, int ileakR)
{
    int x, R, G, B;
    int nR, nG, nB;
    int max = 1024 * 1024 - 1;
    unsigned short *sqrttable = decoder->sqrttable;
    ileakL >>= 6;
    ileakR >>= 6;

    if (sqrttable == NULL)
        return;

    for (x = 0; x < width; x++)
    {
        R = sbase[0] >> 6;
        G = sbase[1] >> 6; //10-bit
        B = sbase[2] >> 6;
        R *= R;
        G *= G;	//20-bit
        B *= B;

        nR = R * (1023 - ileakL) + ileakL * max - G * ileakL;
        nG = G * (1023 - ileakR) + ileakR * max - ((R + B) >> 1) * ileakR;
        nB = B * (1023 - ileakL) + ileakL * max - G * ileakL;

        nR >>= 10; //20-bit
        nG >>= 10;
        nB >>= 10;

        if (nR > max) nR = max;
        if (nR < 0) nR = 0;
        if (nG > max) nG = max;
        if (nG < 0) nG = 0;
        if (nB > max) nB = max;
        if (nB < 0) nB = 0;

        if (sqrttable[nR] == 65535)
            sqrttable[nR] = (int)sqrt(nR);
        if (sqrttable[nG] == 65535)
            sqrttable[nG] = (int)sqrt(nG);
        if (sqrttable[nB] == 65535)
            sqrttable[nB] = (int)sqrt(nB);
        sbase[0] = sqrttable[nR] << 6;
        sbase[1] = sqrttable[nG] << 6;
        sbase[2] = sqrttable[nB] << 6;
        sbase += 3;
    }
}


void ProcessLine3D(DECODER *decoder, uint8_t *buffer, int bufferremain, uint8_t *output, int pitch, uint8_t *source_buffer, int source_pitch, int channel_offset, int y, int blank)
{
    uint16_t *scratchline, *scratchline2, *scratchline3;
    uint16_t *sptr;
    uint16_t *srclineA, *srclineB;
    uint16_t *dstlineA, *dstlineB;
    int x, y2;
    int width = decoder->frame.width;
    int height = decoder->frame.height;
    int skip = 3;
    int sskip = 3;
    uint8_t *bptr1;
    uint8_t *bptr2;
    uint8_t *baseptr1;
    uint8_t *baseptr2;
    float windowMaskL = decoder->cfhddata.channel[0].FloatingWindowMaskL;
    float windowMaskR = decoder->cfhddata.channel[0].FloatingWindowMaskR;
    float frameTilt = decoder->cfhddata.channel[0].FrameTilt;
    float horizOffset = decoder->cfhddata.channel[1].HorizontalOffset;
    float horizOffsetR = decoder->cfhddata.channel[2].HorizontalOffset;
    float rotOffset = decoder->cfhddata.channel[1].RotationOffset;
    float rotOffsetR = decoder->cfhddata.channel[2].RotationOffset;
    float horizOffsetStep = 0;
    float horizOffsetStepR = 0;
    int flip1 = 0, flip2 = 0;
    int channel_flip = decoder->cfhddata.channel_flip;
    int source_pitch1 = source_pitch;
    int source_pitch2 = source_pitch;
    uint8_t *outputline = output + y * pitch;
    uint8_t *outputline2 = NULL;
    float horizOffsetBase;
    float rotOffsetBase;
    float horizOffsetBaseR;
    float rotOffsetBaseR;
    int formatdone = 0;
    float xmin = decoder->cfhddata.channel[0].FrameMask.topLftX;
    float xmax = decoder->cfhddata.channel[0].FrameMask.topRgtX;
    //float ymin = decoder->cfhddata.channel[0].FrameMask.topLftY;
    float ymax = decoder->cfhddata.channel[0].FrameMask.botLftY;
    float zoom;
    float zoomR;
    float frameZoom1 = decoder->cfhddata.channel[1].FrameZoom;
    float frameZoom2 = decoder->cfhddata.channel[2].FrameZoom;
    float frameAutoZoom = decoder->cfhddata.channel[0].FrameAutoZoom;
    float frameDiffZoom1 = decoder->cfhddata.channel[1].FrameDiffZoom;
    float frameDiffZoom2 = decoder->cfhddata.channel[2].FrameDiffZoom;
    float frameHDynamic = decoder->cfhddata.FrameHDynamic;
    float frameHDynCenter = decoder->cfhddata.FrameHDynCenter;
    float frameHDynWidth = decoder->cfhddata.FrameHDynWidth;
    float frameHScale = decoder->cfhddata.FrameHScale;
    int alphachannel = 0;
    int whitepoint = 16;
    float blursharpenL = decoder->cfhddata.channel[1].user_blur_sharpen;
    float blursharpenR = decoder->cfhddata.channel[2].user_blur_sharpen;
    float vignette = decoder->cfhddata.channel[0].user_vignette_start;
    int flip_LR = 0;
    float vig_r1;
    float vig_r2;
    float vig_gain;

    if (blank) // blankline, no shifts required
    {
        windowMaskL = 0;
        windowMaskR = 0;
        frameTilt = 0;
        horizOffset = 0;
        horizOffsetR = 0;
        rotOffset = 0;
        rotOffsetR = 0;
        frameZoom1 = 1.0;
        frameZoom2 = 1.0;
        frameAutoZoom = 1.0;
        frameDiffZoom1 = 1.0;
        frameDiffZoom2 = 1.0;
        frameHScale = 1.0;
        frameHDynamic = 1.0;
        frameHDynCenter = 0.5;
        frameHDynWidth = 0.0;
    }

    if ( decoder->StereoBufferFormat == DECODED_FORMAT_RG64 ||
            decoder->StereoBufferFormat == DECODED_FORMAT_W13A ||
            decoder->StereoBufferFormat == DECODED_FORMAT_RGB32)
        alphachannel = 1;

    if (xmax == 0.0) xmax = 1.0;
    if (ymax == 0.0) ymax = 1.0;

    if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
    {
        width *= 2;
    }

    if (decoder->source_channels < 2) // 2D
    {
        channel_flip &= 0x3;
        channel_flip |= channel_flip << 2;
        decoder->cfhddata.channel_flip = channel_flip;
    }

    if (!(decoder->cfhddata.process_path_flags & PROCESSING_COLORMATRIX) ||
            decoder->frame.resolution == DECODED_RESOLUTION_QUARTER ||
            decoder->frame.resolution == DECODED_RESOLUTION_LOWPASS_ONLY ||
            decoder->frame.resolution == DECODED_RESOLUTION_QUARTER_NODEBAYER_SCALED)
    {
        blursharpenL = 0.0;
        blursharpenR = 0.0;
    }

    if (!(decoder->cfhddata.process_path_flags & PROCESSING_ORIENTATION))
    {
        horizOffset = rotOffset = 0;
        horizOffsetR = rotOffsetR = 0;
        frameTilt = 0;
        frameAutoZoom = 1.0;
        frameDiffZoom1 = 1.0;
        frameDiffZoom2 = 1.0;
    }

    if (!(decoder->cfhddata.process_path_flags & PROCESSING_IMAGEFLIPS))
    {
        channel_flip = 0;
    }

    if (decoder->cfhddata.process_path_flags & PROCESSING_FRAMING)
    {
        horizOffset += decoder->cfhddata.FrameOffsetX;
        horizOffsetR -= decoder->cfhddata.FrameOffsetX;
        frameZoom1 += frameHScale - 1.0f;
        frameZoom2 += frameHScale - 1.0f;

        if (frameHDynamic != 1.0)
        {
            frameZoom1 += 0.00001f;
            frameZoom2 += 0.00001f;
        }

        if (vignette != 0.0)
        {
            float vig_diag = sqrtf(1.0f + ((float)decoder->frame.height / (float) decoder->frame.width) * ((float)decoder->frame.height / (float) decoder->frame.width));

            vig_r1 = (vignette + 1.0f);
            vig_r2 = (decoder->cfhddata.channel[0].user_vignette_end + 1.0f);
            vig_gain = decoder->cfhddata.channel[0].user_vignette_gain;

            vig_r1 *= vig_diag;
            vig_r2 *= vig_diag;
        }
    }
    else
    {
        frameZoom1 = 1.0f;
        frameZoom2 = 1.0f;
        vignette = 0;
    }

    zoom = frameZoom1 * frameAutoZoom * frameDiffZoom1;
    if (frameDiffZoom2 != 0.0)
        zoomR = frameZoom2 * frameAutoZoom / frameDiffZoom2;
    else
        zoomR = 0.0;

    if (decoder->cfhddata.process_path_flags & PROCESSING_FRAMING)
    {
        if (decoder->cfhddata.InvertOffset)
        {
            rotOffset = -rotOffset;
            rotOffsetR = -rotOffsetR;

            rotOffset -= decoder->cfhddata.FrameOffsetR;
            rotOffsetR -= -decoder->cfhddata.FrameOffsetR;
        }
        else
        {
            rotOffset += decoder->cfhddata.FrameOffsetR;
            rotOffsetR += -decoder->cfhddata.FrameOffsetR;
        }
    }



    rotOffsetBase = rotOffset;
    horizOffsetBase = horizOffset;
    rotOffsetBaseR = rotOffsetR;
    horizOffsetBaseR = horizOffsetR;

    horizOffset -= rotOffset * 0.5f;
    horizOffsetStep = rotOffset / (float)height;
    horizOffsetR -= rotOffsetR * 0.5f;
    horizOffsetStepR = rotOffsetR / (float)height;

    horizOffset += horizOffsetStep * y;
    horizOffsetR += horizOffsetStepR * y;

    assert(bufferremain >= width * 8 * 2 * 2);

    baseptr1 = source_buffer;
    baseptr2 = source_buffer + channel_offset;

    if (channel_flip & 0xf)
    {
        if (channel_flip & 1)
        {
            flip1 = 1;
        }
        if (channel_flip & 4)
        {
            flip2 = 1;
        }
    }

    if (source_pitch1 < 0)
        flip_LR = 1;

    decoder->sharpen_flip = 0;
    if (channel_flip & 2) //ProcessLine3D
    {
        if (decoder->channel_blend_type == BLEND_NONE && decoder->channel_current == 1) // right channel only (stored in baseptr1)
        {
        }
        else
        {
            baseptr1 += source_pitch1 * (height - 1);
            source_pitch1 = -source_pitch1;
            decoder->sharpen_flip = 1;
        }
    }
    if (channel_flip & 8)
    {
        if (decoder->channel_blend_type == BLEND_NONE && decoder->channel_current == 1) // right channel only (stored in baseptr1)
        {
            baseptr1 += source_pitch1 * (height - 1);
            source_pitch1 = -source_pitch1;
            decoder->sharpen_flip = 1;
        }
        else
        {
            baseptr2 += source_pitch2 * (height - 1);
            source_pitch2 = -source_pitch2;
        }
    }

    bptr1 = baseptr1 + y * source_pitch1;
    bptr2 = baseptr2 + y * source_pitch2;

    y2 = y;
    if (decoder->channel_blend_type == BLEND_FREEVIEW) //FreeView
    {
        if (y2 < height / 4)
        {
            blank = 1;
            y2 = 0;
        }
        else
        {
            y2 -= height / 4;
            y2 *= 2;

            if (y2 >= height - 1)
            {
                blank = 1;
                y2 = height - 2;
            }
        }
        bptr1 = baseptr1 + y2 * source_pitch1;
        bptr2 = baseptr2 + y2 * source_pitch2;
    }

    srclineA = (uint16_t *)bptr1;
    srclineB = (uint16_t *)bptr2;

    scratchline = (uint16_t *)buffer;
    scratchline2 = (uint16_t *)(buffer + width * 6 + width) /* as we pad the line */ ;;
    scratchline3 = (uint16_t *)(buffer + width * 6 * 2 + width * 2) /* as we pad the line */ ;

    if (alphachannel)
    {
        scratchline = (uint16_t *)buffer;
        scratchline2 = (uint16_t *)(buffer + width * 8 + width) /* as we pad the line */ ;;
        scratchline3 = (uint16_t *)(buffer + width * 8 * 2 + width * 2) /* as we pad the line */ ;
    }

    dstlineA = sptr = scratchline;
    dstlineB = scratchline3;


    switch (decoder->StereoBufferFormat)
    {
        case DECODED_FORMAT_RG64:
            whitepoint = 16;
            skip = 8;
            sskip = 4;
            break;
        case DECODED_FORMAT_W13A:
            whitepoint = 13;
            skip = 8;
            sskip = 4;
            break;
        case DECODED_FORMAT_WP13:
            whitepoint = 13;
            skip = 6;
            sskip = 3;
            break;
        case DECODED_FORMAT_RG48:
            skip = 6;
            sskip = 3;
            break;
        case DECODED_FORMAT_RGB32:
            skip = 4;
            break;
        case DECODED_FORMAT_RGB24:
            skip = 3;
            break;
        case DECODED_FORMAT_YUYV:
            skip = 2;
            break;
    }

    if (blank)
    {
        if (srclineA)
            memset(srclineA, 0, width * skip);
        if (srclineB && decoder->channel_decodes > 1)
            memset(srclineB, 0, width * skip);
    }



    if (blursharpenL != 0.0 || blursharpenR != 0.0)
    {
        if (decoder->channel_blend_type == BLEND_FREEVIEW ||
                decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC ||
                decoder->channel_blend_type == BLEND_LINE_INTERLEAVED
           )
        {
            decoder->doVerticalFilter = 0;
        }
        else
        {
            decoder->doVerticalFilter = 1;
        }
    }

    {
        switch (decoder->channel_blend_type)
        {
            case BLEND_FREEVIEW:
            case BLEND_SIDEBYSIDE_ANAMORPHIC: //side by side
                if (!blank)
                {
                    if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL || decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER)
                    {
                        dstlineA = srclineA;
                        sptr = dstlineA;

                        if (zoom != 1.0 || zoomR != 1.0 || horizOffsetR || horizOffset || channel_flip || frameTilt)
                        {
                            if (!alphachannel)
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                {
                                    RGB48HoriShift(decoder, srclineA, scratchline2, width / 2, -horizOffset, flip1);
                                    RGB48HoriShift(decoder, srclineB, scratchline2, width / 2, horizOffsetR, flip2);
                                }
                                else
                                {
                                    RGB48HoriShiftZoom(decoder, srclineA, scratchline2, width / 2, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                    RGB48HoriShiftZoom(decoder, srclineB, scratchline2, width / 2, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                                }
                            }
                            else
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                {
                                    RGBA64HoriShift(decoder, srclineA, scratchline2, width / 2, -horizOffset, flip1);
                                    RGBA64HoriShift(decoder, srclineB, scratchline2, width / 2, horizOffsetR, flip2);
                                }
                                else
                                {
                                    RGBA64HoriShiftZoom(decoder, srclineA, scratchline2, width / 2, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                    RGBA64HoriShiftZoom(decoder, srclineB, scratchline2, width / 2, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                                }
                            }
                        }

                        if (vignette != 0.0)
                        {
                            int cwidth = width / 2;
                            if (decoder->channel_blend_type == BLEND_SIDEBYSIDE_ANAMORPHIC)
                                cwidth = width;

                            FastVignetteInplaceWP13(decoder, width / 2, cwidth, height, y, vig_r1, vig_r2, vig_gain,
                                                    (int16_t *)srclineA, decoder->frame.resolution, skip);
                            FastVignetteInplaceWP13(decoder, width / 2, cwidth, height, y, vig_r1, vig_r2, vig_gain,
                                                    (int16_t *)srclineB, decoder->frame.resolution, skip);
                        }

                        if (blursharpenL != 0.0) FastSharpeningBlurHinplaceWP13(width / 2, (int16_t *)srclineA, blursharpenL, decoder->frame.resolution, skip);
                        if (blursharpenR != 0.0) FastSharpeningBlurHinplaceWP13(width / 2, (int16_t *)srclineB, blursharpenR, decoder->frame.resolution, skip);

                        memcpy(dstlineA + sskip * (width / 2), srclineB, width / 2 * sskip * 2);
                    }
                    else
                    {

                        int16_t *ptr;
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;

                        if (!alphachannel)
                        {
                            if (zoom != 1.0 || zoomR != 1.0 || horizOffsetR || horizOffset || channel_flip || frameTilt)
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                {
                                    RGB48HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                                    RGB48HoriShift(decoder, srclineB, scratchline2, width, horizOffset, flip2);
                                }
                                else
                                {
                                    RGB48HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                    RGB48HoriShiftZoom(decoder, srclineB, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                                }
                            }
                        }
                        else
                        {
                            if (zoom != 1.0 || zoomR != 1.0 || horizOffsetR || horizOffset || channel_flip || frameTilt)
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                {
                                    RGBA64HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                                    RGBA64HoriShift(decoder, srclineB, scratchline2, width, horizOffset, flip2);
                                }
                                else
                                {
                                    RGBA64HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                    RGBA64HoriShiftZoom(decoder, srclineB, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                                }
                            }
                        }

                        if (vignette != 0.0)
                        {
                            int cwidth = width / 2;
                            if (decoder->channel_blend_type == BLEND_SIDEBYSIDE_ANAMORPHIC)
                                cwidth = width;

                            FastVignetteInplaceWP13(decoder, width, cwidth, height, y, vig_r1, vig_r2, vig_gain,
                                                    (int16_t *)srclineA, decoder->frame.resolution, skip);
                            FastVignetteInplaceWP13(decoder, width, cwidth, height, y, vig_r1, vig_r2, vig_gain,
                                                    (int16_t *)srclineB, decoder->frame.resolution, skip);
                        }

                        if (blursharpenL != 0.0) FastSharpeningBlurHinplaceWP13(width, (int16_t *)srclineA, blursharpenL, decoder->frame.resolution, skip);
                        if (blursharpenR != 0.0) FastSharpeningBlurHinplaceWP13(width, (int16_t *)srclineB, blursharpenR, decoder->frame.resolution, skip);

                        dstlineA = srclineA;
                        ptr = (int16_t *)srclineA;
                        for (x = 0; x < width / 2; x++)
                        {
                            *ptr++ = (ptr1[0] + ptr1[3]) >> 1;
                            *ptr++ = (ptr1[1] + ptr1[4]) >> 1;
                            *ptr++ = (ptr1[2] + ptr1[5]) >> 1 ;

                            ptr1 += sskip * 2;
                        }
                        for (; x < width; x++)
                        {
                            *ptr++ = (ptr2[0] + ptr2[3]) >> 1;
                            *ptr++ = (ptr2[1] + ptr2[4]) >> 1;
                            *ptr++ = (ptr2[2] + ptr2[5]) >> 1;

                            ptr2 += sskip * 2;
                        }
                    }


                    if (windowMaskL || xmin)
                    {
                        float mask =  windowMaskL > xmin ? windowMaskL : xmin;
                        RGB48WindowMask(decoder, dstlineA, width / 2, 0, mask);

                        if (windowMaskL < 0)
                            RGB48WindowMask(decoder, dstlineA, width / 2, 0, windowMaskL);

                        if (xmin)
                        {
                            RGB48WindowMask(decoder, dstlineA, width / 2, 1, xmin);
                        }
                    }
                    if (windowMaskR || (1.0 - xmax))
                    {
                        float mask =  windowMaskR > (1.0f - xmax) ? windowMaskR : (1.0f - xmax);
                        RGB48WindowMask(decoder, dstlineA + width * sskip / 2, width / 2, 1, mask);

                        if (windowMaskR < 0)
                            RGB48WindowMask(decoder, dstlineA + width * sskip / 2, width / 2, 1, windowMaskR);

                        if (xmin)
                        {
                            RGB48WindowMask(decoder, dstlineA + width * sskip / 2, width / 2, 0, xmin);
                        }
                    }

                    if (decoder->channel_swapped_flags & FLAG3D_GHOSTBUST)
                    {
                        if (decoder->ghost_bust_left || decoder->ghost_bust_right)
                        {
                            GhostBust(decoder, dstlineA, dstlineA + width * sskip / 2, width / 2, decoder->ghost_bust_left, decoder->ghost_bust_right);
                        }
                    }

                    if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                    {
                        memcpy(scratchline2 + width * sskip / 2, dstlineA, width * sskip * 2 / 2);
                        memcpy(dstlineA, dstlineA + width * sskip / 2, width * sskip * 2 / 2);
                        memcpy(dstlineA + width * sskip / 2, scratchline2 + width * sskip / 2, width * sskip * 2 / 2);
                    }
                }
                break;



            case BLEND_STACKED_ANAMORPHIC: //stacked
            case BLEND_LINE_INTERLEAVED: //fields
                if ((y & 1) == 1) return;

                if (!blank)
                {
                    uint16_t *ptrA1 = (uint16_t *)srclineA;
                    uint16_t *ptrA2 = (uint16_t *)srclineA + (source_pitch1 >> 1);
                    uint16_t *ptrB1 = (uint16_t *)srclineB;
                    uint16_t *ptrB2 = (uint16_t *)srclineB + (source_pitch2 >> 1);


                    FastBlendWP13((short *)ptrA1, (short *)ptrA2, (short *)ptrA1/*output*/, width * skip);
                    FastBlendWP13((short *)ptrB1, (short *)ptrB2, (short *)ptrB1/*output*/, width * skip);

                    if (zoom != 1.0 || zoomR != 1.0 || horizOffset || horizOffsetR || channel_flip || frameTilt)
                    {
                        if (!alphachannel)
                        {
                            if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                            {
                                RGB48HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                                RGB48HoriShift(decoder, srclineB, scratchline2, width, horizOffsetR, flip2);
                            }
                            else
                            {
                                RGB48HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                RGB48HoriShiftZoom(decoder, srclineB, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR,  flip2, frameTilt, 1);
                            }
                        }
                        else
                        {
                            if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                            {
                                RGBA64HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                                RGBA64HoriShift(decoder, srclineB, scratchline2, width, horizOffsetR, flip2);
                            }
                            else
                            {
                                RGBA64HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                RGBA64HoriShiftZoom(decoder, srclineB, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR,  flip2, frameTilt, 1);
                            }
                        }
                    }

                    if (vignette != 0.0)
                    {
                        FastVignetteInplaceWP13(decoder, width, width, height, y, vig_r1, vig_r2, vig_gain,
                                                (short *)srclineA, decoder->frame.resolution, skip);
                        FastVignetteInplaceWP13(decoder, width, width, height, y, vig_r1, vig_r2, vig_gain,
                                                (short *)srclineB, decoder->frame.resolution, skip);
                    }

                    if (blursharpenL != 0.0) FastSharpeningBlurHinplaceWP13(width, (short *)srclineA, blursharpenL, decoder->frame.resolution, skip);
                    if (blursharpenR != 0.0) FastSharpeningBlurHinplaceWP13(width, (short *)srclineB, blursharpenR, decoder->frame.resolution, skip);


                    if (windowMaskL || xmin)
                    {
                        float mask =  windowMaskL > xmin ? windowMaskL : xmin;
                        RGB48WindowMask(decoder, srclineA, width, 0, mask);

                        if (windowMaskL < 0)
                            RGB48WindowMask(decoder, srclineA, width, 0, windowMaskL);

                        if (xmin)
                        {
                            RGB48WindowMask(decoder, srclineA, width, 1, xmin);
                        }
                    }
                    if (windowMaskR || (1.0 - xmax))
                    {
                        float mask =  windowMaskR > (1.0f - xmax) ? windowMaskR : (1.0f - xmax);
                        RGB48WindowMask(decoder, srclineB, width, 1, mask);

                        if (windowMaskR < 0)
                            RGB48WindowMask(decoder, srclineB, width, 1, windowMaskR);

                        if (xmin)
                        {
                            RGB48WindowMask(decoder, srclineB, width, 0, xmin);
                        }
                    }

                    if (decoder->channel_swapped_flags & FLAG3D_GHOSTBUST)
                    {
                        if (decoder->ghost_bust_left || decoder->ghost_bust_right)
                        {
                            GhostBust(decoder, srclineA, srclineB, width, decoder->ghost_bust_left, decoder->ghost_bust_right);
                        }
                    }

                    if (decoder->doVerticalFilter == 0)
                    {
                        if (decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC) //stacked
                        {
                            if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                            {
                                outputline2 = output + (y >> 1) * pitch;
                                outputline = output + ((y >> 1) + (height / 2)) * pitch;
                            }
                            else
                            {
                                outputline = output + (y >> 1) * pitch;
                                outputline2 = output + ((y >> 1) + (height / 2)) * pitch;
                            }
                        }
                        else //fields
                        {
                            if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                            {
                                outputline = output + (y) * pitch;
                                outputline2 = output + (y + 1) * pitch;
                            }
                            else
                            {
                                outputline2 = output + (y) * pitch;
                                outputline = output + (y + 1) * pitch;
                            }
                        }

                        if (flip_LR/*source_pitch1 < 0*/) // flip Left and Right
                        {
                            uint8_t *tmp = outputline2;
                            outputline2 = outputline;
                            outputline = tmp;
                        }
                    }
                    else
                    {
                        if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                        {
                            memcpy(scratchline2, srclineA, width * skip);
                            memcpy(srclineA, srclineB, width * skip);
                            memcpy(srclineB, scratchline2, width * skip);
                        }
                    }
                }
                break;


            case BLEND_ONION: //onion
            case BLEND_DIFFERENCE: //difference
            case BLEND_SPLITVIEW: //splitView
                if (!blank)
                {
                    //dstlineA = source_buffer;
                    //dstlineA += (source_pitch>>1) * y;
                    sptr = dstlineA = srclineA;
                    srclineA = (uint16_t *)bptr1;
                    srclineB = (uint16_t *)bptr2;

                    if (zoom != 1.0 || zoomR != 1.0 || horizOffset || horizOffsetR || channel_flip || frameTilt)
                    {
                        if (!alphachannel)
                        {
                            if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                            {
                                RGB48HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                                RGB48HoriShift(decoder, srclineB, scratchline2, width, horizOffsetR, flip2);
                            }
                            else
                            {
                                RGB48HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                RGB48HoriShiftZoom(decoder, srclineB, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                            }
                        }
                        else
                        {
                            if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                            {
                                RGBA64HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                                RGBA64HoriShift(decoder, srclineB, scratchline2, width, horizOffsetR, flip2);
                            }
                            else
                            {
                                RGBA64HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                                RGBA64HoriShiftZoom(decoder, srclineB, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                            }
                        }
                    }

                    if (vignette != 0.0)
                    {
                        FastVignetteInplaceWP13(decoder, width, width, height, y, vig_r1, vig_r2, vig_gain,
                                                (short *)srclineA, decoder->frame.resolution, skip);
                        FastVignetteInplaceWP13(decoder, width, width, height, y, vig_r1, vig_r2, vig_gain,
                                                (short *)srclineB, decoder->frame.resolution, skip);
                    }

                    if (blursharpenL != 0.0) FastSharpeningBlurHinplaceWP13(width, (short *)srclineA, blursharpenL, decoder->frame.resolution, skip);
                    if (blursharpenR != 0.0) FastSharpeningBlurHinplaceWP13(width, (short *)srclineB, blursharpenR, decoder->frame.resolution, skip);

                    if (windowMaskL || xmin)
                    {
                        float mask =  windowMaskL > xmin ? windowMaskL : xmin;
                        RGB48WindowMask(decoder, srclineA, width, 0, mask);

                        if (windowMaskL < 0)
                            RGB48WindowMask(decoder, srclineA, width, 0, windowMaskL);

                        if (xmin)
                        {
                            RGB48WindowMask(decoder, srclineA, width, 1, xmin);
                        }
                    }

                    if (windowMaskR || (1.0 - xmax))
                    {
                        float mask =  windowMaskR > (1.0f - xmax) ? windowMaskR : (1.0f - xmax);
                        RGB48WindowMask(decoder, srclineB, width, 1, mask);

                        if (windowMaskR < 0)
                            RGB48WindowMask(decoder, srclineB, width, 1, windowMaskR);

                        if (xmin)
                        {
                            RGB48WindowMask(decoder, srclineB, width, 0, xmin);
                        }
                    }

                    x = 0;
                    if (decoder->channel_blend_type == BLEND_SPLITVIEW) //split view
                    {
                        int xsplit = width * (decoder->cfhddata.split_pos_xy & 0xff) / 255;
                        for (x = xsplit * sskip; x < width * sskip; x++)
                        {
                            srclineA[x] = srclineB[x];
                        }
                    }
                    else if (decoder->channel_blend_type == BLEND_ONION) //onion
                    {
                        FastBlendWP13((short *)srclineA, (short *)srclineB, (short *)dstlineA/*output*/, width * skip);
                    }
                    else if (decoder->channel_blend_type == BLEND_DIFFERENCE) //difference
                    {
#if XMMOPT
                        int width8 = (width * sskip) & 0xfff8;
                        __m128i mid_epi16;
                        //int unaligned = ((int)sbase) & 15;
                        //unaligned += ((int)in_rgb8) & 15;
                        if (whitepoint == 13)
                            mid_epi16 = _mm_set1_epi16(0x0fff);
                        else
                            mid_epi16 = _mm_set1_epi16(0x1fff);

                        for (x = 0; x < width8; x += 8)
                        {
                            __m128i rgb16A = _mm_load_si128((__m128i *)&srclineA[x]);
                            __m128i rgb16B = _mm_load_si128((__m128i *)&srclineB[x]);

                            // 0 to 0xffff
                            if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                            {
                                rgb16A = _mm_subs_epi16(rgb16B, rgb16A); // -3fff to 3fff
                            }
                            else
                            {
                                rgb16A = _mm_subs_epi16(rgb16A, rgb16B);
                            }
                            rgb16A = _mm_adds_epi16(rgb16A, mid_epi16); // -0x1fff to 0x5fff , avg 0x1fff


                            _mm_store_si128((__m128i *)&dstlineA[x], rgb16A);
                        }
#endif
                        for (; x < width * sskip; x++)
                        {
                            int val;

                            if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                            {
                                val = (srclineB[x] - srclineA[x]) + 32768;
                            }
                            else
                            {
                                val = (srclineA[x] - srclineB[x]) + 32768;
                            }
                            if (val > 0x7fff) val = 0x7fff;
                            if (val < 0) val = 0;
                            dstlineA[x] = val;
                        }
                    }
                }
                break;

            case BLEND_ANAGLYPH_RC:
            case BLEND_ANAGLYPH_RC_BW:
            case BLEND_ANAGLYPH_AB:
            case BLEND_ANAGLYPH_AB_BW:
            case BLEND_ANAGLYPH_GM:
            case BLEND_ANAGLYPH_GM_BW:
            case BLEND_ANAGLYPH_DUBOIS: //Optimized
            {
                uint16_t *sptr1 = scratchline2;
                uint16_t *sptr2 = scratchline3;

                dstlineA = (uint16_t *)bptr1;
                //	dstlineA += (source_pitch>>1) * y;
                sptr = dstlineA;
                sptr1 = srclineA = (uint16_t *)bptr1;
                sptr2 = srclineB = (uint16_t *)bptr2;

                if (zoom != 1.0 || zoomR != 1.0 || horizOffset || horizOffsetR || channel_flip || frameTilt)
                {
                    if (!alphachannel)
                    {
                        if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                        {
                            RGB48HoriShift(decoder, srclineA, scratchline, width, -horizOffset, flip1);
                            RGB48HoriShift(decoder, srclineB, scratchline, width, horizOffsetR, flip2);
                        }
                        else
                        {
                            RGB48HoriShiftZoom(decoder, srclineA, scratchline, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                            RGB48HoriShiftZoom(decoder, srclineB, scratchline, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                        }
                    }
                    else
                    {
                        if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                        {
                            RGBA64HoriShift(decoder, scratchline2, scratchline, width, -horizOffset, flip1);
                            RGBA64HoriShift(decoder, scratchline3, scratchline, width, horizOffsetR, flip2);
                        }
                        else
                        {
                            RGBA64HoriShiftZoom(decoder, scratchline2, scratchline, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                            RGBA64HoriShiftZoom(decoder, scratchline3, scratchline, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                        }
                    }
                }


                if (vignette != 0.0)
                {
                    FastVignetteInplaceWP13(decoder, width, width, height, y, vig_r1, vig_r2, vig_gain,
                                            (short *)srclineA, decoder->frame.resolution, skip);
                    FastVignetteInplaceWP13(decoder, width, width, height, y, vig_r1, vig_r2, vig_gain,
                                            (short *)srclineB, decoder->frame.resolution, skip);
                }

                if (blursharpenL != 0.0) FastSharpeningBlurHinplaceWP13(width, (short *)srclineA, blursharpenL, decoder->frame.resolution, skip);
                if (blursharpenR != 0.0) FastSharpeningBlurHinplaceWP13(width, (short *)srclineB, blursharpenR, decoder->frame.resolution, skip);

                if (decoder->channel_swapped_flags & FLAG3D_GHOSTBUST)
                {
                    if (decoder->ghost_bust_left || decoder->ghost_bust_right)
                    {
                        GhostBust(decoder, srclineA, srclineB, width, decoder->ghost_bust_left, decoder->ghost_bust_right);
                    }
                }

                if (windowMaskL || xmin)
                {
                    float mask =  windowMaskL > xmin ? windowMaskL : xmin;
                    RGB48WindowMask(decoder, srclineA, width, 0, mask);

                    if (windowMaskL < 0)
                        RGB48WindowMask(decoder, srclineA, width, 0, windowMaskL);

                    if (xmin)
                    {
                        RGB48WindowMask(decoder, srclineA, width, 1, xmin);
                    }
                }
                if (windowMaskR || (1.0 - xmax))
                {
                    float mask =  windowMaskR > (1.0f - xmax) ? windowMaskR : (1.0f - xmax);
                    RGB48WindowMask(decoder, srclineB, width, 1, mask);

                    if (windowMaskR < 0)
                        RGB48WindowMask(decoder, srclineB, width, 1, windowMaskR);

                    if (xmin)
                    {
                        RGB48WindowMask(decoder, srclineB, width, 0, xmin);
                    }
                }


                if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                {
                    uint16_t *tmp = srclineA;
                    srclineA = srclineB;
                    srclineB = tmp;
                }


                switch (decoder->channel_blend_type)
                {
                    case BLEND_ANAGLYPH_RC:
                    {
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;

                        if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                        {
                            for (x = 0; x < width; x++)
                            {
                                sptr[0] = ptr2[0];
                                sptr[1] = ptr1[1];
                                sptr[2] = ptr1[2];

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                        else
                        {
                            for (x = 0; x < width; x++)
                            {
                                sptr[0] = ptr1[0];
                                sptr[1] = ptr2[1];
                                sptr[2] = ptr2[2];

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                    }
                    break;
                    case BLEND_ANAGLYPH_RC_BW:
                    {
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;

                        if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                        {
                            for (x = 0; x < width; x++)
                            {
                                int y1 = (ptr1[0] * 5 + ptr1[1] * 10 + ptr1[2]) >> 4;
                                int y2 = (ptr2[0] * 5 + ptr2[1] * 10 + ptr2[2]) >> 4;

                                sptr[0] = y2;
                                sptr[1] = y1;
                                sptr[2] = y1;

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                        else
                        {
                            for (x = 0; x < width; x++)
                            {
                                int y1 = (ptr1[0] * 5 + ptr1[1] * 10 + ptr1[2]) >> 4;
                                int y2 = (ptr2[0] * 5 + ptr2[1] * 10 + ptr2[2]) >> 4;

                                sptr[0] = y1;
                                sptr[1] = y2;
                                sptr[2] = y2;

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                    }
                    break;

                    case BLEND_ANAGLYPH_AB:
                    {
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;

                        if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                        {
                            for (x = 0; x < width; x++)
                            {
                                sptr[0] = ptr2[0];
                                sptr[1] = ptr2[1];
                                sptr[2] = ptr1[2];

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                        else
                        {
                            for (x = 0; x < width; x++)
                            {
                                sptr[0] = ptr1[0];
                                sptr[1] = ptr1[1];
                                sptr[2] = ptr2[2];

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                    }
                    break;
                    case BLEND_ANAGLYPH_AB_BW:
                    {
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;

                        if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                        {
                            for (x = 0; x < width; x++)
                            {
                                int y1 = (ptr1[0] * 5 + ptr1[1] * 10 + ptr1[2]) >> 4;
                                int y2 = (ptr2[0] * 5 + ptr2[1] * 10 + ptr2[2]) >> 4;

                                sptr[0] = y2;
                                sptr[1] = y2;
                                sptr[2] = y1;

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                        else
                        {
                            for (x = 0; x < width; x++)
                            {
                                int y1 = (ptr1[0] * 5 + ptr1[1] * 10 + ptr1[2]) >> 4;
                                int y2 = (ptr2[0] * 5 + ptr2[1] * 10 + ptr2[2]) >> 4;

                                sptr[0] = y1;
                                sptr[1] = y1;
                                sptr[2] = y2;

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                    }
                    break;
                    case BLEND_ANAGLYPH_GM:
                    {
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;

                        if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                        {
                            for (x = 0; x < width; x++)
                            {
                                sptr[0] = ptr1[0];
                                sptr[1] = ptr2[1];
                                sptr[2] = ptr1[2];

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                        else
                        {
                            for (x = 0; x < width; x++)
                            {
                                sptr[0] = ptr2[0];
                                sptr[1] = ptr1[1];
                                sptr[2] = ptr2[2];

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                    }
                    break;
                    case BLEND_ANAGLYPH_GM_BW:
                    {
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;

                        if (decoder->channel_swapped_flags & FLAG3D_SWAPPED)
                        {
                            for (x = 0; x < width; x++)
                            {
                                int y1 = (ptr1[0] * 5 + ptr1[1] * 10 + ptr1[2]) >> 4;
                                int y2 = (ptr2[0] * 5 + ptr2[1] * 10 + ptr2[2]) >> 4;

                                sptr[0] = y1;
                                sptr[1] = y2;
                                sptr[2] = y1;

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                        else
                        {
                            for (x = 0; x < width; x++)
                            {
                                int y1 = (ptr1[0] * 5 + ptr1[1] * 10 + ptr1[2]) >> 4;
                                int y2 = (ptr2[0] * 5 + ptr2[1] * 10 + ptr2[2]) >> 4;

                                sptr[0] = y2;
                                sptr[1] = y1;
                                sptr[2] = y2;

                                ptr1 += sskip;
                                ptr2 += sskip;
                                sptr += sskip;
                            }
                        }
                    }
                    break;
                    case BLEND_ANAGLYPH_DUBOIS: //Optimized
                    {
                        int16_t *ptr1 = (int16_t *)srclineA;
                        int16_t *ptr2 = (int16_t *)srclineB;
                        int r, g, b;

                        for (x = 0; x < width; x++)
                        {
                            r = (ptr1[0] * 456 + ptr1[1] * 500 + ptr1[2] * 176 + ptr2[0] * -43 + ptr2[1] * -88 + ptr2[2] * -2  ) / 1000;
                            g = (ptr1[0] * -40 + ptr1[1] * -38 + ptr1[2] * -16 + ptr2[0] * 378 + ptr2[1] * 734 + ptr2[2] * -18 ) / 1000;
                            b = (ptr1[0] * -15 + ptr1[1] * -21 + ptr1[2] * -5  + ptr2[0] * -72 + ptr2[1] * -113 + ptr2[2] * 1226) / 1000;

                            if (r < 0) r = 0;
                            if (r > 0x3fff) r = 0x3fff;
                            if (g < 0) g = 0;
                            if (g > 0x3fff) g = 0x3fff;
                            if (b < 0) b = 0;
                            if (b > 0x3fff) b = 0x3fff;

                            sptr[0] = r;
                            sptr[1] = g;
                            sptr[2] = b;

                            ptr1 += sskip;
                            ptr2 += sskip;
                            sptr += sskip;
                        }
                    }
                    break;
                }
            }
            break;

            case BLEND_NONE:
            default:
                if (decoder->channel_decodes == 1) // only one channel
                {
                    if (skip == 8)
                    {
                        //the data is already in the correct format
                        sptr = (unsigned short *)bptr1;
                        // shift if needed.
                        if (zoom != 1.0 || zoomR != 1.0 || horizOffsetR || horizOffset || channel_flip || frameTilt)
                        {
                            if (decoder->channel_current == 0)
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                    RGBA64HoriShift(decoder, sptr, scratchline2, width, -horizOffset, flip1);
                                else
                                    RGBA64HoriShiftZoom(decoder, sptr, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                            }
                            else
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                    RGBA64HoriShift(decoder, sptr, scratchline2, width, horizOffsetR, flip2);
                                else
                                    RGBA64HoriShiftZoom(decoder, sptr, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                            }
                        }
                    }
                    else if (skip == 6)
                    {
                        //the data is already in the correct format
                        dstlineA = sptr = (unsigned short *)srclineA;
                        // shift if needed.
                        if (zoom != 1.0 || zoomR != 1.0 || horizOffsetR || horizOffset || channel_flip || frameTilt)
                        {
                            if (decoder->channel_current == 0)
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                    RGB48HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                                else
                                    RGB48HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);
                            }
                            else
                            {
                                if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                                    RGB48HoriShift(decoder, srclineA, scratchline2, width, horizOffsetR, flip2);
                                else
                                    RGB48HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                            }
                        }

                        if (vignette != 0.0)
                        {
                            FastVignetteInplaceWP13(decoder, width, width, height, y, vig_r1, vig_r2, vig_gain,
                                                    (int16_t *)srclineA, decoder->frame.resolution, skip);
                        }


                        if (decoder->channel_current == 0)
                        {
                            if (blursharpenL != 0.0)
                            {
                                FastSharpeningBlurHinplaceWP13(width, (int16_t *)srclineA, blursharpenL, decoder->frame.resolution, skip);
                            }
                        }
                        else
                        {
                            if (blursharpenR != 0.0)
                            {
                                FastSharpeningBlurHinplaceWP13(width, (int16_t *)srclineA, blursharpenR, decoder->frame.resolution, skip);
                            }
                        }

                    }

                    if ((windowMaskL && decoder->channel_current == 0) || xmin)
                    {
                        float mask =  windowMaskL > xmin ? windowMaskL : xmin;
                        if (decoder->channel_current != 0) mask = xmin;

                        if (windowMaskL < 0)
                            RGB48WindowMask(decoder, srclineA, width, 0, windowMaskL);

                        RGB48WindowMask(decoder, srclineA, width, 0, mask);
                    }

                    if ((windowMaskR && decoder->channel_current == 1) || (1.0f - xmax))
                    {
                        float mask =  windowMaskR > (1.0f - xmax) ? windowMaskR : (1.0f - xmax);
                        if (decoder->channel_current != 1) mask = (1.0f - xmax);

                        if (windowMaskR < 0)
                            RGB48WindowMask(decoder, srclineA, width, 1, windowMaskR);

                        RGB48WindowMask(decoder, srclineA, width, 1, mask);
                    }
                }
                else
                {
                    outputline2 = output + (y + height) * pitch;

                    if (zoom != 1.0 || zoomR != 1.0 || horizOffsetR || horizOffset || channel_flip || frameTilt)
                    {
                        if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                            RGB48HoriShift(decoder, srclineA, scratchline2, width, -horizOffset, flip1);
                        else
                            RGB48HoriShiftZoom(decoder, srclineA, scratchline2, width, height, y, -horizOffsetBase, rotOffsetBase, zoom, flip1, frameTilt, 0);

                        if (zoom == 1.0 && zoomR == 1.0 && frameTilt == 0.0)
                            RGB48HoriShift(decoder, srclineB, scratchline2, width, horizOffset, flip2);
                        else
                            RGB48HoriShiftZoom(decoder, srclineB, scratchline2, width, height, y, horizOffsetBaseR, -rotOffsetBaseR, zoomR, flip2, frameTilt, 1);
                    }

                    if (windowMaskL || xmin)
                    {
                        float mask =  windowMaskL > xmin ? windowMaskL : xmin;
                        RGB48WindowMask(decoder, srclineA, width, 0, mask);

                        if (windowMaskL < 0)
                            RGB48WindowMask(decoder, srclineA, width, 0, windowMaskL);
                    }

                    if (windowMaskR || (1.0 - xmax))
                    {
                        float mask =  windowMaskR > (1.0f - xmax) ? windowMaskR : (1.0f - xmax);
                        RGB48WindowMask(decoder, srclineB, width, 1, mask);

                        if (windowMaskR < 0)
                            RGB48WindowMask(decoder, srclineB, width, 1, windowMaskR);
                    }

                    if (decoder->channel_swapped_flags & FLAG3D_GHOSTBUST)
                    {
                        if (decoder->ghost_bust_left || decoder->ghost_bust_right)
                        {
                            GhostBust(decoder, srclineA, srclineB, width, decoder->ghost_bust_left, decoder->ghost_bust_right);
                        }
                    }
                }
                break;
        }
    }


    if (!formatdone)
    {
        int flags = ACTIVEMETADATA_PRESATURATED;
        int whitebitdepth = 16;
        if (decoder->StereoBufferFormat == DECODED_FORMAT_WP13 || decoder->StereoBufferFormat == DECODED_FORMAT_W13A)
        {
            flags = 0;
            whitebitdepth = 13;
        }

        if (outputline2)
        {
            //	if(decoder->cfhddata.ComputeFlags&2 && (0 == (y&3)) && decoder->tools)
            //		HistogramLine(decoder, srclineA, width, DECODED_FORMAT_RG48, whitebitdepth);

            if (decoder->doVerticalFilter == 0) // No sharp stage so output now
            {
                if (alphachannel)
                    Convert4444LinesToOutput(decoder, width, 1, y, srclineA,
                                             outputline, pitch, decoder->frame.format, whitebitdepth, flags);
                else
                    ConvertLinesToOutput(decoder, width, 1, y, srclineA,
                                         outputline, pitch, decoder->frame.format, whitebitdepth, flags);

                //if(decoder->cfhddata.ComputeFlags&2 && (0 == (y&3)) && decoder->tools)
                //	HistogramLine(decoder, dstlineA, width, DECODED_FORMAT_RG48, whitebitdepth);

                if (alphachannel)
                    Convert4444LinesToOutput(decoder, width, 1, y, srclineB,
                                             outputline2, pitch, decoder->frame.format, whitebitdepth, flags);
                else
                    ConvertLinesToOutput(decoder, width, 1, y, srclineB,
                                         outputline2, pitch, decoder->frame.format, whitebitdepth, flags);
            }
        }
        else
        {
            //if(decoder->cfhddata.ComputeFlags&2 && (0 == (y&3)) && decoder->tools)
            //{
            //	if(alphachannel)
            //		HistogramLine(decoder, srclineA, width, DECODED_FORMAT_RG64, whitebitdepth);
            //	else
            //		HistogramLine(decoder, srclineA, width, DECODED_FORMAT_RG48, whitebitdepth);
            //}

            if (decoder->doVerticalFilter == 0) // No sharp stage so output now
            {
                if (alphachannel)
                    Convert4444LinesToOutput(decoder, width, 1, y, srclineA,
                                             outputline, pitch, decoder->frame.format, whitebitdepth, flags);
                else
                    ConvertLinesToOutput(decoder, width, 1, y, srclineA,
                                         outputline, pitch, decoder->frame.format, whitebitdepth, flags);
            }
        }
    }
}


void SharpenLine(DECODER *decoder, uint8_t *buffer, int bufferremain, uint8_t *output, int pitch, uint8_t *local_output, int local_pitch, int channel_offset, int y, int thread_index)
{
    uint16_t *sbase;//*sbase2 = NULL;
    int width = decoder->frame.width;
    int height = decoder->frame.height;
    int skip = 3;
    //int flip1=0;//flip2=0;
    int channel_flip = decoder->cfhddata.channel_flip;
    //int local_pitch1 = local_pitch;
    //int local_pitch2 = local_pitch;
    uint8_t *outputline = output + y * pitch;
    //uint8_t *outputline2 = NULL;
    short *scratch;
    //int formatdone = 0;
    //float xmin = decoder->cfhddata.channel[0].FrameMask.topLftX;
    //float xmax = decoder->cfhddata.channel[0].FrameMask.topRgtX;
    //float ymin = decoder->cfhddata.channel[0].FrameMask.topLftY;
    //float ymax = decoder->cfhddata.channel[0].FrameMask.botLftY;
    int alphachannel = 0;
    float blursharpen = 0;
    int line_max = decoder->frame.height;
    int yy = y;

    if (decoder->channel_current == 0)
        blursharpen = decoder->cfhddata.channel[1].user_blur_sharpen;  // TODO LEFT and RIGHT separate vertical sharpen
    else
        blursharpen = decoder->cfhddata.channel[2].user_blur_sharpen;  // TODO LEFT and RIGHT separate vertical sharpen



    if (!(decoder->cfhddata.process_path_flags & PROCESSING_COLORMATRIX) ||
            decoder->frame.resolution == DECODED_RESOLUTION_QUARTER ||
            decoder->frame.resolution == DECODED_RESOLUTION_LOWPASS_ONLY ||
            decoder->frame.resolution == DECODED_RESOLUTION_QUARTER_NODEBAYER_SCALED)
    {
        blursharpen = 0.0;
    }

    if (decoder->channel_mix_half_res == 1)
        line_max *= 2;

    if (!(decoder->cfhddata.process_path_flags & PROCESSING_IMAGEFLIPS))
    {
        channel_flip = 0;
    }

    if (decoder->sharpen_flip) //SharpenLine
    {
        //if(!(decoder->channel_blend_type == BLEND_NONE && decoder->channel_current == 1)) // right channel only (stored in baseptr1)
        {
            yy = (line_max - 1 - y);
            outputline = output + yy * pitch;
        }
    }



    if ( decoder->StereoBufferFormat == DECODED_FORMAT_RG64 ||
            decoder->StereoBufferFormat == DECODED_FORMAT_W13A ||
            decoder->StereoBufferFormat == DECODED_FORMAT_RGB32)
        alphachannel = 1;

    if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
    {
        width *= 2;
    }

    sbase = (uint16_t *)local_output;
    sbase += (local_pitch >> 1) * y;


    switch (decoder->StereoBufferFormat)
    {
        case DECODED_FORMAT_RG64:
        case DECODED_FORMAT_W13A:
            skip = 8;
            break;
        case DECODED_FORMAT_WP13:
            skip = 6;
            break;
        case DECODED_FORMAT_RG48:
            skip = 6;
            break;
        case DECODED_FORMAT_RGB32:
            skip = 4;
            break;
        case DECODED_FORMAT_RGB24:
            skip = 3;
            break;
        case DECODED_FORMAT_YUYV:
            skip = 2;
            break;
    }


    scratch = (short *)(buffer + width * skip * thread_index);

    {
        int flags = ACTIVEMETADATA_PRESATURATED;
        int whitebitdepth = 16;
        if ((decoder->StereoBufferFormat == DECODED_FORMAT_WP13 || decoder->StereoBufferFormat == DECODED_FORMAT_W13A))
        {
            int use_pitch = local_pitch;
            int edgeclose = 0;
            flags = 0;
            whitebitdepth = 13;

            if (blursharpen != 0.0 && local_pitch != 0)
            {
                short *Aptr, *Bptr, *Cptr, *Dptr, *Eptr;

                switch (decoder->channel_blend_type)
                {
                    case BLEND_STACKED_ANAMORPHIC:
                        sbase = (uint16_t *)local_output;
                        sbase += (local_pitch >> 1) * y * 2;
                        if (y <= 4) edgeclose = 1;
                        if (y >= 2) Aptr = (short *)sbase - (local_pitch >> 1) * 4;
                        else Aptr = (short *)sbase;
                        if (y >= 1) Bptr = (short *)sbase - (local_pitch >> 1) * 2;
                        else Bptr = (short *)sbase;
                        Cptr = (short *)sbase;
                        if (y < height - 1) Dptr = (short *)sbase + (local_pitch >> 1) * 2;
                        else Dptr = (short *)sbase;
                        if (y < height - 2) Eptr = (short *)sbase + (local_pitch >> 1) * 4;
                        else Eptr = (short *)sbase;
                        if (y >= height - 4) edgeclose = 1;
                        use_pitch = local_pitch * 2;
                        break;

                    case BLEND_LINE_INTERLEAVED:
                        sbase = (uint16_t *)local_output;
                        if (y & 1)
                        {
                            y--;
                            sbase += (local_pitch >> 1) * y;
                        }
                        else
                        {
                            sbase += (local_pitch >> 1) * y;
                            sbase += channel_offset >> 1;
                        }

                        if (y <= 8) edgeclose = 1;
                        if (y >= 4) Aptr = (short *)sbase - (local_pitch >> 1) * 4;
                        else Aptr = (short *)sbase;
                        if (y >= 2) Bptr = (short *)sbase - (local_pitch >> 1) * 2;
                        else Bptr = (short *)sbase;
                        Cptr = (short *)sbase;
                        if (y < height - 2) Dptr = (short *)sbase + (local_pitch >> 1) * 2;
                        else Dptr = (short *)sbase;
                        if (y < height - 4) Eptr = (short *)sbase + (local_pitch >> 1) * 4;
                        else Eptr = (short *)sbase;
                        if (y >= height - 8) edgeclose = 1;
                        use_pitch = local_pitch * 2;
                        break;

                    default:
                        if (y <= 4) edgeclose = 1;
                        if (y >= 2) Aptr = (short *)sbase - (local_pitch >> 1) * 2;
                        else Aptr = (short *)sbase;
                        if (y >= 1) Bptr = (short *)sbase - (local_pitch >> 1) * 1;
                        else Bptr = (short *)sbase;
                        Cptr = (short *)sbase;
                        if (y < height - 1) Dptr = (short *)sbase + (local_pitch >> 1) * 1;
                        else Dptr = (short *)sbase;
                        if (y < height - 2) Eptr = (short *)sbase + (local_pitch >> 1) * 2;
                        else Eptr = (short *)sbase;
                        if (y >= height - 4) edgeclose = 1;
                        use_pitch = local_pitch;
                        break;
                }

                if (skip == 8)
                {
                    FastSharpeningBlurVW13A(Aptr, Bptr, Cptr, Dptr, Eptr, use_pitch, edgeclose,
                                            scratch, width, blursharpen,
                                            decoder->frame.resolution,
                                            decoder->channel_blend_type);
                }
                else
                {
                    FastSharpeningBlurVWP13(Aptr, Bptr, Cptr, Dptr, Eptr, use_pitch, edgeclose,
                                            scratch, width, blursharpen,
                                            decoder->frame.resolution,
                                            decoder->channel_blend_type);
                }

                sbase = (uint16_t *)scratch;
            }
        }

        if (alphachannel)
            Convert4444LinesToOutput(decoder, width, 1, y, sbase,
                                     outputline, pitch, decoder->frame.format, whitebitdepth, flags);
        else
            ConvertLinesToOutput(decoder, width, 1, y, sbase,
                                 outputline, pitch, decoder->frame.format, whitebitdepth, flags);
    }
}

extern int geomesh_alloc_cache(void *gm);

#define DEG2RAD(d)    (PI*(d)/180.0f)
#define RAD2DEG(r)    (180.0f*(r)/PI)

bool approx_equal(int x, int y)
{
    if (y > 1080)
    {
        x >>= 6;
        y >>= 6;
    }
    else if (y > 540)
    {
        x >>= 5;
        y >>= 5;
    }
    else
    {
        x >>= 4;
        y >>= 4;
    }

    if (x == y || x + 1 == y || x == y + 1)
        return true;

    return false;
}

bool approx_equal_float(float x, float y)
{
    if (x * 0.99 < y && y < x * 1.01)
        return true;

    return false;
}

void ConvertLocalToOutput(DECODER *decoder, uint8_t *output, int pitch, int output_format, uint8_t *local_output, int local_pitch, int channel_offset)
{
    uint8_t *local_output_double = local_output;

    //Frame_Region emptyFrameMask = {0};
    if (decoder->StereoBuffer)
        local_output_double = local_output = (uint8_t *)decoder->StereoBuffer;


    if (channel_offset < 0) // channel swapped
    {
        channel_offset = -channel_offset;
    }

    if (INVERTEDFORMAT(decoder->frame.format) != INVERTEDFORMAT(output_format))
    {
        local_output += local_pitch * (decoder->frame.height - 1);
        if (decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC)
            local_output_double += local_pitch * (decoder->frame.height * decoder->channel_decodes - 1);
        else
            local_output_double = local_output;
        local_pitch = -local_pitch;
    }
    if (FLIPCOLORS(output_format) || output_format & 0x80000000)
    {
        decoder->cfhddata.InvertOffset = 1;
    }
    else
    {
        decoder->cfhddata.InvertOffset = 0;
    }
    decoder->frame.format = output_format;

    //decoder->frame.colorspace = COLOR_SPACE_CG_601;
#if _THREADED
    {
        WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;
        int workunits;

#if _DELAY_THREAD_START
        if (decoder->worker_thread.pool.thread_count == 0)
        {
            CreateLock(&decoder->worker_thread.lock);
            // Initialize the pool of transform worker threads
            ThreadPoolCreate(&decoder->worker_thread.pool,
                             decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                             WorkerThreadProc,
                             decoder);
        }
#endif


        if (	((decoder->cfhddata.process_path_flags & PROCESSING_ORIENTATION) &&
                 (decoder->cfhddata.channel[0].FrameAutoZoom * decoder->cfhddata.channel[1].FrameDiffZoom != 1.0 ||
                  decoder->cfhddata.channel[1].FrameKeyStone ||
                  decoder->cfhddata.channel[1].VerticalOffset ||
                  decoder->cfhddata.channel[1].RotationOffset ||
                  decoder->cfhddata.channel[1].FrameTilt ||
                  decoder->cfhddata.channel[0].FrameAutoZoom / decoder->cfhddata.channel[2].FrameDiffZoom != 1.0 ||
                  decoder->cfhddata.channel[2].FrameKeyStone ||
                  decoder->cfhddata.channel[2].VerticalOffset ||
                  decoder->cfhddata.channel[2].RotationOffset ||
                  decoder->cfhddata.channel[2].FrameTilt))
                ||
                ((decoder->cfhddata.process_path_flags & PROCESSING_FRAMING) &&
                 (decoder->cfhddata.FrameOffsetY ||
                  decoder->cfhddata.FrameOffsetR ||
                  //	decoder->cfhddata.FrameOffsetX || ||
                  decoder->cfhddata.FrameHScale != 1.0 ||
                  decoder->cfhddata.FrameHDynamic != 1.0 ||
                  decoder->cfhddata.channel[1].FrameZoom != 1.0 ||
                  decoder->cfhddata.channel[2].FrameZoom != 1.0) ))
        {
            //int x;
            int xbytes, xstep;
            //uint8_t *base = local_output;
            int width, height, chunk_size;
            int fine_vertical = 0;
            width = decoder->frame.width;
            height = decoder->frame.height;


            switch (decoder->StereoBufferFormat)
            {
                case DECODED_FORMAT_RGB32:
                    xbytes = width * 4;
                    xstep = 16;
                    break;
                case DECODED_FORMAT_RGB24:
                    xbytes = width * 3;
                    xstep = 16;
                    break;
                case DECODED_FORMAT_YUYV:
                    xbytes = width * 2;
                    xstep = 16;
                    break;
                case DECODED_FORMAT_W13A:
                case DECODED_FORMAT_RG64:
                    xbytes = width * 8;
                    xstep = 32;
                    break;
                case DECODED_FORMAT_WP13:
                case DECODED_FORMAT_RG48:
                    xbytes = width * 6;
                    xstep = 32;
                    break;
                default:
                    assert(0);
                    break;
            }

            if (!(decoder->cfhddata.process_path_flags & (PROCESSING_ORIENTATION | PROCESSING_FRAMING)) ||
                    (decoder->cfhddata.channel[1].RotationOffset == 0.0 && decoder->cfhddata.channel[1].FrameKeyStone == 0.0 &&
                     decoder->cfhddata.channel[2].RotationOffset == 0.0 && decoder->cfhddata.channel[2].FrameKeyStone == 0.0 &&
                     decoder->cfhddata.FrameOffsetR == 0.0))
            {
                chunk_size = 8;
            }
            else
            {
                chunk_size = 1;

                if ((fabs(decoder->cfhddata.channel[1].RotationOffset) +
                        fabs(decoder->cfhddata.channel[1].FrameKeyStone * 0.2) +
                        fabs(decoder->cfhddata.FrameOffsetR)) > 0.015  ||

                        (fabs(decoder->cfhddata.channel[2].RotationOffset) +
                         fabs(decoder->cfhddata.channel[2].FrameKeyStone * 0.2) +
                         fabs(decoder->cfhddata.FrameOffsetR)) > 0.015)
                {
                    switch (decoder->StereoBufferFormat)
                    {
                        case DECODED_FORMAT_RGB32:
                            xstep = 4;
                            break;
                        case DECODED_FORMAT_RGB24:
                            xstep = 3;
                            break;
                        case DECODED_FORMAT_YUYV:
                            xstep = 4;
                            break;
                        case DECODED_FORMAT_W13A:
                        case DECODED_FORMAT_RG64:
                            xstep = 8;
                            break;
                        case DECODED_FORMAT_WP13:
                        case DECODED_FORMAT_RG48:
                        default:
                            xstep = 6;
                            break;
                    }

                    fine_vertical = 1;
                }
            }

            if ( decoder->codec.encoded_format == ENCODED_FORMAT_YUV_422 &&
                    (decoder->frame.resolution == DECODED_RESOLUTION_FULL ||
                     decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL) &&
                    decoder->codec.progressive == false)
            {
                int interlaced_pitch = local_pitch * 2;
                uint8_t *field2_output = local_output + local_pitch;

                // Post a message to the mailbox
                mailbox->local_output = local_output;
                mailbox->local_pitch = interlaced_pitch;
                mailbox->channel_offset = channel_offset;
                memcpy(&mailbox->info, &decoder->frame, sizeof(FRAME_INFO));
                mailbox->info.height >>= 1;
                mailbox->line_max = (xbytes + xstep - 1) / xstep;
                mailbox->chunk_size = chunk_size;
                mailbox->fine_vertical = fine_vertical;
                mailbox->jobType = JOB_TYPE_VERTICAL_3D; // 3d work -- vertical

                workunits = (mailbox->line_max + mailbox->chunk_size - 1) / mailbox->chunk_size;

                // Set the work count to the number of rows to process
                ThreadPoolSetWorkCount(&decoder->worker_thread.pool, workunits);

                // Start the transform worker threads
                ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                // Wait for all of the worker threads to finish
                ThreadPoolWaitAllDone(&decoder->worker_thread.pool);


                // Post a message to the mailbox
                mailbox->local_output = field2_output;
                mailbox->local_pitch = interlaced_pitch;
                mailbox->channel_offset = channel_offset;
                memcpy(&mailbox->info, &decoder->frame, sizeof(FRAME_INFO));
                mailbox->info.height >>= 1;
                mailbox->chunk_size = chunk_size;
                mailbox->line_max = (xbytes + xstep - 1) / xstep;
                mailbox->fine_vertical = fine_vertical;
                mailbox->jobType = JOB_TYPE_VERTICAL_3D; // 3d work -- vertical

                workunits = (mailbox->line_max + mailbox->chunk_size - 1) / mailbox->chunk_size;

                // Set the work count to the number of rows to process
                ThreadPoolSetWorkCount(&decoder->worker_thread.pool, workunits);

                // Start the transform worker threads
                ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                // Wait for all of the worker threads to finish
                ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
            }
            else
            {
                //TODO Lens corect here.
                //call JOB_TYPE_VERTICAL_3D then  (or lens correction equivalent.)
                //     JOB_TYPE_HORIZONTAL_3D
                //before doing any offset and rotation corrections.




                if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER) //HACK //DAN20110129
                    width /= 2;

                // Post a message to the mailbox
                mailbox->local_output = local_output;
                mailbox->local_pitch = local_pitch;
                mailbox->channel_offset = channel_offset;
                memcpy(&mailbox->info, &decoder->frame, sizeof(FRAME_INFO));
                mailbox->chunk_size = chunk_size;
                mailbox->line_max = (xbytes + xstep - 1) / xstep;
                mailbox->fine_vertical = fine_vertical;
                mailbox->jobType = JOB_TYPE_VERTICAL_3D; // 3d work -- vertical

                workunits = (mailbox->line_max + mailbox->chunk_size - 1) / mailbox->chunk_size;

                // Set the work count to the number of rows to process
                ThreadPoolSetWorkCount(&decoder->worker_thread.pool, workunits);

                // Start the transform worker threads
                ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                // Wait for all of the worker threads to finish
                ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

            }
        }


        // Post a message to the mailbox
        mailbox->output = output;
        mailbox->pitch = pitch;

        mailbox->local_output = local_output;
        mailbox->local_pitch = local_pitch;
        mailbox->channel_offset = channel_offset;
        memcpy(&mailbox->info, &decoder->frame, sizeof(FRAME_INFO));

        mailbox->chunk_size = 16;
        mailbox->line_max = decoder->frame.height;
        if (decoder->channel_mix_half_res == 1)
            mailbox->line_max *= 2;
        workunits = (mailbox->line_max + mailbox->chunk_size - 1) / mailbox->chunk_size;

        decoder->doVerticalFilter = 0;
        mailbox->jobType = JOB_TYPE_HORIZONAL_3D; // 3d work && horizontal and vertical flips

        // Set the work count to the number of rows to process
        ThreadPoolSetWorkCount(&decoder->worker_thread.pool, workunits);

        // Start the transform worker threads
        ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

        // Wait for all of the worker threads to finish
        ThreadPoolWaitAllDone(&decoder->worker_thread.pool);



        if (decoder->doVerticalFilter)
        {
            // Post a message to the mailbox
            mailbox->output = output;
            mailbox->pitch = pitch;

            mailbox->local_output = local_output_double;
            mailbox->local_pitch = local_pitch;
            mailbox->channel_offset = channel_offset;
            memcpy(&mailbox->info, &decoder->frame, sizeof(FRAME_INFO));

            mailbox->chunk_size = 16;
            mailbox->line_max = decoder->frame.height;


            if (decoder->channel_decodes == 2 && decoder->channel_blend_type == 0)
                mailbox->line_max *= 2;

            if (decoder->channel_mix_half_res == 1)
                mailbox->line_max *= 2;
            workunits = (mailbox->line_max + mailbox->chunk_size - 1) / mailbox->chunk_size;

            mailbox->jobType = JOB_TYPE_SHARPEN; // 3d work && horizontal and vertical flips

            // Set the work count to the number of rows to process
            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, workunits);

            // Start the transform worker threads
            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

            // Wait for all of the worker threads to finish
            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
        }
    }
#else
    {
        int y, width, height;
        uint8_t scratch[4096 * 16];
        int scratchremain = 4096 * 16;
        int ymin = 0, ymax;



        width = decoder->frame.width;
        height = decoder->frame.height;

        ymax = height;

        if ((decoder->cfhddata.process_path_flags & PROCESSING_FRAMING) &&
                memcmp(&decoder->cfhddata.channel[0].FrameMask, &emptyFrameMask, 32))
        {
            ymin = (float)height * decoder->cfhddata.channel[0].FrameMask.topLftY;
            ymax = (float)height * decoder->cfhddata.channel[0].FrameMask.botLftY;
        }

        if (	((decoder->cfhddata.process_path_flags & PROCESSING_ORIENTATION) &&
                 (decoder->cfhddata.channel[0].FrameAutoZoom * decoder->cfhddata.channel[1].FrameDiffZoom != 1.0 ||
                  decoder->cfhddata.channel[1].FrameKeyStone ||
                  decoder->cfhddata.channel[1].VerticalOffset ||
                  decoder->cfhddata.channel[1].RotationOffset ||
                  decoder->cfhddata.channel[0].FrameAutoZoom / decoder->cfhddata.channel[2].FrameDiffZoom != 1.0 ||
                  decoder->cfhddata.channel[2].FrameKeyStone ||
                  decoder->cfhddata.channel[2].VerticalOffset ||
                  decoder->cfhddata.channel[2].RotationOffset))
                ||
                ((decoder->cfhddata.process_path_flags & PROCESSING_FRAMING) &&
                 (decoder->cfhddata.FrameOffsetY ||
                  decoder->cfhddata.FrameOffsetR ||
                  decoder->cfhddata.FrameOffsetX ||
                  decoder->cfhddata.FrameHScale != 1.0 ||
                  decoder->cfhddata.FrameHDynamic != 1.0 ||
                  decoder->cfhddata.channel[1].FrameZoom != 1.0 ||
                  decoder->cfhddata.channel[2].FrameZoom != 1.0))
    {
        int x, xbytes, xstep;
        uint8_t *base = local_output;
        float voffsetstep;
        float voffset = decoder->cfhddata.channel[1].VerticalOffset;
            float roffset = decoder->cfhddata.channel[1].RotationOffset;
            float voffset1, voffset2;
            float voffsetstep1, voffsetstep2;
            int channel_flip = decoder->cfhddata.channel_flip;
            int aspectx, aspecty;
            float aspectfix;

            GetDisplayAspectRatio(decoder, &aspectx, &aspecty);
            aspectfix = (float)(aspectx * aspectx) / (float)(aspecty * aspecty);

            if (!(decoder->cfhddata.process_path_flags & PROCESSING_ORIENTATION))
            {
                voffset = roffset = 0;
            }

            if (!(decoder->cfhddata.process_path_flags & PROCESSING_IMAGEFLIPS))
            {
                channel_flip = 0;
            }

            if (decoder->cfhddata.process_path_flags & PROCESSING_FRAMING)
                voffset += decoder->cfhddata.FrameOffsetY;

            if (decoder->cfhddata.InvertOffset)
            {
                voffset = -voffset;
                roffset = -roffset;
            }

            switch (decoder->StereoBufferFormat)
            {
                case DECODED_FORMAT_RGB32:
                    xbytes = width * 4;
                    xstep = 16;
                    break;
                case DECODED_FORMAT_RGB24:
                    xbytes = width * 3;
                    xstep = 16;
                    break;
                case DECODED_FORMAT_YUYV:
                    xbytes = width * 2;
                    xstep = 16;
                    break;
                case DECODED_FORMAT_WP13:
                case DECODED_FORMAT_RG48:
                default:
                    xbytes = width * 6;
                    xstep = 32;
                    break;
            }

            //DAN20100923 -- simplied
            //voffset += roffset * (float)(width*width) / (float)(height*height) * 0.5;
            //voffsetstep = -roffset * (float)(width*width) / (float)(height*height)  / (float)(xbytes/xstep);
            voffset += roffset * aspectfix * 0.5;
            voffsetstep = -roffset * aspectfix / (float)(xbytes / xstep);

            if (roffset == 0.0)
                xstep = xbytes;

            voffset1 = voffset2 = voffset;
            voffsetstep1 = voffsetstep2 = voffsetstep;

            if (channel_flip & 0xf)
            {
                if (channel_flip & 2)
                {
                    voffset1 = -voffset1;
                    voffsetstep1 = -voffsetstep1;
                }
                if (channel_flip & 8)
                {
                    voffset2 = -voffset2;
                    voffsetstep2 = -voffsetstep2;
                }
                if (channel_flip & 1)
                {
                    voffset1 += voffsetstep1 * (xbytes / xstep);
                    voffsetstep1 = -voffsetstep1;
                }
                if (channel_flip & 4)
                {
                    voffset2 += voffsetstep2 * (xbytes / xstep);
                    voffsetstep2 = -voffsetstep2;
                }
            }


            for (x = 0; x < xbytes; x += xstep)
            {
                if (decoder->channel_decodes == 1 && decoder->channel_current == 1) // Right only
                {
                    RGB48VerticalShift(decoder, base, (unsigned short *)scratch,
                                       xstep, height, local_pitch, -voffset2);
                }
                else
                {
                    RGB48VerticalShift(decoder, base, (unsigned short *)scratch,
                                       xstep, height, local_pitch, voffset1);
                }
                if (decoder->channel_decodes == 2)
                {
                    uint8_t *bptr = base + channel_offset;
                    RGB48VerticalShift(decoder, bptr, (unsigned short *)scratch,
                                       xstep, height, local_pitch, -voffset2);
                }

                base += xstep;
                voffset1 += voffsetstep1;
                voffset2 += voffsetstep2;
            }
        }

        if (decoder->channel_mix_half_res == 1)
        height *= 2;

                  if (ymin)
        {
            memset(local_output, 0, abs(local_pitch)); // zero one line;
            }
        for (y = 0; y < ymin; y++)
    {
        ProcessLine3D(decoder, scratch, scratchremain, output, pitch, local_output, 0, channel_offset, y, 0);
        }
        for (; y < ymax; y++)
    {
        ProcessLine3D(decoder, scratch, scratchremain, output, pitch, local_output, local_pitch, channel_offset, y, 0);
        }
        for (; y < height; y++)
    {
        ProcessLine3D(decoder, scratch, scratchremain, output, pitch, local_output, 0, channel_offset, y, 0);
        }
    }
#endif
}



// Decode a sample from the input bitstream into the output frame buffer
bool DecodeSample(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams, CFHDDATA *cfhddata)
{
    //CODEC_ERROR error = CODEC_ERROR_OKAY;
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    //CODEC_STATE *codec = &decoder->codec;
    //int subband_wavelet_index[] = {5, 5, 5, 5, 4, 4, 4, 3, 3, 3, 1, 1, 1, 0, 0, 0};
    int channel_decodes = 1; // 3D Work
    int channel_offset = 0;
    int channel_mask = 0;
    int channel_current = 0;
    //int wavelet_index;
    bool result = true;
    uint8_t *local_output = output;
    uint8_t *local_buffer = NULL;
    int local_pitch = pitch;
    int internal_format = decoder->frame.format;
    int output_format = decoder->frame.output_format;
    bool use_local_buffer = false;
    DECODER *local_decoder = decoder;
    //Frame_Region emptyFrameMask = {0};
    Frame_Region emptyFrameMask = FRAME_REGION_INITIALIZER;
    int orig_width = decoder->frame.width;
    int orig_height = decoder->frame.height;

    decoder->local_output = local_output; // used for NV12 decodes.

    decoder->sample_uncompressed = 0; // set if a uncompressed sample is found.
    decoder->image_dev_only = 0;

    if (decoder->flags & (1 << 3)) // This is an image development only decode.
    {
        decoder->sample_uncompressed = 1;
        decoder->image_dev_only = 1;
        decoder->codec.encoded_format = ENCODED_FORMAT_RGB_444;
        decoder->codec.unique_framenumber = 0; //What should this be?
        decoder->frame.white_point = 16; // how to we pass this in?

        decoder->uncompressed_chunk = (uint32_t *)input->lpCurrentBuffer;

        switch (output_format & 0x7fffffff)
        {
            case COLOR_FORMAT_RGB24:
                decoder->uncompressed_size = orig_width * orig_height * 3;
                break;
            case COLOR_FORMAT_RGB32:
                decoder->uncompressed_size = orig_width * orig_height * 4;
                break;
            case COLOR_FORMAT_RG48:
            case COLOR_FORMAT_WP13:
                decoder->uncompressed_size = orig_width * orig_height * 6;
                break;
            default:
                decoder->uncompressed_size = orig_width * orig_height * 6;
                assert(0);
                break;
        }
    }

    decoder->frame.alpha_Companded = 0; // reset this state.
    if (decoder->parallelDecoder)
        decoder->parallelDecoder->sample_uncompressed = 0;

    decoder->error = CODEC_ERROR_OKAY;
    input->error = BITSTREAM_ERROR_OKAY;

    // first time through encoded_format is not initized.
    if (input->nWordsUsed > 4096 && decoder->image_dev_only == 0) // an I-frame is needed
    {
        SAMPLE_HEADER header;
        BITSTREAM input2;
        InitBitstreamBuffer(&input2, input->lpCurrentWord, input->nWordsUsed, BITSTREAM_ACCESS_READ);
        memset(&header, 0, sizeof(SAMPLE_HEADER));
        header.find_lowpass_bands = 2; // help finding the uncompressed flag
        if (ParseSampleHeader(&input2, &header))
        {
            decoder->codec.encoded_format = header.encoded_format;
            decoder->sample_uncompressed = header.hdr_uncompressed;
            if (decoder->parallelDecoder)
                decoder->parallelDecoder->sample_uncompressed = header.hdr_uncompressed;
        }
    }

    if ((uintptr_t)input->lpCurrentBuffer & 0x3)
    {

        if (decoder->aligned_sample_buffer == NULL)
        {

#if _ALLOCATOR
            ALLOCATOR *allocator = decoder->allocator;
            decoder->aligned_sample_buffer =
                (uint8_t *)AllocAligned(allocator, (size_t)input->dwBlockLength, 16);
#else
            decoder->aligned_sample_buffer =
                (uint8_t *)MEMORY_ALIGNED_ALLOC(input->dwBlockLength, 16);
#endif
            memcpy(decoder->aligned_sample_buffer, input->lpCurrentBuffer, input->dwBlockLength);
            decoder->aligned_sample_buffer_size = input->dwBlockLength;
        }
        else
        {
            if ((size_t)input->dwBlockLength <= decoder->aligned_sample_buffer_size)
            {
                memcpy(decoder->aligned_sample_buffer, input->lpCurrentBuffer, input->dwBlockLength);
            }
            else
            {
#if _ALLOCATOR
                ALLOCATOR *allocator = decoder->allocator;
                FreeAligned(decoder->allocator, decoder->aligned_sample_buffer);
                decoder->aligned_sample_buffer =
                    (uint8_t *)AllocAligned(allocator, input->dwBlockLength, 16);
#else
                MEMORY_ALIGNED_FREE(decoder->aligned_sample_buffer);
                decoder->aligned_sample_buffer =
                    (uint8_t *)MEMORY_ALIGNED_ALLOC(input->dwBlockLength, 16);
#endif
                memcpy(decoder->aligned_sample_buffer, input->lpCurrentBuffer, input->dwBlockLength);
                decoder->aligned_sample_buffer_size = input->dwBlockLength;
            }
        }

        input->lpCurrentBuffer = decoder->aligned_sample_buffer;
        input->lpCurrentWord = decoder->aligned_sample_buffer;
    }

#if 0 // Test for missaligning the image data
    if (((int)input->lpCurrentBuffer & 3) == 0)
    {
        int i;
        uint8_t *ptr = (uint8_t *)input->lpCurrentBuffer;
        int missaligned = 1; //2 or 3

        for (i = input->dwBlockLength - 1; i >= 0; i--)
            ptr[i + missaligned] = ptr[missaligned];

        input->lpCurrentBuffer = (uint8_t *)&ptr[missaligned];
        input->lpCurrentWord = (uint8_t *)&ptr[missaligned];
    }
#endif

    //HACK
    // Unfortunately I need color matrix data deep within the codec for RT playback.
    if (cfhddata && cfhddata->MagicNumber == CFHDDATA_MAGIC_NUMBER) // valid input
    {
        if (decoder->cfhddata.MagicNumber != CFHDDATA_MAGIC_NUMBER)
        {
            //int size = cfhddata->size;
            size_t size = cfhddata->size;
            memset(&decoder->cfhddata, 0, sizeof(CFHDDATA));
            if (size > sizeof(CFHDDATA))
            {
                // Limit the size to the known structure
                size = sizeof(CFHDDATA);
            }
            memcpy(&decoder->cfhddata, cfhddata, size);
        }
    }
    else
    {
        unsigned short value;

        if (decoder->cfhddata.MagicNumber != CFHDDATA_MAGIC_NUMBER || decoder->cfhddata.size != sizeof(CFHDDATA))
        {
            memset(&decoder->cfhddata, 0, sizeof(CFHDDATA));
            decoder->cfhddata.MagicNumber = CFHDDATA_MAGIC_NUMBER;
            decoder->cfhddata.size = sizeof(CFHDDATA);

            if (decoder->image_dev_only) // For baseband image only corrections, initize the decoder with defaults
            {
                decoder->cfhddata.cfhd_subtype = 2;		//RGB
                decoder->cfhddata.num_channels = 3;
            }
            else if (GetTuplet(input->lpCurrentBuffer, input->nWordsUsed, CODEC_TAG_INPUT_FORMAT, &value))
            {
                if (value == COLOR_FORMAT_RG48)
                {
                    decoder->cfhddata.cfhd_subtype = 2;		//RGB
                    decoder->cfhddata.num_channels = 3;
                }
                else if (value == COLOR_FORMAT_RG64)
                {
                    decoder->cfhddata.cfhd_subtype = 3;		//RGBA
                    decoder->cfhddata.num_channels = 4;
                }
                else if (value > COLOR_FORMAT_BAYER && value < COLOR_FORMAT_BAYER_END)
                {
                    unsigned int format = BAYER_FORMAT_RED_GRN;

                    decoder->cfhddata.cfhd_subtype = 1;		//BAYER
                    decoder->cfhddata.bayer_format = format; // default to Red-Grn
                    decoder->cfhddata.version = CFHDDATA_VERSION;
                }
            }
        }
    }


    OverrideCFHDDATA(decoder, input->lpCurrentBuffer, input->nWordsUsed);
    if (decoder->image_dev_only) // HACK we need to support 3D also.
        decoder->source_channels = 1;
    else
        decoder->source_channels = decoder->real_channels = SkipVideoChannel(decoder, input, 0);

    if (!decoder->basic_only && (decoder->cfhddata.MSChannel_type_value || decoder->cfhddata.MSCTV_Override))
    {
        //int channels = 0;
        int channel_blend_type = BLEND_NONE;
        int channel_swapped_flags = 0;

        if (decoder->cfhddata.MSCTV_Override)
        {
            channel_mask = decoder->cfhddata.MSCTV_Override & 0xff;
            channel_blend_type = ((decoder->cfhddata.MSCTV_Override >> 8) & 0xff);
            channel_swapped_flags = ((decoder->cfhddata.MSCTV_Override >> 16) & 0xffff);
        }
        else
        {
            channel_mask = decoder->cfhddata.MSChannel_type_value & 0xff;
            channel_blend_type = ((decoder->cfhddata.MSChannel_type_value >> 8) & 0xff);
            channel_swapped_flags = ((decoder->cfhddata.MSChannel_type_value >> 16) & 0xffff);
        }

        if (channel_mask != 3)
        {
            channel_blend_type = BLEND_NONE;
            channel_swapped_flags = 0;
        }

        //if(channels >= 2) // even "mono" files need to be displayed as Stereo if a 3D mode is selected //DAN20090302
        {

            if (channel_mask == 1 && decoder->source_channels >= 2) // Decode Left only
            {
                if (decoder->cfhddata.FramingFlags & 2) // channel swap
                {
                    SkipVideoChannel(decoder, input, 2); // 3D work
                }
            }
            else if (channel_mask == 2 && decoder->source_channels >= 2) // Decode Right only
            {
                if (decoder->cfhddata.FramingFlags & 2) // channel swap
                {
                    SkipVideoChannel(decoder, input, 1); // 3D work
                }
                else
                {
                    //assume second channel decode
                    SkipVideoChannel(decoder, input, 2); // 3D work
                }
                channel_current = 1;
                channel_decodes = 1;
                channel_blend_type = BLEND_NONE;
                channel_swapped_flags = 0;
            }
            else if (channel_mask == 2 && decoder->source_channels <= 1) // Decode 2D as Right channel
            {
                channel_current = 1;
                channel_decodes = 1;
                channel_blend_type = BLEND_NONE;
                channel_swapped_flags = 0;
            }
            else if ((channel_mask & 3) == 3) // A+B 3d work
            {
                channel_decodes = 2;
                decoder->channel_mix_half_res = 0;

                if (channel_blend_type != BLEND_NONE)
                {

                    if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                    {
                        //if(decoder->frame.format == DECODED_FORMAT_W13A)
                        //	{
                        //		decoder->frame.format = internal_format = DECODED_FORMAT_W13A;
                        //	}
                        //else
                        //{
                        //		decoder->frame.format = internal_format = DECODED_FORMAT_RG64;
                        //	}

                        decoder->frame.format = internal_format = DECODED_FORMAT_RGB32;
                        local_pitch = decoder->frame.width * 4;
                    }
                    else
                    {
                        decoder->frame.format = internal_format = DECODED_FORMAT_RGB24;
                        local_pitch = decoder->frame.width * 3; //RGB24
                    }

                    /*	if(decoder->frame.resolution == DECODED_RESOLUTION_FULL &&
                    		(output_format == DECODED_FORMAT_YUYV ||
                    		output_format == DECODED_FORMAT_UYVY))
                    	{
                    		if(  channel_blend_type == BLEND_FREEVIEW ||
                    			((channel_blend_type == BLEND_STACKED_ANAMORPHIC ||
                    			 channel_blend_type == BLEND_SIDEBYSIDE_ANAMORPHIC ||
                    			 channel_blend_type == BLEND_LINE_INTERLEAVED) && decoder->frame.width > 1280))
                    		{
                    			decoder->frame.resolution = DECODED_RESOLUTION_HALF;
                    			decoder->channel_mix_half_res = 1;
                    			decoder->frame.width /= 2;
                    			decoder->frame.height /= 2;

                    			local_pitch = (decoder->frame.width) * 3; //RGB24
                    		}
                    	} */
                }

                /*	if(channel_blend_type == BLEND_STEREO_YUY2inRGBA) //YUY2 in RGBA
                	{
                		decoder->frame.format = internal_format = DECODED_FORMAT_YUYV;
                		local_pitch = decoder->frame.width * 2; //YUY2

                		channel_offset = local_pitch * (decoder->frame.height);
                		use_local_buffer = true;
                	}*/

                /* DAN20120316 	FLAG3D_HALFRES broken			if(decoder->frame.resolution == DECODED_RESOLUTION_FULL && channel_swapped_flags & FLAG3D_HALFRES && output_format != DECODED_FORMAT_W13A)
                				{
                					decoder->frame.resolution = DECODED_RESOLUTION_HALF;
                					decoder->channel_mix_half_res = 1;
                					decoder->frame.width /= 2;
                					decoder->frame.height /= 2;
                					local_pitch /= 2;
                				} */

                if ( decoder->frame.resolution == DECODED_RESOLUTION_FULL &&
                        (channel_blend_type == BLEND_SIDEBYSIDE_ANAMORPHIC || channel_blend_type == BLEND_FREEVIEW))
                {
                    if (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER)
                    {
                        if (decoder->sample_uncompressed)
                        {
                            decoder->frame.resolution = DECODED_RESOLUTION_HALF;
                            decoder->channel_mix_half_res = 1;
                            decoder->frame.width /= 2;
                            decoder->frame.height /= 2;
                            local_pitch /= 2;
                        }
                        else
                        {
                            if (decoder->preformatted_3D_type > BLEND_NONE)
                            {
                                // leave as is.
                            }
                            else if (FORMAT8BIT(output_format))
                            {
                                decoder->frame.resolution = DECODED_RESOLUTION_HALF_HORIZONTAL;
                                decoder->frame.width /= 2;
                                local_pitch /= 2;
                            }
                        }
                    }
                    else
                    {
                        if (FORMAT8BIT(output_format))
                            decoder->frame.resolution = DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER;
                    }

                    //TODO int uncompressed = decoder->uncompressed_chunk && decoder->uncompressed_size && decoder->sample_uncompressed;

                }


                if (channel_blend_type >= BLEND_STACKED_ANAMORPHIC && channel_blend_type < BLEND_ANAGLYPH_RC) // stacked, side-by-side, fields, Onion, YUY2
                {
                    channel_offset = local_pitch * (decoder->frame.height);

                }
                else if (channel_blend_type >= BLEND_ANAGLYPH_RC)
                {
                    /*		if(channel_blend_type & 1 && channel_blend_type <= 21) // B&W Anaglyph
                    		{
                    			//B&W using YUYV
                    			decoder->frame.format = internal_format = DECODED_FORMAT_YUYV;
                    			local_pitch = decoder->frame.width * 2; //YUY2
                    		}*/

                    channel_offset = local_pitch * (decoder->frame.height);
                    use_local_buffer = true;
                }
                else if (channel_blend_type == BLEND_NONE) // double high
                {
                    channel_offset = pitch * decoder->frame.height;
                }
                else
                {
                    channel_blend_type = BLEND_STACKED_ANAMORPHIC;
                    channel_offset = pitch * (decoder->frame.height / 2);
                }

                // fields, stacked, etc, only works on full or half res.
                if (channel_blend_type > BLEND_NONE && channel_blend_type <= BLEND_LINE_INTERLEAVED &&
                        decoder->frame.resolution == DECODED_RESOLUTION_LOWPASS_ONLY) //thumnbail.
                {
                    channel_decodes = 1;
                    channel_blend_type = BLEND_NONE;
                    channel_swapped_flags = 0;
                }
                if (channel_blend_type != BLEND_NONE &&
                        (output_format == DECODED_FORMAT_BYR1 ||
                         output_format == DECODED_FORMAT_BYR2 ||
                         output_format == DECODED_FORMAT_BYR3 ||
                         output_format == DECODED_FORMAT_BYR4 ))
                {
                    channel_decodes = 1;
                    channel_blend_type = BLEND_NONE;
                    channel_swapped_flags = 0;
                }
            }
        }

        decoder->channel_decodes = channel_decodes;
        decoder->channel_blend_type = channel_blend_type;
        decoder->channel_swapped_flags = channel_swapped_flags;
    }
    else
    {
        decoder->channel_decodes = channel_decodes = 1;
        decoder->channel_blend_type = BLEND_NONE;
        decoder->channel_swapped_flags = 0;
    }

    if (cfhddata) // So the P-frames can know the bayerformat
    {
        //int size = cfhddata->size;
        size_t size = cfhddata->size;

        if (size > sizeof(CFHDDATA))
        {
            size = sizeof(CFHDDATA);
        }
        memcpy(cfhddata, &decoder->cfhddata, size);
    }

    {
        bool doOrientation = true;
        bool doFraming = true;
        bool doBurins = true;
        bool doImageflips = true;
        bool doGhostBust = false;
        bool doPrimaries = true;
        int process_path_flags = decoder->cfhddata.process_path_flags;
        int process_path_flags_mask = decoder->cfhddata.process_path_flags_mask;



        if (decoder->basic_only)
        {
            doOrientation = false;
            doFraming = false;
            doBurins = false;
            doImageflips = false;
            doPrimaries = false;
        }
        else
        {
            if (decoder->cfhddata.process_path_flags_mask)
            {
                //DAN20101007 --
                if (process_path_flags == 0)
                    decoder->cfhddata.process_path_flags = process_path_flags = decoder->cfhddata.process_path_flags_mask;

                process_path_flags &= decoder->cfhddata.process_path_flags_mask;
                if (process_path_flags_mask & PROCESSING_ACTIVE2)
                {
                    if (!(process_path_flags_mask & PROCESSING_ORIENTATION))
                        doOrientation = false;
                    if (!(process_path_flags_mask & PROCESSING_FRAMING))
                        doFraming = false;
                    if (!(process_path_flags_mask & PROCESSING_BURNINS))
                        doBurins = false;
                    if (!(process_path_flags_mask & PROCESSING_IMAGEFLIPS))
                        doImageflips = false;
                }

                if (!(process_path_flags_mask & PROCESSING_COLORMATRIX))
                    doPrimaries = false;
            }

            if (process_path_flags & PROCESSING_ACTIVE2)
            {
                if (!(process_path_flags & PROCESSING_ORIENTATION))
                    doOrientation = false;
                if (!(process_path_flags & PROCESSING_FRAMING))
                    doFraming = false;
                if (!(process_path_flags & PROCESSING_BURNINS))
                    doBurins = false;
                if (!(process_path_flags & PROCESSING_IMAGEFLIPS))
                    doImageflips = false;
                if (!(process_path_flags	& PROCESSING_COLORMATRIX))
                    doPrimaries = false;
            }
        }

        if (doOrientation)
            process_path_flags |= PROCESSING_ORIENTATION;
        if (doFraming)
            process_path_flags |= PROCESSING_FRAMING;
        if (doBurins)
            process_path_flags |= PROCESSING_BURNINS;
        if (doImageflips)
            process_path_flags |= PROCESSING_IMAGEFLIPS;
        if (doPrimaries)
            process_path_flags |= PROCESSING_COLORMATRIX;

        if (decoder->channel_swapped_flags & FLAG3D_GHOSTBUST)
        {
            if (decoder->ghost_bust_left || decoder->ghost_bust_right)
            {
                doGhostBust = true;
            }
        }

        decoder->cfhddata.process_path_flags = process_path_flags;

        if ((!decoder->basic_only &&
                (doOrientation && (	decoder->cfhddata.channel[0].FloatingWindowMaskL ||
                                    decoder->cfhddata.channel[0].FloatingWindowMaskR ||
                                    decoder->cfhddata.channel[0].FrameKeyStone ||
                                    decoder->cfhddata.channel[0].FrameTilt ||
                                    decoder->cfhddata.channel[0].HorizontalOffset ||
                                    decoder->cfhddata.channel[0].VerticalOffset ||
                                    decoder->cfhddata.channel[0].RotationOffset ||

                                    decoder->cfhddata.channel[1].FloatingWindowMaskL ||
                                    decoder->cfhddata.channel[1].FloatingWindowMaskR ||
                                    decoder->cfhddata.channel[1].FrameKeyStone ||
                                    decoder->cfhddata.channel[1].FrameTilt ||
                                    decoder->cfhddata.channel[1].HorizontalOffset ||
                                    decoder->cfhddata.channel[1].VerticalOffset ||
                                    decoder->cfhddata.channel[1].RotationOffset ||
                                    decoder->cfhddata.channel[0].FrameAutoZoom * decoder->cfhddata.channel[1].FrameDiffZoom != 1.0 ||

                                    decoder->cfhddata.channel[2].FloatingWindowMaskL ||
                                    decoder->cfhddata.channel[2].FloatingWindowMaskR ||
                                    decoder->cfhddata.channel[2].FrameKeyStone ||
                                    decoder->cfhddata.channel[2].FrameTilt ||
                                    decoder->cfhddata.channel[2].HorizontalOffset ||
                                    decoder->cfhddata.channel[2].VerticalOffset ||
                                    decoder->cfhddata.channel[2].RotationOffset ||
                                    decoder->cfhddata.channel[0].FrameAutoZoom / decoder->cfhddata.channel[2].FrameDiffZoom != 1.0)))
                ||
                (doPrimaries && (	decoder->cfhddata.channel[0].user_blur_sharpen != 0.0 ||
                                    decoder->cfhddata.channel[1].user_blur_sharpen != 0.0 ||
                                    decoder->cfhddata.channel[2].user_blur_sharpen != 0.0))
                ||
                (doFraming && (		decoder->cfhddata.channel[0].user_vignette_start != 0.0 ||
                                    decoder->cfhddata.channel[1].user_vignette_start != 0.0 ||
                                    decoder->cfhddata.channel[2].user_vignette_start != 0.0))
                ||
                (doFraming &&	(	memcmp(&decoder->cfhddata.channel[0].FrameMask, &emptyFrameMask, 32) ||
                                    decoder->cfhddata.FrameOffsetX ||
                                    decoder->cfhddata.FrameOffsetY ||
                                    decoder->cfhddata.FrameOffsetR ||
                                    decoder->cfhddata.FrameHScale != 1.0 ||
                                    decoder->cfhddata.FrameHDynamic != 1.0 ||
                                    decoder->cfhddata.channel[1].FrameZoom != 1.0 ||
                                    decoder->cfhddata.channel[2].FrameZoom != 1.0))
                ||
                (doGhostBust && (decoder->channel_blend_type == BLEND_NONE) && (channel_decodes == 2))
                ||
                (doImageflips && decoder->cfhddata.channel_flip)
                ||
                (decoder->preformatted_3D_type == BLEND_STACKED_ANAMORPHIC) ||
                (decoder->preformatted_3D_type == BLEND_SIDEBYSIDE_ANAMORPHIC) ||
                (decoder->channel_blend_type && decoder->frame.resolution == DECODED_RESOLUTION_QUARTER) ||  // 3D mode generally don't work in quarter res -- this prevents crashes.
                ( ((decoder->frame.width + 7) / 8) * 8 != decoder->frame.width  || (channel_decodes > 1 && decoder->channel_blend_type != BLEND_NONE) ||
                  decoder->sample_uncompressed) ||
                (decoder->cfhddata.doMesh)

           )
        {
            if (	output_format == DECODED_FORMAT_BYR1 ||
                    output_format == DECODED_FORMAT_BYR2 ||
                    output_format == DECODED_FORMAT_BYR3 ||
                    output_format == DECODED_FORMAT_BYR4 )
            {
                // no manipulation should be applied
            }
            else
            {
                use_local_buffer = true;
                local_pitch = ((decoder->frame.width + 7) / 8) * 8 * 6; //RGB48

                if (decoder->image_dev_only)
                {
                    decoder->frame.white_point = 13;
                    decoder->frame.format = internal_format = DECODED_FORMAT_WP13;
                }
                else if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                {
                    decoder->frame.white_point = 13;
                    decoder->frame.format = internal_format = DECODED_FORMAT_W13A;
                    local_pitch = ((decoder->frame.width + 7) / 8) * 8 * 8;
                }
                else
                {
                    decoder->frame.white_point = 13;
                    decoder->frame.format = internal_format = DECODED_FORMAT_WP13;
                }

                if (	decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL ||
                        decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER)
                {
                    local_pitch *= 2;  // need horizontal room to make 3D side by side frame
                }

                /*
                				if(output_format == DECODED_FORMAT_WP13 || output_format == DECODED_FORMAT_W13A)
                				{
                					// preserve HDR
                					decoder->frame.format = internal_format = output_format;//DECODED_FORMAT_WP13; // HDR output

                					if(output_format == DECODED_FORMAT_W13A)
                						local_pitch = decoder->frame.width * 8;
                				}
                				else
                				{
                					if(decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                					{
                						decoder->frame.format = internal_format = DECODED_FORMAT_RG64;
                						local_pitch = decoder->frame.width * 8;
                					}
                					else
                					{
                						decoder->frame.format = internal_format = DECODED_FORMAT_RG48;
                					}
                				}*/

                channel_offset = local_pitch * (decoder->frame.height);
            }
        }
    }

    if (output_format == DECODED_FORMAT_BYR4 && decoder->cfhddata.encode_curve_preset == 0)
    {
        if (decoder->BYR4LinearRestore == NULL)
        {
            int j, val;
            int encode_curve_type = decoder->cfhddata.encode_curve >> 16;
            //int encode_curve_neg = encode_curve_type & CURVE_TYPE_NEGATIVE;
            float encode_curvebase;

            if (encode_curve_type) //1 or 2
            {
                if (encode_curve_type & CURVE_TYPE_EXTENDED)
                    encode_curvebase = (float)(decoder->cfhddata.encode_curve & 0xffff); // use all 16-bits for larger log bases
                else
                    encode_curvebase = (float)((decoder->cfhddata.encode_curve >> 8) & 0xff) / (float)(decoder->cfhddata.encode_curve & 0xff);
            }
            else
            {
                encode_curve_type = CURVE_TYPE_LOG;
                encode_curvebase = 90.0;
            }

#if _ALLOCATOR
            decoder->BYR4LinearRestore = (unsigned short *)AllocAligned(decoder->allocator, 16384 * 2, 16);
#else
            decoder->BYR4LinearRestore = (unsigned short *)MEMORY_ALIGNED_ALLOC(16384 * 2, 16);
#endif

            for (j = 0; j < 16384; j++) //0 to 1
            {
                switch (encode_curve_type & CURVE_TYPE_MASK)
                {
                    case CURVE_TYPE_LOG:
                        val = (int)(CURVE_LOG2LIN((float)j / 16384.0f,
                                                  (float)encode_curvebase) * 65535.0f);
                        break;
                    case CURVE_TYPE_GAMMA:
                        val = (int)(CURVE_GAM2LIN((float)j / 16384.0f,
                                                  (float)encode_curvebase) * 65535.0f);
                        break;
                    case CURVE_TYPE_CINEON:
                        val = (int)(CURVE_CINEON2LIN((float)j / 16384.0f,
                                                     (float)encode_curvebase) * 65535.0f);
                        break;
                    case CURVE_TYPE_CINE985:
                        val = (int)(CURVE_CINE9852LIN((float)j / 16384.0f,
                                                      (float)encode_curvebase) * 65535.0f);
                        break;
                    case CURVE_TYPE_PARA:
                        val = (int)(CURVE_PARA2LIN((float)j / 16384.0f,
                                                   (int)((decoder->cfhddata.encode_curve >> 8) & 0xff), (int)(decoder->cfhddata.encode_curve & 0xff)) * 65535.0f);
                        break;
                    case CURVE_TYPE_CSTYLE:
                        val = (int)(CURVE_CSTYLE2LIN((float)j / 16384.0f,
                                                     (int)((decoder->cfhddata.encode_curve >> 8) & 0xff)) * 65535.0f);
                        break;
                    case CURVE_TYPE_SLOG:
                        val = (int)(CURVE_SLOG2LIN((float)j / 16384.0f) * 65535.0f);
                        break;
                    case CURVE_TYPE_LOGC:
                        val = (int)(CURVE_LOGC2LIN((float)j / 16384.0f) * 65535.0f);
                        break;
                    case CURVE_TYPE_LINEAR:
                    default:
                        val = j;
                        break;
                }
                if (val < 0) val = 0;
                if (val > 65535) val = 65535;
                decoder->BYR4LinearRestore[j] = val;
            }
        }
    }

    //DAN20120319 - removed
    /*if(decoder->channel_mix_half_res)	//decoding half but scaling to double the output size
    {
    	local_pitch *= 2;
    	channel_offset = local_pitch * (decoder->frame.height*2);
    }*/


    if (use_local_buffer == true) // need buffer for anaglyph and other 3D presentation formats
    {
        int stereoframesize = channel_offset * channel_decodes/*stacked frames*/;
        if (decoder->source_channels == 1 && decoder->preformatted_3D_type == BLEND_NONE)
            stereoframesize = channel_offset;

        if (channel_decodes == 1 && decoder->preformatted_3D_type != BLEND_NONE)
            stereoframesize = channel_offset * 2;

        if (channel_decodes == 2 && decoder->source_channels == 1 && decoder->channel_blend_type != BLEND_NONE)
            stereoframesize = channel_offset * 2;


        if (decoder->StereoBuffer == NULL || decoder->StereoBufferSize < stereoframesize)
        {

#if _ALLOCATOR
            if (decoder->StereoBuffer)
            {
                FreeAligned(decoder->allocator, decoder->StereoBuffer);
                decoder->StereoBuffer = NULL;
            }
            decoder->StereoBuffer = (PIXEL16U *)AllocAligned(decoder->allocator, stereoframesize + 256, 16); //DAN20130517 add 256, as 2.7K half we are write off the buffers end for zoom, don't know why yet.
#else
            if (decoder->StereoBuffer)
            {
                MEMORY_ALIGNED_FREE(decoder->StereoBuffer);
                decoder->StereoBuffer = NULL;
            }
            decoder->StereoBuffer = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(stereoframesize + 256, 16); //DAN20130517 add 256, as 2.7K half we are write off the buffers end for zoom, don't know why yet.
#endif
            assert(decoder->StereoBuffer != NULL);
            if (! (decoder->StereoBuffer != NULL))
            {
                return CODEC_ERROR_MEMORY_ALLOC;
            }
            decoder->StereoBufferSize = stereoframesize;
        }

        decoder->StereoBufferFormat = internal_format;
        local_buffer = (uint8_t *)decoder->StereoBuffer;
        local_output = local_buffer;
    }

    DecodeEntropyInit(decoder);
    //swapped  -- Maybe useful for double height decodes.
    /*	if(channel_decodes == 2 && channel_swapped_flags & FLAG3D_SWAPPED)
    	{
    		local_output += channel_offset;
    		channel_offset = -channel_offset;
    	}*/

    decoder->use_local_buffer = use_local_buffer ? 1 : 0;

    if (channel_decodes == 2 && decoder->parallelDecoder == NULL && decoder->source_channels > 1)
    {
        int encoded_width = decoder->frame.width;
        int encoded_height = decoder->frame.height;
        if (decoder->frame.resolution == DECODED_RESOLUTION_HALF)
        {
            // Compute the encoded dimensions from the frame dimensions
            encoded_width *= 2;
            encoded_height *= 2;
        }
        else if (decoder->frame.resolution == DECODED_RESOLUTION_QUARTER)
        {
            // Compute the encoded dimensions from the frame dimensions
            encoded_width *= 4;
            encoded_height *= 4;
        }
        else if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
        {
            // Compute the encoded dimensions from the frame dimensions
            encoded_width *= 2;
        }
        else if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_VERTICAL)
        {
            // Compute the encoded dimensions from the frame dimensions
            encoded_height *= 2;
        }


#if _ALLOCATOR
        decoder->parallelDecoder = (DECODER *)Alloc(decoder->allocator, sizeof(DECODER));
        if (decoder->parallelDecoder)
        {
            memset(decoder->parallelDecoder, 0, sizeof(DECODER));
            DecodeInit(decoder->allocator, decoder->parallelDecoder, encoded_width, encoded_height,
                       internal_format, DECODED_RESOLUTION_FULL, NULL);
        }
#else
        decoder->parallelDecoder = (DECODER *)MEMORY_ALLOC(sizeof(DECODER));
        if (decoder->parallelDecoder)
        {
            memset(decoder->parallelDecoder, 0, sizeof(DECODER));
            decoder->parallelDecoder->thread_cntrl = decoder->thread_cntrl;
            DecodeInit(decoder->parallelDecoder, encoded_width, encoded_height,
                       internal_format, DECODED_RESOLUTION_FULL, NULL);
        }
#endif
    }

    // Using the parallel decoder?
    if (decoder->parallelDecoder)
    {
        // Initialize the parallel decoder with parameters from the regular decoder
        memcpy(&decoder->parallelDecoder->cfhddata, &decoder->cfhddata, sizeof(CFHDDATA));

        DecodeEntropyInit(decoder->parallelDecoder);

        decoder->parallelDecoder->channel_decodes = decoder->channel_decodes;
        decoder->parallelDecoder->channel_blend_type = decoder->channel_blend_type;
        decoder->parallelDecoder->flags = decoder->flags;
        decoder->parallelDecoder->frame = decoder->frame;

        decoder->parallelDecoder->use_local_buffer = use_local_buffer ? 1 : 0;
        decoder->parallelDecoder->codec.encoded_format = decoder->codec.encoded_format;

        if (decoder->parallelDecoder->decoder_thread.pool.thread_count == 0)
        {
            CreateLock(&decoder->parallelDecoder->decoder_thread.lock);

            // Initialize the pool of transform worker threads
            ThreadPoolCreate(&decoder->parallelDecoder->decoder_thread.pool,
                             1, //
                             ParallelThreadProc,
                             decoder->parallelDecoder);
        }
    }

    if (channel_decodes == 2 && decoder->real_channels > 1 && decoder->parallelDecoder && decoder->parallelDecoder->decoder_thread.pool.thread_count)
    {
        // Second stream as a thread.
        BITSTREAM second_input = *input;

        if (decoder->cfhddata.FramingFlags & 2 && decoder->source_channels >= 2) // channel swap
        {
            BITSTREAM leftEye_input = *input;
            SkipVideoChannel(decoder, &leftEye_input, 2); // 3D work
            *input = leftEye_input;
            SkipVideoChannel(decoder, &second_input, 1); // 3D work
        }
        else
            SkipVideoChannel(decoder, &second_input, 2); // 3D work

        decoder->channel_current = 0;
        decoder->parallelDecoder->channel_current = 1;

        // Instead of reading the metadata databases again, use the ones in the main decoder
        OverrideCFHDDATAUsingParent(decoder->parallelDecoder, decoder, input->lpCurrentBuffer, input->nWordsUsed);

        // Hack, this gets lost
        decoder->parallelDecoder->cfhddata.split_CC_position = decoder->cfhddata.split_CC_position;

        // Post a message to the mailbox
        decoder->parallelDecoder->decoder_thread.input = &second_input;

        if (use_local_buffer == false &&
                (decoder->frame.format == DECODED_FORMAT_RGB32 || decoder->frame.format == DECODED_FORMAT_RGB24))
        {
            decoder->parallelDecoder->decoder_thread.output = local_output;
            local_output += channel_offset;
        }
        else
        {
            decoder->parallelDecoder->decoder_thread.output = local_output + channel_offset;
        }

        decoder->parallelDecoder->decoder_thread.pitch = local_pitch;
        decoder->parallelDecoder->decoder_thread.colorparams = colorparams;

        // Set the work count to the number of rows to process
        ThreadPoolSetWorkCount(&decoder->parallelDecoder->decoder_thread.pool, 1);

        // Start the transform worker threads
        ThreadPoolSendMessage(&decoder->parallelDecoder->decoder_thread.pool, THREAD_MESSAGE_START);

        // do the first channel
        {
            TAGVALUE segment;
            int sample_type;

#if _THREADED
            decoder->entropy_worker_new.next_queue_num = 0;
            decoder->entropy_worker_new.threads_used = 0;
#endif

            // Get the type of sample
            segment = GetTagValue(input);
            assert(segment.tuple.tag == CODEC_TAG_SAMPLE);
            if (!IsValidSegment(input, segment, CODEC_TAG_SAMPLE))
            {
                decoder->error = CODEC_ERROR_BITSTREAM;
                STOP(tk_decompress);
                return false;
            }
            sample_type = segment.tuple.value;

            switch (sample_type)
            {
                case SAMPLE_TYPE_GROUP:		// Group of frames (decode the first frame)
                    result = DecodeSampleGroup(decoder, input, local_output, local_pitch, colorparams);
                    break;

                case SAMPLE_TYPE_FRAME:		// Decode the second or later frame in a group
                    result = DecodeSampleFrame(decoder, input, local_output, local_pitch, colorparams);
                    break;

                case SAMPLE_TYPE_IFRAME:	// Decode a sample that represents an isolated frame
                    result = DecodeSampleIntraFrame(decoder, input, local_output, local_pitch, colorparams);
                    break;

                case SAMPLE_TYPE_SEQUENCE_HEADER:
                    // The video sequence header is ignored
                    result = true;
                    break;

                default:
                    // Need to fill the output frame
                    //error = CODEC_ERROR_SAMPLE_TYPE;
                    result = false;
            }
        }

        // Wait for all of the worker threads to finish
        ThreadPoolWaitAllDone(&decoder->parallelDecoder->decoder_thread.pool);
    }
    else
    {
        while (channel_decodes > 0)
        {
            TAGVALUE segment;
            int sample_type;

            local_decoder->channel_current = channel_current++;

#if _THREADED
            local_decoder->entropy_worker_new.next_queue_num = 0;
            local_decoder->entropy_worker_new.threads_used = 0;
#endif

            if (decoder->image_dev_only)
            {
                result = DecodeSampleIntraFrame(local_decoder, input, local_output, local_pitch, colorparams);
            }
            else
            {
                // Get the type of sample
                segment = GetTagValue(input);
                assert(segment.tuple.tag == CODEC_TAG_SAMPLE);
                if (!IsValidSegment(input, segment, CODEC_TAG_SAMPLE))
                {
                    local_decoder->error = CODEC_ERROR_BITSTREAM;
                    STOP(tk_decompress);
                    return false;
                }
                sample_type = segment.tuple.value;

                switch (sample_type)
                {
                    case SAMPLE_TYPE_GROUP:		// Group of frames (decode the first frame)
                        result = DecodeSampleGroup(local_decoder, input, local_output, local_pitch, colorparams);
                        break;

                    case SAMPLE_TYPE_FRAME:		// Decode the second or later frame in a group
                        result = DecodeSampleFrame(local_decoder, input, local_output, local_pitch, colorparams);
                        break;

                    case SAMPLE_TYPE_IFRAME:	// Decode a sample that represents an isolated frame
                        result = DecodeSampleIntraFrame(local_decoder, input, local_output, local_pitch, colorparams);
                        break;

                    case SAMPLE_TYPE_SEQUENCE_HEADER:
                        // The video sequence header is ignored
                        result = true;
                        break;

                    default:
                        // Need to fill the output frame
                        //error = CODEC_ERROR_SAMPLE_TYPE;
                        result = false;
                }
            }

            if (ConvertPreformatted3D(decoder, use_local_buffer, internal_format, channel_mask, local_output, local_pitch, &channel_offset))
            {
                channel_decodes = 0;
            }
            else
            {
                channel_decodes--;

                local_output += channel_offset;

                if (decoder->parallelDecoder)
                {
                    local_decoder = decoder->parallelDecoder;
                }
            }
        }
    }

    if (use_local_buffer && output)
    {
        decoder->use_local_buffer = 0;
        ConvertLocalToOutput(decoder, output, pitch, output_format, local_buffer, local_pitch, abs(channel_offset));
    }

    if (decoder->channel_mix_half_res)	//HACK
    {
        decoder->frame.resolution = DECODED_RESOLUTION_FULL;
        decoder->frame.width *= 2;
        decoder->frame.height *= 2;
        decoder->channel_mix_half_res = 0;
    }

    if (	decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL) //HACK
    {
        decoder->frame.resolution = DECODED_RESOLUTION_FULL;
        decoder->frame.width *= 2;
    }
    if (	decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER) //HACK
    {
        decoder->frame.resolution = DECODED_RESOLUTION_FULL;
    }

    STOP(tk_decompress);

    // Return indication of whether decoding succeeded or failed
    return result;
}


// Decode a sample that encoded a group of frames (return the first frame)
bool DecodeSampleGroup(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    int32_t frame_size = decoder->frame.height * pitch;
    int resolution = decoder->frame.resolution;
    bool result = true;

    static int subband_wavelet_index[] = {5, 5, 5, 5, 4, 4, 4, 3, 3, 3, 3, 1, 1, 1, 0, 0, 0};
    static int subband_band_index[] = {0, 1, 2, 3, 1, 2, 3, 0, 1, 2, 3, 1, 2, 3, 1, 2, 3};

    int num_subbands = sizeof(subband_wavelet_index) / sizeof(subband_wavelet_index[0]);

#if (0 && DEBUG)
    // Force quarter resolution decoding for debug that feature
    resolution = DECODED_RESOLUTION_QUARTER;
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decoding sample group\n");
    }
#endif

    START(tk_decoding);

    // Initialize the codec state
    InitCodecState(&decoder->codec);

    // Allocate the transform data structure for the group of frames
    AllocDecoderGroup(decoder);

    // Initialize the tables for decoding the wavelet transforms
    InitWaveletDecoding(decoder, subband_wavelet_index, subband_band_index, num_subbands);

    // Clear the flags in the wavelet transforms
    ClearTransformFlags(decoder);

    // Process the tag value pairs until an encoded subband is found
    for (;;)
    {
        TAGVALUE segment;

        // Read the next tag value pair from the bitstream
        //segment = GetTagValue(input);
        segment = GetSegment(input);
        assert(input->error == BITSTREAM_ERROR_OKAY);
        if (input->error != BITSTREAM_ERROR_OKAY)
        {
            decoder->error = CODEC_ERROR_BITSTREAM;
            result = false;
            break;
        }

        // Update the codec state with the information in the tag value pair
        {
            TAGWORD tag = segment.tuple.tag;
            TAGWORD value = segment.tuple.value;

            // Use the tag value pair to update the codec state
            error = UpdateCodecState(decoder, input, codec, tag, value);

            assert(error == CODEC_ERROR_OKAY);

            if (error != CODEC_ERROR_OKAY)
            {
                decoder->error = error;
                result = false;
                break;
                //NOTE: Consider moving the error code into the codec state
            }
        }

        // Check whether the group has been decoded
        if (codec->sample_done) break;

        // Skip the rest of the current channel?
        if (CanSkipChannel(decoder, resolution))
        {
            if (codec->channel == 3 && (decoder->frame.format == DECODED_FORMAT_YUYV || decoder->frame.format == DECODED_FORMAT_UYVY))
            {
                int channel = codec->channel;
                uint32_t channel_size = codec->channel_size[channel];
                uint8_t  *position = codec->channel_position + channel_size;

                // Advance the bitstream to the next channel
                SetBitstreamPosition(input, position);

                // Reset the decoded subband flags (otherwise this code will be executed again)
                codec->decoded_subband_flags = 0;

                codec->num_channels = 3;
                goto decoding_complete;
            }
            else if (resolution == DECODED_RESOLUTION_LOWPASS_ONLY)
            {
                int channel = codec->channel;
                uint32_t channel_size = codec->channel_size[channel];
                uint8_t  *position = codec->channel_position + channel_size;


                // Advance the bitstream to the next channel
                SetBitstreamPosition(input, position);

                // Reset the decoded subband flags (otherwise this code will be executed again)
                codec->decoded_subband_flags = 0;
            }
            else
            {
                // Compute the bitstream position after the current channel
                int channel = codec->channel;
                uint32_t channel_size = codec->channel_size[channel];
                uint8_t  *position = codec->channel_position + channel_size;

                // Get the temporal wavelet
                int temporal_index = 2;
                TRANSFORM *transform = decoder->transform[channel];
                IMAGE *wavelet = transform->wavelet[temporal_index];

#if (0 && DEBUG)
                if (IsBandValid(wavelet, HIGHPASS_BAND))
                {
                    int static count = 0;
                    if (count < 20)
                    {
                        char label[_MAX_PATH];
                        sprintf(label, "Temporal-decode-%d-", count);
                        DumpBandPGM(label, wavelet, HIGHPASS_BAND, NULL);
                    }
                    count++;
                }
#endif
#if _THREADED_DECODER
                // Ready to invert this wavelet to get the lowpass band in the lower wavelet?
                //if (DecodedBandsValid(wavelet, temporal_index))
                if (resolution != DECODED_RESOLUTION_QUARTER || (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER))
#else
                // Have all bands in the temporal wavelet been decoded?
                //if (wavelet && BANDS_ALL_VALID(wavelet))
                if (AllBandsValid(wavelet))
#endif
                {
                    //PIXEL *buffer = (PIXEL *)decoder->buffer;
                    //size_t buffer_size = decoder->buffer_size;
                    int precision = codec->precision;
#if (0 && DEBUG)
                    if (logfile)
                    {
                        fprintf(logfile, "Reconstructing the lowpass bands in the first level wavelets\n");
                    }
#endif
#if _THREADED_DECODER
                    // Add the temporal inverse transform to the processing queue
                    if (decoder->entropy_worker_new.pool.thread_count)
                    {
                        ReconstructWaveletBand(decoder, transform, channel, wavelet, temporal_index,
                                               precision, &decoder->scratch, 1);
                        QueueThreadedTransform(decoder, channel, temporal_index);
                    }
                    else
#endif
                    {
                        // Reconstruct the lowpass bands in the first level wavelets
                        //ReconstructWaveletBand(transform, channel, wavelet, temporal_index, precision, buffer, buffer_size);
                        ReconstructWaveletBand(decoder, transform, channel, wavelet, temporal_index,
                                               precision, &decoder->scratch, 0 );
                    }

                    // Advance the bitstream to the next channel
                    SetBitstreamPosition(input, position);

                    // Reset the decoded subband flags (otherwise this code will be executed again)
                    codec->decoded_subband_flags = 0;

                    // Note that the subband flags are also reset when the channel header is decoded
                }
                // Was the wavelet created?
                else if (wavelet == NULL)
                {
                    // The temporal wavelet is not created during quarter resolution decoding

                    // Advance the bitstream to the next channel
                    SetBitstreamPosition(input, position);

                    // Reset the decoded subband flags (otherwise this code will be executed again)
                    codec->decoded_subband_flags = 0;
                }

                //TODO: Improve quarter resolution decoding so that the wavelet is created?
            }
        }
    }

decoding_complete:
    STOP(tk_decoding);

#if (0 && DEBUG)
    if (logfile)
    {
        char label[_MAX_PATH];
        int channel;

        for (channel = 0; channel < codec->num_channels; channel++)
        {
            TRANSFORM *transform = decoder->transform[channel];
            IMAGE *wavelet = transform->wavelet[2];
            uint8_t *data = (uint8_t *)wavelet->band[HIGHPASS_BAND];
            int height = wavelet->height;
            int pitch = wavelet->pitch;
            int size = height * pitch;
            int band;

            for (band = 0; band < wavelet->num_bands; band++)
            {
                sprintf(label, "Temporal channel: %d, band: %d", channel, band);
                DumpBandStatistics(label, wavelet, band, logfile);
#if 0
                sprintf(label, "Temporal-channel%d-band%d-", channel, band);
                DumpBandPGM(label, wavelet, band, NULL);
#endif
            }

            assert(size > 0);
            ZeroMemory(data, size);
        }
    }
#endif

    if (result)
    {
        // Two frames have been decoded
        decoder->gop_length = 2;
        decoder->frame_count += 2;

#if (1 && DEBUG)
        if (logfile)
        {
            fprintf(logfile,
                    "DecodeSampleGroup, decoder: 0x%p, GOP length: %d\n",
                    decoder, decoder->gop_length);
        }
#endif

        // Return the first frame in the group
        if (!decoder->no_output)
        {
#if 0
            // Decoding to quarter frame resolution at full frame rate?
            if (resolution == DECODED_RESOLUTION_QUARTER)
            {
                int num_channels = codec->num_channels;
                FRAME_INFO *info = &decoder->frame;
                char *buffer = decoder->buffer;
                size_t buffer_size = decoder->buffer_size;

                uint8_t *frame1 = output;
                uint8_t *frame2 = decoder->output2;
                assert(frame2 != NULL);

                // Reconstruct two frames at quarter resolution
                ReconstructQuarterFrame(decoder, num_channels,
                                        frame1, frame2, pitch,
                                        info, buffer, buffer_size);
            }
            else
#endif

                // Finish computing the output frame
                ReconstructSampleFrameToBuffer(decoder, 0, output, pitch);
        }

        if (decoder->error != CODEC_ERROR_OKAY)
        {
            result = false;
        }

#if TIMING
        // Increment the count of bytes that have been decoded
        decode_byte_count += (COUNTER)BitstreamByteCount(input);
#endif
    }

    if (!result)
    {
        // Check that the frame can be cleared
        assert(frame_size > 0);
        if (frame_size > 0)
        {
            // Zero the frame
            memset(output, 0, frame_size);
        }
    }

    return result;
}

// Decode a sample that represents the second frame in a group
bool DecodeSampleFrame(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    CODEC_STATE *codec = &decoder->codec;
    int32_t frame_size = decoder->frame.height * pitch;
    bool result = true;

    START(tk_decoding);

    // Decode the tag value pairs in the frame sample
    for (;;)
    {
        TAGWORD tag;
        TAGWORD value;

        // Read the next tag value pair from the bitstream
        //TAGVALUE segment = GetTagValue(input);
        TAGVALUE segment = GetSegment(input);
        assert(input->error == BITSTREAM_ERROR_OKAY);
        if (input->error != BITSTREAM_ERROR_OKAY)
        {
            decoder->error = CODEC_ERROR_BITSTREAM;
            result = false;
            break;
        }

        // Update the codec state with the information in the tag value pair
        tag = segment.tuple.tag;
        value = segment.tuple.value;

        // Use the tag value pair to update the codec state
        error = UpdateCodecState(decoder, input, codec, tag, value);
        assert(error == CODEC_ERROR_OKAY);
        if (error != CODEC_ERROR_OKAY)
        {
            decoder->error = error;
            result = false;
            break;
        }

        // End of the frame header?
        if (tag == CODEC_TAG_FRAME_INDEX) break;
    }

    STOP(tk_decoding);

#if (1 && DEBUG)
    if (logfile)
    {
        fprintf(logfile,
                "DecodeSampleFrame, decoder: 0x%p, GOP length: %d\n",
                decoder, decoder->gop_length);
    }
#endif

    if (result)
    {
        // Return the second frame in the group
        //		assert(decoder->gop_length >= 2);
        if (decoder->gop_length >= 2)
        {
            int frame_index = 1;	// Display the second frame in the group

            ReconstructSampleFrameToBuffer(decoder, frame_index, output, pitch);
            if (decoder->error != CODEC_ERROR_OKAY)
            {
                result = false;
            }
        }
        else if (decoder->gop_length > 0)
        {
            int frame_index = 0;	// Display the first frame in the group

            ReconstructSampleFrameToBuffer(decoder, frame_index, output, pitch);
            if (decoder->error != CODEC_ERROR_OKAY)
            {
                result = false;
            }
        }

#if TIMING
        // Increment the count of bytes that have been decoded
        decode_byte_count += (COUNTER)BitstreamByteCount(input);
#endif
    }

    if (!result)
    {
        // Frame type that is not handled

        // Check that the frame can be cleared
        assert(frame_size > 0);
        if (frame_size > 0)
        {
            // Zero the frame
            memset(output, 0, frame_size);
        }
    }

    return result;
}

// Decode a sample that encodes an intra frame
bool DecodeSampleIntraFrame(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    int32_t frame_size = decoder->frame.height * pitch;
    int resolution = decoder->frame.resolution;
    bool result = true;

    static int subband_wavelet_index[] = {2, 2, 2, 2, 1, 1, 1, 0, 0, 0};
    static int subband_band_index[] = {0, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3};
    int num_subbands = sizeof(subband_wavelet_index) / sizeof(subband_wavelet_index[0]);

    START(tk_decoding);

    if (decoder->image_dev_only) goto decoding_completeI;

    // Initialize the codec state
    InitCodecState(&decoder->codec);

    // Allocate the transform data structure for the group of frames
    AllocDecoderGroup(decoder);

    // Initialize the tables for decoding the wavelet transforms
    InitWaveletDecoding(decoder, subband_wavelet_index, subband_band_index, num_subbands);

    // Clear the flags in the wavelet transforms
    ClearTransformFlags(decoder);

    //Force V210 output for debugging ***DEBUG***
    //decoder->frame.format = DECODED_FORMAT_V210;

    // Process the tag value pairs until an encoded subband is found
    for (;;)
    {
        TAGVALUE segment;

        // Read the next tag value pair from the bitstream
        segment = GetSegment(input);
        assert(input->error == BITSTREAM_ERROR_OKAY);
        if (input->error != BITSTREAM_ERROR_OKAY)
        {
            decoder->error = CODEC_ERROR_BITSTREAM;
            result = false;
            break;
        }

        {
            TAGWORD tag = segment.tuple.tag;
            TAGWORD value = segment.tuple.value;

            // Use the tag value pair to update the codec state
            error = UpdateCodecState(decoder, input, codec, tag, value);

            assert(error == CODEC_ERROR_OKAY);

            if (error != CODEC_ERROR_OKAY)
            {
                decoder->error = error;
                result = false;
                break;

                //NOTE: Consider moving the error code into the codec state
            }
        }

        // Check whether the group has been decoded
        if (codec->sample_done)
        {
            break;
        }

        // Skip the rest of the current channel?
        if (CanSkipChannel(decoder, resolution))
        {
            if (codec->channel == 3 && (decoder->frame.format == DECODED_FORMAT_YUYV || decoder->frame.format == DECODED_FORMAT_UYVY))
            {
                int channel = codec->channel;
                uint32_t channel_size = codec->channel_size[channel];
                uint8_t  *position = codec->channel_position + channel_size;

                // Advance the bitstream to the next channel
                SetBitstreamPosition(input, position);

                // Reset the decoded subband flags (otherwise this code will be executed again)
                codec->decoded_subband_flags = 0;

                codec->num_channels = 3;
                goto decoding_completeI;
            }
            else if (resolution == DECODED_RESOLUTION_LOWPASS_ONLY)
            {
                int channel = codec->channel;
                uint32_t channel_size = codec->channel_size[channel];
                uint8_t  *position = codec->channel_position + channel_size;

                // Advance the bitstream to the next channel
                SetBitstreamPosition(input, position);

                // Reset the decoded subband flags (otherwise this code will be executed again)
                codec->decoded_subband_flags = 0;
            }
            else
            {
                // Compute the bitstream position after the current channel
                int channel = codec->channel;
                uint32_t channel_size = codec->channel_size[channel];
                uint8_t  *position = codec->channel_position + channel_size;

                // Get the highest wavelet in the pyramid
                int wavelet_index = 2;
                TRANSFORM *transform = decoder->transform[channel];
                IMAGE *wavelet = transform->wavelet[wavelet_index];

#if _THREADED_DECODER
                // Ready to invert this wavelet to get the lowpass band in the lower wavelet?
                //if (DecodedBandsValid(wavelet, temporal_index))
                if (resolution != DECODED_RESOLUTION_QUARTER || (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER))
#else
                // Have all bands in the wavelet been decoded?
                if (AllBandsValid(wavelet))
#endif
                {
                    //PIXEL *buffer = (PIXEL *)decoder->buffer;
                    //size_t buffer_size = decoder->buffer_size;
                    int precision = codec->precision;
#if (0 && DEBUG)
                    if (logfile)
                    {
                        char label[_MAX_PATH];
                        int band;

                        sprintf(label, "Channel: %d, index: %d", channel, wavelet_index);
                        DumpImageStatistics(label, wavelet, logfile);
#if 1
                        for (band = 1; band < wavelet->num_bands; band++)
                        {
                            sprintf(label, "Channel: %d, index: %d, band: %d", channel, wavelet_index, band);
                            DumpBandStatistics(label, wavelet, band, logfile);
                        }
#endif
                    }
#endif
#if (0 & DEBUG)
                    if (logfile)
                    {
                        fprintf(logfile, "Reconstructing the lowpass bands in the first level wavelets\n");
                    }
#endif
#if _THREADED_DECODER
                    // Add the inverse spatial transform to the processing queue
                    if (decoder->entropy_worker_new.pool.thread_count)
                    {
                        ReconstructWaveletBand(decoder, transform, channel, wavelet, wavelet_index,
                                               precision, &decoder->scratch, 1);
                        QueueThreadedTransform(decoder, channel, wavelet_index);
                    }
                    else
#endif
                    {
                        // Reconstruct the lowpass bands in the first level wavelets
                        //ReconstructWaveletBand(transform, channel, wavelet, temporal_index, precision, buffer, buffer_size);
                        ReconstructWaveletBand(decoder, transform, channel, wavelet, wavelet_index,
                                               precision, &decoder->scratch, 0);
                    }
                    // Advance the bitstream to the next channel
                    SetBitstreamPosition(input, position);

                    // Reset the decoded subband flags (otherwise this code will be executed again)
                    codec->decoded_subband_flags = 0;

                    // Note that the subband flags are also reset when the channel header is decoded
                }
                // Was the wavelet created?
                //else if (wavelet == NULL)
                else
                {
                    // The wavelet may not have been created during quarter resolution decoding

                    // The wavelet should have been created if all bands are valid
                    assert(wavelet != NULL);

                    // Advance the bitstream to the next channel
                    SetBitstreamPosition(input, position);

                    // Reset the decoded subband flags (otherwise this code will be executed again)
                    codec->decoded_subband_flags = 0;
                }
                //TODO: Improve quarter resolution decoding so that the wavelet is created?
            }
        }
    }


decoding_completeI:
    STOP(tk_decoding);

    if (result)
    {
        // One frame has been decoded
        decoder->gop_length = 1;
        decoder->frame_count += 1;

#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile,
                    "DecodeSampleIntraFrame, decoder: 0x%p, GOP length: %d\n",
                    decoder, decoder->gop_length);
        }
#endif

        // Return the first frame (the only frame that was decoded)
        if (!decoder->no_output)
        {
            int uncompressed = decoder->uncompressed_chunk && decoder->uncompressed_size && decoder->sample_uncompressed;
            if ( !uncompressed && resolution == DECODED_RESOLUTION_QUARTER && (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER))
            {
                //CODEC_STATE *codec = &decoder->codec;
                TRANSFORM **transform_array = decoder->transform;
                int num_channels = codec->num_channels;
                //int progressive = codec->progressive;
                FRAME_INFO *info = &decoder->frame;
                int precision = codec->precision;

#if _THREADED_DECODER
                // Wait until the transform thread has finished all pending transforms
                WaitForTransformThread(decoder);
#endif
                ConvertQuarterFrameToBuffer(decoder, transform_array, num_channels, output, pitch, info, precision);
            }
            else
            {
                // Finish computing the output frame
                ReconstructSampleFrameToBuffer(decoder, 0, output, pitch);
            }
        }

        if (decoder->error != CODEC_ERROR_OKAY)
        {
            result = false;
        }

#if TIMING
        // Increment the count of bytes that have been decoded
        decode_byte_count += (COUNTER)BitstreamByteCount(input);
#endif
    }

    if (!result)
    {
        // Check that the frame can be cleared
        assert(frame_size > 0);
        if (frame_size > 0)
        {
            // Zero the frame
            memset(output, 0, frame_size);
        }
    }

    return result;
}

// Decode a sample channel header
bool DecodeSampleChannelHeader(DECODER *decoder, BITSTREAM *input)
{
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_ERROR error = CODEC_ERROR_OKAY;

    CODEC_STATE *codec = &decoder->codec;
    int channel = codec->channel;

    CHANNEL_HEADER header;

    TRANSFORM *transform = decoder->transform[channel];
    TRANSFORM *next_transform;

    // Advance to the next channel
    channel++;

    // Get the next transform for decoded information
    //TRANSFORM *next_transform = AllocGroupTransform(group, channel);

    // Decode the rest of the channel header
    error = DecodeChannelHeader(input, &header, SAMPLE_TYPE_CHANNEL);
    assert(error == CODEC_ERROR_OKAY);
    decoder->error = error;
    if (error != CODEC_ERROR_OKAY) return false;

    // The decoder is not able to skip channels
    assert(header.channel == channel);

    // Initialize the next transform using the previous one
    next_transform = decoder->transform[channel];
    InitChannelTransform(next_transform, transform);

    // Update the channel
    codec->channel = channel;

    // Reset the subband counter
    codec->band.subband = 0;

    // Reset the decoded subband flags
    codec->decoded_subband_flags = 0;

    // Loop back to decode the next channel
    //transform = next_transform;

    return true;
}

// Decode the coefficients in a subband
bool DecodeSampleSubband(DECODER *decoder, BITSTREAM *input, int subband)
{
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    int channel = codec->channel;
    TRANSFORM *transform = decoder->transform[channel];
    int *subband_wavelet_index = decoder->subband_wavelet_index;

    // Used for quarter resolution and threaded decoding
    int transform_type = transform->type;

    // Wavelet parameters
    int width;
    int height;
    int level;
    int type;
    int band;
    int threading = 1;

    // Wavelet containing the band to decode
    int index;
    IMAGE *wavelet = NULL;

    bool result;

    if (subband >= 7 && subband <= 10 && transform_type == TRANSFORM_TYPE_FIELDPLUS)
        threading = 0;

    // Update the transform data structure from the codec state
    UpdateCodecTransform(transform, codec);

    // Is this an empty band?
    if (subband == 255)
    {
        // Decode an empty band

        // This wavelet is the temporal wavelet
        index = 2;
        wavelet = transform->wavelet[index];

        // Get the wavelet parameters decoded from the bitstream
        width = codec->band.width;
        height = codec->band.height;
        level = codec->highpass.wavelet_level;
        type = codec->highpass.wavelet_type;
        band = codec->band.number;

        // The empty band should be the highpass band in a temporal wavelet
        assert(type == WAVELET_TYPE_TEMPORAL && band == 1);

#if _THREADED_DECODER
        // Allocate (or reallocate) the wavelet with thread safety
        wavelet = GetWaveletThreadSafe(decoder, transform, index, width, height, level, type);
#else
        // Allocate (or reallocate) the wavelet
#if _ALLOCATOR
        wavelet = ReallocWaveletEx(decoder->allocator, wavelet, width, height, level, type);
#else
        wavelet = ReallocWaveletEx(wavelet, width, height, level, type);
#endif
        // Save this wavelet in the transform data structure
        transform->wavelet[index] = wavelet;
#endif
        // Set the wavelet parameters
        wavelet->pixel_type[band] = PIXEL_TYPE_16S;
        wavelet->num_bands = 2;

        result = DecodeSampleEmptyBand(decoder, input, wavelet, band);

        // Set the subband number for the next band expected in the bitstream
        codec->band.subband = 11;
    }

    // Is this a highpass band?
    else if (subband > 0)
    {
        // Decode a highpass band

        // Get the wavelet that contains this subband
        index = subband_wavelet_index[subband];
        wavelet = transform->wavelet[index];

        // Get the wavelet parameters decoded from the bitstream
        width = codec->band.width;
        height = codec->band.height;
        level = codec->highpass.wavelet_level;
        type = codec->highpass.wavelet_type;
        band = codec->band.number;

#if _THREADED_DECODER
        // Allocate (or reallocate) the wavelet with thread safety
        wavelet = GetWaveletThreadSafe(decoder, transform, index, width, height, level, type);
#else
        // Allocate (or reallocate) the wavelet
#if _ALLOCATOR
        wavelet = ReallocWaveletEx(decoder->allocator, wavelet, width, height, level, type);
#else
        wavelet = ReallocWaveletEx(wavelet, width, height, level, type);
#endif
        // Save this wavelet in the transform data structure
        transform->wavelet[index] = wavelet;
#endif
        result = DecodeSampleHighPassBand(decoder, input, wavelet, band, threading);
        if (result)
        {
            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandStartedFlags(decoder, wavelet, band);
        }

        // Reset the default encoding method
        codec->band.encoding = BAND_ENCODING_RUNLENGTHS;

        // Set the subband number for the next band expected in the bitstream
        codec->band.subband = subband + 1;
    }
    else
    {
        // Decode a lowpass band

        // Get the wavelet that contains this subband
        index = subband_wavelet_index[0];
        wavelet = transform->wavelet[index];

        // Get the wavelet parameters decoded from the bitstream
        width = codec->lowpass.width;
        height = codec->lowpass.height;
        level = codec->lowpass.level;
        type = codec->first_wavelet;
        //band = codec->band.number;
        band = 0;

#if _THREADED_DECODER
        // Allocate (or reallocate) the wavelet with thread safety
        wavelet = GetWaveletThreadSafe(decoder, transform, index, width, height, level, type);
#else
        // Allocate (or reallocate) the wavelet
#if _ALLOCATOR
        wavelet = ReallocWaveletEx(decoder->allocator, wavelet, width, height, level, type);
#else
        wavelet = ReallocWaveletEx(wavelet, width, height, level, type);
#endif
        // Save this wavelet in the transform data structure
        transform->wavelet[index] = wavelet;
#endif
        // The lowpass data is always stored in wavelet band zero
        assert(band == 0);

        // The lowpass band must be subband zero
        assert(subband == 0);

        result = DecodeSampleLowPassBand(decoder, input, wavelet);
        if (result)
        {
            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandValidFlags(decoder, wavelet, band);
        }

        // Set the subband number for the next band expected in the bitstream
        codec->band.subband = subband + 1;
    }

    // Was the subband successfully decoded?
    if (result)
    {
        // The transform will set the band valid flag if this is the temporal wavelet
        //if (index != 2)

        // Record that this subband has been decoded successfully
        if (0 <= subband && subband <= CODEC_MAX_SUBBAND)
            codec->decoded_subband_flags |= DECODED_SUBBAND_MASK(subband);

#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile, "Decoded subband: %d, wavelet: %d, channel: %d\n",
                    subband, index, channel);
        }
#endif
    }

#if _THREADED_DECODER
    // Ready to queue a threaded transform to invert this wavelet?

    if (BANDS_ALL_STARTED(wavelet))
    {
        // Are frames being decoded to quarter resolution?

        if (decoder->frame.resolution == DECODED_RESOLUTION_QUARTER && (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER))
        {
            // Smallest spatial wavelet above the lowpass temporal band (fieldplus transform)
            int highest_index = 5;

            if (transform_type == TRANSFORM_TYPE_SPATIAL)
            {
                // Smallest wavelet in the spatial transform
                highest_index = 2;
            }

            // Only the smallest spatial wavelet must be reconstructed
            if (index != highest_index)
            {
                return result;
            }

            //TODO: Can we improve on the current scheme for quarter resolution decoding?
        }

        if ((transform->type == TRANSFORM_TYPE_SPATIAL && index > 0) || index >= 2)
        {
            if (decoder->entropy_worker_new.pool.thread_count && threading)
            {
                ReconstructWaveletBand(decoder, transform, codec->channel, wavelet, index,
                                       codec->precision, &decoder->scratch, 1);
                // Add the inverse wavelet transform to the processing queue
                QueueThreadedTransform(decoder, codec->channel, index);
            }
            else
            {
                // Apply the inverse wavelet transform to reconstruct the lower level wavelet
                ReconstructWaveletBand(decoder, transform, codec->channel, wavelet, index,
                                       codec->precision, &decoder->scratch, 0);
            }
        }
    }

#else
    // Ready to invert this wavelet to get the lowpass band in the lower wavelet?
    if (BANDS_ALL_VALID(wavelet))
    {
        int channel = codec->channel;
        //PIXEL *buffer = (PIXEL *)decoder->buffer;
        //size_t buffer_size = decoder->buffer_size;
        int precision = codec->precision;

#if (0 && DEBUG)
        if (logfile)
        {
            char label[_MAX_PATH];
            int band;

            sprintf(label, "Channel: %d, index: %d", channel, index);
            DumpImageStatistics(label, wavelet, logfile);
#if 1
            for (band = 1; band < wavelet->num_bands; band++)
            {
                sprintf(label, "Channel: %d, index: %d, band: %d", channel, index, band);
                DumpBandStatistics(label, wavelet, band, logfile);
            }
#endif
        }
#endif
        // Are frames being decoded to quarter resolution?
        if (decoder->frame.resolution == DECODED_RESOLUTION_QUARTER && (decoder->codec.encoded_format != ENCODED_FORMAT_BAYER))
        {
            // Smallest spatial wavelet above the lowpass temporal band (fieldplus transform)
            int highest_index = 5;

            if (transform_type == TRANSFORM_TYPE_SPATIAL)
            {
                // Smallest wavelet in the spatial transform
                highest_index = 2;
            }

            // Only the smallest spatial wavelet must be reconstructed
            if (index != highest_index)
            {
                return result;
            }

            //TODO: Can we improve on the current scheme for quarter resolution decoding?
        }

        // Apply the inverse wavelet transform to reconstruct the lower level wavelet
        ReconstructWaveletBand(decoder, transform, channel, wavelet, index, precision, &decoder->scratch, 0);
    }
#endif

    return result;
}

// Decode the coefficients in a lowpass band
bool DecodeSampleLowPassBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    int channel = codec->channel;
    bool result = true;

    int lowpass_width;		// Lowpass band dimensions
    int lowpass_height;
    int lowpass_pitch;
    PIXEL *pLowPassRow;		// Pointer into the lowpass band

    //int wavelet_width;	// Dimensions of the wavelet image
    //int wavelet_height;

    int bits_per_pixel;
    int quantization;
    int offset;

    //int pixel_divisor = (1 << (2 * codec->lowpass.level));
    int row, column;
    int32_t solid_color = -1;

    const int gain = 128;
    const int colorshift = 0;

    //	int channelgain[4];
    //int waterrow=19, watercol=214;

    //int cspace = decoder->frame.colorspace;

    // Lowpass image dimensions may be smaller than the wavelet dimensions
    // because the encoder may have transmitted an image without the border
    lowpass_width = codec->lowpass.width;
    lowpass_height = codec->lowpass.height;
    lowpass_pitch = wavelet->pitch / sizeof(PIXEL);
    pLowPassRow = wavelet->band[0];


    // Get the parameters for quantization performed by the encoder
    quantization = codec->lowpass.quantization;
    offset = codec->lowpass.pixel_offset;
    bits_per_pixel = codec->lowpass.bits_per_pixel;

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decode lowpass subband\n");
    }
#endif

    if (bits_per_pixel == 16 && stream->nBitsFree == BITSTREAM_BUFFER_SIZE && !(lowpass_width & 1))
    {
        int32_t *lpCurrentLong = (int32_t *)stream->lpCurrentWord;
        //int signval = 0;
        //int channel3stats = 0;
        int channeloffset = 0;

        if (decoder->codec.precision == 8)
        {
            channeloffset = (codec->num_frames == 2 ? 64 : 32);
        }
        else if (decoder->codec.precision == 10)
        {
            switch (decoder->frame.format)
            {
                case DECODED_FORMAT_YU64:
                case DECODED_FORMAT_YR16:
                case DECODED_FORMAT_V210:
                    channeloffset = codec->num_frames == 2 ? 14 : 4; //DAN20090601, recal I-frame DAN20110301
                    break;
                default:
                    channeloffset = codec->num_frames == 2 ? 48 : 24; //DAN20090601
            }

            if (decoder->sample_uncompressed) //DAN20110301 was testing the GOP length for this (why?)
                channeloffset = 0; //DAN20100822 -- Prevent offset between uncompressed V210 and compressed frames
        }
        else if (decoder->codec.precision == 12)
        {
            switch (decoder->frame.format)
            {
                case DECODED_FORMAT_RGB24:
                case DECODED_FORMAT_RGB24_INVERTED:
                case DECODED_FORMAT_RGB32:
                case DECODED_FORMAT_RGB32_INVERTED:
                    channeloffset = 8;  //DAN200906010
                    break;

                // 16-bit precision:
                case DECODED_FORMAT_RG48:
                case DECODED_FORMAT_RG64:
                case DECODED_FORMAT_B64A:
                case DECODED_FORMAT_WP13:
                case DECODED_FORMAT_W13A:
                    channeloffset = 0;
                    break;

                case DECODED_FORMAT_RG30:
                case DECODED_FORMAT_R210:
                case DECODED_FORMAT_DPX0:
                case DECODED_FORMAT_AR10:
                case DECODED_FORMAT_AB10:
                    channeloffset = 6;   //DAN200906010  //DAN20100822 -- prefect for uncompressed to compressed.
                    break;

                default:
                    channeloffset = 0;
                    break;
            }
        }

        if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)	//DAN20090728 -- Prevent offset between uncompressed and compressed RAW frames
            channeloffset = 0;


#define DUMPLL 0
#if (_DEBUG && DUMPLL)
        FILE *fp;

        if (channel == 0)
        {
            static int inc = 1;
            char name[256];

            sprintf(name, "C:\\Cedoc\\LLdec%03d.pgm", inc++);


            fp = fopen(name, "w");
            fprintf(fp, "P2\n# CREATOR: DAN\n%d %d\n255\n", lowpass_width, lowpass_height);
        }
#endif

#if LOSSLESS
        channeloffset = 0; //LOSSLESS
#endif

        //if(lpCurrentLong[0] == 0xffffffff)
        if (lpCurrentLong[0] == (int32_t)UINT32_MAX)
        {
            if (SwapInt32BtoN(lpCurrentLong[2]) == (uint32_t)lowpass_width)
            {
                if (SwapInt32BtoN(lpCurrentLong[3]) == (uint32_t)lowpass_height)
                {
                    solid_color = SwapInt32BtoN(lpCurrentLong[1]);
                    solid_color |= (solid_color << 16);
                    lpCurrentLong += 4;
                }
            }
        }

        // Decode each row in the lowpass image
        for (row = 0; row < lowpass_height; row++)
        {
            int pixels;

            // Start at the first column
            column = 0;

            // Process the rest of the row
            {
                for (; column < lowpass_width; column++)
                {
                    int pixel_value;
                    //int i;

                    // Perform inverse quantization
                    if (column & 1)
                    {
                        pixel_value = pixels;

                    }
                    else
                    {
                        //pixels = _bswap(*(lpCurrentLong++));
                        if (solid_color == -1)
                            pixels = SwapInt32BtoN(*(lpCurrentLong++));
                        else
                            pixels = solid_color;
                        pixel_value = (pixels >> 16);
                        pixels <<= 16;
                        pixels >>= 16;
                    }


                    //  Store the pixel in the lowpass band of the wavelet
                    pixel_value += channeloffset;
                    //	pixel_value -= 64;
                    //	pixel_value += ((rand() & 0x7fff) - 0x4000);
                    //	if(pixel_value < 0) pixel_value = 0;

                    if (pixel_value > 0x7fff) pixel_value = 0x7fff;
                    pLowPassRow[column] = pixel_value;

#if (_DEBUG && DUMPLL)
                    if (channel == 0 && fp)
                        fprintf(fp, "%d\n", pixel_value >> 7);
#endif
                }
            }
            // Advance to the next row in the lowpass image
            pLowPassRow += lowpass_pitch;
        }


#if (_DEBUG && DUMPLL)
        if (channel == 0 && fp)
            fclose(fp);
#endif


#if ERROR_TOLERANT
        // Update the count of bytes used
        stream->nWordsUsed -= (int)(((intptr_t)lpCurrentLong - (intptr_t)stream->lpCurrentWord));
#endif
        // Update the bitstream
        stream->lpCurrentWord = (uint8_t *)lpCurrentLong;

    }
    else if (bits_per_pixel == 8 && stream->nBitsFree == BITSTREAM_BUFFER_SIZE)
    {
        uint8_t *lpCurrentByte = (uint8_t *)stream->lpCurrentWord;

        //int signval = 0;

        // Decode each row in the lowpass image
        for (row = 0; row < lowpass_height; row++)
        {
            // Start at the first column
            column = 0;

            // Process the rest of the row
            for (; column < lowpass_width; column++)
            {
                int pixel_value = *(lpCurrentByte++);

                // Perform inverse quantization
#if _ENCODE_CHROMA_ZERO
                if (channel == 0)
                    pixel_value = (quantization * pixel_value) + offset;
                else
                    pixel_value = (pixel_value - offset) * quantization;
#else
                pixel_value = (quantization * pixel_value) + offset;// + colorshift;
#endif
                pixel_value -= 128 * quantization;
                pixel_value *= gain;
                pixel_value >>= 7;

                pixel_value += 128 * quantization;

                pixel_value += colorshift;


                // Store the pixel in the lowpass band of the wavelet
                // Multiply by 16 to turn 8-bit into the new 16-bit format
                pLowPassRow[column] = pixel_value * 16;
            }

            // Advance to the next row in the lowpass image
            pLowPassRow += lowpass_pitch;
        }

#if ERROR_TOLERANT
        // Update the count of bytes used
        stream->nWordsUsed -= (int)(((intptr_t)lpCurrentByte - (intptr_t)stream->lpCurrentWord));
#endif

        // Update the bitstream
        stream->lpCurrentWord = (uint8_t *)lpCurrentByte;
    }
    else
    {
        int channeloffset = 0;

        if (decoder->codec.precision == 8)
        {
            channeloffset = (codec->num_frames == 2 ? 64 : 32);
        }
        else if (decoder->codec.precision == 10)
        {
            channeloffset = (codec->num_frames == 2 ? 10 : 5);
        }
        else if (decoder->codec.precision == 12)
        {
            //	channeloffset = (codec->num_frames==2 ? 4 : 2);  // Seems to result in less shift using the viper images
        }

        //DAN20050923 no longer trying to compensate for YUV to RGB issues.
        if (decoder->frame.format == DECODED_FORMAT_RGB24 || decoder->frame.format == DECODED_FORMAT_RGB32)
        {
            if (decoder->codec.precision == 8)
            {
                switch (channel)
                {
                    case 0:
                        channeloffset += 8;
                        break; // fixed rounding error introduced by YUV->RGB
                    case 1:
                        channeloffset += 16;
                        break;
                    case 2:
                        channeloffset += 10;
                        break;
                }
            }
            else if (decoder->codec.precision == 10)
            {
                switch (channel)
                {
                    case 0:
                        channeloffset += -8;
                        break; // fixed rounding error introduced by YUV->RGB
                    case 1:
                        channeloffset += -4;
                        break;
                    case 2:
                        channeloffset += -4;
                        break;
                }
            }
            else if (decoder->codec.precision == 12)
            {
                switch (channel)
                {
                    case 0:
                        channeloffset += 0;
                        break; // fixed rounding error introduced by YUV->RGB
                    case 1:
                        channeloffset += 0;
                        break;
                    case 2:
                        channeloffset += 0;
                        break;
                }
            }
        }

        if (bits_per_pixel != 16)
            channeloffset = 0;

        for (row = 0; row < lowpass_height; row++)
        {
            for (column = 0; column < lowpass_width; column++)
            {
                int pixel_value = GetBits(stream, bits_per_pixel);

                // Perform inverse quantization
#if _ENCODE_CHROMA_ZERO
                if (channel == 0)
                    pixel_value = (quantization * pixel_value) + offset;
                else
                    pixel_value = (pixel_value - offset) * quantization;
#else
                pixel_value = (quantization * pixel_value) + offset;// + colorshift;
#endif

                // Store the pixel in the lowpass band of the wavelet
                pLowPassRow[column] = SATURATE(pixel_value + channeloffset); // DAN20050926 added chromaoffet to match the normal path -- this code will be used for SD (720) encodes
            }
            stream->nWordsUsed -= lowpass_width * (bits_per_pixel >> 3);

            // Advance to the next row in the lowpass image
            pLowPassRow += lowpass_pitch;
        }
    }

    // Set the wavelet scale factor
    wavelet->scale[0] = quantization;

    // Align the bitstream to the next tag value pair
    AlignBitsTag(stream);

    // Return indication of lowpass decoding success
    return result;
}

// Decode the coefficients in a highpass band
bool DecodeSampleHighPassBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int band, int threading)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    CODEC_STATE *codec = &decoder->codec;
    //int channel = codec->channel;
    //int subband = codec->band.subband;
    //int index = codec->highpass.wavelet_number;

    int width;
    int height;
    int quantization;

    // The encoder may not have used variable-length coding
    int method = codec->band.encoding;

    bool result = true;

    // Check that the band index is in range
    assert(0 <= band && band <= codec->max_subband);

    // Encoded coefficients start on a tag boundary
    AlignBitsTag(stream);

#if (0 && DEBUG)
    // Dump the band header to the logfile
    if (logfile)
    {
        fprintf(logfile,
                "Band header marker: 0x%04X, subband: %d, width: %d, height: %d, encoding: %d\n",
                header->marker, header->subband, header->width, header->height, header->encoding);
    }
#endif

    // Copy the scale factors used by the encoder into the wavelet band
    // (Zero means that the encoder did not supply this parameter)
    if (codec->band.scale > 0)
    {
        wavelet->scale[band] = codec->band.scale;
    }

    // Get the quantization factor that was used to encode the band coefficients
    quantization = codec->band.quantization;

    // Copy the quantization into the wavelet
    wavelet->quantization[band] = quantization;

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decode highpass subband: %d, quantization: %d\n", subband, quantization);
    }
#endif

    // Get the highpass band dimensions
    width = codec->band.width;
    height = codec->band.height;

    // Is this a special band for the temporal high pass thumbnail?
    if (method == BAND_ENCODING_LOSSLESS)
    {
        //lossless temporal subband //DAN20060701
        result = DecodeBand16sLossless(decoder, stream, wavelet, band, width, height);
        assert(result);
        if (result)
        {
            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandValidFlags(decoder, wavelet, band);
        }
    }
    else if (method == BAND_ENCODING_16BIT)
    {
        //lossless temporal subband //DAN20060701
        result = DecodeBand16s(decoder, stream, wavelet, band, width, height);
        assert(result);
        if (result)
        {
            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandValidFlags(decoder, wavelet, band);
        }
    }
    else
    {
        // Must use the runlength encoding method
        assert(codec->band.encoding == BAND_ENCODING_RUNLENGTHS);
#if 0
        // This code attempts to not decode various subbands for 1/4 res decodes.
        // Unforuntately playback would stop after 5 seonds with this code (but not in debug mode.)
        if (subband >= 4 && subband <= 6)
        {
            TAGVALUE segment;

            AlignBitsTag(stream);
            do
            {
                segment = GetTagValue(stream);
            } while (segment.tuple.tag != CODEC_TAG_BAND_TRAILER);

            stream->lpCurrentWord -= 4;
            stream->nWordsUsed += 4;
        }
        else
#elif 0
        // Is this subband required for decoding the frame?
        if (CanSkipSubband(decoder, subband))
        {
            // Skip past the end of this subband
            SkipSubband(stream);
        }
#endif
            // Decode this subband
            result = DecodeFastRunsFSM16s(decoder, stream, wavelet, band, width, height, threading);
    }

    // Return failure if a problem was encountered while reading the band coefficients
    if (!result) return result;

    // The encoded band coefficients end on a bitstream word boundary
    // to avoid interference with the marker for the coefficient band trailer
    AlignBits(stream);

    // Decode the band trailer
    error = DecodeBandTrailer(stream, NULL);
    decoder->error = error;
    assert(error == CODEC_ERROR_OKAY);
    if (error != CODEC_ERROR_OKAY)
    {
#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile, "Error in band %d trailer: %d\n", band, error);
        }
#endif
        return false;
    }

    return result;
}

// Decode an empty band
bool DecodeSampleEmptyBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int band)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    CODEC_STATE *codec = &decoder->codec;
    int quantization;

    // Check that the band is in range
    assert(0 <= band && band <= CODEC_MAX_HIGHBANDS);

    // Check that the highpass band is 16 bits
    assert(wavelet->pixel_type[1] == PIXEL_TYPE_16S);

#if (0 && DEBUG)
    //TODO: Change format string to handle 64-bit pointers
    if (logfile)
    {
        fprintf(logfile, "Start decoding an empty band, stream: 0x%p\n", stream->lpCurrentWord);
    }
#endif

    // Encoded coefficients must start on a word boundary
    AlignBits(stream);

    // Copy the scale factors used by the encoder into the wavelet band
    // (Zero means that the encoder did not supply the parameter)
    if (codec->band.scale > 0)
        wavelet->scale[band] = codec->band.scale;

    // Set the quantization used to encode the band coefficients
    quantization = codec->band.quantization;
    wavelet->quantization[band] = quantization;

#if (0 && DEBUG)
    if (logfile)
    {
        DumpBits(stream, logfile);
    }
#endif

    // Decode the band trailer
    error = DecodeBandTrailer(stream, NULL);
    decoder->error = error;
    assert(error == CODEC_ERROR_OKAY);
    if (error != CODEC_ERROR_OKAY)
    {
#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile, "Error in band: %d, error: %d\n", band, error);
        }
#endif
        return false;
    }

    // The encoded band coefficients end on a bitstream word boundary
    // to avoid interference with the marker for the coefficient band trailer
    AlignBits(stream);

#if (0 && DEBUG)
    // Dump the band trailer to the logfile
    if (logfile)
    {
        fprintf(logfile, "Band trailer marker: 0x%04X\n", trailer->marker);
    }
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        //TODO: Change format string to handle 64-bit pointers
        fprintf(logfile, "End decode empty band, stream: 0x%X\n", stream->lpCurrentWord);
    }
#endif

    return true;
}

bool DecodeBand16s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                   int band_index, int width, int height)
{
    PIXEL *rowptr = wavelet->band[band_index];
    int pitch = wavelet->pitch;
    int row, dequant = wavelet->quantization[band_index];

    // Convert the pitch from bytes to pixels
    pitch /= sizeof(PIXEL);

    //BAND_ENCODING_16BIT
    if (dequant == 1)
    {
        for (row = 0; row < height; row++)
        {
            int column;

#if 0
            for (column = 0; column < width; column++)
            {
                int value = GetWord16s(stream);
                rowptr[column] = value;
            }
#else // Mild speedup (2.5% overall half-res decode improvement.)
            char *sptr = (char *)stream->lpCurrentWord;
            char *dptr = (char *)rowptr;
            for (column = 0; column < width; column++)
            {
                *(dptr + 1) = *sptr++;
                *dptr = *sptr++;
                dptr += 2;
            }

            stream->lpCurrentWord += width * 2;
            stream->nWordsUsed += width * 2;
#endif
            rowptr += pitch;
        }
    }
    else
    {
        for (row = 0; row < height; row++)
        {
            int column;

            for (column = 0; column < width; column++)
            {
                int value = GetWord16s(stream);
                rowptr[column] = value * dequant;
            }

            rowptr += pitch;
        }
    }


#if (0 && DEBUG)
    {
        int static count = 0;
        if (count < 20)
        {
            char label[_MAX_PATH];
            sprintf(label, "Hightemp-decode-%d-", count);
            DumpBandPGM(label, wavelet, band_index, NULL);
        }
        count++;
    }
#endif

    return true;
}


bool DecodeBand16sLossless(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                           int band_index, int width, int height)
{
    //CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    int result = true;
    int quant = wavelet->quantization[band_index];

    // Get the pointer to the finite state machine
    FSM *fsm = &decoder->fsm[decoder->codec.active_codebook];
    int size;
    PIXEL *rowptr;
    //int row = 0;
    int pitch;
    //CODEC_STATE *codec = &decoder->codec;
    //int channel = codec->channel;
    //int subband = codec->band.subband;
    //int num_subbands = codec->num_subbands;
    //int pixel_type = wavelet->pixel_type[band_index];
    //int difference_coding = decoder->codec.difference_coding;
    //int localquant = 1;
    //int threading = 0;

    decoder->codec.active_codebook = 0; // reset CODEC state
    decoder->codec.difference_coding = 0; //reset state for next subband

    // Must have a valid wavelet
    assert(wavelet != NULL);
    if (! (wavelet != NULL))
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    //Must have a valid FSM
    assert(fsm != NULL);
    if (! (fsm != NULL))
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    // All rows are treated as one int32_t row that covers the entire band
    size = fsm->table.num_states;

    assert(size > 0);
    if (size == 0)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    // Check if the band is intended for 8-bit pixels
    assert(wavelet->pixel_type[band_index] == PIXEL_TYPE_16S);

    rowptr = (PIXEL *)wavelet->band[band_index];
    pitch = wavelet->pitch;

    assert(rowptr != NULL && pitch != 0);
    if (! (rowptr != NULL && pitch != 0))
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    DeQuantFSM(fsm, 1); // can;t use this to dequant as we split the cooefficients into high and low bytes.
    if (!DecodeBandFSM16sNoGap2Pass(fsm, stream, (PIXEL16S *)rowptr, width, height, pitch, quant))
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    if (quant)
    {
        int x, y;
        PIXEL *line = rowptr;

        if (quant == 32)
        {
            for (y = 0; y < height; y++)
            {
                for (x = 0; x < width; x++)
                {
                    line[x] <<= 5;
                }
                line += pitch / 2;
            }
        }
        else
        {
            for (y = 0; y < height; y++)
            {
                for (x = 0; x < width; x++)
                {
                    line[x] *= quant;
                }
                line += pitch / 2;
            }
        }
    }

    assert(result == true);
    if (! (result == true))
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    return true;
}


// Invert the wavelet to reconstruct the lower wavelet in the transform
void ReconstructWaveletBand(DECODER *decoder, TRANSFORM *transform, int channel,
                            IMAGE *wavelet, int index, int precision,
                            const SCRATCH *scratch, int allocations_only)
{
    int transform_type = transform->type;
    int width = wavelet->width;
    int height = wavelet->height;
    int level = wavelet->level;

    PIXEL *buffer = (PIXEL *)scratch->free_ptr;
    size_t buffer_size = scratch->free_size;

    // Is the current wavelet a spatial wavelet?
    if (transform_type == TRANSFORM_TYPE_SPATIAL && index > 0)
    {
        // Reconstruct the lowpass band in the lower wavelet
        int lowpass_index = index - 1;
        IMAGE *lowpass = transform->wavelet[lowpass_index];
        int lowpass_width = 2 * width;
        int lowpass_height = 2 * height;
        int lowpass_level = level - 1;
        int lowpass_type = (lowpass_index == 0) ? WAVELET_TYPE_FRAME : WAVELET_TYPE_SPATIAL;

        //const int prescale = 1;
        const bool inverse_prescale = (precision >= CODEC_PRECISION_10BIT);
        int prescale = transform->prescale[index];

#if _THREADED_DECODER
        // Allocate (or reallocate) the wavelet with thread safety
        lowpass = GetWaveletThreadSafe(decoder, transform, lowpass_index,
                                       lowpass_width, lowpass_height,
                                       lowpass_level, lowpass_type);
#else
        // Allocate the wavelet if not already allocated
#if _ALLOCATOR
        lowpass = ReallocWaveletEx(decoder->allocator, lowpass, lowpass_width, lowpass_height, lowpass_level, lowpass_type);
#else
        lowpass = ReallocWaveletEx(lowpass, lowpass_width, lowpass_height, lowpass_level, lowpass_type);
#endif
        transform->wavelet[lowpass_index] = lowpass;
#endif
        // Check that the lowpass band has not already been reconstructed
        //assert((lowpass->band_valid_flags & BAND_VALID_MASK(0)) == 0);

        if (!allocations_only)
        {
            // Check that all of the wavelet bands have been decoded
            assert(BANDS_ALL_VALID(wavelet));

            // Has this wavelet already been reconstructed?
            if ((lowpass->band_valid_flags & BAND_VALID_MASK(0)) == 0)
            {
                // Perform the inverse spatial transform before decoding the next wavelet
                STOP(tk_decoding);
                START(tk_inverse);
                //TransformInverseSpatialQuantLowpass(wavelet, lowpass, buffer, buffer_size, prescale, inverse_prescale);
                TransformInverseSpatialQuantLowpass(wavelet, lowpass, scratch, prescale, inverse_prescale);
                STOP(tk_inverse);
                START(tk_decoding);

                // Call thread safe routine to update the band valid flags
                UpdateWaveletBandValidFlags(decoder, lowpass, 0);
#if TIMING
                // Increment the count of spatial transforms performed during decoding
                spatial_decoding_count++;
#endif
            }
        }
    }

    // Is the current wavelet a spatial wavelet above the temporal lowpass band?
    else if (index > 3)
    {
        // Reconstruct the lowpass band in the lower wavelet
        const int temporal_wavelet_index = 2;
        int lowpass_index = (index > 4) ? index - 1 : index - 2;
        IMAGE *lowpass = transform->wavelet[lowpass_index];
        int lowpass_width = 2 * width;
        int lowpass_height = 2 * height;
        int lowpass_level = level - 1;
        int lowpass_type = ((lowpass_index == temporal_wavelet_index) ? WAVELET_TYPE_TEMPORAL : WAVELET_TYPE_SPATIAL);

        //const int prescale = 2;
        const bool inverse_prescale = (precision >= CODEC_PRECISION_10BIT);
        int prescale = transform->prescale[index];

#if _THREADED_DECODER
        // Allocate (or reallocate) the wavelet with thread safety
        lowpass = GetWaveletThreadSafe(decoder, transform, lowpass_index,
                                       lowpass_width, lowpass_height,
                                       lowpass_level, lowpass_type);
#else
        // Allocate the wavelet if not already allocated
#if _ALLOCATOR
        lowpass = ReallocWaveletEx(decoder->allocator, lowpass, lowpass_width, lowpass_height, lowpass_level, lowpass_type);
#else
        lowpass = ReallocWaveletEx(lowpass, lowpass_width, lowpass_height, lowpass_level, lowpass_type);
#endif
        transform->wavelet[lowpass_index] = lowpass;
#endif

        if (!allocations_only)
        {
            // Check that the lowpass band has not already been reconstructed
            assert((lowpass->band_valid_flags & BAND_VALID_MASK(0)) == 0);

            // Check that all of the wavelet bands have been decoded
            assert(BANDS_ALL_VALID(wavelet));

            // Perform the inverse spatial transform before decoding the next wavelet
            STOP(tk_decoding);
            START(tk_inverse);
            //TransformInverseSpatialQuantLowpass(wavelet, lowpass, buffer, buffer_size, prescale, inverse_prescale);
            TransformInverseSpatialQuantLowpass(wavelet, lowpass, scratch, prescale, inverse_prescale);
            STOP(tk_inverse);
            START(tk_decoding);

            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandValidFlags(decoder, lowpass, 0);
#if TIMING
            // Increment the count of spatial transforms performed during decoding
            spatial_decoding_count++;
#endif
        }
    }

    // Is the current wavelet the spatial wavelet above the temporal highpass band?
    else if (index == 3)
    {
        // Reconstruct the highpass band in the temporal wavelet
        const int temporal_wavelet_index = 2;
        int highpass_index = index - 1;
        IMAGE *highpass = transform->wavelet[highpass_index];
        int highpass_width = 2 * width;
        int highpass_height = 2 * height;
        int highpass_level = level - 1;
        int highpass_type = ((highpass_index == temporal_wavelet_index) ? WAVELET_TYPE_TEMPORAL : WAVELET_TYPE_SPATIAL);

        const bool inverse_prescale = (precision >= CODEC_PRECISION_10BIT);
        int prescale = inverse_prescale ? transform->prescale[index] : 0;

#if _THREADED_DECODER
        // Allocate (or reallocate) the wavelet with thread safety
        highpass = GetWaveletThreadSafe(decoder, transform, highpass_index,
                                        highpass_width, highpass_height,
                                        highpass_level, highpass_type);
#else
        // Allocate the wavelet if not already allocated
#if _ALLOCATOR
        highpass  = ReallocWaveletEx(decoder->allocator, highpass, highpass_width, highpass_height, highpass_level, highpass_type);
#else
        highpass  = ReallocWaveletEx(highpass, highpass_width, highpass_height, highpass_level, highpass_type);
#endif
        transform->wavelet[highpass_index] = highpass;
#endif

        if (!allocations_only)
        {
            // Check that the highpass band has not already been reconstructed
            assert((highpass->band_valid_flags & BAND_VALID_MASK(1)) == 0);

            // Check that all of the wavelet bands have been decoded
            assert(BANDS_ALL_VALID(wavelet));

            // Perform the inverse spatial transform before decoding the next wavelet
            STOP(tk_decoding);
            START(tk_inverse);
            TransformInverseSpatialQuantHighpass(wavelet, highpass, buffer, buffer_size, prescale);
            STOP(tk_inverse);
            START(tk_decoding);

            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandValidFlags(decoder, highpass, 1);
#if TIMING
            // Increment the count of spatial transforms performed during decoding
            spatial_decoding_count++;
#endif
        }
    }

    // Is the current wavelet the temporal wavelet?
    else if (index == 2)
    {
        // Get the temporal wavelet
        IMAGE *temporal = wavelet;

        // Set the frame wavelet parameters
        int frame_level = 1;
        int frame_type = WAVELET_TYPE_FRAME;

        // Get the two frame wavelets
        IMAGE *frame[2];
        frame[0] = transform->wavelet[0];
        frame[1] = transform->wavelet[1];

        // Check that the temporal wavelet is valid
        assert(temporal->num_bands == 2 && temporal->wavelet_type == WAVELET_TYPE_TEMPORAL);

#if _THREADED_DECODER
        // Allocate (or reallocate) the frame wavelets with thread safety
        frame[0] = GetWaveletThreadSafe(decoder, transform, 0, width, height, frame_level, frame_type);
        frame[1] = GetWaveletThreadSafe(decoder, transform, 1, width, height, frame_level, frame_type);
#else
        // Allocate the frame wavelets if not already allocated
#if _ALLOCATOR
        frame[0] = ReallocWaveletEx(decoder->allocator, frame[0], width, height, frame_level, frame_type);
        frame[1] = ReallocWaveletEx(decoder->allocator, frame[1], width, height, frame_level, frame_type);
#else
        frame[0] = ReallocWaveletEx(frame[0], width, height, frame_level, frame_type);
        frame[1] = ReallocWaveletEx(frame[1], width, height, frame_level, frame_type);
#endif
        transform->wavelet[0] = frame[0];
        transform->wavelet[1] = frame[1];
#endif
#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile, "Before inverse temporal transform");
            DumpArray16s("Temporal Lowpass", temporal->band[0], temporal->width, temporal->height, temporal->pitch, logfile);
            DumpArray16s("Temporal Highpass", temporal->band[1], temporal->width, temporal->height, temporal->pitch, logfile);
        }
#endif

        if (!allocations_only)
        {
            // Check that the lowpass bands have not already been reconstructed
            assert((frame[0]->band_valid_flags & BAND_VALID_MASK(0)) == 0);
            assert((frame[1]->band_valid_flags & BAND_VALID_MASK(0)) == 0);

            // Check that all of the wavelet bands have been decoded
            assert(BANDS_ALL_VALID(temporal));

            // Invert the temporal transform between the frame wavelets
            STOP(tk_decoding);
            START(tk_inverse);
            TransformInverseTemporalQuant(temporal, frame[0], frame[1], buffer, buffer_size, precision);
            STOP(tk_inverse);
            START(tk_decoding);

#if (0 && DEBUG)
            if (logfile)
            {
                IMAGE *wavelet = quad[0];
                fprintf(logfile, "After inverse temporal transform\n");
                DumpArray16s("Temporal Lowpass", temporal->band[0], temporal->width, temporal->height, temporal->pitch, logfile);
                DumpArray16s("Temporal Highpass", temporal->band[1], temporal->width, temporal->height, temporal->pitch, logfile);
                DumpArray16s("First frame wavelet, band 0", wavelet->band[0], wavelet->width, wavelet->height, wavelet->pitch, logfile);
            }
#endif

            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandValidFlags(decoder, frame[0], 0);
            UpdateWaveletBandValidFlags(decoder, frame[1], 0);
#if TIMING
            // Increment the number of temporal transforms performed outside of decoding
            temporal_decoding_count++;
#endif
        }
    }
}

// Compute the dimensions of the output buffer
void ComputeOutputDimensions(DECODER *decoder, int frame,
                             int *decoded_width_out, int *decoded_height_out)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    int num_channels = codec->num_channels;

    FRAME_INFO *info = &decoder->frame;

    //int progressive = codec->progressive;

    TRANSFORM **transform_array = decoder->transform;
    //IMAGE *lowpass_images[TRANSFORM_MAX_CHANNELS];
    IMAGE *wavelet = NULL;
    int wavelet_width;
    int wavelet_height;
    int decoded_width;
    int decoded_height;
    int resolution = info->resolution;
    //int chroma_offset = decoder->codec.chroma_offset;
    int decoded_scale = 0;

    if (decoded_width_out == NULL || decoded_height_out == NULL)
    {
        return;
    }

    // Clear the return values in case this routine terminates early
    *decoded_width_out = 0;
    *decoded_height_out = 0;

    // Get the decoding scale
    switch (resolution)
    {
        case DECODED_RESOLUTION_FULL:
        case DECODED_RESOLUTION_HALF_HORIZONTAL:
#if DEBUG
            assert(AllTransformBandsValid(transform_array, num_channels, frame));
#endif
            decoded_scale = 2;
            wavelet = transform_array[0]->wavelet[0];
            break;

        case DECODED_RESOLUTION_HALF:
#if DEBUG
            assert(AllLowpassBandsValid(transform_array, num_channels, frame));
#endif
            decoded_scale = 1;
            wavelet = transform_array[0]->wavelet[0];
            break;

        case DECODED_RESOLUTION_QUARTER:
            if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
            {
#if DEBUG
                assert(AllLowpassBandsValid(transform_array, num_channels, frame));
#endif
                decoded_scale = 1;
                wavelet = transform_array[0]->wavelet[0];
            }
            else
            {
                decoded_scale = 1;
                wavelet = transform_array[0]->wavelet[3];
            }
            break;

        case DECODED_RESOLUTION_LOWPASS_ONLY:
            decoded_scale = 1;
            wavelet = transform_array[0]->wavelet[5];
            if (wavelet == NULL) // there Intra Frame compressed
                wavelet = transform_array[0]->wavelet[2];
            break;

        default:
            assert(0);
            break;
    }

    // Get the decoded frame dimensions
    assert(wavelet != NULL);
    wavelet_width = wavelet->width;
    wavelet_height = wavelet->height;
    if (resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
        decoded_width = wavelet_width;
    else
        decoded_width = decoded_scale * wavelet_width;
    decoded_height = decoded_scale * wavelet_height;

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decoded scale: %d, decoded width: %d, wavelet width: %d\n", decoded_scale, decoded_width, wavelet_width);
    }
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decoded width: %d, height: %d, frame width: %d, height: %d, output pitch: %d\n",
                decoded_width, decoded_height, info->width, info->height, pitch);
    }
#endif

    // Return the decoded width and height
    *decoded_width_out = decoded_width;
    *decoded_height_out = decoded_height;
}

#define DEBUG_ROW16U	0

void ReconstructSampleFrameToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch)
{
    FRAME_INFO local_info;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    FRAME_INFO *info = &local_info;

    CODEC_STATE *codec = &decoder->codec;
    int num_channels = codec->num_channels;
    int progressive = codec->progressive;

    TRANSFORM **transform_array = decoder->transform;
    IMAGE *lowpass_images[TRANSFORM_MAX_CHANNELS];
    IMAGE *wavelet;
    int wavelet_width;
    int wavelet_height;
    int decoded_width;
    int decoded_height;
    int resolution = decoder->frame.resolution;
    int chroma_offset = decoder->codec.chroma_offset;
    int uncompressed = decoder->uncompressed_chunk && decoder->uncompressed_size && decoder->sample_uncompressed;
    //TODO: Change this routine to return the codec error code
    CODEC_ERROR error = CODEC_ERROR_OKAY;

    //TODO: Change this routine to return an error code
    if (decoder == NULL)
    {
        return;
    }

    decoder->gop_frame_num = frame;

#if _THREADED_DECODER
    // Wait until the transform thread has finished all pending transforms
    WaitForTransformThread(decoder);
#endif

    //return;

    // copy frame info in a changable local structure
    memcpy(info, &decoder->frame, sizeof(FRAME_INFO));

    // Use the old code for reconstructing the frame

#if (0 && DEBUG)
    // Force quarter resolution decoding for debugging that feature
    resolution = DECODED_RESOLUTION_QUARTER;
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Inverting last wavelet, frame: %d\n", frame);
    }
#endif

    // The decoder can decode a video sample without returning a frame
    if (output == NULL || pitch == 0) return;

#if (1 && DEBUG_ROW16U)
    // Force decoding to 16-bit pixels for debugging
    info->format = DECODED_FORMAT_YR16;
#endif

#if 0
    if (info->format == DECODED_FORMAT_YR16)
    {
        // Force interlaced or progressive decoding for debugging
        //progressive = false;
        progressive = true;
    }
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decoder flags: 0x%p\n", decoder->flags);
    }
#endif

    // Does this frame have to be reconstructed?
    if ((decoder->flags & DECODER_FLAGS_RENDER) == 0)
    {
#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile, "Decoder discarding frame: %d\n", frame);
        }
#endif
        return;
    }

    // Check that the requested frame is within the limits of the group of frames
    assert(0 <= frame && frame < decoder->gop_length);

    // Check that the frame resolution is valid
    assert(IsValidFrameResolution(resolution));
    if (!IsValidFrameResolution(resolution))
    {
        decoder->error = CODEC_ERROR_RESOLUTION;
        return;
    }

#if (0 && TIMING)	//(0 && DEBUG)
    // Override progressive flag read from the bitstream for debugging
    //progressive = 0;		// Use the inverse frame transform
    progressive = 1;		// Use the inverse spatial transform
#endif

    // Build the 3D LUTs if needed
    ComputeCube(decoder);

    //HACK DAN20110131 -- some formats will not directly decode so need to use the AM route
    {
        if (	decoder->codec.encoded_format == ENCODED_FORMAT_YUV_422 &&
                resolution == DECODED_RESOLUTION_HALF)
        {
            if (	decoder->frame.format == COLOR_FORMAT_R408 ||
                    decoder->frame.format == COLOR_FORMAT_V408)
            {

                decoder->use_active_metadata_decoder = true;
                decoder->apply_color_active_metadata = true;
            }
        }

        if (	decoder->frame.format == COLOR_FORMAT_NV12)
        {
            decoder->use_active_metadata_decoder = true;

            decoder->apply_color_active_metadata = true; // TODO, make it work with this.
        }

        if (decoder->codec.progressive == false && decoder->frame.format == COLOR_FORMAT_RGB24)
        {
            decoder->use_active_metadata_decoder = true;
            decoder->apply_color_active_metadata = true;
        }
    }

    // Get the decoding scale
    if (!uncompressed)
    {
        switch (resolution)
        {
            case DECODED_RESOLUTION_FULL:
            case DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER:
#if DEBUG
                assert(AllTransformBandsValid(transform_array, num_channels, frame));
#endif
                wavelet = transform_array[0]->wavelet[0];
                // Get the decoded frame dimensions
                assert(wavelet != NULL);
                wavelet_width = wavelet->width;
                wavelet_height = wavelet->height;
                decoded_width = 2 * wavelet_width;
                decoded_height = 2 * wavelet_height;
                break;

            case DECODED_RESOLUTION_HALF:
#if DEBUG
                assert(AllLowpassBandsValid(transform_array, num_channels, frame));
#endif
                wavelet = transform_array[0]->wavelet[0];
                // Get the decoded frame dimensions
                assert(wavelet != NULL);
                wavelet_width = wavelet->width;
                wavelet_height = wavelet->height;
                decoded_width = wavelet_width;
                decoded_height = wavelet_height;
                break;

            case DECODED_RESOLUTION_HALF_HORIZONTAL:
#if DEBUG
                assert(AllLowpassBandsValid(transform_array, num_channels, frame));
#endif
                wavelet = transform_array[0]->wavelet[0];
                // Get the decoded frame dimensions
                assert(wavelet != NULL);
                wavelet_width = wavelet->width;
                wavelet_height = wavelet->height;
                decoded_width = wavelet_width;
                decoded_height = 2 * wavelet_height;
                break;

            case DECODED_RESOLUTION_QUARTER:
                if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
                {
#if DEBUG
                    assert(AllLowpassBandsValid(transform_array, num_channels, frame));
#endif
                    wavelet = transform_array[0]->wavelet[0];
                }
                else
                {
                    wavelet = transform_array[0]->wavelet[3];
                }

                // Get the decoded frame dimensions
                assert(wavelet != NULL);
                wavelet_width = wavelet->width;
                wavelet_height = wavelet->height;
                decoded_width = wavelet_width;
                decoded_height = wavelet_height;
                break;

            case DECODED_RESOLUTION_LOWPASS_ONLY:
                wavelet = transform_array[0]->wavelet[5];
                if (wavelet == NULL) // there Intra Frame compressed
                    wavelet = transform_array[0]->wavelet[2];

                // Get the decoded frame dimensions
                assert(wavelet != NULL);
                wavelet_width = wavelet->width;
                wavelet_height = wavelet->height;
                decoded_width = wavelet_width;
                decoded_height = wavelet_height;
                break;

            default:
                assert(0);
                break;
        }
    }
    else
    {
        if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
        {
            decoded_width = info->width / 2;
            decoded_height = info->height / 2;
        }
        else
        {
            decoded_width = info->width;
            decoded_height = info->height;
        }
    }

    if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
    {
        if (resolution == DECODED_RESOLUTION_FULL)
        {
            if (decoded_width * 2 == info->width)
            {
                info->width /= 2;
                info->height /= 2;

                info->resolution = resolution = DECODED_RESOLUTION_FULL_DEBAYER;
            }
        }
        else if (resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER)
        {
            if (decoded_width * 2 == info->width)
            {
                info->width /= 2;
                info->height /= 2;
            }
        }
        else if (resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
        {
            if (decoded_width * 2 == info->width)
            {
                info->height /= 2;
                info->resolution = resolution = DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER;
            }
        }
        else if (decoder->frame.format == DECODED_FORMAT_BYR2 || decoder->frame.format == DECODED_FORMAT_BYR4)
        {
            if (decoded_width * 2 == info->width)
            {
                info->width /= 2;
                info->height /= 2;

                info->resolution = resolution = DECODED_RESOLUTION_HALF_NODEBAYER;
            }
        }
        else
        {
            if (resolution == DECODED_RESOLUTION_HALF)
            {
                if (decoded_width * 2 == info->width)
                {
                    decoded_width *= 2;
                    decoded_height *= 2;
                    info->resolution = resolution = DECODED_RESOLUTION_FULL;
                }
            }
            else if (resolution == DECODED_RESOLUTION_QUARTER)
            {
                if (uncompressed)
                {
                    decoded_width *= 2;
                    decoded_height *= 2;
                    info->resolution = resolution = DECODED_RESOLUTION_QUARTER_NODEBAYER_SCALED;
                }
                else
                {
                    if (decoded_width == info->width)
                    {
                        info->resolution = resolution = DECODED_RESOLUTION_HALF;
                    }
                }
            }
        }
    }

    if (uncompressed)
    {
        // Call the appropriate routine for the encoded format
        switch (decoder->codec.encoded_format)
        {
            case ENCODED_FORMAT_YUVA_4444:		// Four planes of YUVA 4:4:4:4
                // Not implemented
                assert(0);
                error = CODEC_ERROR_UNSUPPORTED_FORMAT;
                break;

            case ENCODED_FORMAT_BAYER:			// Bayer encoded data
                // Add new code here for the final steps in decoding the Bayer format
                error = UncompressedSampleFrameBayerToBuffer(decoder, info, frame, output, pitch);
                break;

            case ENCODED_FORMAT_YUV_422:		// Original encoding scheme for YUV 4:2:2 (always v210)
                error = UncompressedSampleFrameYUVToBuffer(decoder, info, frame, output, pitch);//CODEC_ERROR_UNSUPPORTED_FORMAT;
                break;

            case ENCODED_FORMAT_RGB_444:		// Original encoding scheme for RGB 444 (always DPX0)
                error = UncompressedSampleFrameRGBToBuffer(decoder, info, frame, output, pitch);//CODEC_ERROR_UNSUPPORTED_FORMAT;
                break;

            default:
                // Fall through into the old code for reconstructing frames
                error = CODEC_ERROR_UNSUPPORTED_FORMAT;
                break;
        }
    }
    else
    {
        // Call the appropriate routine for the encoded format
        switch (decoder->codec.encoded_format)
        {
            case ENCODED_FORMAT_RGB_444:		// channels = decoder->codec.num_channels; planes of RGB 4:4:4
            case ENCODED_FORMAT_RGBA_4444:		// Four planes of ARGB 4:4:4:4
                error = ReconstructSampleFrameRGB444ToBuffer(decoder, frame, output, pitch);
                break;

            case ENCODED_FORMAT_YUVA_4444:		// Four planes of YUVA 4:4:4:4
                // Not implemented
                assert(0);
                //error = ReconstructSampleFrameYUVA4444ToBuffer(decoder, frame, output, pitch);
                break;

            case ENCODED_FORMAT_BAYER:			// Bayer encoded data
                // Add new code here for the final steps in decoding the Bayer format
                error = ReconstructSampleFrameBayerToBuffer(decoder, info, frame, output, pitch);
                break;

            case ENCODED_FORMAT_YUV_422:		// Original encoding scheme for YUV 4:2:2
                // Add new code here for the final steps in decoding the original YUV 4:2:2 format
                error = ReconstructSampleFrameYUV422ToBuffer(decoder, frame, output, pitch);
                break;

            default:
                // Fall through into the old code for reconstructing frames
                error = CODEC_ERROR_UNSUPPORTED_FORMAT;
                break;
        }
    }

    // Was the newer code able to successfully reconstruct the frame?
    if (error != CODEC_ERROR_UNSUPPORTED_FORMAT)
    {
        // Save the codec error code in the decoder state and return
        decoder->error = error;
        return;
    }

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decoded scale: %d, decoded width: %d, wavelet width: %d\n", decoded_scale, decoded_width, wavelet_width);
    }
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decoded width: %d, height: %d, frame width: %d, height: %d, output pitch: %d\n",
                decoded_width, decoded_height, info->width, info->height, pitch);
    }
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        IMAGE *wavelet = transform[0]->wavelet[frame];
        int band = 0;
        fprintf(logfile, "Luminance wavelet, frame: %d, band: %d\n", frame, band);
        DumpArray16s("Lowpass Band", wavelet->band[band], wavelet->width, wavelet->height, wavelet->pitch, logfile);
    }
#endif

    // Check that the requested frame is large enough to hold the decoded frame
#if (0 && DEBUG)
    //if (! (info->width >= decoded_width))
    {
        if (logfile)
        {
            //fprintf(logfile, "Requested frame not large enough to hold decoded frame: %d < %d\n", info->width, decoded_width);
            fprintf(logfile, "Output frame width: %d, decoded frame width: %d\n", info->width, decoded_width);
        }
    }
#endif
    assert(info->width >= decoded_width);
    assert((info->height + 7) / 8 >= (decoded_height + 7) / 8);

    if (!(info->width >= decoded_width && (info->height + 7) / 8 >= (decoded_height + 7) / 8))
    {
        decoder->error = CODEC_ERROR_FRAMESIZE;
        return;
    }

#if (0 && DEBUG)
    if (logfile)
    {
        //SUBIMAGE subimage = SUBIMAGE_UPPER_LEFT(16, 16);
        SUBIMAGE subimage = SUBIMAGE_UPPER_RIGHT(16, 16);

        // Adjust the subimage to be at the middle of the right border
        //subimage.row += wavelet_height/2 - 8;

        DumpBand("SIF Image", wavelet, 0, &subimage, logfile);
    }
#endif

    START(tk_inverse);

    if (resolution == DECODED_RESOLUTION_QUARTER)
    {
        int precision = codec->precision;

        // Reconstruct the frame to quarter resolution
        ReconstructQuarterFrame(decoder, num_channels, frame, output, pitch,
                                info, &decoder->scratch, precision);
    }
    else

        // Was the first transform a frame transform (used for interlaced frames)?
        if (!progressive)
        {
            // Can the inverse frame transform and output byte packing be done in one pass?
            if ((resolution == DECODED_RESOLUTION_FULL) &&
                    (info->format == DECODED_FORMAT_YUYV || info->format == DECODED_FORMAT_UYVY))
            {
                // Apply the inverse frame transform and pack the results into the output buffer
                int precision = codec->precision;

#if (0 && DEBUG)
                DumpWaveletBandsPGM(wavelet, frame, num_channels);
#endif
#if _INTERLACED_WORKER_THREADS
                StartInterlaceWorkerThreads(decoder);

                //TODO: support new threading
                // Send the upper and lower rows of the transforms to the worker threads
                TransformInverseFrameThreadedToYUV(decoder, frame, num_channels, output, pitch,
                                                   info, chroma_offset, precision);
#else
                // Transform the wavelets for each channel to the output image (not threaded)
                TransformInverseFrameToYUV(transform_array, frame, num_channels, output, pitch,
                                           info, &decoder->scratch, chroma_offset, precision);
#endif
            }

            //#if BUILD_PROSPECT
            else if (resolution == DECODED_RESOLUTION_FULL && info->format == DECODED_FORMAT_YR16)
            {
                // Apply the inverse frame transform and output rows of luma and chroma

                //DWORD dwThreadID1;
                //DWORD dwThreadID2;
                //HANDLE thread1;
                //HANDLE thread2;
                int precision = codec->precision;

#if _INTERLACED_WORKER_THREADS
                StartInterlaceWorkerThreads(decoder);

                //TODO: support new threading
                // Send the upper and lower rows of the transforms to the worker threads
                TransformInverseFrameThreadedToRow16u(decoder, frame, num_channels,
                                                      (PIXEL16U *)output, pitch,
                                                      info, chroma_offset, precision);
#else
                // Transform the wavelets for each channel to the output image (not threaded)
                TransformInverseFrameToRow16u(decoder, transform_array, frame, num_channels,
                                              (PIXEL16U *)output, pitch, info,
                                              &decoder->scratch, chroma_offset, precision);
#endif
            }
            //#endif
            else
            {
                // Reconstruct the frame as separate planes and combine the planes into a packed output image
                int channel;

                if (resolution == DECODED_RESOLUTION_LOWPASS_ONLY)
                {
                    int scale = 13;

                    for (channel = 0; channel < num_channels; channel++)
                    {
                        lowpass_images[channel] = transform_array[channel]->wavelet[5];
                        if (lowpass_images[channel] == NULL) // therefore IntreFrame compressed.
                        {
                            scale = 12;
                            lowpass_images[channel] = transform_array[channel]->wavelet[2];
                        }
                    }

                    STOP(tk_inverse);

                    CopyLowpass16sToBuffer(decoder, lowpass_images, num_channels, output, pitch, info, chroma_offset,
                                           scale, decoder->codec.encoded_format, decoder->frame.white_point);

                    START(tk_inverse);
                }
                else
                    // In SIF resolution, no need to reconstruct the bottom-level wavelet transforms
                    // Just copy the lowpass images directly into output frame
                    if (resolution == DECODED_RESOLUTION_HALF)
                    {
                        int precision = codec->precision;

                        for (channel = 0; channel < num_channels; channel++)
                        {
                            lowpass_images[channel] = transform_array[channel]->wavelet[frame];
                        }

                        STOP(tk_inverse);

                        CopyLowpass16sToBuffer(decoder, lowpass_images, num_channels, output, pitch, info, chroma_offset,
                                               precision, decoder->codec.encoded_format, decoder->frame.white_point);

                        START(tk_inverse);
                    }

                // In full resolution, reconstruct the frame wavelet and
                // convert the YUYV output to the specified color format
                    else
                    {
                        int precision = codec->precision;
                        TransformInverseFrameToBuffer(transform_array, frame, num_channels, output, pitch,
                                                      info, &decoder->scratch, chroma_offset, precision);
                    }
            }
        }
        else	// The first transform was a spatial transform (used for progressive frames)
        {
            // Can the inverse frame transform and output byte packing be done in one pass?

            if ((resolution == DECODED_RESOLUTION_FULL) &&
                    (info->format == DECODED_FORMAT_YUYV || info->format == DECODED_FORMAT_UYVY) && // Output YUV
                    decoder->thread_cntrl.capabilities & _CPU_FEATURE_SSE2)
            {
                int precision = codec->precision;

                //DWORD dwThreadID1;
                //DWORD dwThreadID2;
                //HANDLE thread1;
                //HANDLE thread2;


                // Apply the inverse frame transform and pack the results into the output buffer
#if _THREADED
                if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
                {
                    uint8_t *pixoutput = output;

                    if (decoder->use_active_metadata_decoder) //WIP
                    {
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                pixoutput, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sBayerThruLUT);
                    }
                    else
                    {
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                pixoutput, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sToBayerYUV);
                    }
                }
                else if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                         (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                {
                    TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                            output, pitch,
                            info, chroma_offset, precision,
                            InvertHorizontalStrip16sRGB2YUV);
                }
                else
                {
                    TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                            output, pitch,
                            info, chroma_offset, precision,
                            InvertHorizontalStrip16sToYUV);
                }
#else
                //TODO : Accelerated BAYER for single thread decoding.

                assert(0);
                // Transform the wavelets for each channel to the output image (not threaded)
                //TransformInverseSpatialToYUV(decoder, transform_array, frame, num_channels, output, pitch, info,
                //							 &decoder->scratch, chroma_offset, precision);
#endif
            }

            else if ((resolution == DECODED_RESOLUTION_FULL) && decoder->codec.encoded_format == ENCODED_FORMAT_BAYER &&
                     (info->format == DECODED_FORMAT_RGB24 || info->format == DECODED_FORMAT_RGB32) && // Output RGB
                     decoder->thread_cntrl.capabilities & _CPU_FEATURE_SSE2 && decoder->use_active_metadata_decoder)
            {
                int precision = codec->precision;

                //DWORD dwThreadID1;
                //DWORD dwThreadID2;
                //HANDLE thread1;
                //HANDLE thread2;


                // Apply the inverse frame transform and pack the results into the output buffer
#if _THREADED
                {
                    uint8_t *pixoutput = output;

                    if (info->format == DECODED_FORMAT_RGB24 || info->format == DECODED_FORMAT_RGB32)
                    {
                        pixoutput += (info->height - 1) * pitch;
                        pitch = -pitch;
                    }

                    TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                            pixoutput, pitch,
                            info, chroma_offset, precision,
                            InvertHorizontalStrip16sBayerThruLUT);
                }
#endif
            }


            //#if BUILD_PROSPECT
            else if (resolution == DECODED_RESOLUTION_FULL && info->format == DECODED_FORMAT_YR16)
            {
                // Apply the inverse frame transform and output rows of luma and chroma
                int precision = codec->precision;

#if _THREADED
                TransformInverseSpatialUniversalThreadedToRow16u(decoder, frame, num_channels,
                        (uint8_t *)output, pitch,
                        info, chroma_offset, precision);
#else
                // Transform the wavelets for each channel to the output image (not threaded)
                TransformInverseSpatialToRow16u(transform_array, frame, num_channels,
                                                (PIXEL16U *)output, pitch, info,
                                                &decoder->scratch, chroma_offset, precision);
#endif
            }
            //#endif
            else
            {
                // Reconstruct the frame as separate planes and combine the planes into a packed output image
                int channel;

                if (resolution == DECODED_RESOLUTION_LOWPASS_ONLY)
                {
                    //int precision = codec->precision;
                    int scale = 13;

                    //DAN20081203 -- fix for 444 decodes in AE32-bit float
                    decoder->frame.white_point = 16;
                    //decoder->frame.signed_pixels = 0;

                    for (channel = 0; channel < num_channels; channel++)
                    {
                        lowpass_images[channel] = transform_array[channel]->wavelet[5];
                        if (lowpass_images[channel] == NULL) // therefore IntreFrame compressed.
                        {
                            scale = 12;
                            lowpass_images[channel] = transform_array[channel]->wavelet[2];
                        }
                    }

                    STOP(tk_inverse);

                    CopyLowpass16sToBuffer(decoder, lowpass_images, num_channels, output, pitch, info, chroma_offset,
                                           scale, decoder->codec.encoded_format, decoder->frame.white_point);

                    START(tk_inverse);
                }
                else
                    // In SIF resolution, no need to reconstruct the bottom-level wavelet transforms
                    // Just copy the lowpass images directly into output frame
                    if (resolution == DECODED_RESOLUTION_HALF || resolution == DECODED_RESOLUTION_HALF_NODEBAYER)// || resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER)
                    {
                        int precision = codec->precision;

                        for (channel = 0; channel < num_channels; channel++)
                        {
                            lowpass_images[channel] = transform_array[channel]->wavelet[frame];
#if (0 && DEBUG)
                            if (logfile)
                            {
                                char label[_MAX_PATH];
                                char *format = decoded_format_string[info->format];
                                sprintf(label, "Output, channel: %d, format: %s", channel, format);
                                DumpImageStatistics(label, lowpass_images[channel], logfile);
                            }
#endif
                        }

                        STOP(tk_inverse);


#if 1 //|| BAYER_SUPPORT
                        if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
                        {
#if _THREADED
                            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
                            if (decoder->worker_thread.pool.thread_count == 0)
                            {
                                CreateLock(&decoder->worker_thread.lock);
                                // Initialize the pool of transform worker threads
                                ThreadPoolCreate(&decoder->worker_thread.pool,
                                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                                 WorkerThreadProc,
                                                 decoder);
                            }
#endif

                            // Post a message to the mailbox
                            mailbox->output = output;
                            mailbox->pitch = pitch;
                            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
                            mailbox->jobType = JOB_TYPE_OUTPUT;

                            // Set the work count to the number of rows to process
                            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

                            // Start the transform worker threads
                            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                            // Wait for all of the worker threads to finish
                            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

#else
                            //unsigned short scanline[4096*3],*sptr;
                            //unsigned short scanline2[4096*3],*sptr2;
                            unsigned short *scanline, *sptr;
                            unsigned short *scanline2, *sptr2;
                            char *buffer = decoder->scratch.free_ptr;
                            size_t buffer_size = decoder->scratch.free_size;

                            IMAGE *g_image = lowpass_images[0];
                            IMAGE *rg_image = lowpass_images[1];
                            IMAGE *bg_image = lowpass_images[2];
                            IMAGE *gd_image = lowpass_images[3];

                            uint8_t *outyuv, *line = output;
                            PIXEL *bayer_line, *bayerptr;
                            PIXEL *G, *RG, *BG, *GD;
                            int x, y;
                            int bayer_pitch = info->width * 4;
                            int format = info->format;
                            bool inverted = false;
                            int maxbound = 4095; //10-bit source
                            int midpoint = 32768 >> 3;
                            int shift = 4;

                            if (precision == 12)
                            {
                                maxbound = 16383;
                                midpoint = 32768 >> 1;
                                shift = 2;
                            }


                            if (buffer_size < info->width * 2 * 3 * 2)
                                assert(0); // not enough memory

                            if (format == DECODED_FORMAT_RGB24 || format == DECODED_FORMAT_RGB32)
                            {
                                inverted = true;
                                line += (info->height - 1) * pitch;
                                pitch = -pitch;
                            }

                            scanline = (unsigned short *)buffer;
                            buffer += info->width * 2 * 3;
                            scanline2 = (unsigned short *)buffer;

                            G = g_image->band[0];
                            RG = rg_image->band[0];
                            BG = bg_image->band[0];


                            for (y = 0; y < info->height; y++)
                            {
                                uint8_t *newline = line;
                                PIXEL *newG = G, *newRG = RG, *newBG = BG;
                                PIXEL *gptr, *rgptr, *bgptr, *gdptr;
                                int r, g, b, rg, bg, y1, y2, u, v;
                                int r1, g1, b1;
                                int i;

                                newline += pitch * y;

                                newG += y * (g_image->pitch / sizeof(PIXEL));
                                newRG += y * (rg_image->pitch / sizeof(PIXEL));
                                newBG += y * (bg_image->pitch / sizeof(PIXEL));

                                gptr = newG;
                                rgptr = newRG;
                                bgptr = newBG;

                                sptr = scanline;

                                for (x = 0; x < info->width; x++)
                                {
                                    g = (*gptr++);
                                    if (g > maxbound) g = maxbound;
                                    rg = (*rgptr++);
                                    bg = (*bgptr++);

                                    r = (rg << 1) - midpoint + g;
                                    b = (bg << 1) - midpoint + g;

                                    if (r > maxbound) r = maxbound;
                                    if (b > maxbound) b = maxbound;

                                    if (r < 0) r = 0;
                                    if (g < 0) g = 0;
                                    if (b < 0) b = 0;

                                    *sptr++ = r << shift;
                                    *sptr++ = g << shift;
                                    *sptr++ = b << shift;
                                }

                                {
                                    int flags = 0;
                                    int whitebitdepth = 16;

                                    sptr = scanline;
                                    if (decoder->apply_color_active_metadata)
                                        sptr = ApplyActiveMetaData(decoder, info->width, 1, y, scanline, scanline2,
                                                                   info->format, &whitebitdepth, &flags);

                                    ConvertLinesToOutput(decoder, info->width, 1, sptr,
                                                         newline, y, pitch,
                                                         info->format, whitebitdepth, flags);
                                }
                            }
#endif
                        }
                        else if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                                 (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                        {

                            IMAGE *g_image = lowpass_images[0];
                            IMAGE *rg_image = lowpass_images[1];
                            IMAGE *bg_image = lowpass_images[2];

                            uint8_t *line = output;
                            unsigned char *rgb8;
                            PIXEL *G, *RG, *BG;
                            int x, y;

                            G = g_image->band[0];
                            RG = rg_image->band[0];
                            BG = bg_image->band[0];

                            if (info->format == DECODED_FORMAT_RGB32)
                            {
                                line = output;
                                line += (info->height - 1) * pitch;
                                for (y = 0; y < info->height; y++)
                                {
                                    PIXEL *gptr, *rgptr, *bgptr;
                                    int r, g, b;
                                    int i, noisearray[32];
                                    for (i = 0; i < 32; i++)
                                    {
                                        noisearray[i] = (rand() & 63);
                                    }

                                    gptr = G;
                                    rgptr = RG;
                                    bgptr = BG;

                                    rgb8 = (unsigned char *)line;
                                    for (x = 0; x < info->width; x++)
                                    {
                                        int rnd = noisearray[x & 31];

                                        g = ((*gptr++) + rnd) >> 6;
                                        r = ((*rgptr++) + rnd) >> 6;
                                        b = ((*bgptr++) + rnd) >> 6;

                                        if (r < 0) r = 0;
                                        if (r > 255) r = 255;
                                        if (g < 0) g = 0;
                                        if (g > 255) g = 255;
                                        if (b < 0) b = 0;
                                        if (b > 255) b = 255;

                                        *rgb8++ = b;
                                        *rgb8++ = g;
                                        *rgb8++ = r;
                                        *rgb8++ = 255;
                                    }

                                    line -= pitch;
                                    G += g_image->pitch / sizeof(PIXEL);
                                    RG += rg_image->pitch / sizeof(PIXEL);
                                    BG += bg_image->pitch / sizeof(PIXEL);
                                }
                            }
                            else if (info->format == DECODED_FORMAT_RGB24)
                            {
                                line = output;
                                line += (info->height - 1) * pitch;
                                for (y = 0; y < info->height; y++)
                                {
                                    PIXEL *gptr, *rgptr, *bgptr;
                                    int r, g, b;
                                    int i, noisearray[32];
                                    for (i = 0; i < 32; i++)
                                    {
                                        noisearray[i] = (rand() & 63);
                                    }

                                    gptr = G;
                                    rgptr = RG;
                                    bgptr = BG;

                                    rgb8 = (unsigned char *)line;
                                    for (x = 0; x < info->width; x++)
                                    {
                                        int rnd = noisearray[x & 31];

                                        g = ((*gptr++) + rnd) >> 6;
                                        r = ((*rgptr++) + rnd) >> 6;
                                        b = ((*bgptr++) + rnd) >> 6;

                                        if (r < 0) r = 0;
                                        if (r > 255) r = 255;
                                        if (g < 0) g = 0;
                                        if (g > 255) g = 255;
                                        if (b < 0) b = 0;
                                        if (b > 255) b = 255;

                                        *rgb8++ = b;
                                        *rgb8++ = g;
                                        *rgb8++ = r;
                                    }

                                    line -= pitch;
                                    G += g_image->pitch / sizeof(PIXEL);
                                    RG += rg_image->pitch / sizeof(PIXEL);
                                    BG += bg_image->pitch / sizeof(PIXEL);
                                }
                            }
                        }
                        else
#endif
                        {
                            CopyLowpass16sToBuffer(decoder, lowpass_images, num_channels, output, pitch, info, chroma_offset,
                                                   precision, decoder->codec.encoded_format, decoder->frame.white_point);
                        }

                        START(tk_inverse);

#if (0 && DEBUG)
                        if (logfile)
                        {
                            char label[_MAX_PATH];
                            int width = info->width;
                            int height = info->height;

                            sprintf(label, "Output");
                            DumpBufferStatistics(label, output, width, height, pitch, logfile);
                        }
#endif
                    }

                // In full resolution, reconstruct the frame wavelet and
                // convert the YUYV output to the specified color format
                    else
                    {
                        // Handle inversion of the output image in this routine
                        FRAME_INFO info2;
                        int format;
                        bool inverted = false;
                        int precision = codec->precision;

                        memcpy(&info2, info, sizeof(FRAME_INFO));

                        format = info2.format;

                        if (format == DECODED_FORMAT_RGB24)
                        {
                            format = DECODED_FORMAT_RGB24_INVERTED;
                            info2.format = format;
                            inverted = true;
                        }
                        else if (format == DECODED_FORMAT_RGB32)
                        {
                            format = DECODED_FORMAT_RGB32_INVERTED;
                            info2.format = format;
                            inverted = true;
                        }

                        // Have the output location and pitch been inverted?
                        if (inverted && pitch > 0)
                        {
                            int height = info->height;
                            if (resolution == DECODED_RESOLUTION_FULL_DEBAYER)
                                height *= 2;
                            output += (height - 1) * pitch;		// Start at the bottom row
                            pitch = NEG(pitch);					// Negate the pitch to go up
                        }

                        //#if BUILD_PROSPECT
                        // Output the frame in V210 foramt?
                        if (	(format == DECODED_FORMAT_V210 ||
                                 format == DECODED_FORMAT_YU64) &&
                                decoder->codec.encoded_format != ENCODED_FORMAT_BAYER )
                        {
                            //char *buffer = decoder->buffer;
                            //size_t buffer_size = decoder->buffer_size;
                            int precision = codec->precision;

                            // The output buffer is an array of 10-bit pixels packed into double words
#if 0
                            TransformInverseSpatialToV210(transform_array, frame, num_channels, output, pitch, &info2,
                                                          buffer, buffer_size, chroma_offset, decoder->codec.precision);
#else
                            TransformInverseSpatialToV210(transform_array, frame, num_channels, output, pitch,
                                                          &info2, &decoder->scratch, chroma_offset, precision);
#endif
                        }
                        else
                            //#endif
                            // Decoding a full resolution progressive frame to a Bayer output format?
                            if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
                            {
                                //char *buffer = decoder->buffer;
                                //size_t buffer_size = decoder->buffer_size;
                                int precision = codec->precision;
                                //	PIXEL16U *RawBayer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(info->width*decoded_height*4*sizeof(PIXEL), 16);
                                if (decoder->RawBayer16 == NULL)
                                {
#if _ALLOCATOR
                                    ALLOCATOR *allocator = decoder->allocator;
                                    size_t size = info->width * decoded_height * 4 * sizeof(PIXEL);

                                    decoder->RawBayer16 =
                                        (PIXEL16U *)AllocAligned(allocator, size, 16);
#else
                                    decoder->RawBayer16 =
                                        (PIXEL16U *)MEMORY_ALIGNED_ALLOC(info->width * decoded_height * 4 * sizeof(PIXEL), 16);
#endif
                                    decoder->RawBayerSize = info->width * decoded_height * 4 * sizeof(PIXEL);
                                }
                                //TODO: Replace this memory allocation with a scratch buffer allocation
                                //#ifdef SHARPENING
                                if (decoder->RGBFilterBuffer16 == NULL)
                                {
#if _ALLOCATOR
                                    ALLOCATOR *allocator = decoder->allocator;
                                    size_t size = info->width * decoded_height * 4 * 3 * sizeof(PIXEL);

                                    decoder->RGBFilterBuffer16 =
                                        (PIXEL16U *)AllocAligned(allocator, size, 16);
#else
                                    decoder->RGBFilterBuffer16 =
                                        (PIXEL16U *)MEMORY_ALIGNED_ALLOC(info->width * decoded_height * 4 * 3 * sizeof(PIXEL), 16);
#endif
                                    decoder->RGBFilterBufferSize = info->width * decoded_height * 4 * 3 * sizeof(PIXEL);
                                }
                                //#endif

                                if (decoder->RawBayer16 == NULL || decoder->RGBFilterBuffer16 == NULL)
                                {
                                    decoder->error = CODEC_ERROR_MEMORY_ALLOC;
                                    return;
                                }


                                if (decoder->RawBayer16)
                                {
                                    uint8_t *line;
                                    PIXEL16U *bayer_line, *bayerptr, *outA16, *outB16;
                                    PIXEL16U *G, *RG, *BG, *GD;
                                    int x, y;
                                    int bayer_pitch = info->width * 4;

                                    //float scale = 256.0;

                                    //int matrix_non_unity = 0;
                                    //int wb_non_unity = 0;
                                    //float curve2lin[2048];
                                    //float lin2curve[2048+512+2];
#if 0
                                    static float rgb2yuv[3][4] =
                                    {
                                        {0.183f, 0.614f, 0.062f, 16.0f / 256.0f},
                                        {-0.101f, -0.338f, 0.439f, 0.5f},
                                        {0.439f, -0.399f, -0.040f, 0.5f}
                                    };

                                    float mtrx[3][4] =
                                    {
                                        {1.0f,  0,   0,   0},
                                        {0,  1.0f,   0,   0},
                                        {0,    0, 1.0f,   0}
                                    };

                                    float whitebalance[3] = { 1.0f, 1.0f, 1.0f };
#endif

#if 0 // Matrix disabled as it can only be correct handled by the 3D LUT due to the required linear conversions
                                    /*						if(decoder->cfhddata.MagicNumber == CFHDDATA_MAGIC_NUMBER && decoder->cfhddata.version >= 2)
                                    						{
                                    							float fval = 0.0;
                                    							int i;
                                    							for(i=0; i<12; i++)
                                    							{
                                    								mtrx[i>>2][i&3] = fval = decoder->cfhddata.colormatrix[i>>2][i&3];

                                    								if((i>>2) == (i&3))
                                    								{
                                    									if(fval != 1.0)
                                    									{
                                    										matrix_non_unity = 1;
                                    									}
                                    								}
                                    								else
                                    								{
                                    									if(fval != 0.0)
                                    									{
                                    										matrix_non_unity = 1;
                                    									}
                                    								}
                                    							}

                                    							// not active as VFW isn't yet support the 3D LUTs
                                    							if(decoder->cfhddata.version >= 5)
                                    							{
                                    								int j;
                                    								float encode_curvebase = 90.0;
                                    								float decode_curvebase = 90.0;
                                    								int encode_curve_type = decoder->cfhddata.encode_curve >> 16;
                                    								int decode_curve_type = decoder->cfhddata.decode_curve >> 16;


                                    								if(decoder->cfhddata.user_white_balance[0] > 0.0)
                                    								{
                                    									wb_non_unity = 1;

                                    									whitebalance[0] = decoder->cfhddata.user_white_balance[0];
                                    									whitebalance[1] = (decoder->cfhddata.user_white_balance[1]+decoder->cfhddata.user_white_balance[2])/2.0;
                                    									whitebalance[2] = decoder->cfhddata.user_white_balance[3];
                                    								}


                                    								if(encode_curve_type) //1 or 2
                                    									encode_curvebase = (float)((decoder->cfhddata.encode_curve >> 8) & 0xff) / (float)(decoder->cfhddata.encode_curve & 0xff);
                                    								else
                                    								{
                                    									encode_curve_type = 1;
                                    									encode_curvebase = 90.0;
                                    								}

                                    								if(decode_curve_type) //1 or 2
                                    									decode_curvebase = (float)((decoder->cfhddata.decode_curve >> 8) & 0xff) / (float)(decoder->cfhddata.decode_curve & 0xff);
                                    								else
                                    								{
                                    									decode_curve_type = 1;
                                    									decode_curvebase = 90.0;
                                    								}


                                    								for(j=0; j<2048; j++)
                                    								{
                                    									if(encode_curve_type == 1)
                                    										curve2lin[j] = CURVE_LOG2LIN((float)j/2047.0,encode_curvebase);
                                    									else
                                    										curve2lin[j] = CURVE_GAM2LIN((float)j/2047.0,encode_curvebase);

                                    								}

                                    								for(j=-512; j<=2048; j++) // -1 to +4
                                    								{
                                    									if(encode_curve_type == CURVE_TYPE_LOG)
                                    										lin2curve[j+512] = CURVE_LIN2LOG((float)j/512.0,encode_curvebase);
                                    									else
                                    										lin2curve[j+512] = CURVE_LIN2GAM((float)j/512.0,encode_curvebase);

                                    								}
                                    							}
                                    						}*/
#endif


#if _THREADED
                                    TransformInverseSpatialUniversalThreadedToRow16u(decoder, frame, num_channels,
                                            (uint8_t *)decoder->RawBayer16, bayer_pitch * sizeof(PIXEL),
                                            info, chroma_offset, precision);
#else
                                    // Decode that last transform to rows of Bayer data (one row per channel)
                                    TransformInverseSpatialToRow16u(transform_array, frame, num_channels,
                                                                    decoder->RawBayer16, bayer_pitch * sizeof(PIXEL), info,
                                                                    &decoder->scratch, chroma_offset, precision);
#endif

                                    if (resolution == DECODED_RESOLUTION_FULL_DEBAYER &&
                                            (info->format < DECODED_FORMAT_BYR1 || info->format > DECODED_FORMAT_BYR4))
                                    {

#if _THREADED				//DemosaicRAW
                                        WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;
#if _DELAY_THREAD_START
                                        if (decoder->worker_thread.pool.thread_count == 0)
                                        {
                                            CreateLock(&decoder->worker_thread.lock);
                                            // Initialize the pool of transform worker threads
                                            ThreadPoolCreate(&decoder->worker_thread.pool,
                                                             decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                                             WorkerThreadProc,
                                                             decoder);
                                        }
#endif
                                        // Post a message to the mailbox
                                        mailbox->output = output;
                                        mailbox->pitch = pitch;
                                        memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
                                        mailbox->jobType = JOB_TYPE_OUTPUT;

                                        // Set the work count to the number of rows to process
                                        ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

                                        // Start the transform worker threads
                                        ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                                        // Wait for all of the worker threads to finish
                                        ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

#else
                                        assert(0) // old code disabled
                                        /*			int bayer_format = decoder->cfhddata.bayer_format;
                                        			unsigned char *outA8, *outB8;
                                        			unsigned short *lineStartA16, *lineStartB16;
                                        			unsigned short *lineA16, *lineB16;

                                        		//	int stats1=0, stats2=0, statsd=0;
                                        		//	double dstats1=0, dstats2=0, dstatsd=0;

                                        			line = output;
                                        			bayer_line = decoder->RawBayer16;
                                        			for(y=0; y<info->height+DEMOSAIC_DELAYLINES; y++)
                                        			{
                                        				bayer_line = decoder->RawBayer16;
                                        				bayer_line += bayer_pitch * y;

                                        				if(y<info->height)
                                        				{
                                        					ColorDifference2Bayer(info->width,
                                        						bayer_line, bayer_pitch, bayer_format);
                                        				}

                                        				if(y>=3+DEMOSAIC_DELAYLINES && y<info->height-3+DEMOSAIC_DELAYLINES) //middle scanline
                                        				{
                                        					unsigned short *delayptr = decoder->RawBayer16;
                                        					delayptr += bayer_pitch * (y-DEMOSAIC_DELAYLINES);

                                        					BayerRippleFilter(info->width,
                                        						delayptr, bayer_pitch, bayer_format, decoder->RawBayer16);
                                        				}

                                        				if(y>=DEMOSAIC_DELAYLINES)
                                        				{
                                        					int delay_y = y - DEMOSAIC_DELAYLINES;
                                        					unsigned short *sptr, scanline[8192*3];
                                        					outA8 = line;
                                        					line += pitch;
                                        					outB8 = line;
                                        					line += pitch;

                                        					sptr = scanline;

                                        					DebayerLine(info->width*2, info->height*2, delay_y*2,
                                        						decoder->RawBayer16,  bayer_format, sptr, sharpening);

                                        					for(x=0; x<info->width*2; x++)
                                        					{
                                        						outA8[2] = *sptr++>>8;
                                        						outA8[1] = *sptr++>>8;
                                        						outA8[0] = *sptr++>>8;
                                        						outA8+=3;
                                        					}
                                        					for(x=0; x<info->width*2; x++)
                                        					{
                                        						outB8[2] = *sptr++>>8;
                                        						outB8[1] = *sptr++>>8;
                                        						outB8[0] = *sptr++>>8;
                                        						outB8+=3;
                                        					}
                                        				}
                                        			}*/
#endif // _THREADED
                                    }
                                    else


                                        if (format == DECODED_FORMAT_BYR2 || format == DECODED_FORMAT_BYR4)
                                        {
#if _THREADED
                                            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
                                            if (decoder->worker_thread.pool.thread_count == 0)
                                            {
                                                CreateLock(&decoder->worker_thread.lock);
                                                // Initialize the pool of transform worker threads
                                                ThreadPoolCreate(&decoder->worker_thread.pool,
                                                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                                                 WorkerThreadProc,
                                                                 decoder);
                                            }
#endif
                                            // Post a message to the mailbox
                                            mailbox->output = output;
                                            mailbox->pitch = pitch;
                                            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
                                            mailbox->jobType = JOB_TYPE_OUTPUT;

                                            // Set the work count to the number of rows to process
                                            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

                                            // Start the transform worker threads
                                            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                                            // Wait for all of the worker threads to finish
                                            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
#else
                                            assert(0) // old code disabled
                                            /*	{
                                            		int bayer_format = decoder->cfhddata.bayer_format;
                                            	//	int stats1=0, stats2=0, statsd=0;
                                            	//	double dstats1=0, dstats2=0, dstatsd=0;
                                            		line = output;
                                            		bayer_line = decoder->RawBayer16;

                                            		for(y=0; y<info->height; y++)
                                            		{
                                            			outA16 = (PIXEL16U *)line;
                                            			line += pitch;
                                            			outB16 = (PIXEL16U *)line;
                                            			line += pitch;

                                            			bayerptr = bayer_line;
                                            			G = bayerptr;
                                            			RG = G + bayer_pitch/4;
                                            			BG = RG + bayer_pitch/4;
                                            			GD = BG + bayer_pitch/4;
                                            			for(x=0; x<info->width; x++)
                                            			{
                                            				int r,g,b,rg,bg,gd,g1,g2,y1,y2,u,v,dither;


                                            				g = (*G++);
                                            				rg = (*RG++);
                                            				bg = (*BG++);
                                            				gd = (*GD++) - 32768;

                                            				r = ((rg - 32768)<<1) + g;
                                            				b = ((bg - 32768)<<1) + g;
                                            				g1 = g + gd;
                                            				g2 = g - gd; //TODO:  Is there a DC offset to gd (causes a check in output )

                                            			//	stats1+=g1;
                                            			//	stats2+=g2;
                                            			//	statsd+=gd;

                                            				if(r < 0) r = 0;
                                            				if(g1 < 0) g1 = 0;
                                            				if(g2 < 0) g2 = 0;
                                            				if(b < 0) b = 0;

                                            				if(r > 0xffff) r = 0xffff;
                                            				if(g1 > 0xffff) g1 = 0xffff;
                                            				if(g2 > 0xffff) g2 = 0xffff;
                                            				if(b > 0xffff) b = 0xffff;

                                            				switch(bayer_format)
                                            				{
                                            				case BAYER_FORMAT_RED_GRN: //Red-grn phase
                                            					*outA16++ = r;
                                            					*outA16++ = g1;
                                            					*outB16++ = g2;
                                            					*outB16++ = b;
                                            					break;
                                            				case BAYER_FORMAT_GRN_RED:// grn-red
                                            					*outA16++ = g1;
                                            					*outA16++ = r;
                                            					*outB16++ = b;
                                            					*outB16++ = g2;
                                            					break;
                                            				case BAYER_FORMAT_GRN_BLU:
                                            					*outA16++ = g1;
                                            					*outA16++ = b;
                                            					*outB16++ = r;
                                            					*outB16++ = g2;
                                            					break;
                                            				case BAYER_FORMAT_BLU_GRN:
                                            					*outA16++ = b;
                                            					*outA16++ = g1;
                                            					*outB16++ = g2;
                                            					*outB16++ = r;
                                            					break;
                                            				}
                                            			}

                                            			bayer_line += bayer_pitch;
                                            		}


                                            		if(decoder->flags & DECODER_FLAGS_HIGH_QUALITY)
                                            		{
                                            			int bayer_format = decoder->cfhddata.bayer_format;

                                            			for(y=2; y<info->height-3; y++)
                                            			{
                                            				int offset = pitch>>1;

                                            				line = output; //0
                                            				line += pitch * y * 2;

                                            				// If on a red line, move to a blue line
                                            				if(bayer_format == BAYER_FORMAT_GRN_RED || bayer_format == BAYER_FORMAT_RED_GRN)
                                            					line -= pitch;


                                            				{
                                            					int offset = pitch>>1;
                                            					outA16 = (PIXEL16U *)line;

                                            					outA16++; //g //for BAYER_FORMAT_RED_GRN input
                                            					outA16++; //b

                                            					outA16++; //g
                                            					outA16++; //b

                                            					//point to green pixel with *outA16
                                            					if(bayer_format == BAYER_FORMAT_GRN_RED || bayer_format == BAYER_FORMAT_GRN_BLU)
                                            						outA16++;

                                            					for(x=2; x<info->width-2; x++)
                                            					{
                                            						int mn,mx,g;
                                            						int range = 8*256; //1<<11
                                            						int shift = 11;
                                            						int delta;
                                            						int alpha;

                                            						g =  *outA16;

                                            						// lines below do not need to be tested for a corrected value
                                            						mn = mx = outA16[offset+1];
                                            						if(mn > outA16[offset-1]) mn = outA16[offset-1];
                                            						if(mx < outA16[offset-1]) mx = outA16[offset-1];
                                            						if((outA16[-offset-1] & 1)==0)

                                            						{
                                            							if(mn > outA16[-offset-1]) mn = outA16[-offset-1];
                                            							if(mx < outA16[-offset-1]) mx = outA16[-offset-1];
                                            						}
                                            						if((outA16[-offset+1] & 1)==0)
                                            						{
                                            							if(mn > outA16[-offset+1]) mn = outA16[-offset+1];
                                            							if(mx < outA16[-offset+1]) mx = outA16[-offset+1];
                                            						}

                                            						delta = mx - mn;

                                            						if(delta < range && ((mn-range < g && g < mn) || (mx+range > g && g > mx)))
                                            						{
                                            							int gmn,gmx;

                                            							gmn = gmx = g;
                                            							if((outA16[-2*offset-2] & 1)==0)
                                            							{
                                            								if(gmn > outA16[-2*offset-2]) gmn = outA16[-2*offset-2];
                                            								if(gmx < outA16[-2*offset-2]) gmx = outA16[-2*offset-2];
                                            							}
                                            							if((outA16[-2*offset] & 1)==0)
                                            							{
                                            								if(gmn > outA16[-2*offset]) gmn = outA16[-2*offset];
                                            								if(gmx < outA16[-2*offset]) gmx = outA16[-2*offset];
                                            							}
                                            							if((outA16[-2*offset+2] & 1)==0)
                                            							{
                                            								if(gmn > outA16[-2*offset+2]) gmn = outA16[-2*offset+2];
                                            								if(gmx < outA16[-2*offset+2]) gmx = outA16[-2*offset+2];
                                            							}
                                            							if((outA16[-2] & 1)==0)
                                            							{
                                            								if(gmn > outA16[-2]) gmn = outA16[-2];
                                            								if(gmx < outA16[-2]) gmx = outA16[-2];
                                            							}
                                            							// lines below do not need to be tested for a corrected value
                                            							if(gmn > outA16[2*offset-2]) gmn = outA16[2*offset-2];
                                            							if(gmx < outA16[2*offset-2]) gmx = outA16[2*offset-2];
                                            							if(gmn > outA16[2*offset]) gmn = outA16[2*offset];
                                            							if(gmx < outA16[2*offset]) gmx = outA16[2*offset];
                                            							if(gmn > outA16[2*offset+2]) gmn = outA16[2*offset+2];
                                            							if(gmx < outA16[2*offset+2]) gmx = outA16[2*offset+2];
                                            							if(gmn > outA16[2]) gmn = outA16[2];
                                            							if(gmx < outA16[2]) gmx = outA16[2];


                                            							if((gmx - gmn) < range)
                                            							{
                                            								alpha = range;//delta;

                                            								if(g > mx)
                                            								{
                                            									alpha *= (g-mx); //max range
                                            									alpha >>= shift;
                                            								}
                                            								else // g < mn
                                            								{
                                            									alpha *= (mn-g); //max range
                                            									alpha >>= shift;
                                            								}

                                            								alpha *= alpha;
                                            								alpha >>= shift;


                                            							//	avg = (outA16[-offset-1] + outA16[offset-1] + outA16[-offset+1] + outA16[offset+1] + 2) >> 2;
                                            							//	*outA16 = avg; //good
                                            							//	*outA16 = mn; //spotty

                                            								if( (abs(outA16[offset] - outA16[-offset]) < range)
                                            									&& ((abs(outA16[1] - outA16[-1]) < range)))
                                            								{
                                            									int val = (alpha*g + (range - alpha)*((mn+mx)>>1))>>shift;
                                            									if(val > 0xffff) val = 0xffff;
                                            									if(val < 0) val = 0;
                                            									val |= 1;
                                            									*outA16 = val;

                                            								//	*outA16 = ((mn+mx)>>1) | 1; // like avg but less compute
                                            								}
                                            							}
                                            						}

                                            						outA16++; //g
                                            						outA16++; //b
                                            					}
                                            				}
                                            			}
                                            		}
                                            	}*/
#endif
                                        }

                                    // Pack the rows of Bayer data (full resolution progressive) into BYR3 format?
                                        else if (format == DECODED_FORMAT_BYR3)
                                        {
                                            PIXEL16U *outR, *outG1, *outG2, *outB;
                                            //	int stats1=0, stats2=0, statsd=0;
                                            //	double dstats1=0, dstats2=0, dstatsd=0;

                                            //	#pragma omp parallel for
                                            for (y = 0; y < info->height; y++)
                                            {

                                                uint8_t *line = output;
                                                PIXEL *bayerptr = (PIXEL *)decoder->RawBayer16;

                                                line += pitch * 2 * y;
                                                bayerptr += bayer_pitch * y;

                                                outR = (PIXEL16U *)line;
                                                outG1 = outR + (pitch / 4);
                                                outG2 = outR + (pitch / 4) * 2;
                                                outB = outR + (pitch / 4) * 3;

                                                G = (PIXEL16U *)bayerptr;
                                                RG = G + bayer_pitch / 4;
                                                BG = RG + bayer_pitch / 4;
                                                GD = BG + bayer_pitch / 4;

                                                // Pack the rows of Bayer components into the BYR3 pattern
#if (1 && XMMOPT)
                                                {

                                                    __m128i *G_128 = (__m128i *)G;
                                                    __m128i *RG_128 = (__m128i *)RG;
                                                    __m128i *BG_128 = (__m128i *)BG;
                                                    __m128i *GD_128 = (__m128i *)GD;

                                                    __m128i *outR_128 = (__m128i *)outR;
                                                    __m128i *outG1_128 = (__m128i *)outG1;
                                                    __m128i *outG2_128 = (__m128i *)outG2;
                                                    __m128i *outB_128 = (__m128i *)outB;

                                                    __m128i limiter = _mm_set1_epi16(0x7fff - 0x3ff);
                                                    __m128i midpoint1 = _mm_set1_epi16(32768 >> 6);
                                                    __m128i midpoint2 = _mm_set1_epi16(32768 >> 5);

                                                    int column_step = 8;
                                                    int post_column = (info->width) - ((info->width) % column_step);

                                                    for (x = 0; x < post_column; x += column_step)
                                                    {
                                                        __m128i r_128;
                                                        __m128i g1_128;
                                                        __m128i g2_128;
                                                        __m128i b_128;

                                                        __m128i g_128;
                                                        __m128i rg_128;
                                                        __m128i bg_128;
                                                        __m128i gd_128;

                                                        g_128 = _mm_load_si128(G_128++);
                                                        rg_128 = _mm_load_si128(RG_128++);
                                                        bg_128 = _mm_load_si128(BG_128++);
                                                        gd_128 = _mm_load_si128(GD_128++);


                                                        g_128 = _mm_srli_epi16(g_128, 6);
                                                        rg_128 = _mm_srli_epi16(rg_128, 5);
                                                        bg_128 = _mm_srli_epi16(bg_128, 5);
                                                        gd_128 = _mm_srli_epi16(gd_128, 6);
                                                        gd_128 = _mm_subs_epi16(gd_128, midpoint1);

                                                        rg_128 = _mm_subs_epi16(rg_128, midpoint2);
                                                        bg_128 = _mm_subs_epi16(bg_128, midpoint2);
                                                        r_128 = _mm_adds_epi16(rg_128, g_128);
                                                        b_128 = _mm_adds_epi16(bg_128, g_128);
                                                        g1_128 = _mm_adds_epi16(g_128, gd_128);
                                                        g2_128 = _mm_subs_epi16(g_128, gd_128);

                                                        r_128 = _mm_adds_epi16(r_128, limiter);
                                                        r_128 = _mm_subs_epu16(r_128, limiter);
                                                        g1_128 = _mm_adds_epi16(g1_128, limiter);
                                                        g1_128 = _mm_subs_epu16(g1_128, limiter);
                                                        g2_128 = _mm_adds_epi16(g2_128, limiter);
                                                        g2_128 = _mm_subs_epu16(g2_128, limiter);
                                                        b_128 = _mm_adds_epi16(b_128, limiter);
                                                        b_128 = _mm_subs_epu16(b_128, limiter);


                                                        _mm_store_si128(outR_128++, r_128);
                                                        _mm_store_si128(outG1_128++, g1_128);
                                                        _mm_store_si128(outG2_128++, g2_128);
                                                        _mm_store_si128(outB_128++, b_128);
                                                    }

                                                    G  = (PIXEL16U *)G_128;
                                                    RG = (PIXEL16U *)RG_128;
                                                    BG = (PIXEL16U *)BG_128;
                                                    GD = (PIXEL16U *)GD_128;

                                                    outR = (PIXEL16U *)outR_128;
                                                    outG1 = (PIXEL16U *)outG1_128;
                                                    outG2 = (PIXEL16U *)outG2_128;
                                                    outB = (PIXEL16U *)outB_128;

                                                }
#endif

                                                for (; x < info->width; x++)
                                                {
                                                    int r, g, b, rg, bg, gd, g1, g2;


                                                    g = (*G++);
                                                    rg = (*RG++);
                                                    bg = (*BG++);
                                                    gd = (*GD++) - 32768;

                                                    r = ((rg - 32768) << 1) + g;
                                                    b = ((bg - 32768) << 1) + g;
                                                    g1 = g + gd;
                                                    g2 = g - gd; //TODO:  Is there a DC offset to gd (causes a check in output )

                                                    if (r < 0) r = 0;
                                                    if (g1 < 0) g1 = 0;
                                                    if (g2 < 0) g2 = 0;
                                                    if (b < 0) b = 0;

                                                    if (r > 0xffff) r = 0xffff;
                                                    if (g1 > 0xffff) g1 = 0xffff;
                                                    if (g2 > 0xffff) g2 = 0xffff;
                                                    if (b > 0xffff) b = 0xffff;

                                                    //Red-grn phase
                                                    *outR++ = r >> 6;
                                                    *outG1++ = g1 >> 6;
                                                    *outG2++ = g2 >> 6;
                                                    *outB++ = b >> 6;
                                                }
                                            }
                                        }

                                    // Pack the rows of Bayer data (full resolution progressive) into BYR4 format?
                                        else if (format == DECODED_FORMAT_BYR4)
                                        {
                                            int bayer_format = decoder->cfhddata.bayer_format;
                                            line = output;
                                            bayer_line = decoder->RawBayer16;

                                            for (y = 0; y < info->height; y++)
                                            {
                                                outA16 = (PIXEL16U *)line;
                                                line += pitch;
                                                outB16 = (PIXEL16U *)line;
                                                line += pitch;

                                                bayerptr = bayer_line;
                                                G = bayerptr;
                                                RG = G + bayer_pitch / 4;
                                                BG = RG + bayer_pitch / 4;
                                                GD = BG + bayer_pitch / 4;
                                                for (x = 0; x < info->width; x++)
                                                {
                                                    //int r,g,b,rg,bg,gd,g1,g2,y1,y2,u,v,dither;
                                                    int32_t r, g, b, rg, bg, gd, g1, g2;

                                                    // The output of the inverse transform is unsigned 16-bit integers
                                                    const int midpoint = 32768;

                                                    g = (*G++);
                                                    rg = (*RG++);
                                                    bg = (*BG++);
                                                    gd = (*GD++) - midpoint;

                                                    r = ((rg - midpoint) << 1) + g;
                                                    b = ((bg - midpoint) << 1) + g;
                                                    g1 = g + gd;
                                                    g2 = g - gd;

                                                    r = SATURATE_16U(r);
                                                    g1 = SATURATE_16U(g1);
                                                    g2 = SATURATE_16U(g2);
                                                    b = SATURATE_16U(b);

                                                    //	stats1+=g1;
                                                    //	stats2+=g2;
                                                    //	statsd+=gd;

                                                    switch (bayer_format)
                                                    {
                                                        case BAYER_FORMAT_RED_GRN: //Red-grn phase
                                                            *outA16++ = r;
                                                            *outA16++ = g1;
                                                            *outB16++ = g2;
                                                            *outB16++ = b;
                                                            break;
                                                        case BAYER_FORMAT_GRN_RED:// grn-red
                                                            *outA16++ = g1;
                                                            *outA16++ = r;
                                                            *outB16++ = b;
                                                            *outB16++ = g2;
                                                            break;
                                                        case BAYER_FORMAT_GRN_BLU:
                                                            *outA16++ = g1;
                                                            *outA16++ = b;
                                                            *outB16++ = r;
                                                            *outB16++ = g2;
                                                            break;
                                                        case BAYER_FORMAT_BLU_GRN:
                                                            *outA16++ = b;
                                                            *outA16++ = g1;
                                                            *outB16++ = g2;
                                                            *outB16++ = r;
                                                            break;

                                                        default:
                                                            // Unsupported Bayer format
                                                            assert(0);
                                                            *outA16++ = 0;
                                                            *outA16++ = 0;
                                                            *outB16++ = 0;
                                                            *outB16++ = 0;
                                                            break;
                                                    }
                                                }

                                                bayer_line += bayer_pitch;
                                            }


                                            if (decoder->flags & DECODER_FLAGS_HIGH_QUALITY)
                                            {
                                                for (y = 2; y < info->height - 3; y++)
                                                {
                                                    //int offset = pitch>>1;

                                                    line = output; //0
                                                    line += pitch * y * 2;

                                                    // If on a red line, move to a blue line
                                                    if (bayer_format == BAYER_FORMAT_GRN_RED || bayer_format == BAYER_FORMAT_RED_GRN)
                                                        line -= pitch;


                                                    {
                                                        int offset = pitch >> 1;
                                                        outA16 = (PIXEL16U *)line;

                                                        outA16++; //g //for BAYER_FORMAT_RED_GRN input
                                                        outA16++; //b

                                                        outA16++; //g
                                                        outA16++; //b

                                                        //point to green pixel with *outA16
                                                        if (bayer_format == BAYER_FORMAT_GRN_RED || bayer_format == BAYER_FORMAT_GRN_BLU)
                                                            outA16++;



                                                        for (x = 2; x < info->width - 2; x++)
                                                        {
                                                            int mn, mx, g;
                                                            int range = 8 * 256; //1<<11
                                                            int shift = 11;
                                                            int delta;
                                                            int alpha;

                                                            g =  *outA16;

                                                            // lines below do not need to be tested for a corrected value
                                                            mn = mx = outA16[offset + 1];
                                                            if (mn > outA16[offset - 1]) mn = outA16[offset - 1];
                                                            if (mx < outA16[offset - 1]) mx = outA16[offset - 1];
                                                            if ((outA16[-offset - 1] & 1) == 0)
                                                            {
                                                                if (mn > outA16[-offset - 1]) mn = outA16[-offset - 1];
                                                                if (mx < outA16[-offset - 1]) mx = outA16[-offset - 1];
                                                            }
                                                            if ((outA16[-offset + 1] & 1) == 0)
                                                            {
                                                                if (mn > outA16[-offset + 1]) mn = outA16[-offset + 1];
                                                                if (mx < outA16[-offset + 1]) mx = outA16[-offset + 1];
                                                            }

                                                            delta = mx - mn;

                                                            if (delta < range && ((mn - range < g && g < mn) || (mx + range > g && g > mx)))
                                                            {
                                                                int gmn, gmx;

                                                                gmn = gmx = g;
                                                                if ((outA16[-2 * offset - 2] & 1) == 0)
                                                                {
                                                                    if (gmn > outA16[-2 * offset - 2]) gmn = outA16[-2 * offset - 2];
                                                                    if (gmx < outA16[-2 * offset - 2]) gmx = outA16[-2 * offset - 2];
                                                                }
                                                                if ((outA16[-2 * offset] & 1) == 0)
                                                                {
                                                                    if (gmn > outA16[-2 * offset]) gmn = outA16[-2 * offset];
                                                                    if (gmx < outA16[-2 * offset]) gmx = outA16[-2 * offset];
                                                                }
                                                                if ((outA16[-2 * offset + 2] & 1) == 0)
                                                                {
                                                                    if (gmn > outA16[-2 * offset + 2]) gmn = outA16[-2 * offset + 2];
                                                                    if (gmx < outA16[-2 * offset + 2]) gmx = outA16[-2 * offset + 2];
                                                                }
                                                                if ((outA16[-2] & 1) == 0)
                                                                {
                                                                    if (gmn > outA16[-2]) gmn = outA16[-2];
                                                                    if (gmx < outA16[-2]) gmx = outA16[-2];
                                                                }
                                                                // lines below do not need to be tested for a corrected value
                                                                if (gmn > outA16[2 * offset - 2]) gmn = outA16[2 * offset - 2];
                                                                if (gmx < outA16[2 * offset - 2]) gmx = outA16[2 * offset - 2];
                                                                if (gmn > outA16[2 * offset]) gmn = outA16[2 * offset];
                                                                if (gmx < outA16[2 * offset]) gmx = outA16[2 * offset];
                                                                if (gmn > outA16[2 * offset + 2]) gmn = outA16[2 * offset + 2];
                                                                if (gmx < outA16[2 * offset + 2]) gmx = outA16[2 * offset + 2];
                                                                if (gmn > outA16[2]) gmn = outA16[2];
                                                                if (gmx < outA16[2]) gmx = outA16[2];


                                                                if ((gmx - gmn) < range)
                                                                {
                                                                    alpha = range;//delta;

                                                                    if (g > mx)
                                                                    {
                                                                        alpha *= (g - mx); //max range
                                                                        alpha >>= shift;
                                                                    }
                                                                    else // g < mn
                                                                    {
                                                                        alpha *= (mn - g); //max range
                                                                        alpha >>= shift;
                                                                    }

                                                                    alpha *= alpha;
                                                                    alpha >>= shift;


                                                                    //	avg = (outA16[-offset-1] + outA16[offset-1] + outA16[-offset+1] + outA16[offset+1] + 2) >> 2;
                                                                    //	*outA16 = avg; //good
                                                                    //	*outA16 = mn; //spotty

                                                                    if ( (abs(outA16[offset] - outA16[-offset]) < range)
                                                                            && ((abs(outA16[1] - outA16[-1]) < range)))
                                                                    {
                                                                        int val = (alpha * g + (range - alpha) * ((mn + mx) >> 1)) >> shift;
                                                                        if (val > 0xffff) val = 0xffff;
                                                                        if (val < 0) val = 0;
                                                                        val |= 1;
                                                                        *outA16 = val;

                                                                        //	*outA16 = ((mn+mx)>>1) | 1; // like avg but less compute
                                                                    }
                                                                }
                                                            }

                                                            outA16++; //g
                                                            outA16++; //b
                                                        }
                                                    }
                                                }


                                            }
                                            // Linear restore
                                            {
                                                unsigned short *buff = (unsigned short *)output;
                                                //static int pos = 0;
                                                for (y = 0; y < info->height * 2; y++)
                                                {
                                                    for (x = 0; x < info->width * 2; x++)
                                                    {
                                                        float val = (float)buff[y * info->width * 2 + x] / 65535.0f;
                                                        float encode_curvebase = 90.0;
                                                        int encode_curve_type = CURVE_TYPE_LOG;
                                                        int encode_curve_neg;

                                                        if ((decoder->cfhddata.encode_curve) >> 16) //1 or 2
                                                        {
                                                            encode_curve_type = (decoder->cfhddata.encode_curve) >> 16;
                                                            if (encode_curve_type & CURVE_TYPE_EXTENDED)
                                                                encode_curvebase = (float)(decoder->cfhddata.encode_curve & 0xffff); // use all 16-bits for larger log bases
                                                            else
                                                                encode_curvebase = (float)((decoder->cfhddata.encode_curve >> 8) & 0xff) / (float)(decoder->cfhddata.encode_curve & 0xff);
                                                        }

                                                        if (encode_curvebase == 1.0 && encode_curve_type <= CURVE_TYPE_LINEAR)
                                                            encode_curve_type = CURVE_TYPE_LINEAR;

                                                        encode_curve_neg = encode_curve_type & CURVE_TYPE_NEGATIVE;

                                                        switch (encode_curve_type & CURVE_TYPE_MASK)
                                                        {
                                                            case CURVE_TYPE_LOG:
                                                                val = CURVE_LOG2LIN(val, encode_curvebase);
                                                                break;

                                                            case CURVE_TYPE_GAMMA:
                                                                val = CURVE_GAM2LIN(val, encode_curvebase);
                                                                break;

                                                            case CURVE_TYPE_CINEON:
                                                                val = CURVE_CINEON2LIN(val, encode_curvebase);
                                                                break;

                                                            case CURVE_TYPE_CINE985:
                                                                val = CURVE_CINE9852LIN(val, encode_curvebase);
                                                                break;

                                                            case CURVE_TYPE_PARA:
                                                                val = CURVE_PARA2LIN(val, (int)((decoder->cfhddata.encode_curve >> 8) & 0xff), (int)(decoder->cfhddata.encode_curve & 0xff));
                                                                break;

                                                            case CURVE_TYPE_CSTYLE:
                                                                val = CURVE_CSTYLE2LIN((float)val, (int)((decoder->cfhddata.encode_curve >> 8) & 0xff));
                                                                break;

                                                            case CURVE_TYPE_SLOG:
                                                                val = CURVE_SLOG2LIN((float)val);
                                                                break;

                                                            case CURVE_TYPE_LOGC:
                                                                val = CURVE_LOGC2LIN((float)val);
                                                                break;

                                                            case CURVE_TYPE_LINEAR:
                                                            default:
                                                                break;
                                                        }

                                                        buff[y * info->width * 2 + x] = (int)(val * 4095.0);
                                                    }
                                                }
                                            }
                                        }
                                        else
                                        {
#if _THREADED
                                            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
                                            if (decoder->worker_thread.pool.thread_count == 0)
                                            {
                                                CreateLock(&decoder->worker_thread.lock);
                                                // Initialize the pool of transform worker threads
                                                ThreadPoolCreate(&decoder->worker_thread.pool,
                                                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                                                 WorkerThreadProc,
                                                                 decoder);
                                            }
#endif
                                            // Post a message to the mailbox
                                            mailbox->output = output;
                                            mailbox->pitch = pitch;
                                            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
                                            mailbox->jobType = JOB_TYPE_OUTPUT;

                                            // Set the work count to the number of rows to process
                                            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

                                            // Start the transform worker threads
                                            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                                            // Wait for all of the worker threads to finish
                                            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
#else
                                            //unsigned short scanline[8192*3],*sptr;
                                            //unsigned short scanline2[8192*3],*sptr2;
                                            unsigned short *scanline, *sptr;
                                            unsigned short *scanline2, *sptr2;
                                            char *buffer = decoder->scratch.free_ptr;
                                            size_t buffer_size = decoder->scratch.free_size;

                                            uint8_t *outyuv, *line = output;
                                            PIXEL *bayerptr;
                                            int x, y;

                                            if (buffer_size < info->width * 2 * 3 * 2)
                                                assert(0); // not enough memory

                                            scanline = (unsigned short *)buffer;
                                            buffer += info->width * 2 * 3;
                                            scanline2 = (unsigned short *)buffer;

                                            line = output;
                                            bayer_line = decoder->RawBayer16;

                                            for (y = 0; y < info->height; y++)
                                            {
                                                int r, g, b, rg, bg, y1, y2, u, v;
                                                int r1, g1, b1;
                                                int i;

                                                __m128i gggggggg, ggggggg2, rgrgrgrg, bgbgbgbg;
                                                __m128i rrrrrrrr, bbbbbbbb;
                                                __m128i mid8192 = _mm_set1_epi16(8192);
                                                __m128i mid16384 = _mm_set1_epi16(16384);
                                                __m128i mid32768 = _mm_set1_epi16(32768);

                                                __m128i overflowprotectRGB_epi16 = _mm_set1_epi16(0x7fff - 0x3fff);
                                                int sse2width = info->width & 0xfff8;

                                                bayerptr = bayer_line;
                                                G = bayerptr;
                                                RG = G + bayer_pitch / 4;
                                                BG = RG + bayer_pitch / 4;
                                                GD = BG + bayer_pitch / 4;

                                                sptr = scanline;



                                                x = 0;
                                                for (; x < sse2width; x += 8)
                                                {
                                                    gggggggg = _mm_loadu_si128((__m128i *)G);
                                                    G += 8;
                                                    rgrgrgrg = _mm_loadu_si128((__m128i *)RG);
                                                    RG += 8;
                                                    bgbgbgbg = _mm_loadu_si128((__m128i *)BG);
                                                    BG += 8;


                                                    ggggggg2 = _mm_srli_epi16(gggggggg, 2);// 0-16383 14bit unsigned
                                                    rgrgrgrg = _mm_srli_epi16(rgrgrgrg, 2);// 14bit unsigned
                                                    bgbgbgbg = _mm_srli_epi16(bgbgbgbg, 2);// 14bit unsigned

                                                    rrrrrrrr = _mm_subs_epi16(rgrgrgrg, mid8192);// -8191 to 8191 14bit signed
                                                    rrrrrrrr = _mm_slli_epi16(rrrrrrrr, 1);		// -16382 to 16382 15bit signed
                                                    rrrrrrrr = _mm_adds_epi16(rrrrrrrr, ggggggg2); // -16382 to 32767

                                                    bbbbbbbb = _mm_subs_epi16(bgbgbgbg, mid8192);// -8191 to 8191 14bit signed
                                                    bbbbbbbb = _mm_slli_epi16(bbbbbbbb, 1);		// -16382 to 16382 15bit signed
                                                    bbbbbbbb = _mm_adds_epi16(bbbbbbbb, ggggggg2); // -16382 to 32767

                                                    //limit to 0 to 16383
                                                    rrrrrrrr = _mm_adds_epi16(rrrrrrrr, overflowprotectRGB_epi16);
                                                    rrrrrrrr = _mm_subs_epu16(rrrrrrrr, overflowprotectRGB_epi16);

                                                    //limit to 0 to 16383
                                                    bbbbbbbb = _mm_adds_epi16(bbbbbbbb, overflowprotectRGB_epi16);
                                                    bbbbbbbb = _mm_subs_epu16(bbbbbbbb, overflowprotectRGB_epi16);

                                                    rrrrrrrr = _mm_slli_epi16(rrrrrrrr, 2); // restore to 0 to 65535
                                                    bbbbbbbb = _mm_slli_epi16(bbbbbbbb, 2); // restore to 0 to 65535


                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 0);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 0);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 0);

                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 1);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 1);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 1);

                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 2);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 2);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 2);

                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 3);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 3);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 3);

                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 4);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 4);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 4);

                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 5);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 5);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 5);

                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 6);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 6);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 6);

                                                    *sptr++ = _mm_extract_epi16(rrrrrrrr, 7);
                                                    *sptr++ = _mm_extract_epi16(gggggggg, 7);
                                                    *sptr++ = _mm_extract_epi16(bbbbbbbb, 7);
                                                }

                                                for (; x < info->width; x++)
                                                {
                                                    g = (*G++);
                                                    rg = (*RG++);
                                                    bg = (*BG++);

                                                    r = ((rg - 32768) << 1) + g;
                                                    b = ((bg - 32768) << 1) + g;

                                                    if (r < 0) r = 0;
                                                    if (r > 0xffff) r = 0xffff;
                                                    if (g < 0) g = 0;
                                                    if (g > 0xffff) g = 0xffff;
                                                    if (b < 0) b = 0;
                                                    if (b > 0xffff) b = 0xffff;

                                                    *sptr++ = r;
                                                    *sptr++ = g;
                                                    *sptr++ = b;
                                                }

                                                {
                                                    int flags = 0;
                                                    int whitebitdepth = 16;

                                                    sptr = scanline;
                                                    if (decoder->apply_color_active_metadata)
                                                        sptr = ApplyActiveMetaData(decoder, info->width, 1, y, scanline, scanline2,
                                                                                   info->format, &whitebitdepth, &flags);

                                                    ConvertLinesToOutput(decoder, info->width, 1, sptr, line, pitch,
                                                                         info->format, whitebitdepth, flags);
                                                }

                                                line += pitch;
                                                bayer_line += bayer_pitch;
                                            }
#endif
                                        }
                                    /* // switch to using the ApplyActiveMetaData() and ConvertLinesToOutput() calls - DAN20071201

                                    // Pack the rows of Bayer data (full resolution progressive) into BYR2 format?
                                    else if (format == DECODED_FORMAT_YUYV)
                                    {
                                    	line = output;
                                    	bayer_line = decoder->RawBayer16;


                                    	scale = 256.0;

                                    	y_rmult = ((rgb2yuv[0][0]) * scale);
                                    	y_gmult = ((rgb2yuv[0][1]) * scale);
                                    	y_bmult = ((rgb2yuv[0][2]) * scale);
                                    	y_offset= ((rgb2yuv[0][3]) * scale);

                                    	u_rmult = ((rgb2yuv[1][0]) * scale);
                                    	u_gmult = ((rgb2yuv[1][1]) * scale);
                                    	u_bmult = ((rgb2yuv[1][2]) * scale);
                                    	u_offset= ((rgb2yuv[1][3]) * scale);

                                    	v_rmult = ((rgb2yuv[2][0]) * scale);
                                    	v_gmult = ((rgb2yuv[2][1]) * scale);
                                    	v_bmult = ((rgb2yuv[2][2]) * scale);
                                    	v_offset= ((rgb2yuv[2][3]) * scale);


                                    	r_rmult= (mtrx[0][0] * scale * whitebalance[0]);
                                    	r_gmult= (mtrx[0][1] * scale * whitebalance[1]);
                                    	r_bmult= (mtrx[0][2] * scale * whitebalance[2]);
                                    	r_offset= (mtrx[0][3] * scale);

                                    	g_rmult= (mtrx[1][0] * scale * whitebalance[0]);
                                    	g_gmult= (mtrx[1][1] * scale * whitebalance[1]);
                                    	g_bmult= (mtrx[1][2] * scale * whitebalance[2]);
                                    	g_offset= (mtrx[1][3] * scale);

                                    	b_rmult= (mtrx[2][0] * scale * whitebalance[0]);
                                    	b_gmult= (mtrx[2][1] * scale * whitebalance[1]);
                                    	b_bmult= (mtrx[2][2] * scale * whitebalance[2]);
                                    	b_offset= (mtrx[2][3] * scale);


                                    	for(y=0; y<info->height; y++)
                                    	{
                                    		outyuv = line;
                                    		bayerptr = bayer_line;
                                    		G = bayerptr;
                                    		RG = G + bayer_pitch/4;
                                    		BG = RG + bayer_pitch/4;
                                    		for(x=0; x<info->width; x+=2)
                                    		{
                                    			int r,g,b,r1,g1,b1,rg,bg,y1,y2,u,v,dither;


                                    			g = (*G++);
                                    			rg = (*RG++);
                                    			bg = (*BG++);

                                    			r = ((rg - 32768)<<1) + g;
                                    			b = ((bg - 32768)<<1) + g;

                                    		//	dither = (rand() & 65535)<<1;


                                    			if(matrix_non_unity)
                                    			{
                                    				//TODO : need on convert to linear first.

                                    				r1= (( r_rmult * r + r_gmult * g + r_bmult * b + r_offset)>>8);
                                    				g1= (( g_rmult * r + g_gmult * g + g_bmult * b + g_offset)>>8);
                                    				b1= (( b_rmult * r + b_gmult * g + b_bmult * b + b_offset)>>8);

                                    				//TODO : need on convert back to log/display curve.

                                    				if(r1 < 0) r1 = 0;
                                    				if(r1 > 65535) r1 = 65535;
                                    				if(g1 < 0) g1 = 0;
                                    				if(g1 > 65535) g1 = 65535;
                                    				if(b1 < 0) b1 = 0;
                                    				if(b1 > 65535) b1 = 65535;
                                    			}
                                    			else
                                    			{
                                    				r1 = r;
                                    				g1 = g;
                                    				b1 = b;
                                    			}

                                    			y1= ( y_rmult * r1 + y_gmult * g1 + y_bmult * b1 + 32768)>>16;
                                    			u = (-u_rmult * r1 - u_gmult * g1 + u_bmult * b1 + 32768)>>16;
                                    			v = ( v_rmult * r1 - v_gmult * g1 - v_bmult * b1 + 32768)>>16;


                                    			g = (*G++);
                                    			rg = (*RG++);
                                    			bg = (*BG++);

                                    			r = ((rg - 32768)<<1) + g;
                                    			b = ((bg - 32768)<<1) + g;

                                    		//	dither = (rand() & 65535)<<1;

                                    			if(matrix_non_unity)
                                    			{
                                    				//TODO : need on convert to linear first.

                                    				r1= (( r_rmult * r + r_gmult * g + r_bmult * b + r_offset)>>8);
                                    				g1= (( g_rmult * r + g_gmult * g + g_bmult * b + g_offset)>>8);
                                    				b1= (( b_rmult * r + b_gmult * g + b_bmult * b + b_offset)>>8);

                                    				//TODO : need on convert back to log/display curve.

                                    				if(r1 < 0) r1 = 0;
                                    				if(r1 > 65535) r1 = 65535;
                                    				if(g1 < 0) g1 = 0;
                                    				if(g1 > 65535) g1 = 65535;
                                    				if(b1 < 0) b1 = 0;
                                    				if(b1 > 65535) b1 = 65535;
                                    			}
                                    			else
                                    			{
                                    				r1 = r;
                                    				g1 = g;
                                    				b1 = b;
                                    			}

                                    			y2 = ( y_rmult * r1 + y_gmult * g1 + y_bmult * b1 + 32768)>>16;
                                    			u += (-u_rmult * r1 - u_gmult * g1 + u_bmult * b1 + 32768)>>16;
                                    			v += ( v_rmult * r1 - v_gmult * g1 - v_bmult * b1 + 32768)>>16;

                                    			u >>= 1;
                                    			v >>= 1;

                                    			y1 += y_offset;
                                    			y2 += y_offset;
                                    			u += u_offset;
                                    			v += v_offset;

                                    			if(y1 < 0) y1 = 0;
                                    			if(y1 > 255) y1 = 255;
                                    			if(y2 < 0) y2 = 0;
                                    			if(y2 > 255) y2 = 255;
                                    			if(u < 0) u = 0;
                                    			if(u > 255) u = 255;
                                    			if(v < 0) v = 0;
                                    			if(v > 255) v = 255;


                                    			*outyuv++ = y1;
                                    			*outyuv++ = u;
                                    			*outyuv++ = y2;
                                    			*outyuv++ = v;
                                    		}
                                    		line += pitch;
                                    		bayer_line += bayer_pitch;
                                    	}
                                    }
                                    else if (format == DECODED_FORMAT_YU64)
                                    {
                                    	int shift = 14;
                                    	PIXEL16U *outyuv64;
                                    	line = output;
                                    	bayer_line = decoder->RawBayer16;


                                    	scale = 16384.0;
                                    	//_mm_empty();	// Clear the mmx register state


                                    	y_rmult = ((rgb2yuv[0][0]) * scale);
                                    	y_gmult = ((rgb2yuv[0][1]) * scale);
                                    	y_bmult = ((rgb2yuv[0][2]) * scale);
                                    	y_offset= ((rgb2yuv[0][3]) * scale * 4.0);

                                    	u_rmult = ((rgb2yuv[1][0]) * scale);
                                    	u_gmult = ((rgb2yuv[1][1]) * scale);
                                    	u_bmult = ((rgb2yuv[1][2]) * scale);
                                    	u_offset= ((rgb2yuv[1][3]) * scale * 4.0);

                                    	v_rmult = ((rgb2yuv[2][0]) * scale);
                                    	v_gmult = ((rgb2yuv[2][1]) * scale);
                                    	v_bmult = ((rgb2yuv[2][2]) * scale);
                                    	v_offset= ((rgb2yuv[2][3]) * scale * 4.0);


                                    	scale = 4096.0;
                                    	r_rmult= (mtrx[0][0] * scale * whitebalance[0]);
                                    	r_gmult= (mtrx[0][1] * scale * whitebalance[1]);
                                    	r_bmult= (mtrx[0][2] * scale * whitebalance[2]);
                                    	r_offset= (mtrx[0][3] * scale);

                                    	g_rmult= (mtrx[1][0] * scale * whitebalance[0]);
                                    	g_gmult= (mtrx[1][1] * scale * whitebalance[1]);
                                    	g_bmult= (mtrx[1][2] * scale * whitebalance[2]);
                                    	g_offset= (mtrx[1][3] * scale);

                                    	b_rmult= (mtrx[2][0] * scale * whitebalance[0]);
                                    	b_gmult= (mtrx[2][1] * scale * whitebalance[1]);
                                    	b_bmult= (mtrx[2][2] * scale * whitebalance[2]);
                                    	b_offset= (mtrx[2][3] * scale);



                                    	y_offset += 26;
                                    	u_offset += 26;
                                    	v_offset += 26;


                                    	for(y=0; y<info->height; y++)
                                    	{
                                    		outyuv64 = (PIXEL16U *)line;
                                    		bayerptr = bayer_line;
                                    		G = bayerptr;
                                    		RG = G + bayer_pitch/4;
                                    		BG = RG + bayer_pitch/4;
                                    		for(x=0; x<info->width; x+=2)
                                    		{
                                    			int r,g,b,r1,g1,b1,rg,bg,y1,y2,u,v,dither;


                                    			g = (*G++);
                                    			rg = (*RG++);
                                    			bg = (*BG++);

                                    			r = ((rg - 32768)<<1) + g;
                                    			b = ((bg - 32768)<<1) + g;

                                    		//	dither = (rand() & 65535)<<1;

                                    			if(matrix_non_unity)
                                    			{
                                    				//TODO : need on convert to linear first.

                                    				r1= (( r_rmult * r + r_gmult * g + r_bmult * b + r_offset)>>12);
                                    				g1= (( g_rmult * r + g_gmult * g + g_bmult * b + g_offset)>>12);
                                    				b1= (( b_rmult * r + b_gmult * g + b_bmult * b + b_offset)>>12);

                                    				//TODO : need on convert back to log/display curve.

                                    				if(r1 < 0) r1 = 0;
                                    				if(r1 > 65535) r1 = 65535;
                                    				if(g1 < 0) g1 = 0;
                                    				if(g1 > 65535) g1 = 65535;
                                    				if(b1 < 0) b1 = 0;
                                    				if(b1 > 65535) b1 = 65535;
                                    			}
                                    			else
                                    			{
                                    				r1 = r;
                                    				g1 = g;
                                    				b1 = b;
                                    			}

                                    			y1= (( y_rmult * r1 + y_gmult * g1 + y_bmult * b1)>>shift) + y_offset;
                                    			u = (( u_rmult * r1 + u_gmult * g1 + u_bmult * b1)>>shift);
                                    			v = (( v_rmult * r1 + v_gmult * g1 + v_bmult * b1)>>shift);

                                    			g = (*G++);
                                    			rg = (*RG++);
                                    			bg = (*BG++);

                                    			r = ((rg - 32768)<<1) + g;
                                    			b = ((bg - 32768)<<1) + g;

                                    		//	dither = (rand() & 65535)<<1;

                                    			if(matrix_non_unity)
                                    			{
                                    				//TODO : need on convert to linear first.

                                    				r1= (( r_rmult * r + r_gmult * g + r_bmult * b + r_offset)>>12);
                                    				g1= (( g_rmult * r + g_gmult * g + g_bmult * b + g_offset)>>12);
                                    				b1= (( b_rmult * r + b_gmult * g + b_bmult * b + b_offset)>>12);

                                    				//TODO : need on convert back to log/display curve.

                                    				if(r1 < 0) r1 = 0;
                                    				if(r1 > 65535) r1 = 65535;
                                    				if(g1 < 0) g1 = 0;
                                    				if(g1 > 65535) g1 = 65535;
                                    				if(b1 < 0) b1 = 0;
                                    				if(b1 > 65535) b1 = 65535;
                                    			}
                                    			else
                                    			{
                                    				r1 = r;
                                    				g1 = g;
                                    				b1 = b;
                                    			}

                                    			y2= (( y_rmult * r1 + y_gmult * g1 + y_bmult * b1)>>shift) + y_offset;
                                    			u+= (( u_rmult * r1 + u_gmult * g1 + u_bmult * b1)>>shift);
                                    			v+= (( v_rmult * r1 + v_gmult * g1 + v_bmult * b1)>>shift);

                                    			u >>= 1;
                                    			v >>= 1;

                                    			u += u_offset;
                                    			v += v_offset;

                                    			if(y1 < 0) y1 = 0;
                                    			if(y1 > 65535) y1 = 65535;
                                    			if(y2 < 0) y2 = 0;
                                    			if(y2 > 65535) y2 = 65535;
                                    			if(u < 0) u = 0;
                                    			if(u > 65535) u = 65535;
                                    			if(v < 0) v = 0;
                                    			if(v > 65535) v = 65535;


                                    			*outyuv64++ = y1;
                                    			*outyuv64++ = v;
                                    			*outyuv64++ = y2;
                                    			*outyuv64++ = u;
                                    		}
                                    		line += pitch;
                                    		bayer_line += bayer_pitch;
                                    	}
                                    }
                                    else //RGBs
                                    {
                                    	line = output;
                                    	bayer_line = decoder->RawBayer16;

                                    	scale = 256.0;

                                    	r_rmult = (mtrx[0][0]) * scale * whitebalance[0];
                                    	r_gmult = (mtrx[0][1]) * scale * whitebalance[1];
                                    	r_bmult = (mtrx[0][2]) * scale * whitebalance[2];
                                    	r_offset= (mtrx[0][3]) * scale;

                                    	g_rmult = (mtrx[1][0]) * scale * whitebalance[0];
                                    	g_gmult = (mtrx[1][1]) * scale * whitebalance[1];
                                    	g_bmult = (mtrx[1][2]) * scale * whitebalance[2];
                                    	g_offset= (mtrx[1][3]) * scale;

                                    	b_rmult = (mtrx[2][0]) * scale * whitebalance[0];
                                    	b_gmult = (mtrx[2][1]) * scale * whitebalance[1];
                                    	b_bmult = (mtrx[2][2]) * scale * whitebalance[2];
                                    	b_offset= (mtrx[2][3]) * scale;


                                    	for(y=0; y<info->height; y++)
                                    	{
                                    		int i,noisearray[32];
                                    		outyuv = line;
                                    		bayerptr = bayer_line;
                                    		G = bayerptr;
                                    		RG = G + bayer_pitch/4;
                                    		BG = RG + bayer_pitch/4;
                                    		GD = RG + bayer_pitch/4;

                                    		for(i=0; i<32; i++)
                                    		{
                                    			noisearray[i] = (rand() & 127);
                                    		}

                                    		if(info->format == DECODED_FORMAT_RGB32)
                                    		{
                                    			for(x=0; x<info->width; x++)
                                    			{
                                    				int R1,G1,B1;
                                    				int rnd = noisearray[x&31];
                                    			//	*ptr++ = *bayerptr++ >> 8;
                                    			//	*ptr++ = 0x80;
                                    			//	*ptr++ = *bayerptr++ >> 8;
                                    			//	*ptr++ = 0x80;

                                    				int r,g,b,g1,g2,gdiff,y1,y2,u,v;

                                    			//	g = (g1+g2)>>1;
                                    			//	*g_row_ptr++ = g;
                                    			//	*rg_row_ptr++ = (r-g+256)>>1;
                                    			//	*bg_row_ptr++ = (b-g+256)>>1;
                                    			//	*gdiff_row_ptr++ = (g1-g2+256)>>1;

                                    				g = ((*G++)>>1);
                                    				r = ((*RG++ + 64)>>0)-(256<<7)+g;
                                    				b = ((*BG++ + 64)>>0)-(256<<7)+g;
                                    			//	gdiff = ((*GD++ + 64)>>7)-256+g;

                                    				if(matrix_non_unity)
                                    				{
                                    					//TODO : need on convert to linear first.

                                    					R1 = ((r*r_rmult + g*r_gmult + b*r_bmult + r_offset)>>8) + rnd;
                                    					G1 = ((r*g_rmult + g*g_gmult + b*g_bmult + g_offset)>>8) + rnd;
                                    					B1 = ((r*b_rmult + g*b_gmult + b*b_bmult + b_offset)>>8) + rnd;

                                    					//TODO : need on convert back to log/display curve.
                                    				}
                                    				else
                                    				{
                                    					R1 = r + rnd;
                                    					G1 = g + rnd;
                                    					B1 = b + rnd;
                                    				}

                                    				R1 >>= 7;
                                    				G1 >>= 7;
                                    				B1 >>= 7;

                                    				if(R1 < 0) R1 = 0;
                                    				if(R1 > 255) R1 = 255;
                                    				if(G1 < 0) G1 = 0;
                                    				if(G1 > 255) G1 = 255;
                                    				if(B1 < 0) B1 = 0;
                                    				if(B1 > 255) B1 = 255;


                                    				*outyuv++ = B1;
                                    				*outyuv++ = G1;
                                    				*outyuv++ = R1;
                                    				*outyuv++ = 255;
                                    			}
                                    		}
                                    		else
                                    		{
                                    			for(x=0; x<info->width; x++)
                                    			{
                                    				int R1,G1,B1;
                                    				int rnd = noisearray[x&31];
                                    			//	*ptr++ = *bayerptr++ >> 8;
                                    			//	*ptr++ = 0x80;
                                    			//	*ptr++ = *bayerptr++ >> 8;
                                    			//	*ptr++ = 0x80;

                                    				int r,g,b,g1,g2,gdiff,y1,y2,u,v;
                                    				//g = (g1+g2)>>1;
                                    			//	*g_row_ptr++ = g;
                                    			//	*rg_row_ptr++ = (r-g+256)>>1;
                                    			//	*bg_row_ptr++ = (b-g+256)>>1;
                                    			//	*gdiff_row_ptr++ = (g1-g2+256)>>1;

                                    				g = ((*G++)>>1);
                                    				r = ((*RG++ + 64)>>0)-(256<<7)+g;
                                    				b = ((*BG++ + 64)>>0)-(256<<7)+g;
                                    			//	gdiff = ((*GD++ + 64)>>7)-256+g;

                                    				if(matrix_non_unity)
                                    				{
                                    					//TODO: Need to convert to linear first.

                                    					R1 = ((r*r_rmult + g*r_gmult + b*r_bmult + r_offset)>>8) + rnd;
                                    					G1 = ((r*g_rmult + g*g_gmult + b*g_bmult + g_offset)>>8) + rnd;
                                    					B1 = ((r*b_rmult + g*b_gmult + b*b_bmult + b_offset)>>8) + rnd;

                                    					//TODO: Need to convert back to log/display curve.
                                    				}
                                    				else
                                    				{
                                    					R1 = r + rnd;
                                    					G1 = g + rnd;
                                    					B1 = b + rnd;
                                    				}

                                    				R1 >>= 7;
                                    				G1 >>= 7;
                                    				B1 >>= 7;

                                    				if(R1 < 0) R1 = 0;
                                    				if(R1 > 255) R1 = 255;
                                    				if(G1 < 0) G1 = 0;
                                    				if(G1 > 255) G1 = 255;
                                    				if(B1 < 0) B1 = 0;
                                    				if(B1 > 255) B1 = 255;


                                    				*outyuv++ = B1;
                                    				*outyuv++ = G1;
                                    				*outyuv++ = R1;
                                    			}
                                    		}

                                    		line += pitch;
                                    		bayer_line += bayer_pitch;
                                    	}
                                    }
                                    */
                                    //MEMORY_ALIGNED_FREE(RawBayer16);
                                }
                            }
                            else if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                                     (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                            {
                                int precision = codec->precision;
                                if (decoder->RawBayer16 == NULL)
                                {
#if _ALLOCATOR
                                    ALLOCATOR *allocator = decoder->allocator;
                                    size_t size = info->width * info->height * num_channels * sizeof(PIXEL);

                                    decoder->RawBayer16 =
                                        (PIXEL16U *)AllocAligned(allocator, size, 16);
#else
                                    decoder->RawBayer16 =
                                        (PIXEL16U *)MEMORY_ALIGNED_ALLOC(info->width * info->height * num_channels * sizeof(PIXEL), 16);
#endif
                                    decoder->RawBayerSize = info->width * info->height * num_channels * sizeof(PIXEL);
                                }

                                //#ifdef SHARPENING
                                if (decoder->RGBFilterBuffer16 == NULL)
                                {
                                    int frame_size = info->width * decoded_height * 4 * 3 * sizeof(PIXEL);
                                    if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                                        frame_size = info->width * decoded_height * 4 * 4 * sizeof(PIXEL);
#if _ALLOCATOR
                                    {
                                        ALLOCATOR *allocator = decoder->allocator;
                                        decoder->RGBFilterBuffer16 =
                                            (PIXEL16U *)AllocAligned(allocator, frame_size, 16);
                                    }
#else
                                    decoder->RGBFilterBuffer16 =
                                        (PIXEL16U *)MEMORY_ALIGNED_ALLOC(frame_size, 16);
#endif
                                    decoder->RGBFilterBufferSize = frame_size;
                                }
                                //#endif

                                if (decoder->RawBayer16 == NULL || decoder->RGBFilterBuffer16 == NULL)
                                {
                                    decoder->error = CODEC_ERROR_MEMORY_ALLOC;
                                    return;
                                }


                                //TODO: Replace this memory allocation with a scratch buffer allocation

                                if (decoder->RawBayer16)
                                {
                                    uint8_t *outyuv, *line, *source_line;
                                    PIXEL16U *bayerptr;
                                    PIXEL16U *G, *RG, *BG;
                                    int x, y;
                                    int src_pitch = info->width * num_channels * sizeof(PIXEL);

                                    int y_rmult, y_gmult, y_bmult, y_offset; //shift=8;
                                    int u_rmult, u_gmult, u_bmult, u_offset;
                                    int v_rmult, v_gmult, v_bmult, v_offset;

                                    float scale = 256.0;

                                    //int matrix_non_unity = 0;
                                    //int wb_non_unity = 0;
                                    //float curve2lin[2048];
                                    //float lin2curve[2048+512+2];

                                    static float rgb2yuv[3][4] =
                                    {
                                        {0.183f, 0.614f, 0.062f, 16.0f / 256.0f},
                                        {-0.101f, -0.338f, 0.439f, 0.5f},
                                        {0.439f, -0.399f, -0.040f, 0.5}
                                    };

#if _THREADED
                                    TransformInverseSpatialUniversalThreadedToRow16u(decoder, frame, num_channels,
                                            (uint8_t *)decoder->RawBayer16, src_pitch,
                                            info, chroma_offset, precision);
#else
                                    TransformInverseSpatialToRow16u(transform_array, frame, num_channels,
                                                                    decoder->RawBayer16, src_pitch, info,
                                                                    &decoder->scratch, chroma_offset, precision);
#endif


                                    if (format == DECODED_FORMAT_YUYV)
                                    {
                                        line = output;
                                        source_line = (unsigned char *)decoder->RawBayer16;


                                        scale = 256.0;

                                        y_rmult = (int)((rgb2yuv[0][0]));
                                        y_gmult = (int)((rgb2yuv[0][1]));
                                        y_bmult = (int)((rgb2yuv[0][2]));
                                        y_offset = (int)((rgb2yuv[0][3]));

                                        u_rmult = (int)((rgb2yuv[1][0]));
                                        u_gmult = (int)((rgb2yuv[1][1]));
                                        u_bmult = (int)((rgb2yuv[1][2]));
                                        u_offset = (int)((rgb2yuv[1][3]));

                                        v_rmult = (int)((rgb2yuv[2][0]));
                                        v_gmult = (int)((rgb2yuv[2][1]));
                                        v_bmult = (int)((rgb2yuv[2][2]));
                                        v_offset = (int)((rgb2yuv[2][3]));


                                        for (y = 0; y < info->height; y++)
                                        {
                                            outyuv = line;
                                            bayerptr = (PIXEL16U *)source_line;
                                            G = bayerptr;
                                            RG = G + src_pitch / (2 * num_channels);
                                            BG = RG + src_pitch / (2 * num_channels);
                                            for (x = 0; x < info->width; x += 2)
                                            {
                                                int r, g, b, r1, g1, b1, rg, bg, y1, y2, u, v;

                                                g = (*G++);
                                                rg = (*RG++);
                                                bg = (*BG++);

                                                r = ((rg - 32768) << 1) + g;
                                                b = ((bg - 32768) << 1) + g;

                                                r1 = r;
                                                g1 = g;
                                                b1 = b;

                                                y1 = ( y_rmult * r1 + y_gmult * g1 + y_bmult * b1 + 32768) >> 16;
                                                u = (-u_rmult * r1 - u_gmult * g1 + u_bmult * b1 + 32768) >> 16;
                                                v = ( v_rmult * r1 - v_gmult * g1 - v_bmult * b1 + 32768) >> 16;

                                                g = (*G++);
                                                rg = (*RG++);
                                                bg = (*BG++);

                                                r = ((rg - 32768) << 1) + g;
                                                b = ((bg - 32768) << 1) + g;

                                                r1 = r;
                                                g1 = g;
                                                b1 = b;

                                                y2 = ( y_rmult * r1 + y_gmult * g1 + y_bmult * b1 + 32768) >> 16;
                                                u += (-u_rmult * r1 - u_gmult * g1 + u_bmult * b1 + 32768) >> 16;
                                                v += ( v_rmult * r1 - v_gmult * g1 - v_bmult * b1 + 32768) >> 16;

                                                u >>= 1;
                                                v >>= 1;

                                                y1 += y_offset;
                                                y2 += y_offset;
                                                u += u_offset;
                                                v += v_offset;

                                                if (y1 < 0) y1 = 0;
                                                if (y1 > 255) y1 = 255;
                                                if (y2 < 0) y2 = 0;
                                                if (y2 > 255) y2 = 255;
                                                if (u < 0) u = 0;
                                                if (u > 255) u = 255;
                                                if (v < 0) v = 0;
                                                if (v > 255) v = 255;

                                                *outyuv++ = y1;
                                                *outyuv++ = u;
                                                *outyuv++ = y2;
                                                *outyuv++ = v;
                                            }
                                            line += pitch;
                                            source_line += src_pitch;
                                        }
                                    }
                                    else if (format == DECODED_FORMAT_YU64)
                                    {
                                        int shift = 14;
                                        PIXEL16U *outyuv64;
                                        line = output;
                                        source_line = (unsigned char *)decoder->RawBayer16;

                                        scale = 16384.0;

                                        y_rmult = (int)((rgb2yuv[0][0]) * scale);
                                        y_gmult = (int)((rgb2yuv[0][1]) * scale);
                                        y_bmult = (int)((rgb2yuv[0][2]) * scale);
                                        y_offset = (int)((rgb2yuv[0][3]) * scale * 4.0f);

                                        u_rmult = (int)((rgb2yuv[1][0]) * scale);
                                        u_gmult = (int)((rgb2yuv[1][1]) * scale);
                                        u_bmult = (int)((rgb2yuv[1][2]) * scale);
                                        u_offset = (int)((rgb2yuv[1][3]) * scale * 4.0f);

                                        v_rmult = (int)((rgb2yuv[2][0]) * scale);
                                        v_gmult = (int)((rgb2yuv[2][1]) * scale);
                                        v_bmult = (int)((rgb2yuv[2][2]) * scale);
                                        v_offset = (int)((rgb2yuv[2][3]) * scale * 4.0f);


                                        scale = 4096.0;

                                        y_offset += 26;
                                        u_offset += 26;
                                        v_offset += 26;


                                        for (y = 0; y < info->height; y++)
                                        {
                                            outyuv64 = (PIXEL16U *)line;
                                            bayerptr = (PIXEL16U *)source_line;
                                            G = bayerptr;
                                            RG = G + src_pitch / (2 * num_channels);
                                            BG = RG + src_pitch / (2 * num_channels);
                                            for (x = 0; x < info->width; x += 2)
                                            {
                                                int r, g, b, r1, g1, b1, rg, bg, y1, y2, u, v;


                                                g = (*G++);
                                                rg = (*RG++);
                                                bg = (*BG++);

                                                r = ((rg - 32768) << 1) + g;
                                                b = ((bg - 32768) << 1) + g;

                                                r1 = r;
                                                g1 = g;
                                                b1 = b;

                                                y1 = (( y_rmult * r1 + y_gmult * g1 + y_bmult * b1) >> shift) + y_offset;
                                                u = (( u_rmult * r1 + u_gmult * g1 + u_bmult * b1) >> shift);
                                                v = (( v_rmult * r1 + v_gmult * g1 + v_bmult * b1) >> shift);

                                                g = (*G++);
                                                rg = (*RG++);
                                                bg = (*BG++);

                                                r = ((rg - 32768) << 1) + g;
                                                b = ((bg - 32768) << 1) + g;

                                                r1 = r;
                                                g1 = g;
                                                b1 = b;

                                                y2 = (( y_rmult * r1 + y_gmult * g1 + y_bmult * b1) >> shift) + y_offset;
                                                u += (( u_rmult * r1 + u_gmult * g1 + u_bmult * b1) >> shift);
                                                v += (( v_rmult * r1 + v_gmult * g1 + v_bmult * b1) >> shift);

                                                u >>= 1;
                                                v >>= 1;

                                                u += u_offset;
                                                v += v_offset;

                                                if (y1 < 0) y1 = 0;
                                                if (y1 > 65535) y1 = 65535;
                                                if (y2 < 0) y2 = 0;
                                                if (y2 > 65535) y2 = 65535;
                                                if (u < 0) u = 0;
                                                if (u > 65535) u = 65535;
                                                if (v < 0) v = 0;
                                                if (v > 65535) v = 65535;


                                                *outyuv64++ = y1;
                                                *outyuv64++ = v;
                                                *outyuv64++ = y2;
                                                *outyuv64++ = u;
                                            }
                                            line += pitch;
                                            source_line += src_pitch;
                                        }
                                    }
                                    else //RGBs
                                    {
                                        line = output;
                                        source_line = (unsigned char *)decoder->RawBayer16;

                                        for (y = 0; y < info->height; y++)
                                        {
                                            int i, noisearray[32];
                                            unsigned short *rgb16 = (unsigned short *)line;
                                            outyuv = line;
                                            bayerptr = (PIXEL16U *)source_line;
                                            G = bayerptr;
                                            RG = G + src_pitch / (2 * num_channels);
                                            BG = RG + src_pitch / (2 * num_channels);

                                            for (i = 0; i < 32; i++)
                                            {
                                                noisearray[i] = (rand() & 255);
                                            }

                                            if (info->format == DECODED_FORMAT_RGB32)
                                            {
                                                for (x = 0; x < info->width; x++)
                                                {
                                                    int R1, G1, B1;
                                                    int rnd = noisearray[x & 31];

#if 0
                                                    G1 = (*G++) + rnd;
                                                    R1 = ((*RG++ << 1) - (128 << 9)) + G1;
                                                    B1 = ((*BG++ << 1) - (128 << 9)) + G1;
#else
                                                    G1 = (*G++) + rnd;
                                                    R1 = (*RG++) + rnd;
                                                    B1 = (*BG++) + rnd;
#endif

                                                    R1 >>= 8;
                                                    G1 >>= 8;
                                                    B1 >>= 8;

                                                    if (R1 < 0) R1 = 0;
                                                    if (R1 > 255) R1 = 255;
                                                    if (G1 < 0) G1 = 0;
                                                    if (G1 > 255) G1 = 255;
                                                    if (B1 < 0) B1 = 0;
                                                    if (B1 > 255) B1 = 255;

                                                    *outyuv++ = B1;
                                                    *outyuv++ = G1;
                                                    *outyuv++ = R1;
                                                    *outyuv++ = 255;
                                                }
                                            }
                                            else if (info->format == DECODED_FORMAT_RGB24)
                                            {
                                                for (x = 0; x < info->width; x++)
                                                {
                                                    int R1, G1, B1;
                                                    int rnd = noisearray[x & 31];

#if 0
                                                    G1 = (*G++) + rnd;
                                                    R1 = ((*RG++ << 1) - (128 << 9)) + G1;
                                                    B1 = ((*BG++ << 1) - (128 << 9)) + G1;
#else
                                                    G1 = (*G++) + rnd;
                                                    R1 = (*RG++) + rnd;
                                                    B1 = (*BG++) + rnd;
#endif

                                                    R1 >>= 8;
                                                    G1 >>= 8;
                                                    B1 >>= 8;

                                                    if (R1 < 0) R1 = 0;
                                                    if (R1 > 255) R1 = 255;
                                                    if (G1 < 0) G1 = 0;
                                                    if (G1 > 255) G1 = 255;
                                                    if (B1 < 0) B1 = 0;
                                                    if (B1 > 255) B1 = 255;

                                                    *outyuv++ = B1;
                                                    *outyuv++ = G1;
                                                    *outyuv++ = R1;
                                                }
                                            }
                                            else if (info->format == DECODED_FORMAT_RG48)
                                            {
                                                for (x = 0; x < info->width; x++)
                                                {
                                                    int R1, G1, B1;

                                                    G1 = (*G++);
                                                    R1 = (*RG++);
                                                    B1 = (*BG++);

                                                    *rgb16++ = R1;
                                                    *rgb16++ = G1;
                                                    *rgb16++ = B1;
                                                }
                                            }

                                            line += pitch;
                                            source_line += src_pitch;
                                        }
                                    }

                                    //MEMORY_ALIGNED_FREE(RawBayer16);
                                }
                            }
                            else // Output the frame in one of the RGB 8-bit formats
                            {
                                //char *buffer = decoder->buffer;
                                //size_t buffer_size = decoder->buffer_size;

                                // Invert the bottom wavelet and convert the output to the requested color format
#if _THREADED
                                TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                        output, pitch,
                                        info, chroma_offset, precision,
                                        InvertHorizontalStrip16sYUVtoRGB);
#else
                                TransformInverseSpatialToBuffer(decoder, transform_array, frame, num_channels, output, pitch,
                                                                &info2, &decoder->scratch, chroma_offset, precision);
#endif
                            }
                    }
            }

#if TIMING
            // Count the number of progressive frames that were decoded
            progressive_decode_count++;
#endif
        }

    STOP(tk_inverse);

#ifdef ADOBE_MEMORY_FUNCTIONS
    if ((decoder->RawBayer16 && decoder->RawBayerSize > 2048 * 1152 * 2) ||
            (decoder->RGBFilterBuffer16 && decoder->RGBFilterBufferSize > 2048 * 1152 * 2))
    {
#if _ALLOCATOR
        if (decoder->RawBayer16)
        {
            FreeAligned(decoder->allocator, decoder->RawBayer16);
            decoder->RawBayer16 = NULL;
            decoder->RawBayerSize = NULL;
        }
        if (decoder->RGBFilterBuffer16)
        {
            FreeAligned(decoder->allocator, decoder->RGBFilterBuffer16);
            decoder->RGBFilterBuffer16 = NULL;
            decoder->RGBFilterBufferSize = NULL;
        }
#else
        if (decoder->RawBayer16)
        {
            MEMORY_ALIGNED_FREE(decoder->RawBayer16);
            decoder->RawBayer16 = NULL;
            decoder->RawBayerSize = NULL;
        }
        if (decoder->RGBFilterBuffer16)
        {
            MEMORY_ALIGNED_FREE(decoder->RGBFilterBuffer16);
            decoder->RGBFilterBuffer16 = NULL;
            decoder->RGBFilterBufferSize = NULL;
        }
#endif
    }
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        //uint8_t *subimage = output;
        uint8_t *subimage = output + (2 * info->width) - 16;
        DumpArray8u("YUV Image", subimage, 16, 16, pitch, logfile);
    }
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Exit ReconstructFrameToBuffer\n");
    }
#endif

#if (0 && DEBUG && _WIN32)
    _CrtCheckMemory();
#endif

}



#if 0

// Reconstruct the frame to quarter resolution at full frame rate
void ReconstructQuarterFrame(DECODER *decoder, int num_channels,
                             uint8_t *frame1, uint8_t *frame2, int output_pitch,
                             FRAME_INFO *info, char *buffer, size_t buffer_size)
{

    TRANSFORM **transform_array = decoder->transform;
    int output_width = info->width;
    int output_height = info->height;
    PIXEL *low_row_ptr[CODEC_MAX_CHANNELS];
    PIXEL *high_row_ptr[CODEC_MAX_CHANNELS];
    PIXEL *out1_row_ptr[CODEC_MAX_CHANNELS];
    PIXEL *out2_row_ptr[CODEC_MAX_CHANNELS];
    PIXEL *bufptr = (PIXEL *)buffer;
    uint8_t *output_row_ptr = output;
    int low_pitch[CODEC_MAX_CHANNELS];
    int high_pitch[CODEC_MAX_CHANNELS];
    int channel;
    int row;

    // Check that there is enough space for the intermediate results from each channel
    assert(output_width * sizeof(PIXEL) < buffer_size);

    // Get pointers into the wavelets for each channel
    for (channel = 0; channel < num_channels; channel++)
    {
        // Get the lowpass bands from the two wavelets for the two halves of the temporal wavelet
        IMAGE *low_wavelet = transform_array[channel]->wavelet[3];
        IMAGE *high_wavelet = transform_array[channel]->wavelet[2];

        // Get the pointers to the first row in each lowpass band
        low_row_ptr[channel] = low_wavelet->band[0];
        high_row_ptr[channel] = high_wavelet->band[0];

        low_pitch[channel] = low_wavelet->pitch / sizeof(PIXEL);
        high_pitch[channel] = high_wavelet->pitch / sizeof(PIXEL);

        // Allocate space for one row of results for this channel
        channel_row_ptr[channel] = bufptr;
        bufptr += low_wavelet->width;
    }

    for (row = 0; row < output_height; row++)
    {
        char *bufptr = buffer;

        for (channel = 0; channel < num_channels; channel++)
        {
            // Invert the temporal transform at quarter resolution
            InvertTemporalQuarterRow16s(low_row_ptr[channel], high_row_ptr[channel], channel_row_ptr[channel]);

            // Advance to the next row in each band for the temporal transform
            low_row_ptr[channel] += low_pitch[channel];
            high_row_ptr[channel] += high_pitch[channel];
        }

        // Pack the intermediate results into the output row
        ConvertUnpacked16sRowToPacked8u(channel_row_ptr, num_channels, output_row_ptr, output_width);

        // Advance the output row pointer
        output_row_ptr += output_pitch;
    }
}

#else

// Reconstruct the frame to quarter resolution at full frame rate
void ReconstructQuarterFrame(DECODER *decoder, int num_channels,
                             int frame_index, uint8_t *output, int output_pitch,
                             FRAME_INFO *info, const SCRATCH *scratch, int precision)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    TRANSFORM **transform_array = decoder->transform;
    int output_width = info->width;
    int output_height = info->height;
    PIXEL *low_row_ptr[CODEC_MAX_CHANNELS];
    PIXEL *high_row_ptr[CODEC_MAX_CHANNELS];
    uint8_t *output_row_ptr = output;
    int low_pitch[CODEC_MAX_CHANNELS];
    int high_pitch[CODEC_MAX_CHANNELS];
    int channel;
    int row;

    // Value used for filling the fourth channel in ARGB output
    int alpha = 255;

    int format = COLORFORMAT(info);
    int color_space = COLORSPACE(info);
    int decoded_format = DECODEDFORMAT(info);
    //bool inverted = false;

    // The pixels are descaled in the inverse temporal transform
    //const int descale = 0;

    // Shift the intermediate results to 16-bit pixels
    const int shift_yu64 = 8;

    // Push the scratch space state to allocate a new section
    char *buffer = scratch->free_ptr;
#if DEBUG
    size_t buffer_size = scratch->free_size;
#endif

    // Initialize a pointer for allocating space in the buffer
    PIXEL *bufptr = (PIXEL *)buffer;

    // Array of pointers to the start of each channel in the intermediate results
    PIXEL *channel_row_ptr[CODEC_MAX_CHANNELS];

    // Check that there is enough space for the intermediate results from each channel
#if DEBUG
    assert(output_width * sizeof(PIXEL) < buffer_size);
#endif
    ComputeCube(decoder);

    // Get pointers into the wavelets for each channel
    for (channel = 0; channel < num_channels; channel++)
    {
        // Get the lowpass bands from the two wavelets for the two halves of the temporal wavelet
        IMAGE *low_wavelet = transform_array[channel]->wavelet[4];
        IMAGE *high_wavelet = transform_array[channel]->wavelet[3];

        // Get the pointers to the first row in each lowpass band
        low_row_ptr[channel] = low_wavelet->band[0];
        high_row_ptr[channel] = high_wavelet->band[0];

        low_pitch[channel] = low_wavelet->pitch / sizeof(PIXEL);
        high_pitch[channel] = high_wavelet->pitch / sizeof(PIXEL);

        // Force the row of intermediate results to be properly aligned
        bufptr = (PIXEL *)ALIGN16(bufptr);

        // Allocate space for one row of results for this channel
        channel_row_ptr[channel] = bufptr;
        bufptr += low_wavelet->width;

        // Check that the row of intermediate results is properly aligned
        assert(ISALIGNED16(channel_row_ptr[channel]));
    }

    // Invert the image if required
    switch (decoded_format)
    {
        case DECODED_FORMAT_RGB24:
        case DECODED_FORMAT_RGB32:
            output_row_ptr += (output_height - 1) * output_pitch;
            output_pitch = NEG(output_pitch);
    }

    //HACK: Seems to work, I don't know why.	//DAN20070304
    if (precision == 12) precision = 8;

    // Apply the inverse temporal transform to the lowpass and highpass rows
    for (row = 0; row < output_height; row++)
    {
        // Most of the color conversion routines use zero descaling
        int descale = 0;
        //char *bufptr = buffer;

        for (channel = 0; channel < num_channels; channel++)
        {
            if (frame_index == 0)
            {
                // Invert the temporal transform at quarter resolution to get the even row
                InvertTemporalQuarterEvenRow16s(low_row_ptr[channel], high_row_ptr[channel],
                                                channel_row_ptr[channel], output_width, precision);
            }
            else
            {
                assert(frame_index == 1);

                // Invert the temporal transform at quarter resolution to get the odd row
                InvertTemporalQuarterOddRow16s(low_row_ptr[channel], high_row_ptr[channel],
                                               channel_row_ptr[channel], output_width, precision);
            }

            // Advance to the next row in each band for the temporal transform
            low_row_ptr[channel] += low_pitch[channel];
            high_row_ptr[channel] += high_pitch[channel];
        }

        if (decoder->use_active_metadata_decoder)
        {
            uint8_t *channeldata[TRANSFORM_MAX_CHANNELS]; // used in quarter res decodes
            int channelpitch[TRANSFORM_MAX_CHANNELS]; // used in quarter res decodes
            int i;

            FRAME_INFO info2;
            memcpy(&info2, info, sizeof(FRAME_INFO));
            info2.height = 1;

            for (i = 0; i < num_channels; i++)
            {
                channeldata[i] = (uint8_t *)channel_row_ptr[i];
                channelpitch[i] = 0;
            }

#if 1
            {
                __m128i *Y = (__m128i *)channeldata[0];
                __m128i *U = (__m128i *)channeldata[1];
                __m128i *V = (__m128i *)channeldata[2];
                __m128i v;
                int x;

                __m128i rgb_limit_epi16 = _mm_set1_epi16(0x7fff - 0x0fff);

                for (x = 0; x < info->width; x += 8)
                {
                    v = _mm_load_si128(Y);
                    v = _mm_adds_epi16(v, rgb_limit_epi16);
                    v = _mm_subs_epu16(v, rgb_limit_epi16);
                    v = _mm_slli_epi16(v, 4);
                    _mm_store_si128(Y++, v);
                }
                for (x = 0; x < info->width / 2; x += 8)
                {
                    v = _mm_load_si128(U);
                    v = _mm_adds_epi16(v, rgb_limit_epi16);
                    v = _mm_subs_epu16(v, rgb_limit_epi16);
                    v = _mm_slli_epi16(v, 4);
                    _mm_store_si128(U++, v);
                }
                for (x = 0; x < info->width / 2; x += 8)
                {
                    v = _mm_load_si128(V);
                    v = _mm_adds_epi16(v, rgb_limit_epi16);
                    v = _mm_subs_epu16(v, rgb_limit_epi16);
                    v = _mm_slli_epi16(v, 4);
                    _mm_store_si128(V++, v);
                }
            }
#else
            //non SSE2
            for (x = 0; x < info->width * 2; x++)
            {
                int val = *gptr++;
                if (val < 0) val = 0;
                if (val > 4095) val = 4095;
                val <<= 4;
                *src++ = val;
            }
            src = scanline2;
#endif

            Row16uQuarter2OutputFormat(decoder, &info2, 0, output_row_ptr, output_pitch,
                                       decoder->gop_frame_num/*0 frame*/, scratch->free_ptr, scratch->free_size, false, channeldata, channelpitch);

        }
        else
        {
            //DAN20081203 -- fix for 444 decodes in AE32-bit float
            decoder->frame.white_point = 16;
            //decoder->frame.signed_pixels = 0;

            // Convert the rows of luma and chroma into the output format
            switch (format)
            {
                case COLOR_FORMAT_YUYV:
                case COLOR_FORMAT_UYVY:
                    // Pack the intermediate results into the output row

                    if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
                    {
                        assert(0);//need quarter res BAYER To YUV decoder
                    }
                    else if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                             (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        //	assert(0);//need quarter res RGB To YUV decoder
                        ConvertRGB2YUV(	channel_row_ptr[1], channel_row_ptr[0], channel_row_ptr[2],
                                        output_width, output_width, output_width,
                                        output_row_ptr, output_pitch,
                                        info->width, 1, 10, info->colorspace, format);

                    }
                    else
                    {
                        ConvertUnpacked16sRowToPacked8u(channel_row_ptr, num_channels, output_row_ptr, output_width, format);
                    }
                    break;

                case COLOR_FORMAT_RGB24:
                    if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        ConvertRGB48toRGB24(	channel_row_ptr[1], channel_row_ptr[0], channel_row_ptr[2],
                                                output_width, output_width, output_width,
                                                output_row_ptr, output_pitch,
                                                info->width, 1, 10, 0);
                    }
                    else
                    {
                        // Convert the intermediate results into a row of RGB24
                        ConvertUnpacked16sRowToRGB24(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                     descale, format, color_space);
                    }
                    break;

                case COLOR_FORMAT_RGB32:
                    if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        ConvertRGBA48toRGB32(channel_row_ptr[1], channel_row_ptr[0], channel_row_ptr[2], NULL,
                                             output_width,
                                             output_row_ptr, output_pitch,
                                             info->width, 1, 10, 0, 3/*only 3 chhanel not 4 for alpha*/);
                    }
                    else
                    {
                        // Convert the intermediate results into a row of RGBA32
                        ConvertUnpacked16sRowToRGB32(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                     descale, format, color_space, alpha);
                    }
                    break;

                case COLOR_FORMAT_YU64:
                case COLOR_FORMAT_V210:
                    // Convert the intermediate results into a row of YU64
                    ConvertUnpacked16sRowToYU64(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                shift_yu64, precision, format);
                    break;

                case COLOR_FORMAT_B64A:
                    if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        // Convert the intermediate results into a row of RGBA with 16 bits per component
                        descale = 2;
                        ConvertUnpacked16sRowToB64A(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                    descale, precision);
                    }
                    else
                    {
                        ConvertUnpackedYUV16sRowToRGB48(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                        descale, precision, COLOR_FORMAT_B64A, color_space);
                    }
                    break;
                case COLOR_FORMAT_R210:
                case COLOR_FORMAT_DPX0:
                case COLOR_FORMAT_RG30:
                case COLOR_FORMAT_AR10:
                case COLOR_FORMAT_AB10:
                    if ((decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        // Convert the intermediate results into a row of RGBA with 16 bits per component
                        descale = 2;
                        ConvertUnpacked16sRowToRGB30(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                     descale, precision, format, color_space);
                    }
                    else
                    {
                        ConvertUnpackedYUV16sRowToRGB48(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                        descale, precision, format, color_space);
                    }
                    break;

                case COLOR_FORMAT_RG48:
                    // Convert the intermediate results into a row of RGBA with 16 bits per component
                    descale = 2;
                    ConvertUnpacked16sRowToRGB48(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                 descale, precision);
                    break;

                case COLOR_FORMAT_RG64:
                    // Convert the intermediate results into a row of RGBA with 16 bits per component
                    descale = 2;
                    ConvertUnpacked16sRowToRGBA64(channel_row_ptr, num_channels, output_row_ptr, output_width,
                                                  descale, precision);
                    break;

                default:
#if (1 && DEBUG)
                    if (logfile)
                    {
                        fprintf(logfile, "ReconstructQuarterFrame bad color format: %d\n", format);
                    }
#endif
                    assert(0);
                    break;
            }
        }

        // Advance the output row pointer
        output_row_ptr += output_pitch;
    }
}

#endif

#if 0
// Copy the quarter resolution lowpass channels from the spatial transform
void CopyQuarterFrameToBuffer(TRANSFORM **transform_array, int num_channels,
                              uint8_t *output, int output_pitch,
                              FRAME_INFO *info, int precision)
{
    int output_width = info->width;
    int output_height = info->height;
    PIXEL *input_row_ptr[CODEC_MAX_CHANNELS];
    uint8_t *output_row_ptr = output;
    int input_pitch[CODEC_MAX_CHANNELS];
    int channel;
    int row;

    // Get pointers into the wavelets for each channel
    for (channel = 0; channel < num_channels; channel++)
    {
        // Get the lowpass bands from the two wavelets for the two halves of the temporal wavelet
        IMAGE *wavelet = transform_array[channel]->wavelet[1];

        // Get the pointers to the first row in each lowpass band
        input_row_ptr[channel] = wavelet->band[0];
        input_pitch[channel] = wavelet->pitch / sizeof(PIXEL);
    }

    for (row = 0; row < output_height; row++)
    {
        // Descale and pack the pixels in each output row
        CopyQuarterRowToBuffer(input_row_ptr, num_channels, output_row_ptr, output_width, precision);

        // Advance the input row pointers
        for (channel = 0; channel < num_channels; channel++)
        {
            input_row_ptr[channel] += input_pitch[channel];
        }

        // Advance the output row pointer
        output_row_ptr += output_pitch;
    }
}
#endif


// Convert the quarter resolution lowpass channels to the specified output format
void ConvertQuarterFrameToBuffer(DECODER *decoder, TRANSFORM **transform_array, int num_channels,
                                 uint8_t *output, int output_pitch,
                                 FRAME_INFO *info, int precision)
{
    int output_width = info->width;
    int output_height = info->height;
    PIXEL *input_row_ptr[CODEC_MAX_CHANNELS];
    uint8_t *output_row_ptr = output;
    int input_pitch[CODEC_MAX_CHANNELS];
    int channel;
    int row;

    // Value used for filling the fourth channel in ARGB output
    int alpha = 255;

    int format = COLORFORMAT(info);
    int color_space = COLORSPACE(info);
    int decoded_format = DECODEDFORMAT(info);
    //bool inverted = false;

    // Get pointers into the wavelets for each channel
    for (channel = 0; channel < num_channels; channel++)
    {
        // Get the lowpass bands from the wavelets with quarter resolution
        const int wavelet_index = 1;
        IMAGE *wavelet = transform_array[channel]->wavelet[wavelet_index];

        // The wavelet should have been reconstructed
        assert(wavelet != NULL);

        // The lowpass band should be valid
        assert((wavelet->band_valid_flags & BAND_VALID_MASK(0)) != 0);

        // Get the pointers to the first row in each lowpass band
        input_row_ptr[channel] = wavelet->band[0];
        input_pitch[channel] = wavelet->pitch / sizeof(PIXEL);
    }

    // Invert the image if required
    switch (decoded_format)
    {
        case DECODED_FORMAT_RGB24:
        case DECODED_FORMAT_RGB32:
            output_row_ptr += (output_height - 1) * output_pitch;
            output_pitch = NEG(output_pitch);
    }

    ComputeCube(decoder);

    //HACK DAN20110122 -- some formats will not directly decode so need to use the AM route
    {
        if (	format == COLOR_FORMAT_YU64 ||
                format == COLOR_FORMAT_V210 ||
                format == COLOR_FORMAT_R408 ||
                format == COLOR_FORMAT_V408)
        {
            if (	(decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                    (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
            {
                decoder->use_active_metadata_decoder = true;
                decoder->apply_color_active_metadata = true;
            }
        }
    }



    if (decoder->use_active_metadata_decoder)
    {
#if _THREADED
        {
            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
            if (decoder->worker_thread.pool.thread_count == 0)
            {
                CreateLock(&decoder->worker_thread.lock);
                // Initialize the pool of transform worker threads
                ThreadPoolCreate(&decoder->worker_thread.pool,
                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                 WorkerThreadProc,
                                 decoder);
            }
#endif
            // Post a message to the mailbox
            mailbox->output = output_row_ptr;
            mailbox->pitch = output_pitch;
            mailbox->framenum = 0;
            for (channel = 0; channel < num_channels; channel++)
            {
                mailbox->channeldata[channel] = (uint8_t *)input_row_ptr[channel];
                mailbox->channelpitch[channel] = input_pitch[channel] * sizeof(PIXEL);
            }
            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
            mailbox->jobType = JOB_TYPE_OUTPUT;
            decoder->RGBFilterBufferPhase = 1;


            // Set the work count to the number of rows to process
            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

            // Start the transform worker threads
            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

            // Wait for all of the worker threads to finish
            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

            decoder->RGBFilterBufferPhase = 0;
        }
#endif
    }
    else
    {
        //DAN20081203 -- fix for 444 decodes in AE32-bit float
        decoder->frame.white_point = 16;
        //decoder->frame.signed_pixels = 0;

        // Convert each row to the specified output format
        for (row = 0; row < output_height; row++)
        {
            // Right shift for converting lowpass coefficients to pixels
            int descale = 4;

            switch (format & 0x7fffffff)
            {
                case COLOR_FORMAT_YUYV:
                case COLOR_FORMAT_UYVY:
                    if (	(decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        //	assert(0);//need quarter res RGB To YUV decoder
                        ConvertRGB2YUV(	input_row_ptr[1], input_row_ptr[0], input_row_ptr[2],
                                        output_width, output_width, output_width,
                                        output_row_ptr, output_pitch,
                                        info->width, 1, 14, info->colorspace, format);

                    }
                    else
                    {
                        // Descale and pack the pixels in each output row
                        CopyQuarterRowToBuffer(input_row_ptr, num_channels, output_row_ptr, output_width,
                                               precision, format);
                    }
                    break;

                case COLOR_FORMAT_RGB24:
                    if (	(decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        ConvertRGB48toRGB24(input_row_ptr[1], input_row_ptr[0], input_row_ptr[2],
                                            output_width, output_width, output_width,
                                            output_row_ptr, output_pitch,
                                            info->width, 1, 14, 0);
                    }
                    else
                    {
                        // Convert the intermediate results into a row of RGB24
                        ConvertUnpacked16sRowToRGB24(input_row_ptr, num_channels, output_row_ptr, output_width, descale, format, color_space);
                    }
                    break;

                case COLOR_FORMAT_RGB32:
                case COLOR_FORMAT_RGB32_INVERTED:
                    if (	(decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        ConvertRGBA48toRGB32(	input_row_ptr[1], input_row_ptr[0], input_row_ptr[2],  input_row_ptr[3],
                                                output_width,
                                                output_row_ptr, output_pitch,
                                                info->width, 1, 14, 0, num_channels);
                    }
                    else
                    {
                        // Convert the intermediate results into a row of RGBA32
                        ConvertUnpacked16sRowToRGB32(input_row_ptr, num_channels, output_row_ptr, output_width,
                                                     descale, format, color_space, alpha);
                    }
                    break;

                case COLOR_FORMAT_YU64:
                case COLOR_FORMAT_V210:
                    if (	(decoder->codec.encoded_format == ENCODED_FORMAT_RGB_444) ||
                            (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444))
                    {
                        //TODO  RGB to YUV Quarter RES DAN20110120 - handle above with HACK DAN20110122
                        //
                    }
                    else
                    {
                        // Convert the intermediate results into a row of YU64
                        ConvertUnpacked16sRowToYU64(input_row_ptr, num_channels, output_row_ptr, output_width,
                                                    descale, precision, format);
                    }
                    break;

                case COLOR_FORMAT_B64A:
                    // Convert the intermediate results to a row of ARGB with 16 bits per pixel
                    descale = 2;
                    ConvertUnpacked16sRowToB64A(input_row_ptr, num_channels, output_row_ptr, output_width,
                                                descale, precision);
                    break;
                case COLOR_FORMAT_R210:
                case COLOR_FORMAT_DPX0:
                case COLOR_FORMAT_RG30:
                case COLOR_FORMAT_AR10:
                case COLOR_FORMAT_AB10:
                    // Convert the intermediate results to a row of ARGB with 16 bits per pixel
                    descale = 2;
                    ConvertUnpacked16sRowToRGB30(input_row_ptr, num_channels, output_row_ptr, output_width,
                                                 descale, precision, format, color_space);
                    break;

                case COLOR_FORMAT_RG48:
                    // Convert the intermediate results into a row of RGBA with 16 bits per component
                    descale = 2;
                    ConvertUnpacked16sRowToRGB48(input_row_ptr, num_channels, output_row_ptr, output_width,
                                                 descale, precision);
                    break;

                case COLOR_FORMAT_RG64:
                    // Convert the intermediate results into a row of RGBA with 16 bits per component
                    descale = 2;
                    ConvertUnpacked16sRowToRGBA64(input_row_ptr, num_channels, output_row_ptr, output_width,
                                                  descale, precision);
                    break;

                default:
                    assert(0);
                    break;
            }

            // Advance the input row pointers
            for (channel = 0; channel < num_channels; channel++)
            {
                input_row_ptr[channel] += input_pitch[channel];
            }

            // Advance the output row pointer
            output_row_ptr += output_pitch;
        }
    }
}

// Release all resources allocated by the decoder
void DecodeRelease(DECODER *decoder, TRANSFORM *transform[], int num_transforms)
{
#if _TIMING && 0
    FILE *logfile = decoder->logfile;
    uint32_t frame_count = decoder->frame_count;

    if (logfile != NULL && frame_count > 0)\
    {
#ifdef _WIN32
        PrintStatistics(logfile, frame_count, NULL, TIMING_CSV_FILENAME);
#else
        PrintStatistics(logfile, frame_count, NULL, NULL);
#endif
    }
#endif

    // Free the data structures allocated for decoding
    ClearDecoder(decoder);
}

void DecodeForceMetadataRefresh(DECODER *decoder)
{
    CFHDDATA *cfhddata = &decoder->cfhddata;

    cfhddata->force_metadata_refresh = true;

    if (decoder->parallelDecoder)
    {
        cfhddata = &decoder->parallelDecoder->cfhddata;
        cfhddata->force_metadata_refresh = true;
    }

}
void SetDecoderFlags(DECODER *decoder, uint32_t flags)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    // Set the decoder flags
    decoder->flags = flags;

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Decoder flags: 0x%p\n", decoder->flags);
    }
#endif
}

void SetDecoderFormat(DECODER *decoder, int width, int height, int format, int resolution)
{
    // Need to modify the codec to use the decoding format

    decoder->frame.width = width;
    decoder->frame.height = height;

    if (format == DECODED_FORMAT_WP13)
    {
        decoder->frame.output_format = format;
        //decoder->frame.format = DECODED_FORMAT_RG48; //TODO Why is this needed with W13A work natively.
        decoder->frame.format = format;
        //decoder->frame.signed_pixels = 1;
        decoder->frame.white_point = 13;
    }
    else if (format == DECODED_FORMAT_W13A)
    {
        decoder->frame.output_format = format;
        //		decoder->frame.format = DECODED_FORMAT_W13A; // TODO eventually this might be DECODED_FORMAT_RG64
        decoder->frame.format = format;
        //decoder->frame.signed_pixels = 1;
        decoder->frame.white_point = 13;
    }
    else
    {
        decoder->frame.output_format = format;
        decoder->frame.format = format;
        //decoder->frame.signed_pixels = 0;
        decoder->frame.white_point = 16;
    }
    decoder->frame.resolution = resolution;
    decoder->frame.pixel_size = PixelSize(decoder->frame.format);
}



void SetDecoderCapabilities(DECODER *decoder)
{
    int processor_count;
#ifdef _WIN32
    int limit_cpus = 32;
#else
    int limit_cpus = 32;		// AJA spins off too many
#endif

    // Set the capabilities that are most likely supported by the Intel Mac
    decoder->thread_cntrl.capabilities = (_CPU_FEATURE_MMX | _CPU_FEATURE_SSE | _CPU_FEATURE_SSE2);

    if (decoder->thread_cntrl.limit)
    {
        limit_cpus = decoder->thread_cntrl.limit;
    }
    else if (decoder->thread_cntrl.affinity)
    {
        int i;
        const int max_cpu_count = 32;

        limit_cpus = 0;

        for (i = 0; i < max_cpu_count; i++)
        {
            if (decoder->thread_cntrl.affinity & (1 << i))
            {
                limit_cpus++;
            }
        }
    }

    // Set the number of processors
    processor_count = GetProcessorCount();

    if (processor_count > limit_cpus)
        processor_count = limit_cpus;

#if (0 && DEBUG)
    // Set the number of processors (for debugging)
    //processor_count = 8;
    processor_count = 1;
    fprintf(stderr, "Limit processors to %d\n", processor_count);
#endif

    decoder->thread_cntrl.capabilities |= (processor_count << 16);
}
int GetDecoderCapabilities(DECODER *decoder)
{
    return decoder->thread_cntrl.capabilities;
}
bool SetDecoderColorFlags(DECODER *decoder, uint32_t color_flags)
{
    if (/*MIN_DECODED_COLOR_SPACE <= color_flags && */color_flags <= MAX_DECODED_COLOR_SPACE)
    {
        decoder->frame.colorspace = color_flags;
        // Indicate that the color flags were set as specified
        return true;
    }

    // The specified color flags were not valid
    return false;
}

// Compute the resolution corresponding to the specified combination of input and output dimensions
int DecodedResolution(int input_width, int input_height, int output_width, int output_height)
{
    int decoded_width;
    int decoded_height;

    // Output height can be negative for inverted RGB
    output_height = abs(output_height);

    if (output_width == input_width && output_height == input_height)
    {
        return DECODED_RESOLUTION_FULL;
    }

    // Compute the dimensions for half resolution decoding
    decoded_width = input_width / 2;
    decoded_height = input_height / 2;

    // Do the output dimensions correspond to half resolution decoding?
    if (output_width == decoded_width && output_height == decoded_height)
    {
        return DECODED_RESOLUTION_HALF;
    }

    // Compute the dimensions for quarter resolution decoding
    decoded_width /= 2;
    decoded_height /= 2;

    // Do the output dimensions correspond to half resolution decoding?
    if (output_width == decoded_width && output_height == decoded_height)
    {
        return DECODED_RESOLUTION_QUARTER;
    }

    return DECODED_RESOLUTION_UNSUPPORTED;
}

void ComputeDecodedDimensions(int encoded_width, int encoded_height, int decoded_resolution,
                              int *decoded_width_out, int *decoded_height_out)
{
    switch (decoded_resolution)
    {
        default:
            assert(0);

        case DECODED_RESOLUTION_FULL:
            *decoded_width_out = encoded_width;
            *decoded_height_out = encoded_height;
            break;

        case DECODED_RESOLUTION_HALF:
            *decoded_width_out = encoded_width / 2;
            *decoded_height_out = encoded_height / 2;
            break;

        case DECODED_RESOLUTION_QUARTER:
            *decoded_width_out = encoded_width / 4;
            *decoded_height_out = encoded_height / 4;
            break;

        case DECODED_RESOLUTION_LOWPASS_ONLY:
            //TODO: Check that the lowpass dimensions are correct
            *decoded_width_out = encoded_width / 8;
            *decoded_height_out = encoded_height / 8;
            break;
    }
}

// Return true if the specified resolution is supported
bool IsDecodedResolution(int resolution)
{
    if (resolution == DECODED_RESOLUTION_QUARTER)
    {
        return true;
    }

    return (resolution == DECODED_RESOLUTION_FULL ||
            resolution == DECODED_RESOLUTION_HALF);
}

// Return true if the encoded sample is a key frame
bool IsSampleKeyFrame(uint8_t *sample, size_t size)
{
    bool key_frame_flag = false;

    // Search the first twenty tags for the sample type
    const int num_tags = 20;
    int i;

    BITSTREAM bitstream;
    InitBitstreamBuffer(&bitstream, sample, size, BITSTREAM_ACCESS_READ);

    for (i = 0; i < num_tags && size > 0; i++, size -= sizeof(TAGVALUE))
    {
        TAGVALUE segment = GetSegment(&bitstream);
        if (segment.tuple.tag == CODEC_TAG_SAMPLE)
        {
            switch (segment.tuple.value)
            {
                case SAMPLE_TYPE_GROUP:
                case SAMPLE_TYPE_FIRST:
                case SAMPLE_TYPE_IFRAME:
                    key_frame_flag = true;
                    break;

                case SAMPLE_TYPE_SEQUENCE_HEADER:
                case SAMPLE_TYPE_FRAME:
                case SAMPLE_TYPE_SECOND:
                case SAMPLE_TYPE_PFRAME:
                default:
                    key_frame_flag = false;
                    break;

                case SAMPLE_TYPE_GROUP_TRAILER:
                case SAMPLE_TYPE_NONE:
                case SAMPLE_TYPE_ERROR:
                case SAMPLE_TYPE_CHANNEL:
                    assert(0);					// Unexpected situation
                    key_frame_flag = false;		// Report the sample as a non-key frame
                    break;
            }

            break;		// Found the sample type
        }
    }

    return key_frame_flag;
}

// Return the number of the more recent decoded frame
uint32_t DecodedFrameNumber(DECODER *decoder)
{
    CODEC_STATE *codec = &decoder->codec;
    if (decoder == NULL) return 0;
    return codec->frame_number;
}


/***** Start of the new code for the finite state machine (FSM) decoder *****/

#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

static inline void ZeroHighPassRow(PIXEL *rowptr, int length)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// This version assumes that the row is a multiple of 8 bytes
static inline void ZeroHighPassRow(PIXEL *rowptr, int length)
{
    int count;

    // Check that the row starts on a 16-byte boundary
    //assert(ISALIGNED(rowptr, 16));

    // Check that the row length (in bytes) is a multiple of 8 byte blocks
    assert(ISALIGNED(length, 8));

    // Convert the length from pixels to 8-byte blocks
    count = (length >> 3);

    // This code assumes that at least one 8-byte block will be zeroed
    assert(count > 0);

    __asm
    {
        pxor    mm0, mm0			// Zero a 16 byte register
        mov     eax, rowptr			// Load the pointer to the memory block
        mov     ebx, count			// Load the count of 8-byte blocks

        loop:	movq	[eax], mm0			// Write 8 bytes of zeros
        add		eax, 8				// Advance to the next 8 byte block
        sub		ebx, 1				// Decrement the number of blocks
        jg		loop
    }

    //_mm_empty();
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

#ifndef  _WIN64
// This version assumes that the row is a multiple of 16 bytes
static inline void ZeroHighPassRow(PIXEL *rowptr, int length)
{
    int count;

    // Check that the row starts on a 16-byte boundary
    assert(ISALIGNED(rowptr, 16));

    // Check that the row length (in bytes) is a multiple of 16 byte blocks
    assert(ISALIGNED(length, 16));

    // Convert the length from pixels to 16-byte blocks
    count = (length >> 4);

    // This code assumes that at least one 16-byte block will be zeroed
    assert(count > 0);

#if 1 //DANREMOVE

    memset(rowptr, 0, length);

#else

    __asm
    {
        pxor    xmm0, xmm0			// Zero a 16 byte register
        mov     eax, rowptr			// Load the pointer to the memory block
        mov     ebx, count			// Load the count of 16-byte blocks

        loop:	movdqa		[eax], xmm0			// Write 16 bytes of zeros
        add		eax, 16				// Advance to the next 16 byte block
        sub		ebx, 1				// Decrement the number of blocks
        jg		loop
    }

#endif
}
#else
// This version assumes that the row is a multiple of 16 bytes
static inline void ZeroHighPassRow(PIXEL *rowptr, int length)
{
    // Check that the row starts on a 16-byte boundary
    assert(ISALIGNED(rowptr, 16));

    // Check that the row length (in bytes) is a multiple of 16 byte blocks
    assert(ISALIGNED(length, 16));


    memset(rowptr, 0, length);
}
#endif
#endif

#if (0 && _DEBUG)

// Functions for the finite state machine decoder (debug version)

static FSMENTRY *GetFSMTableEntry(FSM *fsm, int index)
{
    // Return the address of the next table entry in the finite state machine
    return &fsm->next_state[index];
}

static void ResetFSM(FSM *fsm)
{
    // Reset the state to the beginning of the finite state machine entries
    fsm->next_state = fsm->entries;
}

static void UpdateFSM(FSM *fsm, int next)
{
    // Change the state pointer to the next block of table entries
    fsm->next_state = fsm->entries + (next << FSM_INDEX_SIZE);
}

#else

// Macros for the finite state machine decoder
#if _INDIVIDUAL_LUT

#define GetFSMTableEntry(fsm, index)	(FSMENTRY *)fsm->next_state+index
#define ResetFSM(fsm)					fsm->next_state = fsm->table.entries[0]
#define UpdateFSM(fsm, next)			fsm->next_state = fsm->table.entries[next]

#define GetFSMTableEntryIndividual(fsm, index)	(FSMENTRY *)fsm->table.entries_ind[(fsm->next_state_index << FSM_INDEX_SIZE) | index]
#define ResetFSMIndividual(fsm)					fsm->next_state_index = 0
#define UpdateFSMIndividual(fsm, next)			fsm->next_state_index = next

#else

#define GetFSMTableEntry(fsm, index)	(FSMENTRY *)fsm->next_state+index
#define ResetFSM(fsm)					fsm->next_state = fsm->table.entries
#define UpdateFSM(fsm, next)			fsm->next_state = fsm->table.entries+((int)next << FSM_INDEX_SIZE)

#endif

#endif


#if _DEBUG

static void DebugOutputFSMEntry(FSM *fsm, int index, FSMENTRY *entry)
{
    int pre_skip = (entry->pre_post_skip & 0xFFF);
    int post_skip = (entry->pre_post_skip >> 12);

    // Remove companding
    int value0 = entry->value0 / 32;
    int value1 = entry->value1 / 32;

    // Convert the index to start at the beginning of the table
    index += (int)(fsm->next_state - fsm->table.entries[0]);
}

static void DebugOutputFSMEntryFast(FSM *fsm, int index, FSMENTRYFAST *entry)
{
    int pre_skip = (entry->pre_post_skip & 0xFFF);
    int post_skip = (entry->pre_post_skip >> 12);

    // Remove companding
    int value0 = (entry->values >> 16) / 32;
    int value1 = (entry->values & 0xFFFF) / 32;

    // Convert the index to start at the beginning of the table
    index += (int)(fsm->next_state - fsm->table.entries[0]);
}

static void DebugOutputFSM(FSM *fsm)
{
    int num_entries = FSM_INDEX_ENTRIES;
    int i;

    for (i = 0; i < num_entries; i++)
    {
        FSMENTRY *entry = &fsm->table.entries[0][i];
        int pre_skip = (entry->pre_post_skip & 0xFFF);
        int post_skip = (entry->pre_post_skip >> 12);
    }
}

static void PrintFSMEntry(FSM *fsm, int index, FSMENTRY *entry, FILE *logfile)
{
    int pre_skip = (entry->pre_post_skip & 0xFFF);
    int post_skip = (entry->pre_post_skip >> 12);

    // Remove companding
    int value0 = entry->value0 / 32;
    int value1 = entry->value1 / 32;

    // Convert the index to start at the beginning of the table
    index += (int)(fsm->next_state - fsm->table.entries[0]);

    if (logfile)
    {
        fprintf(logfile, "%d, %d, %d, %d, %d\n", index, value0, value1, pre_skip, post_skip);
    }
}

static void PrintFSMEntryFast(FSM *fsm, int index, FSMENTRYFAST *entry, FILE *logfile)
{
    int pre_skip = (entry->pre_post_skip & 0xFFF);
    int post_skip = (entry->pre_post_skip >> 12);

    // Remove companding
    int value0 = (entry->values >> 16) / 32;
    int value1 = (entry->values & 0xFFFF) / 32;

    // Convert the index to start at the beginning of the table
    index += (int)(fsm->next_state - fsm->table.entries[0]);

    if (logfile)
    {
        fprintf(logfile, "%d, %d, %d, %d, %d\n", index, value0, value1, pre_skip, post_skip);
    }
}

#endif


static inline int GetFastByte(BITSTREAM *stream)
{
    // Inline of the third case of GetByte
    uint8_t  *lpCurrentWord = stream->lpCurrentWord;

    // Get the next byte from the bitstream
    int byte = (uint32_t )(*(lpCurrentWord++));

    // Update the state of the bitstream
    stream->lpCurrentWord = lpCurrentWord;

#if ERROR_TOLERANT
    // Update the count of bytes used
    stream->nWordsUsed--;
#endif

    // Check that the high bits are zero
    assert((byte & ~BITMASK(8)) == 0);

    return byte;
}

#if 0
static inline int GetFastShort(BITSTREAM *stream)
{
    // Adaptation of the code in GetByte
    uint8_t  *lpCurrentWord = stream->lpCurrentWord;

    // Get the next byte from the bitstream
    int byte = (uint32_t )(lpCurrentWord[0]);

    int word = (byte << 8) | (uint32_t )(lpCurrentWord[1]);

    // Update the state of the bitstream
    stream->lpCurrentWord = lpCurrentWord + 2;

    // Check that the high bits are zero
    assert((word & ~BITMASK(16)) == 0);

    return word;
}
#endif

// Must declare the byte swap function even though it is an intrinsic
//int _bswap(int);

#if 0
static inline int GetFastLong(BITSTREAM *stream)
{
    uint32_t  *lpCurrentWord = (uint32_t *)stream->lpCurrentWord;
    int word = *(lpCurrentWord)++;
    //word = _bswap(word);
    word = SwapInt32BtoN(word);
    stream->lpCurrentWord = (uint8_t *)lpCurrentWord;

    return word;
}
#endif

#if 0 //DAN20041030 not used
// Decode a subband using FSM. One byte is read from the bitstream each time and decoded in two steps
// Original version that does not use a separate buffer for decoding
bool DecodeBandFSM(FSM *fsm, BITSTREAM *stream, PIXEL *image, int width, int height, int pitch, int quantization)
{
    int index, byte;
    FSMENTRY *entry;
    PIXEL *rowptr = image;
    int column = 0;
    int32_t value;
    size_t bytes_row_size = width * sizeof(PIXEL);
    PIXEL *maxptr;
    int length = width * sizeof(PIXEL);
    //ROI roi = {width, 1};


    // This version of Huffman decoder assumes that one byte
    // is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == FSM_INDEX_SIZE * 2);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    // Convert the pitch to units of pixels
    pitch /= sizeof(PIXEL);

    // Compute the address of the row after the last row in the band
    maxptr = rowptr + height * pitch;

    // Round up the row length (in bytes) to a multiple of 16 bytes
    length = ALIGN16(length);

#if (0 && DEBUG)
    zerorow_count = 0;
#endif

    ZeroHighPassRow(rowptr, length);

    // Decode runs and magnitude values until the band end trailer is decoded
    for (;;)
    {
        // Read a byte from the bitstream
        byte = GetFastByte(stream);

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return when the entire band is decoded
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Zero out the whole subband from here on
            rowptr += pitch;
            while (rowptr < maxptr)
            {
                ZeroHighPassRow(rowptr, length);
                rowptr += pitch;
            }
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // If no magnitude value is decoded
        if (entry->value0 == 0)
        {
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);
            }
        }
        // If there is only one decoded magnitude value
        else if (entry->value1 == 0)
        {
            // Undo quantization and scaling
            value = quantization * entry->value0;

            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            //assert(index < width);
            assert(0 <= column && column < width);

            // Store the saturated value at the position found in the scan
            rowptr[column] = SATURATE(value);

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);
            }
        }
        // If there are two decoded magnitude values
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < width);

            if (column < width - 1)
            {

                value = quantization * entry->value0;
                rowptr[column++] = SATURATE(value);
                value = quantization * entry->value1;
                rowptr[column++] = SATURATE(value);
            }
            else
            {
                value = quantization * entry->value0;
                rowptr[column] = SATURATE(value);
                value = quantization * entry->value1;
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);

                column = 0;
                rowptr[column++] = SATURATE(value);
            }
        }

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Zero out the whole subband from here on
            rowptr += pitch;
            while (rowptr < maxptr)
            {
                ZeroHighPassRow(rowptr, length);
                rowptr += pitch;
            }
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // If no magnitude value is decoded
        if (entry->value0 == 0)
        {
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);
            }
        }
        // If there is only one decoded magnitude value
        else if (entry->value1 == 0)
        {
            // Undo quantization and scaling
            int32_t value = quantization * entry->value0;

            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            //assert(index < width);
            assert(0 <= column && column < width);

            // Store the saturated value at the position found in the scan
            rowptr[column] = SATURATE(value);

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);
            }
        }
        // If there are two decoded magnitude values
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < width);

            if (column < width - 1)
            {
                value = quantization * entry->value0;
                rowptr[column++] = SATURATE(value);
                value = quantization * entry->value1;
                rowptr[column++] = SATURATE(value);
            }
            else
            {
                value = quantization * entry->value0;
                rowptr[column] = SATURATE(value);
                value = quantization * entry->value1;
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, length);

                column = 0;
                rowptr[column++] = SATURATE(value);
            }
        }
    }
}
#endif

// Decode a subband of highpass coefficients using a finite state machine.
// One byte is read from the bitstream each time and decoded in two steps.
// New version that uses a buffer aligned to the cache for decoding.

#if 0
static inline void ZeroHighPassBuffer(PIXEL *ptrCacheLines, int numCacheLines)
{
    // This routine assume that the cache line size is 64 bytes
    assert(_CACHE_LINE_SIZE == 64);

    // This routine assumes that the input pointer is aligned to a cache line
    assert(ISALIGNED(ptrCacheLines, _CACHE_LINE_SIZE));

    // This routine assumes that at least one cache line will be written
    assert(numCacheLines > 0);

#if __GNUC__

    memset(ptrCacheLines, 0, numCacheLines * _CACHE_LINE_SIZE);

#else

    __asm
    {
        pxor    xmm0, xmm0				// Zero a 16 byte register
        mov     eax, ptrCacheLines		// Load the pointer to the memory block
        mov     ebx, numCacheLines		// Load the count of the number of cache lines

        loop:	movdqa	[eax], xmm0				// Write 64 bytes of zeros using aligned stores
        movdqa	[eax+16], xmm0
        movdqa	[eax+32], xmm0
        movdqa	[eax+48], xmm0

        add		eax, 64					// Advance to the next cache line
        sub		ebx, 1					// Decrement the number of cache lines
        jg		loop
    }
#endif

    // The routine returns the pointer to the cache line after zeroing the block
}
#endif
#if 0
static inline void CopyRowBuffer(char *rowptr, PIXEL *buffer, int length)
{
    // Note that the length is in units of bytes (not pixels)

    int count;		// Number of 16-byte blocks to copy

    // Check that the row length is an integer multiple of 16-byte blocks
    assert(ISALIGNED(length, 16));

    // Convert the row length to the number of 16-byte blocks to copy
    count = length >> 4;

    // This routine assumes that at least one 16 byte block will be copied
    assert(count > 0);

#if __GNUC__

    // Use standard memory copy
    memcpy(rowptr, buffer, length);

#else

    // Copy a multiple of 16 byte blocks
    __asm
    {
        mov		eax, rowptr			// Load the pointer to the destination
        mov		ebx, buffer			// Load the pointer to the source
        mov		ecx, count			// Load the number of 16-byte blocks to copy

        loop:	movdqa	xmm0, [ebx]			// Load 16 bytes from the source
        movntdq	[eax], xmm0			// Copy 16 bytes to the destination
        add		eax, 16				// Advance to the group of 16 bytes
        add		ebx, 16
        sub		ecx, 1				// Decrement the number of blocks to copy
        jg		loop
    }

#endif
}
#endif

// DecodeBandFSMBuffered is no longer used
#if 0 //dan20041030 not used
bool DecodeBandFSMBuffered(FSM *fsm, BITSTREAM *stream, PIXEL *image,
                           int width, int height, int pitch,
                           int quantization, char *decoding_buffer, size_t decoding_buffer_size)
{
    char *rowptr = (char *)image;				// Pointer to current row
    char *maxptr = rowptr + height * pitch;		// Address of row after the last row
    FSMENTRY *entry;
    int index;
    int byte;
    int column = 0;
    int32_t value;
    size_t row_size;
    size_t cache_row_size;						// Size of a row in bytes
    int cache_line_count;						// Size of the buffer in cache lines
    PIXEL *buffer;								// Pixel pointer to the buffer
    int length;									// Length of row in bytes


    // Check that the processing size allows two chunks per byte
    assert(BITSTREAM_WORD_SIZE == FSM_INDEX_SIZE * 2);

    // The bitstream buffer should be empty
    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    // Compute the number of cache lines used in the buffer
    row_size = width * sizeof(PIXEL);
    cache_row_size = ALIGN(row_size, _CACHE_LINE_SIZE);
    cache_line_count = (cache_row_size >> _CACHE_LINE_SHIFT);

    // Check that the buffer is large enough
    assert(decoding_buffer != NULL && decoding_buffer_size >= cache_row_size);

    // Check that the buffer starts on a cache line boundary
    assert(ISALIGNED(decoding_buffer, _CACHE_LINE_SIZE));

    // This routine assumes that the rows are contiguous and the pitch is a multiple of 16 bytes
    length = pitch;
    assert(length == ALIGN(row_size, 16));

    // Cast the buffer pointer for pixel access
    buffer = (PIXEL *)decoding_buffer;

    // Zero the decoding buffer
    ZeroHighPassBuffer(buffer, cache_line_count);

    // Decode runs and magnitude values until the band end trailer is decoded
    for (;;)
    {
        // Read a byte from the bitstream
        byte = GetFastByte(stream);

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return when the entire band is decoded
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Copy the buffer to the row if not already beyond the band
            if (rowptr < maxptr) CopyRowBuffer(rowptr, buffer, length);

            // Advance to the next row
            rowptr += pitch;

            // Zero the remaining rows in the subband
            while (rowptr < maxptr)
            {
                ZeroHighPassRow((PIXEL *)rowptr, length);
                rowptr += pitch;
            }

            // Reset the finite state machine to the root node in the Huffman tree
            ResetFSM(fsm);

            // Return indication that the band was fully decoded
            return true;
        }

        // Set the finite state machine to the next state in the Huffman tree
        UpdateFSM(fsm, entry->next_state);

        // No magnitude values decoded?
        if (entry->value0 == 0)
        {
            // No magnitudes decoded so just advance the column pointer
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);
            }
        }
        // Only one magnitude value decoded?
        else if (entry->value1 == 0)
        {
            // Process the magnitude value that was decoded

            // Undo quantization and scaling
            value = quantization * entry->value0;

            // Advance to the column where the value should be placed
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            assert(0 <= column && column < width);

            // Store the saturated value at the position found in the scan
            buffer[column] = SATURATE(value);

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);
            }
        }
        else	// Two magnitude values were decoded
        {
            // Check the column before storing values
            assert(0 <= column && column < width);

            if (column < width - 1)
            {
                // Dequantize and store the first value
                value = quantization * entry->value0;
                buffer[column++] = SATURATE(value);

                // Dequantize and store the second value
                value = quantization * entry->value1;
                buffer[column++] = SATURATE(value);
            }
            else
            {
                // Dequantize and store the first value in the current row
                value = quantization * entry->value0;
                buffer[column] = SATURATE(value);

                // Dequantize the second value
                value = quantization * entry->value1;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);

                // Reset the column to the beginning of the row
                column = 0;

                // Store the second value in the new row
                buffer[column++] = SATURATE(value);
            }
        }

        // Decode the second 4-bit chunk
        index = byte & FSM_INDEX_MASK;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Copy the buffer to the row if not already beyond the band
            if (rowptr < maxptr) CopyRowBuffer(rowptr, buffer, length);

            // Advance to the next row
            rowptr += pitch;

            // Zero the remaining rows in the subband
            while (rowptr < maxptr)
            {
                ZeroHighPassRow((PIXEL *)rowptr, length);
                rowptr += pitch;
            }

            // Reset the finite state machine to the root node in the Huffman tree
            ResetFSM(fsm);

            // Return indication that the band was fully decoded
            return true;
        }

        // Set the finite state machine to the next state in the Huffman tree
        UpdateFSM(fsm, (int)entry->next_state);

        // If no magnitude value is decoded
        if (entry->value0 == 0)
        {
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);
            }
        }
        // If there is only one decoded magnitude value
        else if (entry->value1 == 0)
        {
            // Undo quantization and scaling
            int32_t value = quantization * entry->value0;

            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            //assert(index < width);
            assert(0 <= column && column < width);

            // Store the saturated value at the position found in the scan
            buffer[column] = SATURATE(value);

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);
            }
        }
        // If there are two decoded magnitude values
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < width);

            if (column < width - 1)
            {
                value = quantization * entry->value0;
                buffer[column++] = SATURATE(value);

                value = quantization * entry->value1;
                buffer[column++] = SATURATE(value);
            }
            else
            {
                value = quantization * entry->value0;
                buffer[column] = SATURATE(value);

                value = quantization * entry->value1;

                // Advance to the next row
                assert(rowptr < maxptr);
                CopyRowBuffer(rowptr, buffer, length);
                rowptr += pitch;

                // Zero the decoding buffer if there are more rows to process
                if (rowptr < maxptr) ZeroHighPassBuffer(buffer, cache_line_count);

                // Reset the column to the beginning of the row
                column = 0;

                buffer[column++] = SATURATE(value);
            }
        }
    }
}
#endif

#if 0 //dan20041030 not used
// Decode a subband using FSM, combine the two results decoded from one byte
bool DecodeBandFSMCombined(FSM *fsm, BITSTREAM *stream, PIXEL *image, int width, int height, int pitch, int quantization)
{
    int index, skip;
    uint8_t byte;
    FSMENTRY *entry1, *entry2;
    PIXEL *rowptr = image;
    int row = 0, column = 0;
    int32_t value, bytes_row_size = width * sizeof(PIXEL);
    PIXEL *maxptr = rowptr + height * pitch;

    // This Huffman decoder assumes each byte is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == FSM_INDEX_SIZE * 2);

    ZeroHighPassRow(rowptr, width);

    // Double check that the bitstream buffer is empty
    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    // Decode runs and magnitude values until the band end trailer is decoded
    for (;;)
    {
        // Read a byte from the bitstream
        //byte = GetBits(stream, BITSTREAM_WORD_SIZE);
#if 0
        byte = GetByte(stream);

        if (stream->error != BITSTREAM_ERROR_OKAY)
        {
            stream->error = VLC_ERROR_NOTFOUND;
            return false;
        }
#else
        // Inline of the third case of GetByte
        uint8_t  *lpCurrentWord = stream->lpCurrentWord;

        // Get the next byte from the bitstream
        byte = (uint32_t )(*(lpCurrentWord++));

        // Update the state of the bitstream
        stream->lpCurrentWord = lpCurrentWord;

        // Check that the high bits are zero
        assert((byte & ~BITMASK(8)) == 0);
#endif

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;
        entry1 = GetFSMTableEntry(fsm, index);
        UpdateFSM(fsm, entry1->next_state);

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);
        entry2 = GetFSMTableEntry(fsm, index);
        UpdateFSM(fsm, entry2->next_state);

        // Return when the subband is completely decoded
        if (entry1->value0 == BAND_END_TRAILER || entry2->value0 == BAND_END_TRAILER)
        {
            ResetFSM(fsm);
            return true;
        }

        // If no magnitude value is decoded at the first step
        if (entry1->value0 == 0)
        {
            // If no magnitude is decoded at the second step
            if (entry2->value0 == 0)
            {
                column += entry1->pre_skip + entry2->pre_skip;

                // Did the scan go beyond the end of the row?
                while (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }
            }

            // If one magnitude is decoded at the second step
            else if (entry2->value1 == 0)
            {
                // Skip to the non-zero position
                column += entry1->pre_skip + entry2->pre_skip;

                // Did the scan go beyond the end of the row?
                while (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }

                // Fill in the decoded magnitude

                // Undo quantization and scaling
                value = quantization * entry2->value0;

                // Check the column before storing the value
                //assert(index < width);
                assert(0 <= column && column < width);

                // Store the saturated value
                rowptr[column] = SATURATE(value);

                column += entry2->post_skip;

                // Did the scan go beyond the end of the row?
                if (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }
            }
            // If two magnitudes are decoded at the second step
            else
            {
                column += entry1->pre_skip;

                // Did the scan go beyond the end of the row?
                while (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }

                // Check the column before storing values
                assert(0 <= column && column < width);

                if (column < width - 1)
                {
                    value = quantization * entry2->value0;
                    rowptr[column++] = SATURATE(value);
                    value = quantization * entry2->value1;
                    rowptr[column++] = SATURATE(value);
                }
                else
                {
                    value = quantization * entry2->value0;
                    rowptr[column] = SATURATE(value);
                    value = quantization * entry2->value1;
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);

                    column = 0;
                    rowptr[column++] = SATURATE(value);
                }
            }
        }

        // If only one magnitude is decoded at the first step
        else if (entry1->value1 == 0)
        {
            // Undo quantization and scaling
            value = quantization * entry1->value0;

            column += entry1->pre_skip;

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            //assert(index < width);
            assert(0 <= column && column < width);

            // Store the saturated value at the position found in the scan
            rowptr[column] = SATURATE(value);

            // If no magnitude is decoded at the second step
            if (entry2->value0 == 0)
            {
                column += entry1->post_skip + entry2->pre_skip;

                // Did the scan go beyond the end of the row?
                while (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }
            }

            // If one magnitude is decoded at the second step
            else if (entry2->value1 == 0)
            {
                // Undo quantization and scaling
                value = quantization * entry2->value0;

                column += entry1->post_skip + entry2->pre_skip;

                // Did the scan go beyond the end of the row?
                while (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }

                // Fill in the decoded magnitude

                // Check the column before storing the value
                assert(0 <= column && column < width);

                // Store the saturated value at the position found in the scan
                rowptr[column] = SATURATE(value);

                column += entry2->post_skip;

                // Did the scan go beyond the end of the row?
                if (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }
            }

            // If two magnitudes are decoded at the second step
            else
            {
                column += entry1->post_skip;

                // Did the scan go beyond the end of the row?
                if (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }

                // Check the column before storing values
                assert(0 <= column && column < width);

                if (column < width - 1)
                {
                    value = quantization * entry2->value0;
                    rowptr[column++] = SATURATE(value);
                    value = quantization * entry2->value1;
                    rowptr[column++] = SATURATE(value);
                }
                else
                {
                    value = quantization * entry2->value0;
                    rowptr[column] = SATURATE(value);
                    value = quantization * entry2->value1;
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);

                    column = 0;
                    rowptr[column++] = SATURATE(value);
                }
            }
        }

        // If two magnitudes are decoded at the first step
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < width);

            if (column < width - 1)
            {
                value = quantization * entry1->value0;
                rowptr[column++] = SATURATE(value);
                value = quantization * entry1->value1;
                rowptr[column++] = SATURATE(value);
            }
            else
            {
                value = quantization * entry1->value0;
                rowptr[column] = SATURATE(value);
                value = quantization * entry1->value1;
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);

                column = 0;
                rowptr[column++] = SATURATE(value);
            }

            // If two magnitudes are decoded at the first step
            // then at most one more magnitude can be decoded at the second step
            assert(entry2->value1 == 0);

            // If no magnitude is decoded at the second step
            if (entry2->value0 == 0)
            {
                column += entry2->pre_skip; // entry2->pre_skip <=4 must be true

                // Did the scan go beyond the end of the row?
                if (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }
            }

            // If one magnitude is decoded at the second step
            else
            {
                column += entry2->pre_skip;		// must be a small zero run

                // Did the scan go beyond the end of the row?
                if (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }

                // Fill in the decoded magnitude

                // Undo quantization and scaling
                value = quantization * entry2->value0;

                // Check the column before storing the value
                assert(0 <= column && column < width);

                // Store the saturated value at the position found in the scan
                rowptr[column] = SATURATE(value);

                column += entry2->post_skip;

                // Did the scan go beyond the end of the row?
                if (column >= width)
                {
                    // Compute the starting column for the next row
                    column -= width;

                    // Advance to the next row
                    rowptr += pitch;

                    if (rowptr < maxptr) ZeroHighPassRow(rowptr, width);
                }
            }
        }
    }
}
#endif


#if 0 //dan20041030 not used
// Decode a subband using FSM. One byte is read from the bitstream each time and decoded in two steps
// Original version that does not use a separate buffer for decoding
bool DecodeBandFSM8s(FSM *fsm, BITSTREAM *stream, PIXEL8S *image, int width, int height, int pitch)
{
    int index, byte;
    FSMENTRY *entry;
    PIXEL8S *rowptr = image;
    int column = 0;
    int32_t value;
    PIXEL8S *maxptr;
    int length = width * sizeof(PIXEL8S);
    //ROI roi = {width, 1};

    // This version of Huffman decoder assumes that one byte
    // is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == FSM_INDEX_SIZE * 2);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    // Convert the pitch to units of pixels
    pitch /= sizeof(PIXEL8S);

    // Compute the address of the row after the last row in the band
    maxptr = rowptr + height * pitch;

    // Round up the row length (in bytes) to a multiple of 16 bytes
    length = ALIGN16(length);

    ZeroHighPassRow((PIXEL *)rowptr, length);

    // Decode runs and magnitude values until the band end trailer is decoded
    for (;;)
    {
        // Read a byte from the bitstream
        byte = GetFastByte(stream);

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return when the entire band is decoded
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Zero out the whole subband from here on
            rowptr += pitch;
            while (rowptr < maxptr)
            {
                ZeroHighPassRow((PIXEL *)rowptr, length);
                rowptr += pitch;
            }
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // If no magnitude value is decoded
        if (entry->value0 == 0)
        {
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);
            }
        }
        // If there is only one decoded magnitude value
        else if (entry->value1 == 0)
        {
            value = entry->value0;

            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            assert(0 <= column && column < width);

            // Store the saturated value at the position found in the scan
            rowptr[column] = SATURATE8S(value);

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);
            }
        }
        // If there are two decoded magnitude values
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < width);

            if (column < width - 1)
            {
                value = entry->value0;
                rowptr[column++] = SATURATE8S(value);
                value = entry->value1;
                rowptr[column++] = SATURATE8S(value);
            }
            else
            {
                value = entry->value0;
                rowptr[column] = SATURATE8S(value);
                value = entry->value1;
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);

                column = 0;
                rowptr[column++] = SATURATE8S(value);
            }
        }

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Zero out the whole subband from here on
            rowptr += pitch;
            while (rowptr < maxptr)
            {
                ZeroHighPassRow((PIXEL *)rowptr, length);
                rowptr += pitch;
            }
            ResetFSM(fsm);
            return true;
        }

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // If no magnitude value is decoded
        if (entry->value0 == 0)
        {
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);
            }
        }
        // If there is only one decoded magnitude value
        else if (entry->value1 == 0)
        {
            value = entry->value0;

            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            assert(0 <= column && column < width);

            // Store the saturated value at the position found in the scan
            rowptr[column] = SATURATE8S(value);

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= width)
            {
                // Compute the starting column for the next row
                column -= width;

                // Advance to the next row
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);
            }
        }
        // If there are two decoded magnitude values
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < width);

            if (column < width - 1)
            {
                value = entry->value0;
                rowptr[column++] = SATURATE8S(value);
                value = entry->value1;
                rowptr[column++] = SATURATE8S(value);
            }
            else
            {
                value = entry->value0;
                rowptr[column] = SATURATE8S(value);
                value = entry->value1;
                rowptr += pitch;

                if (rowptr < maxptr) ZeroHighPassRow((PIXEL *)rowptr, length);

                column = 0;
                rowptr[column++] = SATURATE8S(value);
            }
        }
    }
}
#endif


// same as DecodeBandFSM8sNoGap but output to 16bit data
bool DecodeBandFSM16sNoGap2Pass(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch, int quant)
{
    int index, byte;
    FSMENTRY *entry;
    PIXEL *rowptr = (PIXEL *)image;
    PIXEL16S *bandendptr;
    int value;

#if ERROR_TOLERANT
    uint8_t  *startCurrentWord = stream->lpCurrentWord;
    int32_t startWordsUsed = stream->nWordsUsed;
#endif


#if _FSMBUFFER
    __declspec(align(32)) FSMENTRY buffer;
#endif

    if (image == NULL)
    {
        return false;
    }

    // Reset the decoder
    ResetFSM(fsm);

    pitch /= sizeof(PIXEL16S);

    // Zero out the entire subband
    ZeroHighPassRow((PIXEL *)rowptr, pitch * height * sizeof(PIXEL16S));

    // This Huffman decoder assumes each byte is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == 2 * FSM_INDEX_SIZE);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    bandendptr = rowptr + height * pitch;


#if 0  // test for errors.
    {
        if ((rand() % 10) == 1)
            stream->lpCurrentWord[rand() % 50] ^= 1;
    }
#endif



    // Decode runs and magnitude values until the entire band is decoded
#if ERROR_TOLERANT
    while ((intptr_t)bandendptr - (intptr_t)rowptr >= 0)
#else
    for (;;)
#endif
    {
        // Read a byte from the bitstream
#if ERROR_TOLERANT
        if (stream->nWordsUsed)
        {
            byte = GetFastByte(stream);
        }
        else
        {
            break;
        }
#else
        byte = GetFastByte(stream);
#endif

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            goto SecondPass;
        }

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = value;//SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = value;//SATURATE(value);

        // Skip the appropriate distance
        rowptr = &rowptr[entry->pre_post_skip >> 12];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            goto SecondPass;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = value;//SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = value;//SATURATE(value);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip >> 12];
    }




SecondPass:

    rowptr = (PIXEL16S *)image;

    AlignBits(stream);
    AlignBitsTag(stream);

    stream->lpCurrentWord += 4;
    stream->nWordsUsed -= 4;

    // Decode runs and magnitude values until the entire band is decoded
#if ERROR_TOLERANT
    while ((intptr_t)bandendptr - (intptr_t)rowptr >= 0)
#else
    for (;;)
#endif
    {
        // Read a byte from the bitstream
#if ERROR_TOLERANT
        if (stream->nWordsUsed)
        {
            byte = GetFastByte(stream);
        }
        else
        {
            break;
        }
#else
        byte = GetFastByte(stream);
#endif

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] |= value << 8;

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] |= value << 8;


        // Skip the appropriate distance
        rowptr = &rowptr[entry->pre_post_skip >> 12];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] |= value << 8;

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] |= value << 8;

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip >> 12];
    }





#if ERROR_TOLERANT

    // Reset the decoder
    ResetFSM(fsm);

    // Backup the bitstream to the beginning of the band
    stream->lpCurrentWord = startCurrentWord;
    stream->nWordsUsed = startWordsUsed;

#if 0
    AlignBitsTag(stream);

    // Read the debugging marker
    {
        TAGVALUE segment;

        do
        {
            segment = GetTagValue(stream);
        } while (segment.tuple.tag != CODEC_TAG_BAND_TRAILER);

        stream->lpCurrentWord -= 4;
        stream->nWordsUsed += 4;
    }
#else
    SkipSubband(stream);
#endif
#endif
    return true;
}

// Same as DecodeBandFSM8sNoGap but output to 16bit data
#if _DEBUG
bool DecodeBandFSM16sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch, FILE *logfile)
#else
bool DecodeBandFSM16sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch)
#endif
{
    int index, byte;
    FSMENTRY *entry;
    FSMENTRYFAST *entryfast;
    PIXEL16S *rowptr = image;
    PIXEL16S *bandendptr;
    PIXEL16S *fastendptr;
    int32_t value;

    uint8_t  *startCurrentWord = stream->lpCurrentWord;
    uint8_t  *CurrentWord = stream->lpCurrentWord;
    int32_t startWordsUsed = stream->nWordsUsed;

    ptrdiff_t offset;

#if _FSMBUFFER
    __declspec(align(32)) FSMENTRY buffer;
#endif

#if (0 && DEBUG)
    DebugOutputBitstreamPosition(stream);
    DebugOutputBitstreamBytes(stream, 16);
#endif

    // Reset the decoder
    ResetFSM(fsm);

#if (0 && DEBUG)
    DebugOutputFSM(fsm);
#endif

    pitch /= sizeof(PIXEL16S);

    // Zero out the entire subband
    ZeroHighPassRow((PIXEL *)rowptr, pitch * height * sizeof(PIXEL16S));
    //memset(rowptr, 0, pitch*height*sizeof(PIXEL16S));

    // This Huffman decoder assumes each byte is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == 2 * FSM_INDEX_SIZE);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    bandendptr = rowptr + height * pitch;


#if 0  // test for errors.
    {
        if ((rand() % 10) == 1)
            stream->lpCurrentWord[rand() % 50] ^= 1;
    }
#endif

    fastendptr = bandendptr;
    fastendptr -= 500;

    // Decode runs and magnitude values until the entire band is decoded
    while (rowptr < fastendptr)
    {
        // Read a byte from the bitstream
        byte = *CurrentWord++;

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entryfast = (FSMENTRYFAST *)GetFSMTableEntry(fsm, index);

#if (0 && DEBUG)
        //DebugOutputFSMEntryFast(fsm, index, entryfast);
        PrintFSMEntryFast(fsm, index, entryfast, logfile);
#endif
        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entryfast->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entryfast->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        *((uint32_t *)rowptr) = entryfast->values;

        // Skip the appropriate distance
        rowptr = &rowptr[entryfast->pre_post_skip >> 12];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entryfast = (FSMENTRYFAST *)GetFSMTableEntry(fsm, index);

#if (0 && DEBUG)
        //DebugOutputFSMEntryFast(fsm, index, entryfast);
        PrintFSMEntryFast(fsm, index, entryfast, logfile);
#endif
        // set the pointer to the next state
        UpdateFSM(fsm, (int)entryfast->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entryfast->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        *((uint32_t *)rowptr) = entryfast->values;

        // Skip the decoded zero runs
        rowptr = &rowptr[entryfast->pre_post_skip >> 12];
    }

    offset = CurrentWord - startCurrentWord;
    stream->lpCurrentWord += offset;
    stream->nWordsUsed -= (int)offset;

    // Decode runs and magnitude values until the entire band is decoded
#if ERROR_TOLERANT
    while (bandendptr >= rowptr)
#else
    for (;;)
#endif
    {
#if (0 && DEBUG)
        if (!(rowptr < bandendptr))
        {
            return true;
        }
#endif

#if (0 && DEBUG)
        PrintBitstreamPosition(stream, logfile);
#endif

        // Read a byte from the bitstream
#if ERROR_TOLERANT
        if (stream->nWordsUsed)
        {
            byte = GetFastByte(stream);
        }
        else
        {
            break;
        }
#else
        byte = GetFastByte(stream);
#endif

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);
#if (0 && DEBUG)
        //DebugOutputFSMEntry(fsm, index, entry);
        PrintFSMEntry(fsm, index, entry, logfile);
#endif

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        if ((value = entry->value0))
        {
            rowptr[0] = value;//SATURATE(value);
        }

        // Write down the second decoded magnitude
        if ((value = entry->value1))
        {
            rowptr[1] = value;//SATURATE(value);
        }

        // Skip the appropriate distance
        rowptr = &rowptr[entry->pre_post_skip >> 12];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);
#if (0 && DEBUG)
        //DebugOutputFSMEntry(fsm, index, entry);
        PrintFSMEntry(fsm, index, entry, logfile);
#endif

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        if ((value = entry->value0))
        {
            rowptr[0] = value;//SATURATE(value);
        }

        // Write down the second decoded magnitude
        if ((value = entry->value1))
        {
            rowptr[1] = value;//SATURATE(value);
        }

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip >> 12];
    }

#if ERROR_TOLERANT

    // Reset the decoder
    ResetFSM(fsm);

    // Backup the bitstream to the beginning of the band
    stream->lpCurrentWord = startCurrentWord;
    stream->nWordsUsed = startWordsUsed;

#if 0
    AlignBitsTag(stream);

    // Read the debugging marker
    {
        TAGVALUE segment;

        do
        {
            segment = GetTagValue(stream);
        } while (segment.tuple.tag != CODEC_TAG_BAND_TRAILER);

        stream->lpCurrentWord -= 4;
        stream->nWordsUsed += 4;
    }
#else
    SkipSubband(stream);
#endif
#endif

    return true;
}

bool DecodeBandFSM16sNoGapWithPeaks(FSM *fsm, BITSTREAM *stream, PIXEL16S *image, int width, int height, int pitch, PIXEL *peaks, int level, int quant)
{
    int index, byte;
    FSMENTRY *entry;
    PIXEL16S *rowptr = image;
    PIXEL16S *bandendptr;
    PIXEL16S *fastendptr;
    int32_t value;

    uint8_t  *startCurrentWord = stream->lpCurrentWord;
    uint8_t  *CurrentWord = stream->lpCurrentWord;
    int32_t startWordsUsed = stream->nWordsUsed;

#if _FSMBUFFER
    __declspec(align(32)) FSMENTRY buffer;
#endif

    // Reset the decoder
    ResetFSM(fsm);

    //This is been called with non-prequantized FSM
    if (quant > 1) level /= quant;

    pitch /= sizeof(PIXEL16S);

    // Zero out the entire subband
    ZeroHighPassRow((PIXEL *)rowptr, pitch * height * sizeof(PIXEL16S));

    // This Huffman decoder assumes each byte is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == 2 * FSM_INDEX_SIZE);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    bandendptr = rowptr + height * pitch;


#if 0  // test for errors.
    {
        if ((rand() % 10) == 1)
            stream->lpCurrentWord[rand() % 50] ^= 1;
    }
#endif

    fastendptr = bandendptr;
    fastendptr -= 1000;

    // Decode runs and magnitude values until the entire band is decoded
    while (rowptr < fastendptr)
    {
        // Read a byte from the bitstream
        byte = *CurrentWord++;

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        if (abs(value) > level)
            rowptr[0] = *peaks++ / quant;
        else
            rowptr[0] = value;//SATURATE(value);

        value = entry->value1;
        rowptr[1] = value;//SATURATE(value);

        // Skip the appropriate distance
        rowptr = &rowptr[entry->pre_post_skip >> 12];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        if (abs(value) > level)
            rowptr[0] = *peaks++ / quant;
        else
            rowptr[0] = value;//SATURATE(value);

        value = entry->value1;
        rowptr[1] = value;//SATURATE(value);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip >> 12];
    }

    stream->lpCurrentWord += ((intptr_t)CurrentWord - (intptr_t)startCurrentWord);
    stream->nWordsUsed -= (int)(((intptr_t)CurrentWord - (intptr_t)startCurrentWord));

    // Decode runs and magnitude values until the entire band is decoded
#if ERROR_TOLERANT
    while (((intptr_t)bandendptr - (intptr_t)rowptr) >= 0)
#else
    for (;;)
#endif
    {
#if (0 && DEBUG)
        if (!(rowptr < bandendptr))
        {
            return true;
        }
#endif


        // Read a byte from the bitstream
#if ERROR_TOLERANT
        if (stream->nWordsUsed)
        {
            byte = GetFastByte(stream);
        }
        else
        {
            break;
        }
#else
        byte = GetFastByte(stream);
#endif

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        if (abs(value) > level)
            rowptr[0] = *peaks++ / quant;
        else
            rowptr[0] = value;//SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = value;//SATURATE(value);

        // Skip the appropriate distance
        rowptr = &rowptr[entry->pre_post_skip >> 12];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip & 0xfff];

        // Write down the first decoded magnitude
        value = entry->value0;
        if (abs(value) > level)
            rowptr[0] = *peaks++ / quant;
        else
            rowptr[0] = value;//SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = value;//SATURATE(value);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_post_skip >> 12];
    }

#if ERROR_TOLERANT

    // Reset the decoder
    ResetFSM(fsm);

    // Backup the bitstream to the beginning of the band
    stream->lpCurrentWord = startCurrentWord;
    stream->nWordsUsed = startWordsUsed;

#if 0
    AlignBitsTag(stream);

    // Read the debugging marker
    {
        TAGVALUE segment;

        do
        {
            segment = GetTagValue(stream);
        } while (segment.tuple.tag != CODEC_TAG_BAND_TRAILER);

        stream->lpCurrentWord -= 4;
        stream->nWordsUsed += 4;
    }
#else
    SkipSubband(stream);
#endif
#endif
    return true;
}

// This version of DecodeBandFSM() assumes that the gap between width and pitch has been coded as
// zero runs. Therefore decoded magnitude values can be written down without the need to check
// if the end of a row has been reached. Hence the total number of conditionals in DecodeBandFSM
// can be significantly reduced.

// Decode a subband using FSM. One byte is read from the bitstream each time and decoded in two steps
// Original version that does not use a separate buffer for decoding
#if !_INDIVIDUAL_ENTRY

#if 0 //dan20041030 not used
bool DecodeBandFSM8sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL8S *image, int width, int height, int pitch)
{
    int index, byte;
    FSMENTRY *entry;
    PIXEL8S *rowptr = image;
    PIXEL8S *bandendptr;
    int32_t value;

#if _FSMBUFFER
    __declspec(align(32)) FSMENTRY buffer;
#endif

    pitch /= sizeof(PIXEL8S);

    // Zero out the entire subband
    ZeroHighPassRow((PIXEL *)rowptr, pitch * height);

    // This version of Huffman decoder assumes that one byte
    // is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == FSM_INDEX_SIZE * 2);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    bandendptr = rowptr + height * pitch;

    // Decode runs and magnitude values until the entire band is decoded
    //while (rowptr < bandendptr)
    for (;;)
    {
#if (0 && DEBUG)
        if (!(rowptr < bandendptr))
        {
            return true;
        }
#endif
        // Check that the decoder has not overrun the output array
        //assert(rowptr < bandendptr);

        // Read a byte from the bitstream
        byte = GetFastByte(stream);

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

#if 1
        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }
#endif

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_skip];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = SATURATE(value);

        // Skip the appropriate distance
        rowptr = &rowptr[entry->post_skip];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

#if _FSMBUFFER
        memcpy(&buffer, entry, sizeof(FSMENTRY));
        entry = &buffer;
#endif

#if 1
        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSM(fsm);
            return true;
        }
#endif

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_skip];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = SATURATE(value);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->post_skip];
    }
}
#endif

#elif _SINGLE_FSM_TABLE

bool DecodeBandFSM8sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL8S *image, int width, int height, int pitch)
{
    int index, byte, i;
    FSMENTRY *entry, *firstentry = fsm->table->firstentry;
    PIXEL8S *rowptr = image;
    PIXEL8S *bandendptr;
    int32_t value;

    pitch /= sizeof(PIXEL8S);

    // Zero out the entire subband
    ZeroHighPassRow((PIXEL *)rowptr, pitch * height);

    // The Huffman decoder assumes each byte is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == 2 * FSM_INDEX_SIZE);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    // Decode runs and magnitude values until the entire band is decoded
    for (;;)
    {
        // Check that the decoder has not overrun the output array
        //assert(rowptr < bandendptr);

        // Read a byte from the bitstream
        byte = GetFastByte(stream);

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        i = (fsm->next_state_index << FSM_INDEX_SIZE) | index;//DAN
        entry = firstentry + i; //DAN

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSMIndividual(fsm);

            return true;
        }

        // set the pointer to the next state
        UpdateFSMIndividual(fsm, (entry->next_state));

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_skip];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = SATURATE(value);

        // Skip the appropriate distance
        rowptr = &rowptr[entry->post_skip];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        i = (fsm->next_state_index << FSM_INDEX_SIZE) | index;//DAN
        entry = firstentry + i; //DAN

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            assert(rowptr <= bandendptr);
            ResetFSMIndividual(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSMIndividual(fsm, (entry->next_state));

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_skip];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = SATURATE(value);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->post_skip];
    }
}

#else

bool DecodeBandFSM8sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL8S *image, int width, int height, int pitch)
{
    int index, byte;
    FSMENTRY *entry;
    PIXEL8S *rowptr = image;
    PIXEL8S *bandendptr;
    int32_t value;

#if 1
    __declspec(align(4)) FSMENTRY buffer;
#endif

    pitch /= sizeof(PIXEL8S);

    // zero out the entire subband
    ZeroHighPassRow((PIXEL *)rowptr, pitch * height);

    // The Huffman decoder assumes each byte is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == 2 * FSM_INDEX_SIZE);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    bandendptr = rowptr + height * pitch;

    // Decode runs and magnitude values until the entire band is decoded
    for (;;)
    {
#if (0 && DEBUG)
        if (!(rowptr < bandendptr))
        {
            return true;
        }
#endif
        // Read a byte from the bitstream
        byte = GetFastByte(stream);

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntryIndividual(fsm, index);

        // Return if the subband is decoded completely
        if (entry == NULL)
        {
            assert(rowptr <= bandendptr);
            ResetFSMIndividual(fsm);

            return true;
        }

        // Set the pointer to the next state
        UpdateFSMIndividual(fsm, (entry->next_state));

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_skip];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = SATURATE(value);

        // Skip the appropriate distance
        rowptr = &rowptr[entry->post_skip];

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntryIndividual(fsm, index);

        // Return if the subband is decoded completely
        if (entry == NULL)
        {
            assert(rowptr <= bandendptr);
            ResetFSMIndividual(fsm);
            return true;
        }

        // Set the pointer to the next state
        UpdateFSMIndividual(fsm, (entry->next_state));

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->pre_skip];

        // Write down the first decoded magnitude
        value = entry->value0;
        rowptr[0] = SATURATE(value);

        // Write down the second decoded magnitude
        value = entry->value1;
        rowptr[1] = SATURATE(value);

        // Skip the decoded zero runs
        rowptr = &rowptr[entry->post_skip];
    }
}
#endif

// Decode the highpass band coefficients but do not write them out - used in SIF mode
bool SkipBandFSM(FSM *fsm, BITSTREAM *stream, PIXEL8S *image, int width, int height, int pitch)
{
    int index, byte;
    FSMENTRY *entry;

    pitch /= sizeof(PIXEL8S);

    // The Huffman decoder assumes each byte is processed as two 4-bit chunks
    assert(BITSTREAM_WORD_SIZE == FSM_INDEX_SIZE * 2);

    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    // Decode runs and magnitude values until the entire band is decoded
    for (;;)
    {
        // Read a byte from the bitstream
        byte = GetFastByte(stream);

        // Decode the first 4-bit chunk
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // decode the second 4-bit chunk
        index = byte & ((1 << FSM_INDEX_SIZE) - 1);

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);
    }
}

#if _TIMING
extern TIMER tk_fastruns;
#endif

#if 0 //dan20041030 not used
// New version of coefficient runs decoder that uses a finite state machine with a scaling factor
bool DecodeFastRunsFSM8s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                         int band_index, int width, int height)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;
    FILE *logfile = decoder->logfile;
    int result;

    // Get the pointer to the finite state machine
    FSM *fsm = &decoder->fsm[decoder->codec.active_codebook]; //DAN20041026

    // All rows are treated as one long row that covers the entire band
    int size = fsm->table.num_states;

    PIXEL *rowptr;
    int row = 0;
    int pitch;

    int pixel_type = wavelet->pixel_type[band_index];

    decoder->codec.active_codebook = 0; // reset CODEC state

    // Must have a valid wavelet
    assert(wavelet != NULL);
    if (wavelet == NULL) return false;

    //Must have a valid FSM
    assert(fsm != NULL);
    if (fsm == NULL) return false;

    assert(size > 0);
    if (size == 0)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    // Check if the band is intended for 8-bit pixels
    assert(pixel_type == PIXEL_TYPE_8S);

    START(tk_fastruns);

    rowptr = (PIXEL *)wavelet->band[band_index];
    pitch = wavelet->pitch8s;		// Use the 8-bit pitch
    //pitch = wavelet->pitch;

    // The finite state machine does not support a marker at the end of rows
#if RUNS_ROWEND_MARKER
    assert(0);
#endif

    // Get one byte from the bitstream and decode 4 bits at a time
    result = DecodeBandFSM8sNoGap(fsm, stream, (PIXEL8S *)rowptr, width, height, pitch);

    assert(result == true);
    if (result != true)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

#if (0 && DEBUG && _WIN32)
    _CrtCheckMemory();
#endif

#if (0 && DEBUG)
    if (logfile)
        DumpBand("Band", wavelet, band_index, NULL, logfile);
#endif

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "DecodeFastRunsFSM8s, band index: %d\n", band_index);
        DumpWaveletRow(wavelet, band_index, 0, logfile);
    }
#endif

end:
    STOP(tk_fastruns);

    return true;
}
#endif

#if _DEQUANTIZE_IN_FSM
void ReQuantFSM(FSM *fsm, int quant)
{
    int count = 0;
    int i, j;
    short *restore = &fsm->restoreFSM[0];

#if !_INDIVIDUAL_ENTRY
    for (i = 0; i < fsm->table.num_states; i++)
    {
        FSMENTRY *entry = fsm->table.entries[i];
        for (j = 0; j < (1 << FSM_INDEX_SIZE); j++)
        {
            entry[j].value0 = restore[count++];
            entry[j].value1 = restore[count++];
        }
    }
#else
    for (i = 0; i < (fsm->table.num_states << FSM_INDEX_SIZE); i++)
    {
        FSMENTRY *entry = fsm_table.entries_ind[i];

        if (entry)
        {
            entry->value0 = restore[count++];
            entry->value1 = restore[count++];
        }
    }
#endif
}

void DeQuantFSM(FSM *fsm, int quant)
{
    int i, j;


    if (fsm->LastQuant > 1 && fsm->LastQuant != quant)
    {
        ReQuantFSM(fsm, fsm->LastQuant);
    }
    else if (fsm->LastQuant == quant)
    {
        return;
    }


    if (fsm->InitizedRestore == 0)
    {
        short *restore = &fsm->restoreFSM[0];
        int count = 0;

#if !_INDIVIDUAL_ENTRY
        for (i = 0; i < fsm->table.num_states; i++)
        {
            FSMENTRY *entry = fsm->table.entries[i];
            for (j = 0; j < (1 << FSM_INDEX_SIZE); j++)
            {
                restore[count++] = entry[j].value0;
                restore[count++] = entry[j].value1;
            }
        }
#else
        for (i = 0; i < (fsm->table.num_states << FSM_INDEX_SIZE); i++)
        {
            FSMENTRY *entry = fsm->table.entries_ind[i];

            if (entry)
            {
                restore[count++] = entry->value0;
                restore[count++] = entry->value1;
            }
        }
#endif

        fsm->InitizedRestore = 1;
    }

#if !_INDIVIDUAL_ENTRY
    for (i = 0; i < fsm->table.num_states; i++)
    {
        FSMENTRY *entry = fsm->table.entries[i];
        for (j = 0; j < (1 << FSM_INDEX_SIZE); j++)
        {
            if (entry[j].value0 < 0x7ff0) // band end trailer
                entry[j].value0 *= quant;

            entry[j].value1 *= quant;
        }
    }
#else
    for (i = 0; i < (fsm->table.num_states << FSM_INDEX_SIZE); i++)
    {
        FSMENTRY *entry = fsm->table.entries_ind[i];

        if (entry)
        {
            if (entry->value0 < 0x7ff0) // band end trailer etc
                entry->value0 *= quant;

            entry->value1 *= quant;
        }
    }
#endif

    fsm->LastQuant = quant;

}
#endif // _DEQUANTIZE_IN_FSM

// New version of coefficient runs decoder that uses a finite state machine with a scaling factor
//dan 7-11-03
bool DecodeFastRunsFSM16s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                          int band_index, int width, int height, int threading)
{
    //CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    int result = true;
    int quant = wavelet->quantization[band_index];

    int active_codebook = decoder->codec.active_codebook;
    // Get the pointer to the finite state machine
    FSM *fsm = &decoder->fsm[active_codebook];
    int size;
    PIXEL *rowptr;
    //int row = 0;
    int pitch;
    CODEC_STATE *codec = &decoder->codec;
    //int channel = codec->channel;
    //int subband = codec->band.subband;
    //int num_subbands = codec->num_subbands;
    //int pixel_type = wavelet->pixel_type[band_index];
    int difference_coding = decoder->codec.difference_coding;
    //int localquant = 1;
    int peaklevel = 0;
    //int peaksize = 0;
    PIXEL *peakbase = NULL;

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Subband: %d, active_codebook: %d, difference_coding: %d\n",
                subband, decoder->codec.active_codebook, difference_coding);
    }
#endif

    decoder->codec.active_codebook = 0; // reset CODEC state
    decoder->codec.difference_coding = 0; //reset state for next subband

    // Must have a valid wavelet
    assert(wavelet != NULL);
    if (wavelet == NULL) return false;

    //Must have a valid FSM
    assert(fsm != NULL);
    if (fsm == NULL) return false;

    // All rows are treated as one long row that covers the entire band
    size = fsm->table.num_states;

    assert(size > 0);
    if (size == 0)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    // Check if the band is intended for 8-bit pixels
    assert(wavelet->pixel_type[band_index] == PIXEL_TYPE_16S);

    START(tk_fastruns);

    rowptr = (PIXEL *)wavelet->band[band_index];
    //pitch = wavelet->pitch8s;		// Use the 8-bit pitch
    pitch = wavelet->pitch;

    peaklevel = codec->peak_table.level;
    peakbase = codec->peak_table.base;

#if _THREADED
    threading = decoder->entropy_worker_new.pool.thread_count > 1 ? threading : 0;

    if (threading)
    {
        decoder->entropy_worker_new.threads_used = 1;

        {
            //int start = stream->nWordsUsed;
            int end;
            struct entropy_data_new *data;

            int next_queue_num = decoder->entropy_worker_new.next_queue_num++;
            data = &decoder->entropy_worker_new.entropy_data[next_queue_num];

            memcpy(&data->stream, stream, sizeof(BITSTREAM));
            data->rowptr = rowptr;
            data->width = width;
            data->height = height;
            data->pitch = pitch;
            data->peaks = peakbase;
            data->level = peaklevel;
            data->quant = quant;
            data->wavelet = wavelet;
            data->band_index = band_index;
            data->active_codebook = active_codebook;
            data->difference_coding = difference_coding;

            // Start only a particular threadid
            if (next_queue_num == 0)
            {
                ThreadPoolSetWorkCount(&decoder->entropy_worker_new.pool, 1);

#if _DELAYED_THREAD_START==0
                ThreadPoolSendMessage(&decoder->entropy_worker_new.pool, THREAD_MESSAGE_START);
#endif
            }
            else
            {
                // Set the work count to the number of rows to process
                ThreadPoolAddWorkCount(&decoder->entropy_worker_new.pool, 1);
            }

            {
                unsigned short tag = *(stream->lpCurrentWord - 8) << 8;
                if (tag == (unsigned short)OPTIONALTAG(CODEC_TAG_SUBBAND_SIZE))
                {
                    int chunksize;
                    int value = *(stream->lpCurrentWord - 6) << 8;
                    value |= *(stream->lpCurrentWord - 5);

                    tag |= *(stream->lpCurrentWord - 7);
                    tag = NEG(tag);

                    chunksize = value;
                    chunksize &= 0xffff;
                    chunksize += ((tag & 0xff) << 16);

                    chunksize *= 4;

                    chunksize -= 8;

                    {
                        uint32_t *ptr = (uint32_t *)stream->lpCurrentWord;
                        ptr += (chunksize >> 2);

                        if (*ptr != 0x00003800) // bandend
                        {
                            goto continuesearch;
                        }
                    }

                    stream->lpCurrentWord += chunksize;
                    stream->nWordsUsed -= chunksize;
                    end = stream->nWordsUsed;
                }
                else
                {
continuesearch:
                    while (*((uint32_t *)stream->lpCurrentWord) != 0x00003800) // bandend
                    {
                        stream->lpCurrentWord += 4;
                        stream->nWordsUsed -= 4;
                    }
                    end = stream->nWordsUsed;
                }
            }
        }
    }
    else
#endif // _THREADED
    {
        DeQuantFSM(fsm, quant);

        if (peaklevel)
        {
            result = DecodeBandFSM16sNoGapWithPeaks(fsm, stream, (PIXEL16S *)rowptr, width, height, pitch, peakbase, peaklevel, 1);
        }
        else
        {
#if _DEBUG
            result = DecodeBandFSM16sNoGap(fsm, stream, (PIXEL16S *)rowptr, width, height, pitch, logfile);
#else
            result = DecodeBandFSM16sNoGap(fsm, stream, (PIXEL16S *)rowptr, width, height, pitch);
#endif
        }

        if (difference_coding)
        {
            int x, y;
            PIXEL *line = rowptr;

            for (y = 0; y < height; y++)
            {
                for (x = 1; x < width; x++)
                {
                    line[x] += line[x - 1];
                }
                line += pitch / 2;
            }
        }


        if (result)
        {
            // Call thread safe routine to update the band valid flags
            UpdateWaveletBandValidFlags(decoder, wavelet, band_index);
        }
    }

    assert(result == true);
    if (result != true)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }


    //end:
    STOP(tk_fastruns);

    return true;
}





bool SkipFastRunsFSM(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                     int band_index, int width, int height)
{
    //CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    int result;

    // Get the pointer to the finite state machine
    FSM *fsm = &decoder->fsm[decoder->codec.active_codebook]; //DAN20041026

    // All rows are treated as one long row that covers the entire band
    int size = fsm->table.num_states;

    PIXEL *rowptr;
    //int row = 0;
    int pitch;

    //int pixel_type = wavelet->pixel_type[band_index];

    decoder->codec.active_codebook = 0; // reset CODEC state

    // Must have a valid wavelet
    assert(wavelet != NULL);
    if (wavelet == NULL) return false;

    //Must have a valid FSM
    assert(fsm != NULL);
    if (fsm == NULL) return false;

    assert(size > 0);
    if (size == 0)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    // Check if the band is 8bit/pixel
    assert(wavelet->pixel_type[band_index] == PIXEL_TYPE_8S);

    START(tk_fastruns);

    rowptr = (PIXEL *)wavelet->band[band_index];
    pitch = wavelet->pitch8s;		// Use the 8-bit pitch

    // The finite state machine does not support a marker at the end of rows
#if RUNS_ROWEND_MARKER
    assert(0);
#endif


#if 1		// Get one byte from the bitstream and decode 4 bits at a time
    result = SkipBandFSM(fsm, stream, (PIXEL8S *)rowptr, width, height, pitch);

    assert(result == true);
    if (result != true)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

#endif

#if (0 && DEBUG && _WIN32)
    _CrtCheckMemory();
#endif

#if (0 && DEBUG)
    if (logfile)
        DumpBand("Band", wavelet, band_index, NULL, logfile);
#endif

    //end:
    STOP(tk_fastruns);

    return true;
}


// The third version is also based on the finite state machine decoder with
// gaps between rows encoded as zero runs, but dequantization is performed as
// the highpass values are read from the bitstream and placed into a row buffer.

// The highpass values are not written into the wavelet highpass band.

// Eventually this routine will be merged into the routine DecodeTemporalBand8s
// since this routine contains code specific to the inverse temporal transform
// and DecodeTemporalBand8s has become a shell.

#if 0
bool DecodeBandRunsFSM8s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                         int band_index, int width, int height,
                         IMAGE *frame0, IMAGE *frame1)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;
    FILE *logfile = decoder->logfile;
    int result;

    // Get the pointer to the finite state machine
    FSM *fsm = &decoder->fsm;

    // All rows are treated as one long row that covers the entire band
    int size = fsm->table.num_states;

    PIXEL *lowpass = wavelet->band[0];
    int lowpass_pitch = wavelet->pitch;
    //PIXEL8S *rowptr;
    int row = 0;
    int pitch;
    int row_width;		// Width of the encoded row of highpass coefficients

    PIXEL *even = frame0->band[0];
    PIXEL *odd = frame1->band[0];

    int even_pitch = frame0->pitch;
    int odd_pitch = frame1->pitch;

    int pixel_type = wavelet->pixel_type[band_index];
    int quantization = wavelet->quantization[band_index];
    PIXEL *buffer;
    size_t buffer_size;

    int index, byte;
    FSMENTRY *entry;
    int column = 0;
    int32_t value;
    int buffer_row_size;
    PIXEL *highpass;

    // Check that the wavelet into which the band will be decoded is valid
    assert(wavelet != NULL);
    if (wavelet == NULL) return false;

    // Check that the finite state machine is valid
    assert(fsm != NULL);
    if (fsm == NULL) return false;

    assert(size > 0);
    if (size == 0)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }

    // Check that the band was encoded using 8-bit signed coefficients
    assert(pixel_type == PIXEL_TYPE_8S);

    pitch = wavelet->pitch8s;		// Use the pitch for 8-bit packed rows

    // Get the buffer for storing one row of dequantized highpass coefficients
    buffer = (PIXEL *)decoder->buffer;
    buffer_size = decoder->buffer_size;

    // The finite state machine does not support a marker at the end of each row
    assert(RUNS_ROWEND_MARKER == 0);


    /***** Start of code included from DecodeBandFSM8s() *****/


    // Check that one byte can be processes as two 4-bit nibbles
    assert(BITSTREAM_WORD_SIZE == (2 * FSM_INDEX_SIZE));

    // Check that the bitstream buffer is empty
    assert(stream->nBitsFree == BITSTREAM_BUFFER_SIZE);

    // Convert the pitch to units of pixels
    pitch /= sizeof(PIXEL8S);

    buffer_row_size = pitch * sizeof(PIXEL);

    lowpass_pitch /= sizeof(PIXEL);
    even_pitch /= sizeof(PIXEL);
    odd_pitch /= sizeof(PIXEL);

    // Compute the address of the row after the last row in the band
    //maxptr = rowptr + height * pitch;

    // Round up the row length (in bytes) to a multiple of 16 bytes
    //row_size = ALIGN16(row_size);

    // Check that the buffer is large enough to hold one row
    //assert(buffer_size >= row_size);
    assert(buffer_size >= buffer_row_size);

    // Use the buffer for the row or highpass coefficients
    highpass = buffer;

#if 1
    // The row spans the allocated width (pitch) of the band in no gap mode
    row_width = pitch;
#else
    // For debugging
    row_width = wavelet->encoded_pitch / sizeof(PIXEL8S);
#endif

    // Clear the highpass buffer before decoding the non-zero coefficients
    ZeroHighPassRow(highpass, buffer_row_size);

    // Decode zero runs and magnitude values (with appended sign bit)
    // until the marker for the band end trailer has been decoded
    for (;;)
    {
        // Read a byte from the bitstream
        byte = GetFastByte(stream);


        /***** Decode the first 4-bit nibble *****/

        // Decode the first 4-bit nibble
        index = byte >> FSM_INDEX_SIZE;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return when the entire band is decoded
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Dequantize the highpass coefficients
            //DequantizeBandRow(rowptr, width, quantization, highpass);

            // Apply the inverse temporal transform to the current row
            InvertTemporalRow16s(lowpass, highpass, even, odd, width);

            // Advance to the next lowpass input row
            lowpass += lowpass_pitch;

            // Advance to the next even and odd output rows
            even += even_pitch;
            odd += odd_pitch;

            // Process the rest of the subband
            ZeroHighPassRow(highpass, buffer_row_size);
            while (++row < height)
            {
                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;
            }

            ResetFSM(fsm);
            return true;
        }

        // set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // If no magnitude value is decoded
        if (entry->value0 == 0)
        {
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= row_width)
            {
                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Compute the starting column for the next row
                column -= row_width;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);
            }
        }
        // If there is only one decoded magnitude value
        else if (entry->value1 == 0)
        {
            value = entry->value0;

            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= row_width)
            {
                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Compute the starting column for the next row
                column -= row_width;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            assert(0 <= column && column < row_width);

            // Dequantize the value and store it in the highpass row buffer
            highpass[column] = quantization * value;

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= row_width)
            {
                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Compute the starting column for the next row
                column -= row_width;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);
            }
        }
        // If there are two decoded magnitude values
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < row_width);

            if (column < (row_width - 1))
            {
                // Store both values in the current row
                highpass[column++] = quantization * entry->value0;
                highpass[column++] = quantization * entry->value1;
            }
            else
            {
                value = entry->value0;
                highpass[column] = quantization * value;

                value = entry->value1;

                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);

                column = 0;
                highpass[column++] = quantization * value;
            }
        }


        /***** Decode the second 4-bit nibble *****/

        // Decode the second 4-bit nibble
        index = byte & FSM_INDEX_MASK;

        // Index into the lookup table at that state
        entry = GetFSMTableEntry(fsm, index);

        // Return if the subband is decoded completely
        if (entry->value0 == BAND_END_TRAILER)
        {
            // Dequantize the highpass coefficients
            //DequantizeBandRow(rowptr, width, quantization, highpass);

            // Apply the inverse temporal transform to the current row
            InvertTemporalRow16s(lowpass, highpass, even, odd, width);

            // Advance to the next lowpass input row
            lowpass += lowpass_pitch;

            // Advance to the next even and odd output rows
            even += even_pitch;
            odd += odd_pitch;

            // Process the rest of the subband
            ZeroHighPassRow(highpass, buffer_row_size);
            while (++row < height)
            {
                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;
            }

            ResetFSM(fsm);
            return true;
        }

        // Set the pointer to the next state
        UpdateFSM(fsm, (int)entry->next_state);

        // If no magnitude value is decoded
        if (entry->value0 == 0)
        {
            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= row_width)
            {
                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Compute the starting column for the next row
                column -= row_width;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);
            }
        }
        // If there is only one decoded magnitude value
        else if (entry->value1 == 0)
        {
            value = entry->value0;

            column += entry->pre_skip;

            // The run length scan can go past the end of the row if the row ends
            // with a run of zeros and the next row begins with a run of zeros

            // Did the scan go beyond the end of the row?
            while (column >= row_width)
            {
                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Compute the starting column for the next row
                column -= row_width;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);
            }

            // Fill in the decoded magnitude

            // Check the column before storing the value
            //assert(index < width);
            assert(0 <= column && column < row_width);

            highpass[column] = quantization * value;

            column += entry->post_skip;

            // Did the scan go beyond the end of the row?
            if (column >= row_width)
            {
                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Compute the starting column for the next row
                column -= row_width;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);
            }
        }
        // If there are two decoded magnitude values
        else
        {
            // Check the column before storing values
            assert(0 <= column && column < row_width);

            if (column < (row_width - 1))
            {
                // Store both highpass values in the current row
                highpass[column++] = quantization * entry->value0;
                highpass[column++] = quantization * entry->value1;
            }
            else
            {
                highpass[column] = quantization * entry->value0;
                value = entry->value1;

                // Dequantize the highpass coefficients
                //DequantizeBandRow(rowptr, width, quantization, highpass);

                // Apply the inverse temporal transform to the current row
                InvertTemporalRow16s(lowpass, highpass, even, odd, width);

                // Advance to the next lowpass input row
                lowpass += lowpass_pitch;

                // Advance to the next even and odd output rows
                even += even_pitch;
                odd += odd_pitch;

                // Advance to the next row
                row++;

                // Clear the highpass buffer before decoding the non-zero coefficients
                ZeroHighPassRow(highpass, buffer_row_size);

                column = 0;
                highpass[column++] = quantization * value;
            }
        }
    }
    /***** End of the code included from DecodeBandFSM8s() *****/

#if 0
    assert(result == true);
    if (result != true)
    {
        decoder->error = CODEC_ERROR_RUN_DECODE;
        return false;
    }
#endif

#if (0 && DEBUG && _WIN32)
    _CrtCheckMemory();
#endif

#if (0 && DEBUG)
    if (logfile)
        DumpBand("Band", wavelet, band_index, NULL, logfile);
#endif

#if 0
end:

    return true;
#endif

}
#endif


/***** End of the code for the finite state machine decoder *****/


#if 1

// The second version applies the horizontal inverse filters row by row, so the
// memory access pattern is more efficient.  The lowpass and highpass temporal
// coefficients for each row are inverted and packed into the output in one pass.

// Apply the inverse horizontal-temporal transform and pack the output into a buffer

void TransformInverseFrameToYUV(TRANSFORM *transform[], int frame_index, int num_channels,
                                uint8_t *output, int output_pitch, FRAME_INFO *frame,
                                const SCRATCH *scratch, int chroma_offset, int precision)
{
    // Pointers to the rows in the horizontal wavelet for each channel
    PIXEL *horizontal_lowlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_lowhigh[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highhigh[TRANSFORM_MAX_CHANNELS];

    // Horizontal wavelet band width and pitch
    int horizontal_width[TRANSFORM_MAX_CHANNELS];
    int horizontal_pitch[TRANSFORM_MAX_CHANNELS];
    int horizontal_pitch8s[TRANSFORM_MAX_CHANNELS];

    // Quantization factors
    int lowlow_quantization[TRANSFORM_MAX_CHANNELS];
    int lowhigh_quantization[TRANSFORM_MAX_CHANNELS];
    int highlow_quantization[TRANSFORM_MAX_CHANNELS];
    int highhigh_quantization[TRANSFORM_MAX_CHANNELS];

    // Pointers to the rows in the temporal wavelet for each channel
    PIXEL *temporal_lowpass[TRANSFORM_MAX_CHANNELS];
    PIXEL *temporal_highpass[TRANSFORM_MAX_CHANNELS];

    // Push the scratch space state to allocate a new section
    char *buffer = scratch->free_ptr;
#if DEBUG
    size_t buffer_size = scratch->free_size;
#endif

    // Dimensions of the reconstructed frame
    int frame_width = frame->width;
    int frame_height = frame->height;
    int half_height = frame_height / 2;
    size_t temporal_row_size = frame_width * sizeof(PIXEL);
    int field_pitch = 2 * output_pitch;
    int output_width;
    int channel;
    int row;

    // Round up the temporal row size to an integral number of cache lines
    temporal_row_size = ALIGN(temporal_row_size, _CACHE_LINE_SIZE);

    // Check that the buffer starts on a cache line boundary
    assert(ISALIGNED(buffer, _CACHE_LINE_SIZE));

    // Check that the number of channels is reasonable
    assert(0 < num_channels && num_channels <= TRANSFORM_MAX_CHANNELS);

    // Check that the buffer is large enough
#if DEBUG
    assert((2 * num_channels * temporal_row_size) <= buffer_size);
#endif

    // Allocate buffers for a single row of lowpass and highpass temporal coefficients
    // and initialize the arrays of row pointers into the horizontal transform bands
    for (channel = 0; channel < num_channels; channel++)
    {
        IMAGE *wavelet = transform[channel]->wavelet[frame_index];

#if (0 && DEBUG)
        int static count = 0;
        if (count < 20)
        {
            char label[_MAX_PATH];
            int i;

            sprintf(label, "Frame%d-%d-", frame_index, count);
            DumpPGM(label, wavelet, NULL);

            for (i = 1; i < wavelet->num_bands; i++)
            {
                sprintf(label, "Frame-%d-band%d-%d-", frame_index, i, count);
                DumpBandPGM(label, wavelet, i, NULL);
            }
        }
        count++;
#endif
        // Initialize the row pointers into the horizontal bands
        horizontal_lowlow[channel] = wavelet->band[LL_BAND];
        horizontal_lowhigh[channel] = wavelet->band[LH_BAND];
        horizontal_highlow[channel] = wavelet->band[HL_BAND];
        horizontal_highhigh[channel] = wavelet->band[HH_BAND];

        lowlow_quantization[channel] = wavelet->quantization[LL_BAND];
        lowhigh_quantization[channel] = wavelet->quantization[LH_BAND];
        highlow_quantization[channel] = wavelet->quantization[HL_BAND];
        highhigh_quantization[channel] = wavelet->quantization[HH_BAND];

        // Compute the pitch in units of pixels
        horizontal_pitch[channel] = wavelet->pitch / sizeof(PIXEL);

        // Compute the 8-bit pitch in units of pixels
        horizontal_pitch8s[channel] = wavelet->pitch8s / sizeof(PIXEL);
        //horizontal_pitch8s[channel] = wavelet->pitch8s/sizeof(PIXEL8S);

        // Remember the width of the horizontal wavelet rows for this channel
        horizontal_width[channel] = wavelet->width;

        //TODO: Need to recode the buffer allocations using the scratch space API

        // Divide the buffer into temporal lowpass and highpass rows
        temporal_lowpass[channel] = (PIXEL *)(buffer + (2 * channel) * temporal_row_size);
        temporal_highpass[channel] = (PIXEL *)(buffer + (2 * channel + 1) * temporal_row_size);
    }

    // Process one row at a time from each channel
    for (row = 0; row < half_height; row++)
    {
        PIXEL *line_buffer = (PIXEL *)(buffer + (2 * num_channels + 2) * temporal_row_size);

        // Invert the horizontal transform applied to the temporal bands in each channel
        for (channel = 0; channel < num_channels; channel++)
        {
            int pitch = horizontal_pitch[channel];
            //int pitch8s = horizontal_pitch8s[channel];

            // Invert the horizontal transform applied to the temporal lowpass row
            InvertHorizontalRow16s8sTo16sBuffered(horizontal_lowlow[channel], lowlow_quantization[channel],
                                                  (PIXEL8S *)horizontal_lowhigh[channel], lowhigh_quantization[channel],
                                                  temporal_lowpass[channel],
                                                  horizontal_width[channel],
                                                  (PIXEL *)line_buffer);

            // Invert the horizontal transform applied to the temporal highpass row
            //DAN20051004 -- possible reversiblity issue
            //InvertHorizontalRow8sBuffered //----------------------- Maybe bad
            InvertHorizontalRow16s8sTo16sBuffered(horizontal_highlow[channel], highlow_quantization[channel],
                                                  (PIXEL8S *)horizontal_highhigh[channel], highhigh_quantization[channel],
                                                  temporal_highpass[channel],
                                                  horizontal_width[channel],
                                                  (PIXEL *)line_buffer);

            // Advance to the next row in each horizontal band in this channel
            horizontal_lowlow[channel] += pitch;
            horizontal_lowhigh[channel] += pitch;
            horizontal_highlow[channel] += pitch;
            horizontal_highhigh[channel] += pitch;
        }

        // The output width is twice the width of the wavelet bands
        output_width = 2 * horizontal_width[0];

        // Adjust the frame width to fill to the end of each row
        //frame_width = output_pitch / 2;

        if (precision == CODEC_PRECISION_10BIT)
        {
            // Invert the temporal bands from all channels and pack output pixels
            switch (frame->format)
            {
                // Need to reduce the resolution from 10 bits to 8 bits during the inverse

                case DECODED_FORMAT_YUYV:
                    InvertInterlacedRow16s10bitToYUV(temporal_lowpass, temporal_highpass, num_channels,
                                                     output, output_pitch, output_width, frame_width,
                                                     chroma_offset);
                    break;

                case DECODED_FORMAT_UYVY:
                    InvertInterlacedRow16s10bitToUYVY(temporal_lowpass, temporal_highpass, num_channels,
                                                      output, output_pitch, output_width, frame_width,
                                                      chroma_offset);
                    break;

                default:
                    assert(0);
                    break;
            }
        }

        else	// Older code for 8-bit precision
        {
            int format;

            assert(precision == CODEC_PRECISION_8BIT);

            switch (frame->format)
            {
                case DECODED_FORMAT_YUYV:
                    format = COLOR_FORMAT_YUYV;
                    break;

                case DECODED_FORMAT_UYVY:
                    format = COLOR_FORMAT_UYVY;
                    break;
            }

            // Invert the temporal bands from all channels and pack output pixels
            InvertInterlacedRow16sToYUV(temporal_lowpass, temporal_highpass, num_channels,
                                        output, output_pitch, output_width, frame_width,
                                        chroma_offset, format);
        }

        // Advance to the next row in the packed output image
        output += field_pitch;
    }
}

#endif


#if _INTERLACED_WORKER_THREADS
void TransformInverseFrameSectionToYUV(DECODER *decoder, int thread_index, int frame_index, int num_channels,
                                       uint8_t *output, int output_pitch, FRAME_INFO *frame,
                                       int chroma_offset, int precision)
{
    FILE *logfile = decoder->logfile;
    TRANSFORM **transform = decoder->transform;
    const SCRATCH *scratch = &decoder->scratch;

    // Pointers to the rows in the horizontal wavelet for each channel
    PIXEL *horizontal_lowlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_lowhigh[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highhigh[TRANSFORM_MAX_CHANNELS];

    // Horizontal wavelet band width and pitch
    int horizontal_width[TRANSFORM_MAX_CHANNELS];
    int horizontal_pitch[TRANSFORM_MAX_CHANNELS];
    int horizontal_pitch8s[TRANSFORM_MAX_CHANNELS];

    // Quantization factors
    int lowlow_quantization[TRANSFORM_MAX_CHANNELS];
    int lowhigh_quantization[TRANSFORM_MAX_CHANNELS];
    int highlow_quantization[TRANSFORM_MAX_CHANNELS];
    int highhigh_quantization[TRANSFORM_MAX_CHANNELS];

    // Pointers to the rows in the temporal wavelet for each channel
    PIXEL *temporal_lowpass[TRANSFORM_MAX_CHANNELS];
    PIXEL *temporal_highpass[TRANSFORM_MAX_CHANNELS];

    // Push the scratch space state to allocate a new section
    char *buffer = scratch->free_ptr;
    size_t buffer_size = scratch->free_size;
    uint8_t *output_row_ptr = output;

    // Dimensions of the reconstructed frame
    int frame_width = frame->width;
    int frame_height = frame->height;
    int half_height = frame_height / 2;
    size_t temporal_row_size = frame_width * sizeof(PIXEL);
    int field_pitch = 2 * output_pitch;
    int output_width;
    int channel;
    int row;

    HANDLE row_semaphore = decoder->interlaced_worker.row_semaphore;

    int return_value;

    // Round up the temporal row size to an integral number of cache lines
    temporal_row_size = ALIGN(temporal_row_size, _CACHE_LINE_SIZE);

    // Divide the buffer space between the four threads
    buffer_size /= 4;
    buffer += buffer_size * thread_index;

    // Check that the buffer starts on a cache line boundary
    assert(ISALIGNED(buffer, _CACHE_LINE_SIZE));

    // Check that the number of channels is reasonable
    assert(0 < num_channels && num_channels <= TRANSFORM_MAX_CHANNELS);

    // Check that the buffer is large enough
    assert((2 * num_channels * temporal_row_size) <= buffer_size);

    // Allocate buffers for a single row of lowpass and highpass temporal coefficients
    // and initialize the arrays of row pointers into the horizontal transform bands
    for (channel = 0; channel < num_channels; channel++)
    {
        IMAGE *wavelet = transform[channel]->wavelet[frame_index];

#if (0 && DEBUG)
        int static count = 0;
        if (count < 20)
        {
            char label[_MAX_PATH];
            int i;

            sprintf(label, "Frame%d-%d-", frame_index, count);
            DumpPGM(label, wavelet, NULL);

            for (i = 1; i < wavelet->num_bands; i++)
            {
                sprintf(label, "Frame-%d-band%d-%d-", frame_index, i, count);
                DumpBandPGM(label, wavelet, i, NULL);
            }
        }
        count++;
#endif
        // Initialize the row pointers into the horizontal bands
        horizontal_lowlow[channel] = wavelet->band[LL_BAND];
        horizontal_lowhigh[channel] = wavelet->band[LH_BAND];
        horizontal_highlow[channel] = wavelet->band[HL_BAND];
        horizontal_highhigh[channel] = wavelet->band[HH_BAND];

        lowlow_quantization[channel] = wavelet->quantization[LL_BAND];
        lowhigh_quantization[channel] = wavelet->quantization[LH_BAND];
        highlow_quantization[channel] = wavelet->quantization[HL_BAND];
        highhigh_quantization[channel] = wavelet->quantization[HH_BAND];

        // Compute the pitch in units of pixels
        horizontal_pitch[channel] = wavelet->pitch / sizeof(PIXEL);

        // Compute the 8-bit pitch in units of pixels
        horizontal_pitch8s[channel] = wavelet->pitch8s / sizeof(PIXEL);
        //horizontal_pitch8s[channel] = wavelet->pitch8s/sizeof(PIXEL8S);

        // Remember the width of the horizontal wavelet rows for this channel
        horizontal_width[channel] = wavelet->width;

        //TODO: Need to recode the buffer allocations using the scratch space API

        // Divide the buffer into temporal lowpass and highpass rows
        temporal_lowpass[channel] = (PIXEL *)(buffer + (2 * channel) * temporal_row_size);
        temporal_highpass[channel] = (PIXEL *)(buffer + (2 * channel + 1) * temporal_row_size);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Output buffer: %d (0x%p)\n", output, output);
    }
#endif

    /*	if (thread_index == 0)
    	{
    		row = 0;
    		row_step = 1;
    	}
    	else if (thread_index == 1)
    	{
    		row = half_height - 1;
    		row_step = -1;

    		// Move to the bottom of the transform and process moving up
    		for (channel = 0; channel < num_channels; channel++)
    		{
    			int offset = horizontal_pitch[channel] * (half_height - 1);

    			horizontal_lowlow[channel] += offset;
    			horizontal_lowhigh[channel] += offset;
    			horizontal_highlow[channel] += offset;
    			horizontal_highhigh[channel] += offset;

    			horizontal_pitch[channel] = NEG(horizontal_pitch[channel]);
    			horizontal_pitch8s[channel] = NEG(horizontal_pitch8s[channel]);
    		}

    		output += field_pitch * (half_height - 1);

    		field_pitch = NEG(field_pitch);
    	}
    	else
    	{
    		assert(0); // what about middle threads?
    	}

    #if (0 && DEBUG)
    	if (logfile) {
    		fprintf(logfile, "Thread index: %d, start row: %d, row step: %d, field_pitch: %d\n",
    				thread_index, row, row_step, field_pitch);
    	}
    #endif
    */
    // Loop until all of the rows have been processed
    for (;;)
    {
        // Wait for one row from each channel to invert the transform
        return_value = WaitForSingleObject(row_semaphore, 0);

        // Determine the index of this worker thread
        if (return_value == WAIT_OBJECT_0)
        {
            if (decoder->interlaced_worker.lock_init)
            {
                EnterCriticalSection(&decoder->interlaced_worker.lock);
            }
            row = decoder->interlaced_worker.current_row++;

            if (decoder->interlaced_worker.lock_init)
                LeaveCriticalSection(&decoder->interlaced_worker.lock);

            output_row_ptr = output;
            output_row_ptr += row * 2 * output_pitch;

            for (channel = 0; channel < num_channels; channel++)
            {
                int pitch = horizontal_pitch[channel];
                IMAGE *wavelet = transform[channel]->wavelet[frame_index];

                horizontal_lowlow[channel] = wavelet->band[LL_BAND];
                horizontal_lowhigh[channel] = wavelet->band[LH_BAND];
                horizontal_highlow[channel] = wavelet->band[HL_BAND];
                horizontal_highhigh[channel] = wavelet->band[HH_BAND];

                horizontal_lowlow[channel] += pitch * row;
                horizontal_lowhigh[channel] += pitch * row;
                horizontal_highlow[channel] += pitch * row;
                horizontal_highhigh[channel] += pitch * row;
            }
        }

        if (return_value == WAIT_OBJECT_0 && 0 <= row && row < half_height)
        {
            //PIXEL *line_buffer = (PIXEL *)(buffer + (2 * num_channels + 2) * temporal_row_size);
            PIXEL *line_buffer = (PIXEL *)(buffer + 2 * num_channels * temporal_row_size);

            //	assert(0 <= row && row < half_height);

#if (0 && DEBUG)
            if (logfile)
            {
                fprintf(logfile, "Processing row: %d, thread index: %d, output: %d (0x%p)\n",
                        row, thread_index, output_row_ptr);
            }
#endif
            // Invert the horizontal transform applied to the temporal bands in each channel
            for (channel = 0; channel < num_channels; channel++)
            {
                int pitch = horizontal_pitch[channel];
                //int pitch8s = horizontal_pitch8s[channel];

#if (0 && DEBUG)
                // Invert the horizontal transform by duplicating the lowpass pixels
                InvertHorizontalRowDuplicated16s(horizontal_lowlow[channel], lowlow_quantization[channel],
                                                 (PIXEL8S *)horizontal_lowhigh[channel], lowhigh_quantization[channel],
                                                 temporal_lowpass[channel], horizontal_width[channel],
                                                 (PIXEL *)line_buffer);
#else
                // Invert the horizontal transform applied to the temporal lowpass row
                InvertHorizontalRow16s8sTo16sBuffered(horizontal_lowlow[channel], lowlow_quantization[channel],
                                                      (PIXEL8S *)horizontal_lowhigh[channel], lowhigh_quantization[channel],
                                                      temporal_lowpass[channel],
                                                      horizontal_width[channel],
                                                      (PIXEL *)line_buffer);
#endif
                // Invert the horizontal transform applied to the temporal highpass row
                InvertHorizontalRow8sBuffered((PIXEL8S *)horizontal_highlow[channel], highlow_quantization[channel],
                                              (PIXEL8S *)horizontal_highhigh[channel], highhigh_quantization[channel],
                                              temporal_highpass[channel],
                                              horizontal_width[channel],
                                              (PIXEL *)line_buffer);

                // Advance to the next row in each horizontal band in this channel
                //horizontal_lowlow[channel] += pitch;
                //horizontal_lowhigh[channel] += pitch;
                //horizontal_highlow[channel] += pitch;
                //horizontal_highhigh[channel] += pitch;
            }

            // The output width is twice the width of the wavelet bands
            output_width = 2 * horizontal_width[0];

            // Adjust the frame width to fill to the end of each row
            //frame_width = output_pitch / 2;

            if (precision == CODEC_PRECISION_10BIT)
            {
                // Invert the temporal bands from all channels and pack output pixels
                switch (frame->format)
                {
                    // Need to reduce the resolution from 10 bits to 8 bits during the inverse

                    case DECODED_FORMAT_YUYV:
                        InvertInterlacedRow16s10bitToYUV(temporal_lowpass, temporal_highpass, num_channels,
                                                         output_row_ptr, output_pitch, output_width, frame_width,
                                                         chroma_offset);
                        break;

                    case DECODED_FORMAT_UYVY:
                        InvertInterlacedRow16s10bitToUYVY(temporal_lowpass, temporal_highpass, num_channels,
                                                          output_row_ptr, output_pitch, output_width, frame_width,
                                                          chroma_offset);
                        break;

                    default:
                        assert(0);
                        break;
                }
            }

            else	// Older code for 8-bit precision
            {
                int format;

                assert(precision == CODEC_PRECISION_8BIT);

                switch (frame->format)
                {
                    case DECODED_FORMAT_YUYV:
                        format = COLOR_FORMAT_YUYV;
                        break;

                    case DECODED_FORMAT_UYVY:
                        format = COLOR_FORMAT_UYVY;
                        break;
                }

                // Invert the temporal bands from all channels and pack output pixels
                InvertInterlacedRow16sToYUV(temporal_lowpass, temporal_highpass, num_channels,
                                            output_row_ptr, output_pitch, output_width, frame_width,
                                            chroma_offset, format);
            }

            // Advance to the next row in the input transforms
            //row += row_step;

            // Advance to the next row in the packed output image
            //output += field_pitch;
        }
        else
        {
            // No more rows to process
            break;
        }
    }

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Finished transform, thread index: %d\n", thread_index);
    }
#endif
}

#endif


//#if BUILD_PROSPECT
// Apply the inverse horizontal-temporal transform and output rows of luma and chroma
#if 0
void TransformInverseFrameToRow16u(TRANSFORM *transform[], int frame_index, int num_channels,
                                   PIXEL16U *output, int output_pitch, FRAME_INFO *frame,
                                   char *buffer, size_t buffer_size, int chroma_offset,
                                   int precision)
#else
void TransformInverseFrameToRow16u(DECODER *decoder, TRANSFORM *transform[], int frame_index, int num_channels,
                                   PIXEL16U *output, int output_pitch, FRAME_INFO *frame,
                                   const SCRATCH *scratch, int chroma_offset,
                                   int precision)
#endif
{
    // Pointers to the rows in the horizontal wavelet for each channel
    PIXEL *horizontal_lowlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_lowhigh[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highhigh[TRANSFORM_MAX_CHANNELS];

    // Horizontal wavelet band width and pitch
    int horizontal_width[TRANSFORM_MAX_CHANNELS];
    int horizontal_pitch[TRANSFORM_MAX_CHANNELS];

    // Quantization factors
    int lowlow_quantization[TRANSFORM_MAX_CHANNELS];
    int lowhigh_quantization[TRANSFORM_MAX_CHANNELS];
    int highlow_quantization[TRANSFORM_MAX_CHANNELS];
    int highhigh_quantization[TRANSFORM_MAX_CHANNELS];

    // Push the scratch space state to allocate a new section
    char *buffer = scratch->free_ptr;
#if DEBUG
    size_t buffer_size = scratch->free_size;
#endif
    // Buffers for the rows in the temporal wavelet (reused for each channel)
    PIXEL *temporal_lowpass;
    PIXEL *temporal_highpass;

    int output_row_width[TRANSFORM_MAX_CHANNELS];

    // Dimensions of the reconstructed frame
    int frame_width = frame->width;
    int frame_height = frame->height;
    int half_height = frame_height / 2;
    size_t temporal_row_size = frame_width * sizeof(PIXEL);
    int field_pitch = 2 * output_pitch;

    int luma_width = frame_width;
    int chroma_width = luma_width / 2;

    int channel;
    int row;

#if (1 && DEBUG_ROW16U)
    PIXEL16U *output_buffer;
#endif

    // This routine should only be called to decode rows of 16-bit luma and chroma
    //assert(frame->format == DECODED_FORMAT_YR16);

    // Round up the temporal row size to an integral number of cache lines
    temporal_row_size = ALIGN(temporal_row_size, _CACHE_LINE_SIZE);

    // Check that the buffer starts on a cache line boundary
    assert(ISALIGNED(buffer, _CACHE_LINE_SIZE));

    // Check that the number of channels is reasonable
    assert(0 < num_channels && num_channels <= TRANSFORM_MAX_CHANNELS);

    // Buffer must be large enough for two rows of temporal coefficients (lowpass and highpass)
    // plus the buffer used by the inverse horizontal transform for its intermediate results
#if DEBUG
    assert((2 * temporal_row_size) <= buffer_size);
#endif

    // Allocate buffers for one row of lowpass and highpass temporal coefficients
    temporal_lowpass = (PIXEL *)&buffer[0];
    temporal_highpass = (PIXEL *)&buffer[temporal_row_size];

#if (1 && DEBUG_ROW16U)
    output_buffer = (PIXEL16U *)&buffer[2 * temporal_row_size];
#endif

    // Initialize the arrays of row pointers into the horizontal transform bands
    for (channel = 0; channel < num_channels; channel++)
    {
        IMAGE *wavelet = transform[channel]->wavelet[frame_index];

#if (0 && DEBUG)
        int static count = 0;
        if (count < 20)
        {
            char label[_MAX_PATH];
            int i;

            sprintf(label, "Frame%d-%d-", frame_index, count);
            DumpPGM(label, wavelet, NULL);

            for (i = 1; i < wavelet->num_bands; i++)
            {
                sprintf(label, "Frame-%d-band%d-%d-", frame_index, i, count);
                DumpBandPGM(label, wavelet, i, NULL);
            }
        }
        count++;
#endif
        // Initialize the row pointers into the horizontal bands
        horizontal_lowlow[channel] = wavelet->band[LL_BAND];
        horizontal_lowhigh[channel] = wavelet->band[LH_BAND];
        horizontal_highlow[channel] = wavelet->band[HL_BAND];
        horizontal_highhigh[channel] = wavelet->band[HH_BAND];

        lowlow_quantization[channel] = wavelet->quantization[LL_BAND];
        lowhigh_quantization[channel] = wavelet->quantization[LH_BAND];
        highlow_quantization[channel] = wavelet->quantization[HL_BAND];
        highhigh_quantization[channel] = wavelet->quantization[HH_BAND];

        // Compute the pitch in units of pixels
        horizontal_pitch[channel] = wavelet->pitch / sizeof(PIXEL);

        // Remember the width of the horizontal wavelet rows for this channel
        horizontal_width[channel] = wavelet->width;

        // Compute the width of each row of output pixels
        output_row_width[channel] = (channel == 0) ? luma_width : chroma_width;
    }

    // Process one row at a time from each channel
    for (row = 0; row < half_height; row++)
    {
#if (1 && DEBUG_ROW16U)
        PIXEL16U *output_row_ptr = output_buffer;
        PIXEL16U *planar_output[TRANSFORM_MAX_CHANNELS];
        int planar_pitch[TRANSFORM_MAX_CHANNELS];
        ROI strip = {luma_width, 2};
        uint8_t *yuv_output = (uint8_t *)output;
        uint8_t *output1 = yuv_output;
        uint8_t *output2 = yuv_output + output_pitch;
#else
        PIXEL16U *output_row_ptr = output;
#endif
        // Invert the horizontal transform applied to the temporal bands in each channel
        for (channel = 0; channel < num_channels; channel++)
        {
            int pitch = horizontal_pitch[channel];

            if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
            {
                // Invert the horizontal transform applied to the temporal lowpass row
                BypassHorizontalRow16s(horizontal_lowlow[channel], horizontal_lowhigh[channel],
                                       temporal_lowpass, horizontal_width[channel]);

                // Invert the horizontal transform applied to the temporal highpass row
                BypassHorizontalRow16s(horizontal_highlow[channel], horizontal_highhigh[channel],
                                       temporal_highpass, horizontal_width[channel]);
            }
            else
            {
                // Invert the horizontal transform applied to the temporal lowpass row
                InvertHorizontalRow16s(horizontal_lowlow[channel], horizontal_lowhigh[channel],
                                       temporal_lowpass, horizontal_width[channel]);

                // Invert the horizontal transform applied to the temporal highpass row
                InvertHorizontalRow16s(horizontal_highlow[channel], horizontal_highhigh[channel],
                                       temporal_highpass, horizontal_width[channel]);
            }

            //***DEBUG***
            //ZeroMemory(temporal_highpass, temporal_row_size);
            //FillPixelMemory(temporal_highpass, temporal_row_size/sizeof(PIXEL), 50);

            // Advance to the next row in each horizontal band in this channel
            horizontal_lowlow[channel] += pitch;
            horizontal_lowhigh[channel] += pitch;
            horizontal_highlow[channel] += pitch;
            horizontal_highhigh[channel] += pitch;

#if (1 && DEBUG_ROW16U)
            // Write the rows of 16-bit pixels to a temporary buffer
            planar_output[channel] = output_row_ptr;
            planar_pitch[channel] = output_pitch * sizeof(PIXEL);

            // Invert the temporal transform and output two rows of luma or chroma
            InvertInterlacedRow16sToRow16u(temporal_lowpass, temporal_highpass,
                                           planar_output[channel], planar_pitch[channel],
                                           output_row_width[channel],
                                           frame_width, chroma_offset, precision);
            //if (channel > 0)
            if (0)
            {
                uint8_t *output3 = (uint8_t *)planar_output[channel];
                uint8_t *output4 = (uint8_t *)output3 + planar_pitch[channel];
                int output_size = output_row_width[channel] * sizeof(PIXEL);
                int fill_value = (128 << 8);
                //ZeroMemory(output3, output_size);
                //ZeroMemory(output4, output_size);
                FillPixelMemory((PIXEL *)output3, output_row_width[channel], fill_value);
                FillPixelMemory((PIXEL *)output4, output_row_width[channel], fill_value);
            }
#else
            // Invert the temporal transform and output two rows of luma or chroma
            InvertInterlacedRow16sToRow16u(temporal_lowpass, temporal_highpass,
                                           output_row_ptr, output_pitch, output_row_width[channel],
                                           frame_width, chroma_offset, precision);
#endif
            // Advance the output row pointer to the next channel
            output_row_ptr += output_row_width[channel];

            // Check the output row alignment
            assert(ISALIGNED16(output_row_ptr));
        }

        // Advance to the next group of rows in the output image
        output += field_pitch / sizeof(PIXEL16U);
    }
}
//#endif


#if _INTERLACED_WORKER_THREADS

void TransformInverseFrameSectionToRow16u(DECODER *decoder, int thread_index, int frame_index, int num_channels,
        PIXEL16U *output, int output_pitch, FRAME_INFO *frame,
        int chroma_offset, int precision)
{
    FILE *logfile = decoder->logfile;
    TRANSFORM **transform = decoder->transform;
    const SCRATCH *scratch = &decoder->scratch;

    // Pointers to the rows in the horizontal wavelet for each channel
    PIXEL *horizontal_lowlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_lowhigh[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highhigh[TRANSFORM_MAX_CHANNELS];

    // Horizontal wavelet band width and pitch
    int horizontal_width[TRANSFORM_MAX_CHANNELS];
    int horizontal_pitch[TRANSFORM_MAX_CHANNELS];

    // Quantization factors
    int lowlow_quantization[TRANSFORM_MAX_CHANNELS];
    int lowhigh_quantization[TRANSFORM_MAX_CHANNELS];
    int highlow_quantization[TRANSFORM_MAX_CHANNELS];
    int highhigh_quantization[TRANSFORM_MAX_CHANNELS];

    // Push the scratch space state to allocate a new section
    char *buffer = scratch->free_ptr;
    size_t buffer_size = scratch->free_size;

    // Buffers for the rows in the temporal wavelet (reused for each channel)
    PIXEL *temporal_lowpass;
    PIXEL *temporal_highpass;

    int output_row_width[TRANSFORM_MAX_CHANNELS];

    // Dimensions of the reconstructed frame
    int frame_width = frame->width;
    int frame_height = frame->height;
    int half_height = frame_height / 2;
    size_t temporal_row_size = frame_width * sizeof(PIXEL);
    int field_pitch = 2 * output_pitch;

    int luma_width = frame_width;
    int chroma_width = luma_width / 2;

    int channel;
    int row;

    HANDLE row_semaphore = decoder->interlaced_worker.row_semaphore;

    int return_value;

#if (1 && DEBUG_ROW16U)
    PIXEL16U *output_buffer;
#endif

    // This routine should only be called to decode rows of 16-bit luma and chroma
    //assert(frame->format == DECODED_FORMAT_YR16);

    // Round up the temporal row size to an integral number of cache lines
    temporal_row_size = ALIGN(temporal_row_size, _CACHE_LINE_SIZE);

#if 0
    if (thread_index == 1)
    {
        // Skip over the buffer space used by the other thread
        size_t buffer_usage = 2 * temporal_row_size;
        buffer += buffer_usage;
        buffer_size -= buffer_usage;
    }
#else
    // Divide the buffer space between the two threads
    buffer_size /= 4;
    buffer += buffer_size * thread_index;
#endif

    // Check that the buffer starts on a cache line boundary
    assert(ISALIGNED(buffer, _CACHE_LINE_SIZE));

    // Check that the number of channels is reasonable
    assert(0 < num_channels && num_channels <= TRANSFORM_MAX_CHANNELS);

    // Buffer must be large enough for two rows of temporal coefficients (lowpass and highpass)
    // plus the buffer used by the inverse horizontal transform for its intermediate results
    assert((2 * temporal_row_size) <= buffer_size);

    // Allocate buffers for one row of lowpass and highpass temporal coefficients
    temporal_lowpass = (PIXEL *)&buffer[0];
    temporal_highpass = (PIXEL *)&buffer[temporal_row_size];

#if (1 && DEBUG_ROW16U)
    output_buffer = (PIXEL16U *)&buffer[2 * temporal_row_size];
#endif

    // Initialize the arrays of row pointers into the horizontal transform bands
    for (channel = 0; channel < num_channels; channel++)
    {
        IMAGE *wavelet = transform[channel]->wavelet[frame_index];

#if (0 && DEBUG)
        int static count = 0;
        if (count < 20)
        {
            char label[_MAX_PATH];
            int i;

            sprintf(label, "Frame%d-%d-", frame_index, count);
            DumpPGM(label, wavelet, NULL);

            for (i = 1; i < wavelet->num_bands; i++)
            {
                sprintf(label, "Frame-%d-band%d-%d-", frame_index, i, count);
                DumpBandPGM(label, wavelet, i, NULL);
            }
        }
        count++;
#endif
        // Initialize the row pointers into the horizontal bands
        horizontal_lowlow[channel] = wavelet->band[LL_BAND];
        horizontal_lowhigh[channel] = wavelet->band[LH_BAND];
        horizontal_highlow[channel] = wavelet->band[HL_BAND];
        horizontal_highhigh[channel] = wavelet->band[HH_BAND];

        lowlow_quantization[channel] = wavelet->quantization[LL_BAND];
        lowhigh_quantization[channel] = wavelet->quantization[LH_BAND];
        highlow_quantization[channel] = wavelet->quantization[HL_BAND];
        highhigh_quantization[channel] = wavelet->quantization[HH_BAND];

        // Compute the pitch in units of pixels
        horizontal_pitch[channel] = wavelet->pitch / sizeof(PIXEL);

        // Remember the width of the horizontal wavelet rows for this channel
        horizontal_width[channel] = wavelet->width;

        // Compute the width of each row of output pixels
        output_row_width[channel] = (channel == 0) ? luma_width : chroma_width;
    }

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Output buffer: %d (0x%p)\n", output, output);
    }
#endif

    /*	if (thread_index == 0)
    	{
    		row = 0;
    		row_step = 1;
    	}
    	else if (thread_index == 1)
    	{
    		row = half_height - 1;
    		row_step = -1;

    		// Move to the bottom of the transform and process moving up
    		for (channel = 0; channel < num_channels; channel++)
    		{
    			int offset = horizontal_pitch[channel] * (half_height - 1);

    			horizontal_lowlow[channel] += offset;
    			horizontal_lowhigh[channel] += offset;
    			horizontal_highlow[channel] += offset;
    			horizontal_highhigh[channel] += offset;

    			horizontal_pitch[channel] = NEG(horizontal_pitch[channel]);
    			//horizontal_pitch8s[channel] = NEG(horizontal_pitch8s[channel]);
    		}

    		//output += field_pitch * (half_height - 1);
    		output += (frame_height - 1) * output_pitch/sizeof(PIXEL16U);
    		output_pitch = NEG(output_pitch);
    		field_pitch = NEG(field_pitch);
    	}
    	else
    	{
    		assert(0); // middle threads
    	}
    	*/
#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Thread index: %d, start row: %d, row step: %d, field_pitch: %d\n",
                thread_index, row, row_step, field_pitch);
    }
#endif

    // Loop until all of the rows have been processed
    for (;;)
    {
        PIXEL16U *output_row_ptr;
        // Wait for one row from each channel to invert the transform
        return_value = WaitForSingleObject(row_semaphore, 0);

        // Determine the index of this worker thread
        if (return_value == WAIT_OBJECT_0)
        {
            if (decoder->interlaced_worker.lock_init)
            {
                EnterCriticalSection(&decoder->interlaced_worker.lock);
            }
            row = decoder->interlaced_worker.current_row++;

            if (decoder->interlaced_worker.lock_init)
                LeaveCriticalSection(&decoder->interlaced_worker.lock);

            output_row_ptr = output;
            output_row_ptr += row * output_pitch;

            for (channel = 0; channel < num_channels; channel++)
            {
                int pitch = horizontal_pitch[channel];
                IMAGE *wavelet = transform[channel]->wavelet[frame_index];

                horizontal_lowlow[channel] = wavelet->band[LL_BAND];
                horizontal_lowhigh[channel] = wavelet->band[LH_BAND];
                horizontal_highlow[channel] = wavelet->band[HL_BAND];
                horizontal_highhigh[channel] = wavelet->band[HH_BAND];

                horizontal_lowlow[channel] += pitch * row;
                horizontal_lowhigh[channel] += pitch * row;
                horizontal_highlow[channel] += pitch * row;
                horizontal_highhigh[channel] += pitch * row;
            }
        }

        if (return_value == WAIT_OBJECT_0 && 0 <= row && row < half_height)
        {
            assert(0 <= row && row < half_height);

            if (decoder->frame.resolution == DECODED_RESOLUTION_FULL)
            {
                // Invert the horizontal transform applied to the temporal bands in each channel
                for (channel = 0; channel < num_channels; channel++)
                {
                    int pitch = horizontal_pitch[channel];

                    // Invert the horizontal transform applied to the temporal lowpass row
                    InvertHorizontalRow16s(horizontal_lowlow[channel], horizontal_lowhigh[channel],
                                           temporal_lowpass, horizontal_width[channel]);

                    // Invert the horizontal transform applied to the temporal highpass row
                    InvertHorizontalRow16s(horizontal_highlow[channel], horizontal_highhigh[channel],
                                           temporal_highpass, horizontal_width[channel]);

                    // Invert the temporal transform and output two rows of luma or chroma
                    InvertInterlacedRow16sToRow16u(temporal_lowpass, temporal_highpass,
                                                   output_row_ptr, output_pitch, output_row_width[channel],
                                                   frame_width, chroma_offset, precision);

                    // Advance the output row pointer to the next channel
                    output_row_ptr += output_row_width[channel];
                }
            }
            else if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
            {
                // Invert the horizontal transform applied to the temporal bands in each channel
                for (channel = 0; channel < num_channels; channel++)
                {
                    int pitch = horizontal_pitch[channel];

                    // Invert the horizontal transform applied to the temporal lowpass row
                    BypassHorizontalRow16s(horizontal_lowlow[channel], horizontal_lowhigh[channel],
                                           temporal_lowpass, horizontal_width[channel]);

                    // Invert the horizontal transform applied to the temporal highpass row
                    BypassHorizontalRow16s(horizontal_highlow[channel], horizontal_highhigh[channel],
                                           temporal_highpass, horizontal_width[channel]);

                    // Invert the temporal transform and output two rows of luma or chroma
                    InvertInterlacedRow16sToRow16u(temporal_lowpass, temporal_highpass,
                                                   output_row_ptr, output_pitch, output_row_width[channel],
                                                   frame_width, chroma_offset, precision);

                    // Advance the output row pointer to the next channel
                    output_row_ptr += output_row_width[channel];
                }
            }
        }
        else
        {
            // No more rows to process
            break;
        }
    }

#if (1 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "Finished transform, thread index: %d\n", thread_index);
    }
#endif
}

#endif


#if 0

DWORD WINAPI TransformInverseFrameToRow16utopThread(LPVOID param)
{
    struct data
    {
        TRANSFORM *transform[3];
        int frame_index;
        int num_channels;
        uint8_t *output;
        int output_pitch;
        FRAME_INFO *info;
        SCRATCH *scratch;
        int chroma_offset;
        int precision;
    } *dptr;

    dptr = (struct data *)param;


    TransformInverseFrameToRow16utop(dptr->transform, dptr->frame_index, dptr->num_channels,
                                     (PIXEL16U *)dptr->output, dptr->output_pitch, dptr->info,
                                     dptr->scratch, dptr->chroma_offset, dptr->precision);

    return 0;
}

DWORD WINAPI TransformInverseFrameToRow16ubottomThread(LPVOID param)
{
    struct data
    {
        TRANSFORM *transform[3];
        int frame_index;
        int num_channels;
        uint8_t *output;
        int output_pitch;
        FRAME_INFO *info;
        SCRATCH *scratch;
        int chroma_offset;
        int precision;
    } *dptr;

    dptr = (struct data *)param;


    TransformInverseFrameToRow16ubottom(dptr->transform, dptr->frame_index, dptr->num_channels,
                                        (PIXEL16U *)dptr->output, dptr->output_pitch, dptr->info,
                                        dptr->scratch, dptr->chroma_offset, dptr->precision);

    return 0;
}

#endif


extern void fast_srand( int seed );

// Apply the inverse horizontal-temporal transform and pack the output into a buffer
#if 0
void TransformInverseFrameToBuffer(TRANSFORM *transform[], int frame_index, int num_channels,
                                   uint8_t *output, int output_pitch, FRAME_INFO *frame,
                                   char *buffer, size_t buffer_size, int chroma_offset,
                                   int precision)
#else
void TransformInverseFrameToBuffer(TRANSFORM *transform[], int frame_index, int num_channels,
                                   uint8_t *output, int output_pitch, FRAME_INFO *frame,
                                   const SCRATCH *scratch, int chroma_offset, int precision)
#endif
{
    // Pointers to the rows in the horizontal wavelet for each channel
    PIXEL *horizontal_lowlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_lowhigh[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highlow[TRANSFORM_MAX_CHANNELS];
    PIXEL *horizontal_highhigh[TRANSFORM_MAX_CHANNELS];

    // Horizontal wavelet band width and pitch
    int horizontal_width[TRANSFORM_MAX_CHANNELS];
    int horizontal_pitch[TRANSFORM_MAX_CHANNELS];
    //int horizontal_pitch8s[TRANSFORM_MAX_CHANNELS];

    // Quantization factors
    int lowlow_quantization[TRANSFORM_MAX_CHANNELS];
    int lowhigh_quantization[TRANSFORM_MAX_CHANNELS];
    int highlow_quantization[TRANSFORM_MAX_CHANNELS];
    int highhigh_quantization[TRANSFORM_MAX_CHANNELS];

    // Push the scratch space state to allocate a new section
    char *buffer = scratch->free_ptr;
    size_t buffer_size = scratch->free_size;

    // Pointers to the rows in the temporal wavelet for each channel
    PIXEL *temporal_lowpass[TRANSFORM_MAX_CHANNELS];
    PIXEL *temporal_highpass[TRANSFORM_MAX_CHANNELS];

    // Dimensions of the reconstructed frame
    int frame_width = frame->width;
    int frame_height = frame->height;
    int half_height = frame_height / 2;
    size_t temporal_row_size = frame_width * sizeof(PIXEL);
    size_t temporal_buffer_size = 2 * num_channels * temporal_row_size;
#if DEBUG
    size_t yuv_row_size = frame_width * 2;
#endif
    char *yuv_buffer;
    size_t yuv_buffer_size;
    int field_pitch = 2 * output_pitch;
    int format = frame->format;
    bool inverted = (format == DECODED_FORMAT_RGB24 || format == DECODED_FORMAT_RGB32);
    int output_width;
    int channel;
    int row;

    // Round up the temporal row size to an integral number of cache lines
    temporal_row_size = ALIGN(temporal_row_size, _CACHE_LINE_SIZE);

    // Check that the buffer starts on a cache line boundary
    assert(ISALIGNED(buffer, _CACHE_LINE_SIZE));

    // Check that the number of channels is reasonable
    assert(0 < num_channels && num_channels <= TRANSFORM_MAX_CHANNELS);

    // Check that the buffer is large enough
    assert((2 * num_channels * temporal_row_size) <= buffer_size);

    // Allocate buffers for a single row of lowpass and highpass temporal coefficients
    // and initialize the arrays of row pointers into the horizontal transform bands
    for (channel = 0; channel < num_channels; channel++)
    {
        IMAGE *wavelet = transform[channel]->wavelet[frame_index];

        // Initialize the row pointers into the horizontal bands
        horizontal_lowlow[channel] = wavelet->band[LL_BAND];
        horizontal_lowhigh[channel] = wavelet->band[LH_BAND];
        horizontal_highlow[channel] = wavelet->band[HL_BAND];
        horizontal_highhigh[channel] = wavelet->band[HH_BAND];

        lowlow_quantization[channel] = wavelet->quantization[LL_BAND];
        lowhigh_quantization[channel] = wavelet->quantization[LH_BAND];
        highlow_quantization[channel] = wavelet->quantization[HL_BAND];
        highhigh_quantization[channel] = wavelet->quantization[HH_BAND];

        // Compute the pitch in units of pixels
        horizontal_pitch[channel] = wavelet->pitch / sizeof(PIXEL);

        // Compute the 8-bit pitch in units of pixels
        //horizontal_pitch8s[channel] = wavelet->pitch8s/sizeof(PIXEL);
        //horizontal_pitch8s[channel] = wavelet->pitch8s/sizeof(PIXEL8S);

        // Remember the width of the horizontal wavelet rows for this channel
        horizontal_width[channel] = wavelet->width;

        // Divide the buffer into temporal lowpass and highpass rows
        temporal_lowpass[channel] = (PIXEL *)(buffer + (2 * channel) * temporal_row_size);
        temporal_highpass[channel] = (PIXEL *)(buffer + (2 * channel + 1) * temporal_row_size);
    }

    // Allocate buffer space for the intermediate YUV data
    yuv_buffer = buffer + temporal_buffer_size;
    yuv_buffer_size = buffer_size - temporal_buffer_size;
#if DEBUG
    assert(yuv_buffer_size >= 2 * yuv_row_size);
#endif

    if (inverted)
    {
        output += (frame_height - 1) * output_pitch;
        output_pitch = (- output_pitch);
        field_pitch = (- field_pitch);
    }

    // Process one row at a time from each channel
    for (row = 0; row < half_height; row++)
    {
        PIXEL *line_buffer = (PIXEL *)(buffer + (2 * num_channels + 2) * temporal_row_size);

        // Invert the horizontal transform applied to the temporal bands in each channel
        for (channel = 0; channel < num_channels; channel++)
        {
            int pitch = horizontal_pitch[channel];
            //int pitch8s = horizontal_pitch8s[channel];

            // Invert the horizontal transform applied to the temporal lowpass row
            InvertHorizontalRow16s8sTo16sBuffered(horizontal_lowlow[channel], lowlow_quantization[channel],
                                                  (PIXEL8S *)horizontal_lowhigh[channel], lowhigh_quantization[channel],
                                                  temporal_lowpass[channel],
                                                  horizontal_width[channel],
                                                  (PIXEL *)line_buffer);

            // Invert the horizontal transform applied to the temporal highpass row
            InvertHorizontalRow8sBuffered((PIXEL8S *)horizontal_highlow[channel], highlow_quantization[channel],
                                          (PIXEL8S *)horizontal_highhigh[channel], highhigh_quantization[channel],
                                          temporal_highpass[channel],
                                          horizontal_width[channel],
                                          (PIXEL *)line_buffer);

            // Advance to the next row in each horizontal band in this channel
            horizontal_lowlow[channel] += pitch;
            horizontal_lowhigh[channel] += pitch;
            horizontal_highlow[channel] += pitch;
            horizontal_highhigh[channel] += pitch;
        }

        // The output width is twice the width of the wavelet bands
        output_width = 2 * horizontal_width[0];

        // Adjust the frame width to fill to the end of each row
        //frame_width = output_pitch / 2;

        //#if BUILD_PROSPECT
        if (format == DECODED_FORMAT_V210 || format == DECODED_FORMAT_YU64)
        {
            // Invert the temporal bands from all channels and pack as V210 output
            InvertInterlacedRow16sToV210(temporal_lowpass, temporal_highpass, num_channels,
                                         output, output_pitch, output_width, frame_width,
                                         yuv_buffer, yuv_buffer_size, format, chroma_offset, precision);
        }
        else
            //#endif
        {
            // Invert the temporal bands from all channels and pack as 8-bit output
            InvertInterlacedRow16s(temporal_lowpass, temporal_highpass, num_channels,
                                   output, output_pitch, output_width, frame_width,
                                   yuv_buffer, yuv_buffer_size, format, frame->colorspace,
                                   chroma_offset, precision, row);
        }

        // Advance to the next row in the packed output image
        output += field_pitch;
    }
}

void CopyImageToBuffer(IMAGE *image, uint8_t *output_buffer, int32_t output_pitch, int format)
{
    bool inverted = false;
    size_t output_size;

    START(tk_convert);

    // Determine the type of conversion
    switch (format)
    {
        case DECODED_FORMAT_RGB24:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB24_INVERTED:
            ConvertImageToRGB(image, output_buffer, output_pitch, COLOR_FORMAT_RGB24, inverted);
            break;

        case DECODED_FORMAT_RGB32:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB32_INVERTED:
            ConvertImageToRGB(image, output_buffer, output_pitch, COLOR_FORMAT_RGB32, inverted);
            break;

#if 0
        case DECODED_FORMAT_YUYV_INVERTED:
            inverted = true;
            // Fall through and convert to YUV (first image row displayed at the bottom)
#endif

        case DECODED_FORMAT_YUYV:
            ConvertImageToYUV(image, output_buffer, output_pitch, COLOR_FORMAT_YUYV, inverted);
            break;

#if 0
        case DECODED_FORMAT_UYVY_INVERTED:
            inverted = true;
            // Fall through and convert to YUV (first image row displayed at the bottom)
#endif

        case DECODED_FORMAT_UYVY:
            ConvertImageToYUV(image, output_buffer, output_pitch, COLOR_FORMAT_UYVY, inverted);
            break;

        default:				// Unsupported format (return a blank frame)
            assert(0);
            output_size = image->height * output_pitch;
            memset(output_buffer, COLOR_CHROMA_ZERO, output_size);
            break;
    }

    STOP(tk_convert);
}



void SideLowpass16s10bitToYUYV(IMAGE *images[], uint8_t *output_buffer, int output_width, int output_height,
                               int output_pitch, bool inverted)
{
    IMAGE *y_image = images[0];
    IMAGE *u_image = images[1];
    IMAGE *v_image = images[2];
    int width = y_image->width;
    int height = output_height;

    PIXEL *y_row_ptr = y_image->band[0];
    PIXEL *u_row_ptr = u_image->band[0];
    PIXEL *v_row_ptr = v_image->band[0];
    int y_pitch = y_image->pitch / sizeof(PIXEL);
    int u_pitch = u_image->pitch / sizeof(PIXEL);
    int v_pitch = v_image->pitch / sizeof(PIXEL);

    uint8_t *outrow = output_buffer;
    uint8_t *outptr;
    int row, column;

    // Definitions for optimization
    //const int column_step = 2 * sizeof(__m64);

    // Column at which post processing must begin
    //int post_column = width - (width % column_step);

    // The output pitch should be a positive number before inversion
    assert(output_pitch > 0);

    // Should the image be inverted?
    if (inverted)
    {
        outrow += (height - 1) * output_pitch;		// Start at the bottom row
        output_pitch = NEG(output_pitch);			// Negate the pitch to go up
    }

    for (row = 0; row < height; row++)
    {
        outptr = outrow;

        // Fill the rest of the output row
        for (column = 0; column < width; column += 4)
        {
            int chroma_column = column >> 1;
            *(outptr++) = SATURATE_8U((y_row_ptr[column] + y_row_ptr[column + 1]) >> 5);
            *(outptr++) = SATURATE_8U((v_row_ptr[chroma_column] + v_row_ptr[chroma_column + 1]) >> 5);
            *(outptr++) = SATURATE_8U((y_row_ptr[column + 2] + y_row_ptr[column + 3]) >> 5);
            *(outptr++) = SATURATE_8U((u_row_ptr[chroma_column] + u_row_ptr[chroma_column + 1]) >> 5);
        }

        // Advance to the next rows in the input and output images
        y_row_ptr += y_pitch;// 3D Work
        u_row_ptr += u_pitch;
        v_row_ptr += v_pitch;

        outrow += output_pitch;
    }
}




// Convert 16-bit signed lowpass data into packed RGB/YUV and store it in the output buffer
void CopyLowpass16sToBuffer(DECODER *decoder, IMAGE *images[], int num_channels, uint8_t *output_buffer, int32_t output_pitch,
                            FRAME_INFO *info, int chroma_offset, int precision, int encode_format, int whitebitdepth)
{
    //IMAGE *image = frame->channel[0];
    bool inverted = false;
    int output_width = info->width;
    int output_height = info->height;
    int descale = precision - 8;

    // Get the color format from the decoded format
    int color_format = info->format & COLOR_FORMAT_MASK;

    // Must compile this routine with switches set for decoding to 8-bit unsigned pixels
#if !defined(_DECODE_FRAME_8U) || (_DECODE_FRAME_8U == 0)
    assert(0);
    return;
#endif

    START(tk_convert);

#if 0
    // Fill the output buffer with blank values
    EraseOutputBuffer(output_buffer, info->width, info->height, output_pitch, info->format);
#endif


    // Determine the type of conversion
    switch (info->format)
    {
        case DECODED_FORMAT_RGB24:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB24_INVERTED:
            if (encode_format == ENCODED_FORMAT_RGB_444 || encode_format == ENCODED_FORMAT_RGBA_4444)
            {
                ConvertLowpass16sRGB48ToRGB(images, output_buffer, output_width, output_height, output_pitch,
                                            COLOR_FORMAT_RGB24, info->colorspace, inverted, descale, num_channels);
            }
            else
            {
                ConvertLowpass16sToRGBNoIPPFast(images, output_buffer, output_width, output_height, output_pitch,
                                                COLOR_FORMAT_RGB24, info->colorspace, inverted, descale);
            }
            break;

        case DECODED_FORMAT_RGB32:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB32_INVERTED:
            if (encode_format == ENCODED_FORMAT_RGB_444 || encode_format == ENCODED_FORMAT_RGBA_4444)
            {
                ConvertLowpass16sRGB48ToRGB(images, output_buffer, output_width, output_height, output_pitch,
                                            COLOR_FORMAT_RGB32, info->colorspace, inverted, descale, num_channels);
            }
            else
            {
                ConvertLowpass16sToRGBNoIPPFast(images, output_buffer, output_width, output_height, output_pitch,
                                                COLOR_FORMAT_RGB32, info->colorspace, inverted, descale);
            }
            break;

        case DECODED_FORMAT_RG48:
            if (encode_format == ENCODED_FORMAT_BAYER)
            {
                ConvertLowpass16sBayerToRGB48(images, output_buffer, output_width, output_height,
                                              output_pitch, 2, num_channels);
            }
            else if (encode_format == ENCODED_FORMAT_RGB_444 || encode_format == ENCODED_FORMAT_RGBA_4444)
            {
                int scale = 1;
                if (encode_format == ENCODED_FORMAT_RGB_444 || encode_format == ENCODED_FORMAT_RGBA_4444)
                    scale = 2;
                ConvertLowpass16sRGB48ToRGB48(images, output_buffer, output_width, output_height,
                                              output_pitch, scale, num_channels);
            }
            else
            {
                ConvertLowpass16sYUVtoRGB48(images, (uint8_t *)output_buffer, output_width,
                                            output_height, output_pitch, info->colorspace, inverted, descale,
                                            info->format, whitebitdepth);
            }
            break;


        case DECODED_FORMAT_RG64:
            if (encode_format == ENCODED_FORMAT_RGB_444 || encode_format == ENCODED_FORMAT_RGBA_4444)
            {
                ConvertLowpass16sRGBA64ToRGBA64(images, output_buffer, output_width, output_height, output_pitch,
                                                descale, num_channels, info->format & 0xffff);
            }
            else
            {
                assert(0);
            }
            break;
        case DECODED_FORMAT_B64A:
        case DECODED_FORMAT_R210:
        case DECODED_FORMAT_DPX0:
        case DECODED_FORMAT_RG30:
        case DECODED_FORMAT_AR10:
        case DECODED_FORMAT_AB10:
            if (encode_format == ENCODED_FORMAT_RGB_444 || encode_format == ENCODED_FORMAT_RGBA_4444)
            {
                ConvertLowpass16sRGBA64ToRGBA64(images, output_buffer, output_width, output_height, output_pitch,
                                                descale, num_channels, info->format & 0xffff);
            }
            else
            {
                ConvertLowpass16sYUVtoRGB48(images, (uint8_t *)output_buffer, output_width,
                                            output_height, output_pitch, info->colorspace, inverted, descale,
                                            info->format, whitebitdepth);
            }
            break;
#if 0
        case DECODED_FORMAT_YUYV_INVERTED:
            inverted = true;
            // Fall through and convert to YUV (first image row displayed at the bottom)
#endif

        case DECODED_FORMAT_YUYV:
        case DECODED_FORMAT_UYVY:
            if (precision == CODEC_PRECISION_10BIT)
            {
                int lineskip = 1; // 3D Work
                int pitch = output_pitch;

                if (decoder->channel_decodes > 1 && decoder->frame.format == DECODED_FORMAT_YUYV)
                {
                    if (decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC || decoder->channel_blend_type == BLEND_LINE_INTERLEAVED) // 3d Work
                    {
                        lineskip = 2;
                        if (decoder->channel_blend_type == 3)
                            pitch *= 2;

                    }
                }

                if ((decoder->channel_blend_type == BLEND_SIDEBYSIDE_ANAMORPHIC || decoder->channel_blend_type == BLEND_FREEVIEW) && decoder->frame.format == DECODED_FORMAT_YUYV) //side by side
                {
                    SideLowpass16s10bitToYUYV(images, output_buffer, output_width, output_height, pitch, inverted);
                }
                else
                {
                    //ConvertLowpass16s10bitToYUV(images, output_buffer, output_width, output_height, pitch, COLOR_FORMAT_YUYV, inverted, lineskip);
                    ConvertLowpass16s10bitToYUV(images, output_buffer, output_width, output_height, pitch, color_format, inverted, lineskip);
                }
            }
            else
            {
                //ConvertLowpass16sToYUV(images, output_buffer, output_width, output_height, output_pitch, COLOR_FORMAT_YUYV, inverted);
                ConvertLowpass16sToYUV(images, output_buffer, output_width, output_height, output_pitch, color_format, inverted);
            }
            break;

#if 0
        case DECODED_FORMAT_UYVY_INVERTED:
            inverted = true;
            // Fall through and convert to YUV (first image row displayed at the bottom)
#endif
#if 0
        case DECODED_FORMAT_UYVY:
            ConvertLowpass16sToYUV(images, output_buffer, output_width, output_height, output_pitch, COLOR_FORMAT_UYVY, inverted);
            break;
#endif

        //#if BUILD_PROSPECT
        case DECODED_FORMAT_V210:
            if (precision == CODEC_PRECISION_10BIT)
            {
                ConvertLowpass16s10bitToV210(images, output_buffer, output_width, output_height, output_pitch, COLOR_FORMAT_V210, inverted);
            }
            else
            {
                //ConvertLowpass16sToV210(images, output_buffer, output_width, output_pitch, COLOR_FORMAT_V210, inverted);
                assert(0);
            }
            break;
        //#endif

        case DECODED_FORMAT_YU64:
            // DAN04262004
            ConvertLowpass16sToYUV64(images, output_buffer, output_width, output_height, output_pitch, COLOR_FORMAT_YU64, inverted, precision);
            break;

        //#if BUILD_PROSPECT
        case DECODED_FORMAT_YR16:
            ConvertLowpass16sToYR16(images, output_buffer, output_width, output_height,  output_pitch, COLOR_FORMAT_YR16, inverted, precision);
            break;
        //#endif

        default:				// Unsupported format (output a blank frame)
            assert(0);
            break;
    }

    STOP(tk_convert);
}

void ConvertYUVStripPlanarToBuffer(uint8_t *planar_output[], int planar_pitch[], ROI roi,
                                   uint8_t *output_buffer, int output_pitch, int frame_width,
                                   int format, int colorspace)
{
    bool inverted = false;
    int output_width = roi.width;

#if !defined(_DECODE_FRAME_8U) || (_DECODE_FRAME_8U == 0)
#error Must set compile-time switches to decode to 8-bit pixels
#endif

    START(tk_convert);

#if _ENCODE_CHROMA_OFFSET
#error Cannot handle images encoded with a non-zero chroma offset
#endif

    // Determine the type of conversion
    switch (format)
    {
        case DECODED_FORMAT_RGB24:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB24_INVERTED:
            ConvertPlanarYUVToRGB(planar_output, planar_pitch, roi, output_buffer, output_width, output_pitch,
                                  COLOR_FORMAT_RGB24, colorspace, inverted);
            break;

        case DECODED_FORMAT_RGB32:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB32_INVERTED:
            ConvertPlanarYUVToRGB(planar_output, planar_pitch, roi, output_buffer, output_width, output_pitch,
                                  COLOR_FORMAT_RGB32, colorspace, inverted);
            break;

#if 0
        case DECODED_FORMAT_YUYV_INVERTED:
            inverted = true;
            // Fall through and convert to YUV (first image row displayed at the bottom)
#endif

        case DECODED_FORMAT_YUYV:
            ConvertYUVStripPlanarToPacked(planar_output, planar_pitch, roi,
                                          output_buffer, output_pitch, frame_width, format);
            break;

#if 0
        case DECODED_FORMAT_UYVY_INVERTED:
            inverted = true;
            // Fall through and convert to YUV (first image row displayed at the bottom)
#endif

        case DECODED_FORMAT_UYVY:
            ConvertPlanarYUVToUYVY(planar_output, planar_pitch, roi, output_buffer, output_width, output_pitch,
                                   COLOR_FORMAT_UYVY, colorspace, inverted);
            break;

        default:				// Unsupported format (output a blank frame)
            assert(0);
            break;
    }

    STOP(tk_convert);
}

void ConvertRow16uToDitheredBuffer(DECODER *decoder, uint8_t *planar_output[], int planar_pitch[], ROI roi,
                                   uint8_t *output_buffer, int output_pitch, int frame_width,
                                   int format, int colorspace)
{
    bool inverted = false;
    int output_width = roi.width;

    START(tk_convert);

    // Determine the type of conversion
    switch (format)
    {
        case DECODED_FORMAT_RGB24:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB24_INVERTED:
            //ConvertPlanarYUVToRGB
            ConvertRow16uToDitheredRGB(decoder, planar_output, planar_pitch, roi, output_buffer, output_width, output_pitch,
                                       COLOR_FORMAT_RGB24, colorspace, inverted);
            break;

        case DECODED_FORMAT_RGB32:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB32_INVERTED:
            ConvertRow16uToDitheredRGB(decoder, planar_output, planar_pitch, roi, output_buffer, output_width, output_pitch,
                                       COLOR_FORMAT_RGB32, colorspace, inverted);
            break;


        case COLOR_FORMAT_WP13:
        case COLOR_FORMAT_B64A:
        case COLOR_FORMAT_RG48:
        case COLOR_FORMAT_R210:
        case COLOR_FORMAT_DPX0:
        case COLOR_FORMAT_RG30:
        case COLOR_FORMAT_AR10:
        case COLOR_FORMAT_AB10:
            ConvertYUVRow16uToBGRA64(planar_output, planar_pitch, roi, output_buffer, output_width, output_pitch, format, colorspace, NULL, NULL);
            break;


        case DECODED_FORMAT_YUYV:
            assert(0);// These routines are not yet updated for ROW16u inputs
            ConvertYUVStripPlanarToPacked(planar_output, planar_pitch, roi,
                                          output_buffer, output_pitch, frame_width, format);
            break;

        case DECODED_FORMAT_UYVY:
            assert(0);// These routines are not yet updated for ROW16u inputs
            ConvertPlanarYUVToUYVY(planar_output, planar_pitch, roi, output_buffer, output_width, output_pitch,
                                   COLOR_FORMAT_UYVY, colorspace, inverted);
            break;

        default:				// Unsupported format (output a blank frame)
            assert(0);
            break;
    }

    STOP(tk_convert);
}



// Convert one row of packed YUYV to the specified color
void ConvertRowYUYV(uint8_t *input, uint8_t *output, int length, int format, int colorspace, int precision)
{
    size_t row_size = 2 * length;
    bool inverted = false;

    START(tk_convert);

    // Determine the type of color conversion
    switch (format)
    {
        case DECODED_FORMAT_RGB24:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB24_INVERTED:
            ConvertYUYVRowToRGB(input, output, length, COLOR_FORMAT_RGB24, colorspace, precision);
            break;

        case DECODED_FORMAT_RGB32:
            inverted = true;
        // Fall through and convert to RGB (first image row displayed at the bottom)

        case DECODED_FORMAT_RGB32_INVERTED:
            ConvertYUYVRowToRGB(input, output, length, COLOR_FORMAT_RGB32, colorspace, precision);
            break;

        case DECODED_FORMAT_YUYV:
            if (precision == 8)
                memcpy(output, input, row_size);
            else
            {
                //need to dither to 8-bit
                assert(0);
            }
            break;

        case DECODED_FORMAT_UYVY:
            if (precision == 8)
                ConvertYUYVRowToUYVY(input, output, length, COLOR_FORMAT_UYVY);
            else
            {
                //need to dither to 8-bit
                assert(0);
            }
            break;

        //#if BUILD_PROSPECT
        case DECODED_FORMAT_V210:
            assert(0); // should get here with 8bit data.
            //ConvertYUYVRowToV210(input, output, length, COLOR_FORMAT_V210);
            break;

        case DECODED_FORMAT_YU64:
            assert(0); // should get here with 8bit data.
            //ConvertYUYVRowToYU64(input, output, length, COLOR_FORMAT_YU64);
            break;

        case DECODED_FORMAT_BYR3:
        case DECODED_FORMAT_BYR4:
            assert(0); // should get here with 8bit data.
            //ConvertYUYVRowToYU64(input, output, length, COLOR_FORMAT_YU64);
            break;
        //#endif

        default:				// Unsupported format (output a blank frame)
            assert(0);
            memset(output, 0, row_size);
            break;
    }

    STOP(tk_convert);
}


#if _THREADED_DECODER

IMAGE *GetWaveletThreadSafe(DECODER *decoder, TRANSFORM *transform, int index,
                            int width, int height, int level, int type)
{
    IMAGE *wavelet = transform->wavelet[index];

    assert(decoder != NULL && transform != NULL);
    if (decoder != NULL && transform != NULL)
    {

#if (1 && DEBUG)
        FILE *logfile = decoder->logfile;
#endif

        // Lock access to the wavelet data
#if _DELAYED_THREAD_START==0
        Lock(&decoder->entropy_worker_new.lock);
#endif

        // Get the wavelet from the transform data structure (thread safe)
        wavelet = transform->wavelet[index];

        // Allocate (or reallocate) the wavelet
#if _ALLOCATOR
        wavelet = ReallocWaveletEx(decoder->allocator, wavelet, width, height, level, type);
#else
        wavelet = ReallocWaveletEx(wavelet, width, height, level, type);
#endif
        // Save this wavelet in the transform data structure
        transform->wavelet[index] = wavelet;

        // Unlock access to the wavelet data
#if _DELAYED_THREAD_START==0
        Unlock(&decoder->entropy_worker_new.lock);
#endif
    }

    return wavelet;
}

// Update the codec state with the information in a tag value pair
CODEC_ERROR UpdateCodecState(DECODER *decoder, BITSTREAM *input, CODEC_STATE *codec, TAGWORD tag, TAGWORD value)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    bool optional = false;
    int chunksize = 0;

    bool result;

    // Is this an optional tag?
    if (tag < 0)
    {
        tag = NEG(tag);
        optional = true;
    }

#if (0 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "UpdateCodecState tag: %d, value: %d, optional: %d\n",
                tag, value, optional);
    }
#endif

    switch (tag)
    {
        case CODEC_TAG_ZERO:				// Used internally
            assert(0);						// Should not occur in the bitstream
            error = CODEC_ERROR_INVALID_BITSTREAM;
            break;

        case CODEC_TAG_SAMPLE:				// Type of sample
            //assert(0);
            if (value == SAMPLE_TYPE_CHANNEL)
            {
                result = DecodeSampleChannelHeader(decoder, input);
                if (!result)
                    error = CODEC_ERROR_DECODE_SAMPLE_CHANNEL_HEADER;
                else
                    error = CODEC_ERROR_OKAY;
            }
            break;

        case CODEC_TAG_INDEX:				// Sample index table
            //assert(0);					// Need to figure out how to return the group index
        {
            int count = value;
            uint32_t *index = (uint32_t *)(&codec->channel_size[0]);
            DecodeGroupIndex(input, index, count);
            codec->num_channels = count;
        }
        break;

        case CODEC_TAG_SUBBAND:			// Has the decoder encountered a subband?
        {
            // This tag is obsolete and not used in modern streams
            int subband = value;

            // Check that the subband number makes sense
            assert(0 <= subband && subband <= codec->max_subband);
            if (! (0 <= subband && subband <= codec->max_subband))
            {
                error = CODEC_ERROR_DECODING_SUBBAND;
                break;
            }

            // Decompress the subband
            result = DecodeSampleSubband(decoder, input, subband);
            if (!result)
                error = CODEC_ERROR_DECODING_SUBBAND;
            else
                error = CODEC_ERROR_OKAY;
        }
        break;

        case CODEC_TAG_BAND_HEADER: //CODEC_TAG_BAND_DIVISOR:		// Band divisor. this is last TAG before subband data so act.
            codec->band.divisor = value; // This tag value pair encodes the band divisor which is obsolete
            {
                // This tag value pair marks the beginning of the encoded coefficients

                // The subband number has already been decoded
                int subband = codec->band.subband;

                result = DecodeSampleSubband(decoder, input, subband);
                if (!result)
                    error = CODEC_ERROR_DECODING_SUBBAND;
                else
                    error = CODEC_ERROR_OKAY;
            }
            break;

        case CODEC_TAG_ENTRY:				// Entry in sample index
            assert(0);						// Need to figure out how to return the group index
            break;

        case CODEC_TAG_MARKER:				// Bitstream marker
        {
            int marker = value;
            uint8_t  *current_position;

            // Save the current bitstream position
            current_position = GetBitstreamPosition(input);
            current_position -= 4; // Step back to before the GetSegment i.e. the TAG

            if (IsLowPassHeaderMarker(marker))
            {
                // Save the bitstream position for the start of the channel
                codec->channel_position = current_position;
            }
            else if (IsLowPassBandMarker(marker))
            {
                int subband = 0;

                result = DecodeSampleSubband(decoder, input, subband);
                if (!result)
                    error = CODEC_ERROR_DECODING_SUBBAND;
                else
                    error = CODEC_ERROR_OKAY;
            }
        }

        break;

        case CODEC_TAG_VERSION_MAJOR:		// Version
            assert(0);
            break;

        case CODEC_TAG_VERSION_MINOR:		// Minor version number
            assert(0);
            break;

        case CODEC_TAG_VERSION_REVISION:	// Revision number
            assert(0);
            break;

        case CODEC_TAG_VERSION_EDIT:		// Edit number
            assert(0);
            break;

        case CODEC_TAG_SEQUENCE_FLAGS:		// Video sequence flags
            assert(0);
            break;

        case CODEC_TAG_TRANSFORM_TYPE:		// Type of transform
            assert(TRANSFORM_TYPE_FIRST <= value && value <= TRANSFORM_TYPE_LAST);
            if (TRANSFORM_TYPE_FIRST <= value && value <= TRANSFORM_TYPE_LAST)
            {
                int i;

                codec->transform_type = value;

                for (i = 0; i < TRANSFORM_MAX_CHANNELS; i++)
                {
                    TRANSFORM *transform = decoder->transform[i];
                    if (transform)
                    {
                        GetTransformPrescale(transform, codec->transform_type, codec->precision);
                    }
                }
            }
            else
                error = CODEC_ERROR_TRANSFORM_TYPE;
            break;

        case CODEC_TAG_NUM_FRAMES:			// Number of frames in the group
            assert(0 <= value && value <= TRANSFORM_NUM_FRAMES);
            if (0 <= value && value <= TRANSFORM_NUM_FRAMES)
                codec->num_frames = value;
            else
                error = CODEC_ERROR_NUM_FRAMES;
            break;

        case CODEC_TAG_NUM_CHANNELS:		// Number of channels in the transform
            assert(value <= CODEC_MAX_CHANNELS);
            if (value <= CODEC_MAX_CHANNELS)
                codec->num_channels = value;
            else
                error = CODEC_ERROR_NUM_CHANNELS;
            break;

        case CODEC_TAG_NUM_WAVELETS:		// Number of wavelets in the transform
            assert(0 < value && value <= TRANSFORM_NUM_WAVELETS);
            if (0 < value && value <= TRANSFORM_NUM_WAVELETS)
                codec->num_wavelets = value;
            else
                error = CODEC_ERROR_NUM_WAVELETS;
            break;

        case CODEC_TAG_NUM_SUBBANDS:		// Number of encoded subbands
            assert(0 < value && value <= TRANSFORM_NUM_SUBBANDS);
            if (0 < value && value <= TRANSFORM_NUM_SUBBANDS)
                codec->num_subbands = value;
            else
                error = CODEC_ERROR_NUM_SUBBANDS;
            break;

        case CODEC_TAG_NUM_SPATIAL:			// Number of spatial levels
            assert(0 < value && value <= TRANSFORM_NUM_SPATIAL);
            if (0 < value && value <= TRANSFORM_NUM_SPATIAL)
                codec->num_spatial = value;
            else
                error = CODEC_ERROR_NUM_SPATIAL;
            break;

        case CODEC_TAG_FIRST_WAVELET:		// Type of the first wavelet
            assert(value == TRANSFORM_FIRST_WAVELET);
            if (value == TRANSFORM_FIRST_WAVELET)
                codec->first_wavelet = value;
            else
                error = CODEC_ERROR_FIRST_WAVELET;
            break;

        case CODEC_TAG_CHANNEL_SIZE:		// Number of bytes in each channel
            assert(0);
            break;

        case CODEC_TAG_GROUP_TRAILER:		// Group trailer and checksum
            codec->sample_done = true;
            break;

        case CODEC_TAG_FRAME_TYPE:			// Type of frame marks the frame start
            codec->frame.type = value;
            break;

        case CODEC_TAG_FRAME_WIDTH:			// Width of the frame
            codec->frame.width = value;
            break;

        case CODEC_TAG_FRAME_HEIGHT:		// Height of the frame
            codec->frame.height = value;

            //DAN20080729 -- Initialize the default colorspace based on clip resolution
            if ((decoder->frame.colorspace & COLORSPACE_MASK) == COLOR_SPACE_UNDEFINED)
            {
                int internalheight = value;
                int internalwidth = codec->frame.width;
                if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
                {
                    internalwidth *= 2;
                    internalheight *= 2;
                }

                if (internalheight > 576 || internalwidth > 720)
                    decoder->frame.colorspace |= COLOR_SPACE_CG_709;
                else
                    decoder->frame.colorspace |= COLOR_SPACE_CG_601;
            }
            //if(decoder->frame.colorspace_filedefault)
            //	decoder->frame.colorspace = decoder->frame.colorspace_filedefault;
            if (decoder->frame.colorspace_override)
                decoder->frame.colorspace = decoder->frame.colorspace_override;
            break;

        case CODEC_TAG_ENCODED_COLORSPACE: //DAN20080729
            if (decoder->codec.encoded_format == ENCODED_FORMAT_BAYER)
                value &= ~(COLOR_SPACE_BT_601 | COLOR_SPACE_BT_709); // Bayer has no 601 vs 709,
            //there was a bug in 3.9.4 that had bayer flagged as 601.

            if (decoder->frame.colorspace_override)
                decoder->frame.colorspace = decoder->frame.colorspace_override;
            else
            {
                if (decoder->codec.encoded_format == ENCODED_FORMAT_YUV_422)
                {
                    decoder->frame.colorspace &= ~(COLOR_SPACE_BT_601 | COLOR_SPACE_BT_709);
                    decoder->frame.colorspace |= (value & (COLOR_SPACE_BT_601 | COLOR_SPACE_BT_709));
                    //Let the VSRGB status be controllable by the calling application (e.g. Vegas)
                }
                else
                {
                    decoder->frame.colorspace &= ~(COLOR_SPACE_VS_RGB);
                    decoder->frame.colorspace |= (value & (COLOR_SPACE_VS_RGB));
                }
            }
            decoder->frame.colorspace_filedefault = value;
            break;

        case CODEC_TAG_FRAME_FORMAT:		// Format of the encoded pixels (GRAY, YUV, RGB, RGBA)
            assert(0);
            break;

        case CODEC_TAG_INPUT_FORMAT:		// Format of the original pixels
            codec->input_format = value;

            // Set the encoded format if it has not already been set
            //	error = UpdateEncodedFormat(codec, (COLOR_FORMAT)value);
            break;

        case CODEC_TAG_ENCODED_FORMAT:		// Internal format of the encoded data
        case CODEC_TAG_OLD_ENCODED_FORMAT:
            codec->encoded_format = value;
            if (codec->encoded_format == ENCODED_FORMAT_RGBA_4444 && codec->num_channels == 3)
                codec->encoded_format = ENCODED_FORMAT_RGB_444;
            break;

        case CODEC_TAG_FRAME_INDEX:			// Position of frame within the group
            codec->frame.group_index = value;
            break;

        case CODEC_TAG_FRAME_TRAILER:		// Frame trailer and checksum
            codec->sample_done = true;
            break;

        case CODEC_TAG_LOWPASS_SUBBAND:		// Subband number of the lowpass band
            codec->lowpass.subband = value;
            error = SetDefaultEncodedFormat(codec);
            break;

        case CODEC_TAG_NUM_LEVELS:			// Number of wavelet levels
            codec->lowpass.level = value;
            break;

        case CODEC_TAG_LOWPASS_WIDTH:		// Width of the lowpass band
            codec->lowpass.width = value;
            break;

        case CODEC_TAG_LOWPASS_HEIGHT:		// Height of the lowpass band
            codec->lowpass.height = value;
            break;

        case CODEC_TAG_MARGIN_TOP:			// Margins that define the encoded subset
            codec->lowpass.margin.top = value;
            break;

        case CODEC_TAG_MARGIN_BOTTOM:
            codec->lowpass.margin.bottom = value;
            break;

        case CODEC_TAG_MARGIN_LEFT:
            codec->lowpass.margin.left = value;
            break;

        case CODEC_TAG_MARGIN_RIGHT:
            codec->lowpass.margin.right = value;
            break;

        case CODEC_TAG_PIXEL_OFFSET:		// Quantization parameters
            codec->lowpass.pixel_offset = value;
            break;

        case CODEC_TAG_QUANTIZATION:		// Quantization divisor used during encoding
            codec->lowpass.quantization = value;
            break;

        case CODEC_TAG_PIXEL_DEPTH:			// Number of bits per pixel
            codec->lowpass.bits_per_pixel = value;
            break;

        case CODEC_TAG_LOWPASS_TRAILER:		// Lowpass trailer
            assert(0);
            break;

        case CODEC_TAG_WAVELET_TYPE:		// Type of wavelet
            codec->highpass.wavelet_type = value;
            break;

        case CODEC_TAG_WAVELET_NUMBER:		// Number of the wavelet in the transform
            codec->highpass.wavelet_number = value;
            break;

        case CODEC_TAG_WAVELET_LEVEL:		// Level of the wavelet in the transform
            codec->highpass.wavelet_level = value;
            break;

        case CODEC_TAG_NUM_BANDS:			// Number of wavelet bands
            codec->highpass.num_bands = value;
            break;

        case CODEC_TAG_HIGHPASS_WIDTH:		// Width of each highpass band
            codec->highpass.width = value;
            break;

        case CODEC_TAG_HIGHPASS_HEIGHT:		// Height of each highpass band
            codec->highpass.height = value;
            break;

        case CODEC_TAG_LOWPASS_BORDER:		// Dimensions of lowpass border (obsolete)
            codec->highpass.lowpass_border = value;
            break;

        case CODEC_TAG_HIGHPASS_BORDER:		// Dimensions of highpass border (obsolete)
            codec->highpass.highpass_border = value;
            break;

        case CODEC_TAG_LOWPASS_SCALE:		// Scale factor for lowpass band
            codec->highpass.lowpass_scale = value;
            break;

        case CODEC_TAG_LOWPASS_DIVISOR:		// Divisor for the lowpass band
            codec->highpass.lowpass_divisor = value;
            break;

        case CODEC_TAG_HIGHPASS_TRAILER:	// Highpass trailer
            assert(0);
            break;

        case CODEC_TAG_BAND_NUMBER:			// Identifying number of a wavelet band
            codec->band.number = value;
            break;

        case CODEC_TAG_BAND_WIDTH:			// Band data width
            codec->band.width = value;
            break;

        case CODEC_TAG_BAND_HEIGHT:			// Band data height
            codec->band.height = value;
            break;

        case CODEC_TAG_BAND_SUBBAND:		// Subband number of this wavelet band
            codec->band.subband = value;
            //assert(value != 255);
            break;

        case CODEC_TAG_BAND_ENCODING:		// Encoding method for this band
            codec->band.encoding = value;
            break;

        case CODEC_TAG_BAND_QUANTIZATION:	// Quantization applied to band
            codec->band.quantization = value;
            break;

        case CODEC_TAG_BAND_SCALE:			// Band scale factor
            codec->band.scale = value;
            break;

        case CODEC_TAG_BAND_TRAILER:		// Band trailer
            assert(0);
            break;

        case CODEC_TAG_NUM_ZEROVALUES:		// Number of zero values
            assert(0);
            break;

        case CODEC_TAG_NUM_ZEROTREES:		// Number of zerotrees
            assert(0);
            break;

        case CODEC_TAG_NUM_POSITIVES:		// Number of positive values
            assert(0);
            break;

        case CODEC_TAG_NUM_NEGATIVES:		// Number of negative values
            assert(0);
            break;

        case CODEC_TAG_NUM_ZERONODES:		// Number of zerotree nodes
            assert(0);
            break;

        case CODEC_TAG_CHANNEL:				// Channel number
            assert(0);
            break;

        case CODEC_TAG_INTERLACED_FLAGS:	// Interlaced structure of the video stream
            //assert(0);
            break;
        //assert(0);

        case CODEC_TAG_PROTECTION_FLAGS:	// Copy protection bits
            //assert(0);
            break;

        case CODEC_TAG_PICTURE_ASPECT_X:	// Numerator of the picture aspect ratio
            codec->picture_aspect_x = value;
            //assert(0);
            break;

        case CODEC_TAG_PICTURE_ASPECT_Y:	// Denominator of the picture aspect ratio
            codec->picture_aspect_y = value;
            //assert(0);
            break;

        case CODEC_TAG_SAMPLE_FLAGS:		// Flag bits that control sample decoding
            // Progressive versus interlaced decoding is specified by the sample flags
            error = UpdateCodecFlags(codec, value);
            break;

        case CODEC_TAG_FRAME_NUMBER:		// Sequence number of the frame in the bitstream
            codec->frame_number = value;
            break;

        // This TAG is now support as part of the universal decoder.
        // Only Prospect HD builds can decode 10bit.
        case CODEC_TAG_PRECISION:			// Number of bits in the video source
            codec->precision = value;
            {
                int i;

                for (i = 0; i < TRANSFORM_MAX_CHANNELS; i++)
                {
                    TRANSFORM *transform = decoder->transform[i];
                    if (transform)
                    {
                        GetTransformPrescale(transform, codec->transform_type, codec->precision);
                    }
                }
            }
            break;

        case CODEC_TAG_PRESCALE_TABLE:
        {
            int i;
            int prescale[TRANSFORM_MAX_WAVELETS] = {0};

            for (i = 0; i < TRANSFORM_MAX_WAVELETS; i++)
                prescale[i] = value >> (14 - i * 2) & 0x3;

            for (i = 0; i < TRANSFORM_MAX_CHANNELS; i++)
            {
                TRANSFORM *transform = decoder->transform[i];
                if (transform)
                {
                    memcpy(transform->prescale, prescale, sizeof(prescale));
                }
            }
        }
        break;

        case CODEC_TAG_VERSION:			// Version number of the encoder used in each GOP.
            codec->version[0] = (value >> 12) & 0xf;
            codec->version[1] = (value >> 8) & 0xf;
            codec->version[2] = value & 0xff;
            break;

        case CODEC_TAG_QUALITY_L:		//
            codec->encode_quality &= 0xffff0000;
            codec->encode_quality |= value;
            break;

        case CODEC_TAG_QUALITY_H:		//
            codec->encode_quality &= 0xffff;
            codec->encode_quality |= value << 16;
            break;

        case CODEC_TAG_BAND_CODING_FLAGS:
            codec->active_codebook = value & 0xf; // 0-15 valid code books
            codec->difference_coding = (value >> 4) & 1;
            break;

        // Peak table processing
        case CODEC_TAG_PEAK_TABLE_OFFSET_L:
            codec->peak_table.offset &= ~0xffff;
            codec->peak_table.offset |= (value & 0xffff);
            codec->peak_table.base = (PIXEL *)(input->lpCurrentWord);
            codec->peak_table.level = 0; // reset for the next subband
            break;

        case CODEC_TAG_PEAK_TABLE_OFFSET_H:
            codec->peak_table.offset &= 0xffff;
            codec->peak_table.offset |= (value & 0xffff) << 16;
            codec->peak_table.level = 0; // reset for the next subband
            break;

        case CODEC_TAG_PEAK_LEVEL:
            codec->peak_table.level = value;
            codec->peak_table.base += codec->peak_table.offset / sizeof(PIXEL);
            break;

        case CODEC_TAG_PEAK_TABLE:
            //this is the chunk header, so we have peak data
            codec->peak_table.level = 0; // reset for the next subband

            //Just skip as the data was read ahead

            chunksize = value;
            chunksize &= 0xffff;
            input->lpCurrentWord += chunksize * 4;
            input->nWordsUsed -= chunksize * 4;
            break;


#if (1 && DEBUG)

        case CODEC_TAG_SAMPLE_END:			// Marks the end of the sample (for debugging only)
            assert(0);
            break;

#endif

        default:		// Unknown tag
            if (tag & 0x4000)
            {
                if (tag & 0x2000) // i.e. 0x6xxx = 24bit size.
                {
                    chunksize = value;
                    chunksize &= 0xffff;
                    chunksize += ((tag & 0xff) << 16);
                }
                else // 16bit size
                {
                    chunksize = value;
                    chunksize &= 0xffff;
                }
            }
            else if (tag & 0x2000)	//24bit LONGs chunk size
            {
                optional = true; // Fixes a weird seneraio where the size fields in SizeTagPop() has not
                // updated the size and turned the tag to optional. TODO : WHY
                chunksize = 0; // not not skip
                //	chunksize = value + ((tag & 0xff)<<16);
                //	do not skip an unknown but optional chunk
                //  These are only use to size subbands, but the data within should not be skipped

                // unless
                if ((tag & 0xff00) == CODEC_TAG_UNCOMPRESS)
                {
                    optional = true;
                    chunksize = value;
                    chunksize &= 0xffff;
                    chunksize += ((tag & 0xff) << 16);


                    decoder->uncompressed_chunk = (uint32_t *)input->lpCurrentWord;
                    decoder->uncompressed_size = chunksize * 4;
                    decoder->sample_uncompressed = 1;
                }
            }

            assert(optional);
            if (!optional)
            {
                error = CODEC_ERROR_UNKNOWN_REQUIRED_TAG;
            }
            else if (chunksize > 0) // skip this option chunk
            {
                input->lpCurrentWord += chunksize * 4;
                input->nWordsUsed -= chunksize * 4;
            }
            break;
    }

    return error;
}

void UpdateWaveletBandValidFlags(DECODER *decoder, IMAGE *wavelet, int band)
{
    assert(decoder != NULL);
    assert(wavelet != NULL);

    if (decoder != NULL && wavelet != NULL)
    {

#if (1 && DEBUG)
        FILE *logfile = decoder->logfile;
#endif

#if _THREADED_DECODER
        // Lock access to the wavelet data
        if (decoder->entropy_worker_new.pool.thread_count)
            Lock(&decoder->entropy_worker_new.lock);
#endif

#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile, "Changing band valid flags: 0x%04X, mask: 0x%04X\n",
                    wavelet->band_valid_flags, BAND_VALID_MASK(band));
        }
#endif
        // Update the wavelet band flags
        wavelet->band_valid_flags |= BAND_VALID_MASK(band);
        wavelet->band_started_flags |= BAND_VALID_MASK(band);

#if _THREADED_DECODER

        // Unlock access to the wavelet data
        if (decoder->entropy_worker_new.pool.thread_count)
            Unlock(&decoder->entropy_worker_new.lock);

#endif


    }
}


void UpdateWaveletBandStartedFlags(DECODER *decoder, IMAGE *wavelet, int band)
{
    assert(decoder != NULL);
    assert(wavelet != NULL);

    if (decoder != NULL && wavelet != NULL)
    {
        // Update the wavelet band flags
#if _DELAYED_THREAD_START==0
        if (decoder->entropy_worker_new.pool.thread_count)
            Lock(&decoder->entropy_worker_new.lock);
#endif

        wavelet->band_started_flags |= BAND_VALID_MASK(band);

#if _DELAYED_THREAD_START==0
        if (decoder->entropy_worker_new.pool.thread_count)
            Unlock(&decoder->entropy_worker_new.lock);
#endif
    }
}

bool DecodedBandsValid(IMAGE *wavelet, int index, int transform_type)
{
    uint32_t threaded_band_mask;
    uint32_t wavelet_band_mask;
    uint32_t decoded_band_mask;

    bool decoded_bands_valid;

    // Has this wavelet been created?
    if (wavelet == NULL)
    {
        // Too soon to wait for the wavelet bands to be decoded
        return false;
    }

    // Is this a fieldplus transform?
    if (transform_type == TRANSFORM_TYPE_FIELDPLUS)
    {
        // Is this the temporal wavelet?
        if (index == 2)
        {
            assert(wavelet->wavelet_type == WAVELET_TYPE_TEMPORAL);
            assert(wavelet->num_bands == 2);

            // Earlier transforms in the queue will compute both wavelet bands
            return true;
        }

        // Is this wavelet at the end of a chain of transforms?
        if (index == 3 || index == 5)
        {
            // Must wait for all bands to be decoded
            threaded_band_mask = 0;
        }
        else
        {
            // The lowpass band will be computed by transforms earlier in the queue
            threaded_band_mask = BAND_VALID_MASK(0);
        }
    }

    // Is this a spatial transform?
    else if (transform_type == TRANSFORM_TYPE_SPATIAL)
    {
        // Is this wavelet at the top of the pyramid?
        if (index == 2)
        {
            // Must wait for all bands to be decoded
            threaded_band_mask = 0;
        }
#if 0
        // Is this wavelet at the bottom of the pyramid?
        else if (index == 0)
        {
            // Must wait for all bands to be decoded
            threaded_band_mask = 0;
        }
#endif
        else
        {
            // The lowpass band will be computed by transforms earlier in the queue
            threaded_band_mask = BAND_VALID_MASK(0);
        }
    }

    else
    {
        // Unknown type of transform
        assert(0);

        // Assume that the bands are not valid
        return false;
    }

    // Compute the mask for the bands in this wavelet
    decoded_band_mask = ((1 << wavelet->num_bands) - 1);

    // Clear the bit for the band computed by the threaded transform
    decoded_band_mask &= ~threaded_band_mask;

    // Compute the wavelet bands that have been decoded
    wavelet_band_mask = (wavelet->band_valid_flags & decoded_band_mask);

    // Have all of the bands not computed by the transform thread been decoded?
    decoded_bands_valid = (wavelet_band_mask == decoded_band_mask);

    return decoded_bands_valid;
}

void QueueThreadedTransform(DECODER *decoder, int channel, int index)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    TRANSFORM *transform = decoder->transform[channel];
    //IMAGE *wavelet = transform->wavelet[index];
    int precision = codec->precision;

    // The transform data structure must exist
    assert(transform != NULL);

    // The transform thread variables should have been created
    {
        int free_entry;

#if _DELAYED_THREAD_START==0
        // Lock access to the transform queue
        Lock(&decoder->entropy_worker_new.lock);
#endif

        // Copy the transform parameters into the next queue entry
        free_entry = decoder->transform_queue.free_entry;
        assert(0 <= free_entry && free_entry < DECODING_QUEUE_LENGTH);
        if (0 <= free_entry && free_entry < DECODING_QUEUE_LENGTH)
        {
            assert(transform != NULL);
            assert(0 <= channel && channel < TRANSFORM_MAX_CHANNELS);
            assert(0 <= index && index < TRANSFORM_MAX_WAVELETS);

            // Note: The wavelet may not exist when the transform is queued

            decoder->transform_queue.queue[free_entry].transform = transform;
            decoder->transform_queue.queue[free_entry].channel = channel;
            decoder->transform_queue.queue[free_entry].index = index;
            decoder->transform_queue.queue[free_entry].precision = precision;
            decoder->transform_queue.queue[free_entry].done = 0;

            // Update the transform request queue
            decoder->transform_queue.free_entry++;
            decoder->transform_queue.num_entries++;

#if (1 && DEBUG)
            if (logfile)
            {
                fprintf(logfile, "Queued transform, channel: %d, index: %d\n", channel, index);
            }
#endif
        }
#if _DELAYED_THREAD_START==0
        Unlock(&decoder->entropy_worker_new.lock);
#endif
    }
}


#if _THREADED_DECODER
void WaitForTransformThread(DECODER *decoder)
{
    if (decoder->entropy_worker_new.pool.thread_count)
    {
#if _DELAYED_THREAD_START
        ThreadPoolSendMessage(&decoder->entropy_worker_new.pool, THREAD_MESSAGE_START);
#endif

        ThreadPoolWaitAllDone(&decoder->entropy_worker_new.pool);

        decoder->transform_queue.started = 0;
        decoder->transform_queue.num_entries = 0;
        decoder->transform_queue.next_entry = 0;
        decoder->transform_queue.free_entry = 0;
    }
}
#endif

#endif

#if _INTERLACED_WORKER_THREADS
void TransformInverseFrameThreadedToYUV(DECODER *decoder, int frame_index, int num_channels,
                                        uint8_t *output, int pitch, FRAME_INFO *info,
                                        int chroma_offset, int precision)
{
    int32_t lPreviousCount, i;

    // There are half as many input rows as output rows
    int transform_height = (((info->height + 7) / 8) * 8) / 2;
    int middle_row_count = transform_height;

    // Post a message to the mailbox
    struct interlace_data *mailbox = &decoder->interlaced_worker.interlace_data;
    mailbox->type = THREAD_TRANSFORM_FRAME_YUV;
    mailbox->frame = frame_index;
    mailbox->num_channels = num_channels;
    mailbox->output = output;
    mailbox->pitch = pitch;
    memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
    mailbox->chroma_offset = chroma_offset;
    mailbox->precision = precision;

    // Set the semaphore to the number of rows
    decoder->interlaced_worker.current_row = 0;
    ReleaseSemaphore(decoder->interlaced_worker.row_semaphore, middle_row_count, &lPreviousCount);
    assert(lPreviousCount == 0);

    // Wake up both worker threads
    for (i = 0; i < THREADS_IN_LAST_WAVELET; i++)
    {
        SetEvent(decoder->interlaced_worker.start_event[i]);
    }

    // Wait for both worker threads to finish
    WaitForMultipleObjects(THREADS_IN_LAST_WAVELET, decoder->interlaced_worker.done_event, true, INFINITE);
}

void TransformInverseFrameThreadedToRow16u(DECODER *decoder, int frame_index, int num_channels,
        PIXEL16U *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision)
{
    int32_t lPreviousCount, i;

    // There are half as many input rows as output rows
    int transform_height = (((info->height + 7) / 8) * 8) / 2;
    int middle_row_count = transform_height;

    // Post a message to the mailbox
    struct interlace_data *mailbox = &decoder->interlaced_worker.interlace_data;
    mailbox->type = THREAD_TRANSFORM_FRAME_ROW16U;
    mailbox->frame = frame_index;
    mailbox->num_channels = num_channels;
    mailbox->output = (uint8_t *)output;
    mailbox->pitch = pitch;
    memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
    mailbox->chroma_offset = chroma_offset;
    mailbox->precision = precision;

    // Set the semaphore to the number of rows
    decoder->interlaced_worker.current_row = 0;
    ReleaseSemaphore(decoder->interlaced_worker.row_semaphore, middle_row_count, &lPreviousCount);
    assert(lPreviousCount == 0);

    // Wake up both worker threads
    for (i = 0; i < THREADS_IN_LAST_WAVELET; i++)
    {
        SetEvent(decoder->interlaced_worker.start_event[i]);
    }

    // Wait for both worker threads to finish
    WaitForMultipleObjects(THREADS_IN_LAST_WAVELET, decoder->interlaced_worker.done_event, true, INFINITE);
}


DWORD WINAPI InterlacedWorkerThreadProc(LPVOID lpParam)
{
    DECODER *decoder = (DECODER *)lpParam;
    FILE *logfile = decoder->logfile;
    struct interlace_data *data = &decoder->interlaced_worker.interlace_data;
    int thread_index;

    HANDLE hObjects[2];
    DWORD dwReturnValue;

    if (decoder->thread_cntrl.affinity)
    {
        HANDLE hCurrentThread = GetCurrentThread();
        SetThreadAffinityMask(hCurrentThread, decoder->thread_cntrl.affinity);
    }

    // Determine the index of this worker thread
    if (decoder->interlaced_worker.lock_init)
    {
        EnterCriticalSection(&decoder->interlaced_worker.lock);
    }

    thread_index = decoder->interlaced_worker.thread_count++;

    if (decoder->interlaced_worker.lock_init)
        LeaveCriticalSection(&decoder->interlaced_worker.lock);

    // The transform worker variables should have been created
    assert(decoder->interlaced_worker.start_event[thread_index] != NULL);
    assert(decoder->interlaced_worker.row_semaphore != NULL);
    assert(decoder->interlaced_worker.done_event[thread_index] != NULL);
    assert(decoder->interlaced_worker.stop_event != NULL);

    if (!(decoder->interlaced_worker.start_event[thread_index] != NULL &&
            decoder->interlaced_worker.row_semaphore != NULL &&
            decoder->interlaced_worker.done_event[thread_index] != NULL &&
            decoder->interlaced_worker.stop_event != NULL))
    {
        return 1;
    }

    hObjects[0] = decoder->interlaced_worker.start_event[thread_index];
    hObjects[1] = decoder->interlaced_worker.stop_event;

    for (;;)
    {
        // Wait for the signal to begin processing a transform
        dwReturnValue = WaitForMultipleObjects(2, hObjects, false, INFINITE);

        // Received a signal to begin inverse transform processing?
        if (dwReturnValue == WAIT_OBJECT_0)
        {
            int type;				// Type of inverse transform to perform
            int frame_index;		// Index of output frame to produce
            int num_channels;		// Number of channels in the transform array
            uint8_t *output;			// Output frame buffer
            int pitch;				// Output frame pitch
            FRAME_INFO info;		// Format of the output frame
            int chroma_offset;		// Offset for the output chroma
            int precision;			// Source pixel bit depth

            // Lock access to the transform data
            if (decoder->interlaced_worker.lock_init)
            {
                EnterCriticalSection(&decoder->interlaced_worker.lock);
            }
            // Get the processing parameters
            type = data->type;
            frame_index = data->frame;
            num_channels = data->num_channels;
            output = data->output;
            pitch = data->pitch;
            memcpy(&info, &data->info, sizeof(FRAME_INFO));
            chroma_offset = data->chroma_offset;
            precision = data->precision;

            // Unlock access to the transform data
            if (decoder->interlaced_worker.lock_init)
                LeaveCriticalSection(&decoder->interlaced_worker.lock);

            // Select the type of inverse transform to perform
            switch (type)
            {
                case THREAD_TRANSFORM_FRAME_YUV:
                    //TODO: more to new _THREADED model
                    TransformInverseFrameSectionToYUV(decoder, thread_index, frame_index, num_channels,
                                                      output, pitch, &info, chroma_offset, precision);
                    break;

                case THREAD_TRANSFORM_FRAME_ROW16U:
                    //TODO: more to new _THREADED model
                    TransformInverseFrameSectionToRow16u(decoder, thread_index, frame_index, num_channels,
                                                         (PIXEL16U *)output, pitch, &info, chroma_offset, precision);
                    break;

                default:
                    assert(0);
                    break;
            }

            // Signal that this thread is done
            SetEvent(decoder->interlaced_worker.done_event[thread_index]);
        }
        else
        {
            // Should have a condition that causes the thread to terminate
            assert(dwReturnValue == WAIT_OBJECT_0 + 1 || dwReturnValue == WAIT_ABANDONED);
            break;
        }
    }

    return 0;
}


#endif

void GetDecodedFrameDimensions(TRANSFORM **transform_array,
                               int num_channels,
                               int frame_index,
                               int resolution,
                               int *decoded_width_out,
                               int *decoded_height_out)
{
    IMAGE *wavelet = NULL;
    int decoded_scale = 0;
    int wavelet_width;
    int wavelet_height;
    int decoded_width;
    int decoded_height;

    // Get the decoding scale
    switch (resolution)
    {
        case DECODED_RESOLUTION_FULL_DEBAYER:
        case DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER:
#if DEBUG
            assert(AllTransformBandsValid(transform_array, num_channels, frame_index));
#endif
            decoded_scale = 2;
            wavelet = transform_array[0]->wavelet[0];
            break;

        case DECODED_RESOLUTION_FULL:
#if DEBUG
            assert(AllTransformBandsValid(transform_array, num_channels, frame_index));
#endif
            decoded_scale = 2;
            wavelet = transform_array[0]->wavelet[0];
            break;
        case DECODED_RESOLUTION_HALF_NODEBAYER:
        case DECODED_RESOLUTION_HALF:
#if DEBUG
            assert(AllLowpassBandsValid(transform_array, num_channels, frame_index));
#endif
            decoded_scale = 1;
            wavelet = transform_array[0]->wavelet[0];
            break;

        case DECODED_RESOLUTION_QUARTER:
            decoded_scale = 1;
            wavelet = transform_array[0]->wavelet[3];
            break;

        case DECODED_RESOLUTION_LOWPASS_ONLY:
            decoded_scale = 1;
            wavelet = transform_array[0]->wavelet[5];

            // Is this an intra frame?
            if (wavelet == NULL)
            {
                wavelet = transform_array[0]->wavelet[2];
            }

            break;

        default:
            assert(0);
            break;
    }

    // Compute the decoded frame dimensions
    assert(wavelet != NULL);
    wavelet_width = wavelet->width;
    wavelet_height = wavelet->height;
    decoded_width = decoded_scale * wavelet_width;
    decoded_height = decoded_scale * wavelet_height;

    if (decoded_width_out)
    {
        *decoded_width_out = decoded_width;
    }

    if (decoded_height_out)
    {
        *decoded_height_out = decoded_height;
    }
}

// Reconstruct Bayer format to the requested output format
CODEC_ERROR UncompressedSampleFrameBayerToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output_buffer, int output_pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    //CODEC_STATE *codec = &decoder->codec;
    //int num_channels = codec->num_channels;
    //int precision = codec->precision;
    int format = info->format;
    int width = info->width;
    int height = info->height;
    //int resolution = info->resolution;

    // Compute the number of bytes between each row of Bayer data
    //int bayer_pitch = 2 * width * sizeof(PIXEL16U);

    // Compute the pitch between pairs of rows of bayer data (one pair per image row)
    //int raw_bayer_pitch = 2 * bayer_pitch;

    //int chroma_offset = decoder->codec.chroma_offset;

    error = CODEC_ERROR_UNSUPPORTED_FORMAT;
    switch (format)
    {
        case DECODED_FORMAT_RGB24:
        case DECODED_FORMAT_RGB32:
        case DECODED_FORMAT_RG48: //DAN20090120 added not sure why they weren't here.
        case DECODED_FORMAT_RG64: //DAN20101207 added not sure why they weren't here.
        case DECODED_FORMAT_WP13: //DAN20090120  ""
        case DECODED_FORMAT_W13A: //DAN20101207  ""
        case DECODED_FORMAT_B64A:
        case DECODED_FORMAT_R210:
        case DECODED_FORMAT_DPX0:
        case DECODED_FORMAT_RG30:
        case DECODED_FORMAT_AR10:
        case DECODED_FORMAT_AB10:
        case DECODED_FORMAT_YR16:
        case DECODED_FORMAT_V210:
        case DECODED_FORMAT_YU64:
        case DECODED_FORMAT_YUYV: //?
        case DECODED_FORMAT_UYVY: //?
        case DECODED_FORMAT_R408:
        case DECODED_FORMAT_V408:
            error = CODEC_ERROR_OKAY;
            break;

        case DECODED_FORMAT_BYR2:
        case DECODED_FORMAT_BYR4:
        {
            //bool linearRestore = false;
            unsigned short *curve = NULL;

            if (decoder->BYR4LinearRestore && decoder->frame.format == DECODED_FORMAT_BYR4 && decoder->cfhddata.encode_curve_preset == 0)
            {
                curve = decoder->BYR4LinearRestore;
            }
            ConvertPackedToBYR2(width, height, decoder->uncompressed_chunk, decoder->uncompressed_size, output_buffer, output_pitch, curve);
        }
        decoder->uncompressed_chunk = 0;
        decoder->uncompressed_size = 0;
        return CODEC_ERROR_OKAY;
        break;
        case DECODED_FORMAT_BYR3:
            ConvertPackedToBYR3(width, height, decoder->uncompressed_chunk, decoder->uncompressed_size, output_buffer, output_pitch);
            decoder->uncompressed_chunk = 0;
            decoder->uncompressed_size = 0;
            return CODEC_ERROR_OKAY;
            break;

    }

    if (error)
        return error;


    //int row;
    //int column;

    // Need to allocate a scratch buffer for decoding the Bayer frame?
    if (decoder->RawBayer16 == NULL)
    {
        // Four Bayer data samples at each 2x2 quad in the grid
        int pixel_size = 4 * sizeof(PIXEL16U);
        int frame_size;
        const size_t alignment = 16;

#if _ALLOCATOR
        ALLOCATOR *allocator = decoder->allocator;
#endif

        frame_size = width * height * pixel_size;

#if _ALLOCATOR
        decoder->RawBayer16 = (PIXEL16U *)AllocAligned(allocator, (size_t)frame_size, alignment);
#else
        decoder->RawBayer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(frame_size, alignment);
#endif
        assert(decoder->RawBayer16 != NULL);
        if (! (decoder->RawBayer16 != NULL))
        {
            return CODEC_ERROR_MEMORY_ALLOC;
        }
        decoder->RawBayerSize = frame_size;

        if (decoder->RGBFilterBuffer16 == NULL)
        {
            int size = frame_size * 3;
            if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                size = frame_size * 4;
#if _ALLOCATOR
            decoder->RGBFilterBuffer16 = (PIXEL16U *)AllocAligned(allocator, (size_t)size, 16);
#else
            decoder->RGBFilterBuffer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(size, 16);
#endif
            assert(decoder->RGBFilterBuffer16 != NULL);
            if (! (decoder->RGBFilterBuffer16 != NULL))
            {
                return CODEC_ERROR_MEMORY_ALLOC;
            }
            decoder->RGBFilterBufferSize = frame_size * 3;
        }
    }
    // Using the RGBFilterBuffer16 as scratch space
    ConvertPackedToRawBayer16(width, height, decoder->uncompressed_chunk, decoder->uncompressed_size, decoder->RawBayer16, decoder->RGBFilterBuffer16, info->resolution);
    decoder->uncompressed_chunk = 0;
    decoder->uncompressed_size = 0;


#if _THREADED

    //DemosaicRAW
    {
        WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;
        int inverted = false;
        uint8_t *output = output_buffer;
        int pitch = output_pitch;

#if _DELAY_THREAD_START
        if (decoder->worker_thread.pool.thread_count == 0)
        {
            CreateLock(&decoder->worker_thread.lock);
            // Initialize the pool of transform worker threads
            ThreadPoolCreate(&decoder->worker_thread.pool,
                             decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                             WorkerThreadProc,
                             decoder);
        }
#endif
        if (format == DECODED_FORMAT_RGB24)
        {
            format = DECODED_FORMAT_RGB24_INVERTED;
            inverted = true;
        }
        else if (format == DECODED_FORMAT_RGB32)
        {
            format = DECODED_FORMAT_RGB32_INVERTED;
            inverted = true;
        }

        // Have the output location and pitch been inverted?
        if (inverted && pitch > 0)
        {
            int height = info->height;
            if (info->resolution == DECODED_RESOLUTION_FULL_DEBAYER || info->resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER)
                height *= 2;
            output += (height - 1) * pitch;		// Start at the bottom row
            pitch = NEG(pitch);					// Negate the pitch to go up
        }

        // Post a message to the mailbox
        mailbox->output = output;
        mailbox->pitch = pitch;
        memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
        mailbox->jobType = JOB_TYPE_OUTPUT;

        // Set the work count to the number of rows to process
        ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

        // Start the transform worker threads
        ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

        // Wait for all of the worker threads to finish
        ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
    }

#else
    error = CODEC_ERROR_UNSUPPORTED_FORMAT;
#endif

    return error;
}


// Reconstruct uncompressed v210 YUV format to the requested output format
CODEC_ERROR UncompressedSampleFrameYUVToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output_buffer, int output_pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    //CODEC_STATE *codec = &decoder->codec;
    //int num_channels = codec->num_channels;
    //int precision = codec->precision;
    int format = info->format;
    int width = info->width;
    int height = info->height;
    int resolution = info->resolution;

    // Compute the number of bytes between each row of Bayer data
    //int bayer_pitch = 2 * width * sizeof(PIXEL16U);

    // Compute the pitch between pairs of rows of bayer data (one pair per image row)
    //int raw_bayer_pitch = 2 * bayer_pitch;

    //int chroma_offset = decoder->codec.chroma_offset;

    error = CODEC_ERROR_UNSUPPORTED_FORMAT;

    if (format == DECODED_FORMAT_V210 && resolution == DECODED_RESOLUTION_FULL && decoder->use_active_metadata_decoder == false)
    {
        int smallest_Stride = output_pitch;
        int unc_Stride = decoder->uncompressed_size / height;

        if (unc_Stride < smallest_Stride)
            smallest_Stride = unc_Stride;


        if (unc_Stride == output_pitch)
            memcpy(output_buffer, decoder->uncompressed_chunk, decoder->uncompressed_size);
        else
        {
            int y;
            uint8_t *src = (uint8_t *)decoder->uncompressed_chunk;
            uint8_t *dst = (uint8_t *)output_buffer;

            for (y = 0; y < height; y++)
            {
                memcpy(dst, src, smallest_Stride);
                src += unc_Stride;
                dst += output_pitch;
            }
        }
        decoder->uncompressed_chunk = 0;
        decoder->uncompressed_size = 0;
        return CODEC_ERROR_OKAY;
    }


    if ((format == DECODED_FORMAT_YUYV || format == DECODED_FORMAT_UYVY) && resolution == DECODED_RESOLUTION_FULL && decoder->use_active_metadata_decoder == false)
    {
        int smallest_Stride = output_pitch;
        int unc_Stride = decoder->uncompressed_size / height;

        if (unc_Stride < smallest_Stride)
            smallest_Stride = unc_Stride;

        {
            int y;
            uint8_t *src = (uint8_t *)decoder->uncompressed_chunk;
            uint8_t *dst = (uint8_t *)output_buffer;

            for (y = 0; y < height; y++)
            {
                uint32_t *input_ptr = (uint32_t *)src;
                int pos = 0;
                int column = 0, length = width;
                length -= length % 6; //DAN03252004 -- fix a memory overflow.

                for (column = 0; column < length; column += 6)
                {
                    uint32_t yuv;

                    int y;
                    int u;
                    int v;

                    // Read the first word
                    yuv = *(input_ptr++);

                    u = (yuv >> V210_VALUE1_SHIFT) & V210_VALUE_MASK;
                    y = (yuv >> V210_VALUE2_SHIFT) & V210_VALUE_MASK;
                    v = (yuv >> V210_VALUE3_SHIFT) & V210_VALUE_MASK;

                    // Expand the pixels to sixteen bits
                    u <<= 6;
                    y <<= 6;
                    v <<= 6;

                    dst[pos++] = SATURATE_16U(y) >> 8;
                    dst[pos++] = SATURATE_16U(u) >> 8;

                    // Read the second word
                    yuv = *(input_ptr++);

                    y = (yuv >> V210_VALUE1_SHIFT) & V210_VALUE_MASK;

                    y <<= 6;

                    dst[pos++] = SATURATE_16U(y) >> 8;
                    dst[pos++] = SATURATE_16U(v) >> 8;

                    u = (yuv >> V210_VALUE2_SHIFT) & V210_VALUE_MASK;
                    y = (yuv >> V210_VALUE3_SHIFT) & V210_VALUE_MASK;

                    u <<= 6;
                    y <<= 6;

                    dst[pos++] = SATURATE_16U(y) >> 8;
                    dst[pos++] = SATURATE_16U(u) >> 8;

                    // Read the third word
                    yuv = *(input_ptr++);

                    v = (yuv >> V210_VALUE1_SHIFT) & V210_VALUE_MASK;
                    y = (yuv >> V210_VALUE2_SHIFT) & V210_VALUE_MASK;

                    v <<= 6;
                    y <<= 6;

                    dst[pos++] = SATURATE_16U(y) >> 8;
                    dst[pos++] = SATURATE_16U(v) >> 8;

                    u = (yuv >> V210_VALUE3_SHIFT) & V210_VALUE_MASK;
                    u <<= 6;

                    // Read the fourth word
                    yuv = *(input_ptr++);

                    y = (yuv >> V210_VALUE1_SHIFT) & V210_VALUE_MASK;
                    y <<= 6;

                    dst[pos++] = SATURATE_16U(y) >> 8;
                    dst[pos++] = SATURATE_16U(u) >> 8;

                    v = (yuv >> V210_VALUE2_SHIFT) & V210_VALUE_MASK;
                    y = (yuv >> V210_VALUE3_SHIFT) & V210_VALUE_MASK;

                    v <<= 6;
                    y <<= 6;

                    dst[pos++] = SATURATE_16U(y) >> 8;
                    dst[pos++] = SATURATE_16U(v) >> 8;
                }

                if (format == DECODED_FORMAT_UYVY)
                {
                    for (column = 0; column < pos; column += 2)
                    {
                        int t = dst[column];

                        dst[column] = dst[column + 1];
                        dst[column + 1] = t;
                    }
                }


                src += unc_Stride;
                dst += output_pitch;
            }
        }
        decoder->uncompressed_chunk = 0;
        decoder->uncompressed_size = 0;
        return CODEC_ERROR_OKAY;
    }

    {
        // Expand YUV at the target resolution, and use the ActiveMetadata engine.

        // Need to allocate a scratch buffer for decoding the frame?
        if (decoder->RawBayer16 == NULL || decoder->RawBayerSize < width * 64) //RawBayer used as a scratch buffer
        {
            //int pixel_size = 2 * sizeof(PIXEL16U);
            const size_t alignment = 16;
#if _ALLOCATOR
            ALLOCATOR *allocator = decoder->allocator;
#endif

            int orig_width = width;
            if (resolution == DECODED_RESOLUTION_HALF)
                orig_width *= 2;
            if (resolution == DECODED_RESOLUTION_QUARTER)
                orig_width *= 4;

            if (decoder->RawBayer16)
            {
#if _ALLOCATOR
                FreeAligned(allocator, decoder->RawBayer16);
                decoder->RawBayer16 = NULL;
                decoder->RawBayerSize = 0;
#else
                MEMORY_ALIGNED_FREE(decoder->RawBayer16);
                decoder->RawBayer16 = NULL;
                decoder->RawBayerSize = 0;
#endif
            }


#if _ALLOCATOR
            decoder->RawBayer16 = (PIXEL16U *)AllocAligned(allocator, orig_width * 64, alignment);
#else
            decoder->RawBayer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(orig_width * 64, alignment);
#endif
            assert(decoder->RawBayer16 != NULL);
            if (! (decoder->RawBayer16 != NULL))
            {
                return CODEC_ERROR_MEMORY_ALLOC;
            }
            decoder->RawBayerSize = orig_width * 64;
        }
    }

    // unpack source original YUV into YU64?

    if (decoder->RawBayer16)
    {
        //uint8_t *src = (uint8_t *)decoder->uncompressed_chunk;
        //uint8_t *dst = (uint8_t *)output_buffer;

#if _THREADED
        {
            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
            if (decoder->worker_thread.pool.thread_count == 0)
            {
                CreateLock(&decoder->worker_thread.lock);
                // Initialize the pool of transform worker threads
                ThreadPoolCreate(&decoder->worker_thread.pool,
                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                 WorkerThreadProc,
                                 decoder);
            }
#endif

            // Post a message to the mailbox
            mailbox->output = output_buffer;
            mailbox->pitch = output_pitch;
            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
            mailbox->jobType = JOB_TYPE_OUTPUT_UNCOMPRESSED;

            // Set the work count to the number of rows to process
            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, height);

            // Start the transform worker threads
            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

            // Wait for all of the worker threads to finish
            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
        }
#else

        {
            int orig_width = width;
            int orig_height = height;
            int row, lines = 1;
            int start, end;
            if (resolution == DECODED_RESOLUTION_HALF)
            {
                orig_width *= 2;
                orig_height *= 2;
                lines = 2;
            }
            if (resolution == DECODED_RESOLUTION_QUARTER)
            {
                orig_width *= 4;
                orig_height *= 4;
                lines = 4;
            }

            start = 0;
            end = height;
            if (format == DECODED_FORMAT_RGB32 || format == DECODED_FORMAT_RGB24)
            {
                start = height - 1;
                end = -1;
            }
            for (row = start; row != end; end > start ? row++ : row--)
            {
                int whitebitdepth = 16;
                int flags = 0;
                uint8_t *planar_output[3];
                int planar_pitch[3];
                ROI roi;
                PIXEL16U *y_row_ptr;
                PIXEL16U *u_row_ptr;
                PIXEL16U *v_row_ptr;
                PIXEL16U *scanline = (PIXEL16U *)decoder->RawBayer16;
                PIXEL16U *scanline2 = scanline + orig_width * 8;
                unsigned short *sptr;
                int i, unc_Stride = decoder->uncompressed_size / orig_height;

                y_row_ptr = (PIXEL16U *)scanline;
                u_row_ptr = y_row_ptr + orig_width;
                v_row_ptr = u_row_ptr + orig_width / 2;
                for (i = 0; i < lines; i++)
                {
                    src = (uint8_t *)decoder->uncompressed_chunk;
                    src += row * unc_Stride;

                    // Repack the row of 10-bit pixels into 16-bit pixels
                    ConvertV210RowToYUV16((uint8_t *)src, y_row_ptr, u_row_ptr, v_row_ptr, orig_width, scanline2);

                    // Advance to the next rows in the input and output images
                    y_row_ptr += orig_width * 2;
                    u_row_ptr = y_row_ptr + orig_width;
                    v_row_ptr = u_row_ptr + orig_width / 2;

                }


                y_row_ptr = (PIXEL16U *)scanline;
                u_row_ptr = y_row_ptr + width;
                v_row_ptr = u_row_ptr + width / 2;
                if (lines == 2)
                {
                    for (i = 0; i < width * 2; i++)
                        y_row_ptr[i] = (y_row_ptr[i * 2] + y_row_ptr[i * 2 + 1] + y_row_ptr[orig_width * 2 + i * 2] + y_row_ptr[orig_width * 2 + i * 2 + 1]) >> 2;

                }
                else if (lines == 4)
                {
                    for (i = 0; i < width * 2; i++)
                        y_row_ptr[i] = (y_row_ptr[i * 4] + y_row_ptr[i * 4 + 2] + y_row_ptr[orig_width * 2 * 2 + i * 4] + y_row_ptr[orig_width * 2 * 2 + i * 4 + 2]) >> 2;
                }


                roi.width = width;
                roi.height = 1;

                planar_output[0] = (uint8_t *)y_row_ptr;
                planar_output[1] = (uint8_t *)v_row_ptr;
                planar_output[2] = (uint8_t *)u_row_ptr;
                planar_pitch[0] = 0;
                planar_pitch[1] = 0;
                planar_pitch[2] = 0;

                if (decoder->apply_color_active_metadata)
                {
                    ConvertYUVRow16uToBGRA64(planar_output, planar_pitch, roi,
                                             (unsigned char *)scanline2, width, output_pitch,
                                             COLOR_FORMAT_RGB_8PIXEL_PLANAR, decoder->frame.colorspace, &whitebitdepth, &flags);
                    sptr = scanline2;

                    sptr = ApplyActiveMetaData(decoder, width, 1, row, scanline2, scanline,
                                               info->format, &whitebitdepth, &flags);
                }
                else
                {
                    ConvertYUVRow16uToBGRA64(planar_output, planar_pitch, roi,
                                             (unsigned char *)scanline2, width, output_pitch,
                                             COLOR_FORMAT_WP13, decoder->frame.colorspace, &whitebitdepth, &flags);
                    sptr = scanline2;
                }

                ConvertLinesToOutput(decoder, width, 1, row, sptr,
                                     dst, output_pitch, format, whitebitdepth, flags);

                dst += output_pitch;
            }
        }
#endif
    }

    error = CODEC_ERROR_OKAY;

    return error;
}





// Reconstruct uncompressed DPX0 RGB format to the requested output format
CODEC_ERROR UncompressedSampleFrameRGBToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output_buffer, int output_pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    //CODEC_STATE *codec = &decoder->codec;
    //int num_channels = codec->num_channels;
    //int precision = codec->precision;
    int format = info->format;
    //int output_format = info->output_format; // used by image_dev_only decodes
    int width = info->width;
    int height = info->height;
    int resolution = info->resolution;
    //int chroma_offset = decoder->codec.chroma_offset;

    error = CODEC_ERROR_UNSUPPORTED_FORMAT;

    if (	(format == DECODED_FORMAT_DPX0 || format == DECODED_FORMAT_AR10 || format == DECODED_FORMAT_AB10 || format == DECODED_FORMAT_RG30 || format == DECODED_FORMAT_R210) &&
            resolution == DECODED_RESOLUTION_FULL && decoder->use_active_metadata_decoder == false)
    {
        int smallest_Stride = output_pitch;
        int unc_Stride = decoder->uncompressed_size / height;

        if (unc_Stride < smallest_Stride)
            smallest_Stride = unc_Stride;

        if (format != DECODED_FORMAT_DPX0)
        {
            int unc_Stride = decoder->uncompressed_size / height;
            ConvertDPX0ToRGB10((uint8_t *)decoder->uncompressed_chunk, unc_Stride, width, height, format);
        }

        if (unc_Stride == output_pitch)
            memcpy(output_buffer, decoder->uncompressed_chunk, decoder->uncompressed_size);
        else
        {
            int y;
            uint8_t *src = (uint8_t *)decoder->uncompressed_chunk;
            uint8_t *dst = (uint8_t *)output_buffer;

            for (y = 0; y < height; y++)
            {
                memcpy(dst, src, smallest_Stride);
                src += unc_Stride;
                dst += output_pitch;
            }
        }
        decoder->uncompressed_chunk = 0;
        decoder->uncompressed_size = 0;
        return CODEC_ERROR_OKAY;
    }


    {
        // Expand YUV at the target resolution, and use the ActiveMetadata engine.

        // Need to allocate a scratch buffer for decoding the frame?
        if (decoder->RawBayer16 == NULL || decoder->RawBayerSize < width * 64) //RawBayer used as a scratch buffer
        {
            //int pixel_size = 2 * sizeof(PIXEL16U);
            const size_t alignment = 16;
#if _ALLOCATOR
            ALLOCATOR *allocator = decoder->allocator;
#endif

            int orig_width = width;
            if (resolution == DECODED_RESOLUTION_HALF)
                orig_width *= 2;
            if (resolution == DECODED_RESOLUTION_QUARTER)
                orig_width *= 4;

            if (decoder->RawBayer16)
            {
#if _ALLOCATOR
                FreeAligned(allocator, decoder->RawBayer16);
                decoder->RawBayer16 = NULL;
                decoder->RawBayerSize = 0;
#else
                MEMORY_ALIGNED_FREE(decoder->RawBayer16);
                decoder->RawBayer16 = NULL;
                decoder->RawBayerSize = 0;
#endif
            }


#if _ALLOCATOR
            decoder->RawBayer16 = (PIXEL16U *)AllocAligned(allocator, orig_width * 64, alignment);
#else
            decoder->RawBayer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(orig_width * 64, alignment);
#endif
            assert(decoder->RawBayer16 != NULL);
            if (! (decoder->RawBayer16 != NULL))
            {
                return CODEC_ERROR_MEMORY_ALLOC;
            }
            decoder->RawBayerSize = orig_width * 64;
        }
    }

    // unpack source original YUV into YU64?

    if (decoder->RawBayer16)
    {
        //uint8_t *src = (uint8_t *)decoder->uncompressed_chunk;
        //uint8_t *dst = (uint8_t *)output_buffer;

#if _THREADED
        {
            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
            if (decoder->worker_thread.pool.thread_count == 0)
            {
                CreateLock(&decoder->worker_thread.lock);
                // Initialize the pool of transform worker threads
                ThreadPoolCreate(&decoder->worker_thread.pool,
                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                 WorkerThreadProc,
                                 decoder);
            }
#endif

            // Post a message to the mailbox
            mailbox->output = output_buffer;
            mailbox->pitch = output_pitch;
            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
            mailbox->jobType = JOB_TYPE_OUTPUT_UNCOMPRESSED;

            // Set the work count to the number of rows to process
            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, height);

            // Start the transform worker threads
            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

            // Wait for all of the worker threads to finish
            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
        }
#else

        {
            int orig_width = width;
            int orig_height = height;
            int row, lines = 1;
            int start, end;
            if (resolution == DECODED_RESOLUTION_HALF)
            {
                orig_width *= 2;
                orig_height *= 2;
                lines = 2;
            }
            if (resolution == DECODED_RESOLUTION_QUARTER)
            {
                orig_width *= 4;
                orig_height *= 4;
                lines = 4;
            }

            start = 0;
            end = height;
            if (format == DECODED_FORMAT_RGB32 || format == DECODED_FORMAT_RGB24) // Can this work, all the code below expects 10-bit
            {
                start = height - 1;
                end = -1;
            }
            for (row = start; row != end; end > start ? row++ : row--)
            {
                int whitebitdepth = 16;
                int flags = 0;
                uint8_t *planar_output[3];
                int planar_pitch[3];
                ROI roi;
                PIXEL16U *y_row_ptr;
                PIXEL16U *u_row_ptr;
                PIXEL16U *v_row_ptr;
                PIXEL16U *scanline = (PIXEL16U *)decoder->RawBayer16;
                PIXEL16U *scanline2 = scanline + orig_width * 8;
                unsigned short *sptr;
                int i, unc_Stride = decoder->uncompressed_size / orig_height;

                whitebitdepth = 13;
                if (decoder->apply_color_active_metadata)
                    flags = ACTIVEMETADATA_SRC_8PIXEL_PLANAR;
                else
                    flags = 0;

                roi.width = width;
                roi.height = 1;

                if (lines == 1)
                {
                    uint16_t *sptr;
                    uint32_t j, *lptr = (uint32_t *)decoder->uncompressed_chunk;
                    PIXEL16U *ptr = (PIXEL16U *)scanline;

                    lptr += row * (unc_Stride >> 2);
                    sptr = (uint16_t *)lptr;
                    for (i = 0; i < width; i += 8)
                    {
                        int val, r, g, b;
                        if (flags == ACTIVEMETADATA_SRC_8PIXEL_PLANAR)
                        {
                            if (decoder->image_dev_only) // HACK, currently assuming RG48 input data.
                            {
                                for (j = 0; j < 8; j++)
                                {
                                    ptr[j] = sptr[0] >> 3;
                                    ptr[j + 8] = sptr[1] >> 3;
                                    ptr[j + 16] = sptr[2] >> 3;

                                    sptr += 3;
                                }
                            }
                            else
                            {
                                for (j = 0; j < 8; j++)
                                {
                                    val = SwapInt32(*lptr++);
                                    val >>= 2;
                                    b = (val & 0x3ff) << 3;
                                    val >>= 10;
                                    g = (val & 0x3ff) << 3;
                                    val >>= 10;
                                    r = (val & 0x3ff) << 3;

                                    ptr[j] = r;
                                    ptr[j + 8] = g;
                                    ptr[j + 16] = b;
                                }
                            }
                        }
                        else
                        {
                            if (decoder->image_dev_only) // HACK, currently assuming RG48 input data.
                            {
                                for (j = 0; j < 8 * 3; j += 3)
                                {
                                    ptr[j] = sptr[0] >> 3;
                                    ptr[j + 1] = sptr[1] >> 3;
                                    ptr[j + 2] = sptr[2] >> 3;

                                    sptr += 3;
                                }
                            }
                            else
                            {
                                for (j = 0; j < 8 * 3; j += 3)
                                {
                                    val = SwapInt32(*lptr++);
                                    val >>= 2;
                                    b = (val & 0x3ff) << 3;
                                    val >>= 10;
                                    g = (val & 0x3ff) << 3;
                                    val >>= 10;
                                    r = (val & 0x3ff) << 3;

                                    ptr[j] = r;
                                    ptr[j + 1] = g;
                                    ptr[j + 2] = b;
                                }
                            }
                        }

                        ptr += 24;
                    }
                }
                else if (lines == 2)
                {
                    uint32_t j, *lptr = (uint32_t)decoder->uncompressed_chunk;
                    PIXEL16U *ptr = (PIXEL16U *)scanline;

                    lptr += row * (unc_Stride >> 2) * lines;
                    for (i = 0; i < width; i += 8)
                    {
                        int val, r, g, b, r2, g2, b2, r3, g3, b3, r4, g4, b4;
                        for (j = 0; j < 8; j++)
                        {
                            val = SwapInt32(lptr[0]);
                            val >>= 2;
                            b = (val & 0x3ff) << 3;
                            val >>= 10;
                            g = (val & 0x3ff) << 3;
                            val >>= 10;
                            r = (val & 0x3ff) << 3;

                            val = SwapInt32(lptr[1]);
                            val >>= 2;
                            b += (val & 0x3ff) << 3;
                            val >>= 10;
                            g += (val & 0x3ff) << 3;
                            val >>= 10;
                            r += (val & 0x3ff) << 3;

                            val = SwapInt32(lptr[unc_Stride >> 2]);
                            val >>= 2;
                            b += (val & 0x3ff) << 3;
                            val >>= 10;
                            g += (val & 0x3ff) << 3;
                            val >>= 10;
                            r += (val & 0x3ff) << 3;

                            val = SwapInt32(lptr[(unc_Stride >> 2) + 1]);
                            val >>= 2;
                            b += (val & 0x3ff) << 3;
                            val >>= 10;
                            g += (val & 0x3ff) << 3;
                            val >>= 10;
                            r += (val & 0x3ff) << 3;

                            if (flags == ACTIVEMETADATA_SRC_8PIXEL_PLANAR)
                            {
                                ptr[j] = r >> 2;
                                ptr[j + 8] = g >> 2;
                                ptr[j + 16] = b >> 2;
                            }
                            else
                            {
                                ptr[j * 3] = r >> 2;
                                ptr[j * 3 + 1] = g >> 2;
                                ptr[j * 3 + 2] = b >> 2;
                            }


                            lptr += lines;
                        }
                        ptr += 24;
                    }
                }
                else if (lines == 4)
                {
                    uint32_t j, *lptr = (uint32_t)decoder->uncompressed_chunk;
                    PIXEL16U *ptr = (PIXEL16U *)scanline;

                    lptr += row * (unc_Stride >> 2) * lines;
                    for (i = 0; i < width; i += 8)
                    {
                        int val, r, g, b, r2, g2, b2, r3, g3, b3, r4, g4, b4;
                        for (j = 0; j < 8; j++)
                        {
                            val = SwapInt32(lptr[0]);
                            val >>= 2;
                            b = (val & 0x3ff) << 3;
                            val >>= 10;
                            g = (val & 0x3ff) << 3;
                            val >>= 10;
                            r = (val & 0x3ff) << 3;

                            val = SwapInt32(lptr[2]);
                            val >>= 2;
                            b += (val & 0x3ff) << 3;
                            val >>= 10;
                            g += (val & 0x3ff) << 3;
                            val >>= 10;
                            r += (val & 0x3ff) << 3;

                            val = SwapInt32(lptr[unc_Stride >> 1]);
                            val >>= 2;
                            b += (val & 0x3ff) << 3;
                            val >>= 10;
                            g += (val & 0x3ff) << 3;
                            val >>= 10;
                            r += (val & 0x3ff) << 3;

                            val = SwapInt32(lptr[(unc_Stride >> 1) + 2]);
                            val >>= 2;
                            b += (val & 0x3ff) << 3;
                            val >>= 10;
                            g += (val & 0x3ff) << 3;
                            val >>= 10;
                            r += (val & 0x3ff) << 3;

                            if (flags == ACTIVEMETADATA_SRC_8PIXEL_PLANAR)
                            {
                                ptr[j] = r >> 2;
                                ptr[j + 8] = g >> 2;
                                ptr[j + 16] = b >> 2;
                            }
                            else
                            {
                                ptr[j * 3] = r >> 2;
                                ptr[j * 3 + 1] = g >> 2;
                                ptr[j * 3 + 2] = b >> 2;
                            }

                            lptr += lines;
                        }
                        ptr += 24;
                    }
                }

                sptr = scanline;
                if (decoder->apply_color_active_metadata)
                    sptr = ApplyActiveMetaData(decoder, width, 1, row, scanline, scanline2,
                                               info->format, &whitebitdepth, &flags);

                ConvertLinesToOutput(decoder, width, 1, row, sptr,
                                     dst, output_pitch, format, whitebitdepth, flags);

                dst += output_pitch;
            }
        }
#endif
    }

    error = CODEC_ERROR_OKAY;

    return error;
}


// Reconstruct Bayer format to the requested output format
CODEC_ERROR ReconstructSampleFrameBayerToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output, int pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;


#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    //CODEC_STATE *codec = &decoder->codec;
    //int num_channels = codec->num_channels;
    //int progressive = codec->progressive;
    //int precision = codec->precision;

    //TRANSFORM **transform_array = decoder->transform;
    int resolution = info->resolution;
    //int format = info->format;

    // Switch to the subroutine for the requested resolution
    switch (resolution)
    {
        case DECODED_RESOLUTION_FULL_DEBAYER:
        case DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER:
            //error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            return ReconstructSampleFrameDeBayerFullToBuffer(decoder, info, frame, output, pitch);
            break;

        case DECODED_RESOLUTION_FULL:
            //return ReconstructSampleFrameBayerFullToBuffer(decoder, info, frame, output, pitch);
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            break;

        //case DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER:
        case DECODED_RESOLUTION_HALF_NODEBAYER:
        case DECODED_RESOLUTION_HALF:
            //return ReconstructSampleFrameBayerHalfToBuffer(decoder, info, frame, output, pitch);
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            break;

        case DECODED_RESOLUTION_QUARTER:
            //return ReconstructSampleFrameBayerQuarterToBuffer(decoder, frame, output, pitch);
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            break;

        case DECODED_RESOLUTION_LOWPASS_ONLY:
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            break;

        default:
            // The decoded resolution is not supported by this routine
            assert(0);
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            break;
    }

    return error;
}

// Reconstruct Bayer encoded data to full resolution
CODEC_ERROR ReconstructSampleFrameBayerFullToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output_buffer, int output_pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    int num_channels = codec->num_channels;
    //int progressive = codec->progressive;
    //int precision = codec->precision;

    //TRANSFORM **transform_array = decoder->transform;
    //int decoded_width = 0;
    //int decoded_height = 0;
    //int resolution = info->resolution;
    int format = info->format;
    //int width = info->width;
    //int height = info->height;

    // Compute the number of bytes between each row of Bayer data
    //int bayer_pitch = 2 * width * sizeof(PIXEL16U);

    // Compute the pitch between pairs of rows of bayer data (one pair per image row)
    //int raw_bayer_pitch = 2 * bayer_pitch;

    //int chroma_offset = decoder->codec.chroma_offset;

    //int row;
    //int column;

    // Need to allocate a scratch buffer for decoding the Bayer frame?
    if (decoder->RawBayer16 == NULL)
    {
        TRANSFORM **transform_array = decoder->transform;
        int decoded_width = 0;
        int decoded_height = 0;
        int resolution = info->resolution;
        //int format = info->format;
        // Four Bayer data samples at each 2x2 quad in the grid
        int pixel_size = 4 * sizeof(PIXEL16U);
        int frame_size;
        const size_t alignment = 16;

#if _ALLOCATOR
        ALLOCATOR *allocator = decoder->allocator;
#endif
        // Compute the decoded width and height for the specified resolution
        GetDecodedFrameDimensions(transform_array, num_channels, frame, resolution, &decoded_width, &decoded_height);
        assert(decoded_width > 0 && decoded_height > 0);
        if (! (decoded_width > 0 && decoded_height > 0))
        {
            return CODEC_ERROR_UNSUPPORTED_FORMAT;
        }

        frame_size = decoded_width * decoded_height * pixel_size;

#if _ALLOCATOR
        decoder->RawBayer16 = (PIXEL16U *)AllocAligned(allocator, (size_t)frame_size, alignment);
#else
        decoder->RawBayer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(frame_size, alignment);
#endif
        assert(decoder->RawBayer16 != NULL);
        if (! (decoder->RawBayer16 != NULL))
        {
            return CODEC_ERROR_MEMORY_ALLOC;
        }
        decoder->RawBayerSize = frame_size;

        //#ifdef SHARPENING
        if (decoder->RGBFilterBuffer16 == NULL)
        {
            int size = frame_size * 3;
            if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                size = frame_size * 4;
#if _ALLOCATOR
            decoder->RGBFilterBuffer16 = (PIXEL16U *)AllocAligned(allocator, (size_t)size, 16);
#else
            decoder->RGBFilterBuffer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(size, 16);
#endif
            assert(decoder->RGBFilterBuffer16 != NULL);
            if (! (decoder->RGBFilterBuffer16 != NULL))
            {
                return CODEC_ERROR_MEMORY_ALLOC;
            }
            decoder->RGBFilterBufferSize = frame_size * 3;
        }
        //#endif
    }

    //TODO: Need to add more output formats to this routine
    switch (format)
    {
        case DECODED_FORMAT_RGB32:
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;

            // Decode the last transform to rows of Bayer data (one row per channel)
            //	TransformInverseSpatialToRow16u(transform_array, frame, num_channels,
            //								decoder->RawBayer16, raw_bayer_pitch, info,
            //								&decoder->scratch, chroma_offset, precision);

            //	ConvertPackedBayerToRGB32(decoder->RawBayer16, info, bayer_pitch,
            //							  output_buffer, output_pitch,
            //							  width, height);

            break;

        case DECODED_FORMAT_RGB24:
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            // Decode the last transform to rows of Bayer data (one row per channel)
            //TransformInverseSpatialToRow16u(transform_array, frame, num_channels,
            //							decoder->RawBayer16, raw_bayer_pitch, info,
            //							&decoder->scratch, chroma_offset, precision);

            //ConvertPackedBayerToRGB24(decoder->RawBayer16, info, bayer_pitch,
            //						  output_buffer, output_pitch,
            //						  width, height);
            break;

        default:
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            break;
    }

    return error;
}

// Reconstruct Bayer encoded data and demosaic to full resolution
CODEC_ERROR ReconstructSampleFrameDeBayerFullToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output_buffer, int output_pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    CODEC_STATE *codec = &decoder->codec;
    int num_channels = codec->num_channels;
    //int progressive = codec->progressive;
    int precision = codec->precision;

    //TRANSFORM **transform_array = decoder->transform;
    //int decoded_width = 0;
    //int decoded_height = 0;
    //int resolution = info->resolution;
    int format = info->format;
    int width = info->width;
    //int height = info->height;

    // Compute the number of bytes between each row of Bayer data
    int bayer_pitch = 2 * width * sizeof(PIXEL16U);

    // Compute the pitch between pairs of rows of bayer data (one pair per image row)
    //int raw_bayer_pitch = 2 * bayer_pitch;

    int chroma_offset = decoder->codec.chroma_offset;


    error = CODEC_ERROR_UNSUPPORTED_FORMAT;
    switch (format)
    {
        case DECODED_FORMAT_RGB24:
        case DECODED_FORMAT_RGB32:
        case DECODED_FORMAT_RG48: //DAN20090120 added not sure why they weren't here.
        case DECODED_FORMAT_WP13: //DAN20090120  ""
        case DECODED_FORMAT_B64A:
        case DECODED_FORMAT_R210:
        case DECODED_FORMAT_DPX0:
        case DECODED_FORMAT_RG30:
        case DECODED_FORMAT_AR10:
        case DECODED_FORMAT_AB10:
        case DECODED_FORMAT_YR16:
        case DECODED_FORMAT_V210:
        case DECODED_FORMAT_YU64:
            error = CODEC_ERROR_OKAY;
            break;
    }

    if (error)
        return error;


    //int row;
    //int column;

    // Need to allocate a scratch buffer for decoding the Bayer frame?
    if (decoder->RawBayer16 == NULL)
    {
        TRANSFORM **transform_array = decoder->transform;
        int decoded_width = 0;
        int decoded_height = 0;
        int resolution = info->resolution;
        //int format = info->format;
        // Four Bayer data samples at each 2x2 quad in the grid
        int pixel_size = 4 * sizeof(PIXEL16U);
        int frame_size;
        const size_t alignment = 16;

#if _ALLOCATOR
        ALLOCATOR *allocator = decoder->allocator;
#endif

        // Compute the decoded width and height for the specified resolution
        GetDecodedFrameDimensions(transform_array, num_channels, frame, resolution, &decoded_width, &decoded_height);
        assert(decoded_width > 0 && decoded_height > 0);
        if (! (decoded_width > 0 && decoded_height > 0))
        {
            return CODEC_ERROR_UNSUPPORTED_FORMAT;
        }

        frame_size = decoded_width * decoded_height * pixel_size;

#if _ALLOCATOR
        decoder->RawBayer16 = (PIXEL16U *)AllocAligned(allocator, (size_t)frame_size, alignment);
#else
        decoder->RawBayer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(frame_size, alignment);
#endif
        assert(decoder->RawBayer16 != NULL);
        if (! (decoder->RawBayer16 != NULL))
        {
            return CODEC_ERROR_MEMORY_ALLOC;
        }
        decoder->RawBayerSize = frame_size;

        //#ifdef SHARPENING
        if (decoder->RGBFilterBuffer16 == NULL)
        {
            int size = frame_size * 3;
            if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                size = frame_size * 4;
#if _ALLOCATOR
            decoder->RGBFilterBuffer16 = (PIXEL16U *)AllocAligned(allocator, (size_t)size, 16);
#else
            decoder->RGBFilterBuffer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(size, 16);
#endif
            assert(decoder->RGBFilterBuffer16 != NULL);
            if (! (decoder->RGBFilterBuffer16 != NULL))
            {
                return CODEC_ERROR_MEMORY_ALLOC;
            }
            decoder->RGBFilterBufferSize = frame_size * 3;
        }
        //#endif
    }

#if _THREADED
    TransformInverseSpatialUniversalThreadedToRow16u(decoder, frame, num_channels,
            (uint8_t *)decoder->RawBayer16, bayer_pitch * sizeof(PIXEL),
            info, chroma_offset, precision);


    //DemosaicRAW
    {
        WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;
        int inverted = false;
        uint8_t *output = output_buffer;
        int pitch = output_pitch;

#if _DELAY_THREAD_START
        if (decoder->worker_thread.pool.thread_count == 0)
        {
            CreateLock(&decoder->worker_thread.lock);
            // Initialize the pool of transform worker threads
            ThreadPoolCreate(&decoder->worker_thread.pool,
                             decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                             WorkerThreadProc,
                             decoder);
        }
#endif
        if (format == DECODED_FORMAT_RGB24)
        {
            format = DECODED_FORMAT_RGB24_INVERTED;
            inverted = true;
        }
        else if (format == DECODED_FORMAT_RGB32)
        {
            format = DECODED_FORMAT_RGB32_INVERTED;
            inverted = true;
        }

        // Have the output location and pitch been inverted?
        if (inverted && pitch > 0)
        {
            int height = info->height;
            if (info->resolution == DECODED_RESOLUTION_FULL_DEBAYER || info->resolution == DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER)
                height *= 2;
            output += (height - 1) * pitch;		// Start at the bottom row
            pitch = NEG(pitch);					// Negate the pitch to go up
        }

        // Post a message to the mailbox
        mailbox->output = output;
        mailbox->pitch = pitch;
        memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
        mailbox->jobType = JOB_TYPE_OUTPUT;

        // Set the work count to the number of rows to process
        ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

        // Start the transform worker threads
        ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

        // Wait for all of the worker threads to finish
        ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
    }

#else
    error = CODEC_ERROR_UNSUPPORTED_FORMAT;
#endif

    return error;
}

// Reconstruct Bayer encoded data to half resolution
CODEC_ERROR ReconstructSampleFrameBayerHalfToBuffer(DECODER *decoder, FRAME_INFO *info, int frame, uint8_t *output_buffer, int output_pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    //CODEC_STATE *codec = &decoder->codec;
    //int num_channels = codec->num_channels;
    //int progressive = codec->progressive;
    //int precision = codec->precision;

    TRANSFORM **transform_array = decoder->transform;
    int frame_width = info->width;
    int frame_height = info->height;
    //int resolution = info->resolution;
    int format = info->format;

    //IMAGE *lowpass_images[TRANSFORM_MAX_CHANNELS];

    PIXEL16U *g1_plane;
    PIXEL16U *rg_plane;
    PIXEL16U *bg_plane;
    PIXEL16U *g2_plane;

    int g1_pitch;
    int rg_pitch;
    int bg_pitch;
    int g2_pitch;

#if 0
    int channel;
    for (channel = 0; channel < num_channels; channel++)
    {
        lowpass_images[channel] = transform_array[channel]->wavelet[frame];

#if (0 && DEBUG)
        if (logfile)
        {
            char label[_MAX_PATH];
            char *format = decoded_format_string[info->format];
            sprintf(label, "Output, channel: %d, format: %s", channel, format);
            DumpImageStatistics(label, lowpass_images[channel], logfile);
        }
#endif
    }
#endif

    // Get the lowpass bands in the wavelet coresponding to the output frame
    g1_plane = (PIXEL16U *)transform_array[0]->wavelet[frame]->band[0];
    rg_plane = (PIXEL16U *)transform_array[1]->wavelet[frame]->band[0];
    bg_plane = (PIXEL16U *)transform_array[2]->wavelet[frame]->band[0];

    if (transform_array[3]->wavelet[frame]) //half res don't decode g1-g2 //HACK
    {
        g2_plane = (PIXEL16U *)transform_array[3]->wavelet[frame]->band[0];
        g2_pitch = transform_array[3]->wavelet[frame]->pitch;
    }
    else
    {
        g2_plane = NULL;
        g2_pitch = 0;
    }

    // Get the pitch of each plane
    g1_pitch = transform_array[0]->wavelet[frame]->pitch;
    rg_pitch = transform_array[1]->wavelet[frame]->pitch;
    bg_pitch = transform_array[2]->wavelet[frame]->pitch;

    switch (format)
    {
        case DECODED_FORMAT_RGB32:
            ConvertPlanarBayerToRGB32(g1_plane, g1_pitch, rg_plane, rg_pitch,
                                      bg_plane, bg_pitch, g2_plane, g2_pitch,
                                      output_buffer, output_pitch,
                                      frame_width, frame_height);
            break;

        default:
            error = CODEC_ERROR_UNSUPPORTED_FORMAT;
            break;
    }

    return error;
}

// Reconstruct Bayer encoded data to quarter resolution
CODEC_ERROR ReconstructSampleFrameBayerQuarterToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    //FRAME_INFO *info = &decoder->frame;

    //CODEC_STATE *codec = &decoder->codec;
    //int num_channels = codec->num_channels;
    //int progressive = codec->progressive;
    //int precision = codec->precision;

    //TRANSFORM **transform_array = decoder->transform;
    //int decoded_width = 0;
    //int decoded_height = 0;
    //int resolution = info->resolution;
    //int format = info->format;

    //TODO: Need to finish this routine
    assert(0);

    return error;
}

// Reconstruct the original YUV 4:2:2 encoded format to the requested output format
CODEC_ERROR ReconstructSampleFrameYUV422ToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    FRAME_INFO *info = &decoder->frame;

    CODEC_STATE *codec = &decoder->codec;
    int num_channels = codec->num_channels;
    int progressive = codec->progressive;
    int precision = codec->precision;

    TRANSFORM **transform_array = decoder->transform;
    //int decoded_width = 0;
    //int decoded_height = 0;
    int resolution = info->resolution;
    int format = info->format;

    //int color_space = decoder->frame.colorspace;

    //TODO: Eliminate use of the chroma offset
    int chroma_offset = decoder->codec.chroma_offset;

#if _THREADED
    // Type of threaded inverse transform
    //int type;
#endif

#if _ALLOCATOR
    ALLOCATOR *allocator = decoder->allocator;
#endif

    if (decoder == NULL)
    {
        return CODEC_ERROR_INVALID_ARGUMENT;
    }

    //TODO: Split this routine into subroutines for progressive versus interlaced video
    //TODO: Split progressive and interlaced routines into subroutines for each resolution

    if (resolution == DECODED_RESOLUTION_HALF)
    {
        bool inverted = false;
        FRAME_INFO info2;

        memcpy(&info2, info, sizeof(FRAME_INFO));

        format = info2.format;

        if (format == DECODED_FORMAT_RGB24)
        {
            format = DECODED_FORMAT_RGB24_INVERTED;
            info2.format = format;
            inverted = true;
        }
        else if (format == DECODED_FORMAT_RGB32)
        {
            format = DECODED_FORMAT_RGB32_INVERTED;
            info2.format = format;
            inverted = true;
        }
#if 1
        // Have the output location and pitch been inverted?
        if (inverted && pitch > 0)
        {
            int height = info->height;
            output += (height - 1) * pitch;		// Start at the bottom row
            pitch = NEG(pitch);					// Negate the pitch to go up
        }
#endif

        if (decoder->use_active_metadata_decoder)
        {
#if _THREADED
            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
            if (decoder->worker_thread.pool.thread_count == 0)
            {
                CreateLock(&decoder->worker_thread.lock);
                // Initialize the pool of transform worker threads
                ThreadPoolCreate(&decoder->worker_thread.pool,
                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                 WorkerThreadProc,
                                 decoder);
            }
#endif
            // Post a message to the mailbox
            mailbox->output = output;
            mailbox->pitch = pitch;
            mailbox->framenum = frame;
            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
            mailbox->jobType = JOB_TYPE_OUTPUT;
            decoder->RGBFilterBufferPhase = 1;

            // Set the work count to the number of rows to process
            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

            // Start the transform worker threads
            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

            // Wait for all of the worker threads to finish
            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

            decoder->RGBFilterBufferPhase = 0;
            return CODEC_ERROR_OKAY;
#endif
        }
        else
        {
            int precision = codec->precision;
            TRANSFORM **transform_array = decoder->transform;
            int channel;
            IMAGE *lowpass_images[TRANSFORM_MAX_CHANNELS];
            CODEC_STATE *codec = &decoder->codec;
            int num_channels = codec->num_channels;

            for (channel = 0; channel < num_channels; channel++)
            {
                lowpass_images[channel] = transform_array[channel]->wavelet[frame];
            }

            CopyLowpass16sToBuffer(decoder, lowpass_images, num_channels, output, pitch, &info2, chroma_offset,
                                   precision, decoder->codec.encoded_format, decoder->frame.white_point);
        }
        return CODEC_ERROR_OKAY;
    }


    // Was the video source interlaced or progressive?
    if (progressive)
    {
        // The video source was progressive (the first transform was a spatial transform)

        if (resolution == DECODED_RESOLUTION_FULL || resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
        {
            FRAME_INFO info2;
            int format;
            bool inverted = false;
            int precision = codec->precision;

            memcpy(&info2, info, sizeof(FRAME_INFO));

            format = info2.format;

            if (format == DECODED_FORMAT_RGB24)
            {
                format = DECODED_FORMAT_RGB24_INVERTED;
                info2.format = format;
                inverted = true;
            }
            else if (format == DECODED_FORMAT_RGB32)
            {
                format = DECODED_FORMAT_RGB32_INVERTED;
                info2.format = format;
                inverted = true;
            }
#if 1
            // Have the output location and pitch been inverted?
            if (inverted && pitch > 0)
            {
                int height = info->height;
                output += (height - 1) * pitch;		// Start at the bottom row
                pitch = NEG(pitch);					// Negate the pitch to go up
            }
#endif


            /*if(decoder->use_active_metadata_decoder)
            {
            	switch (format & 0x7ffffff)
            	{
            	case DECODED_FORMAT_RGB24: // Output buffer is too small to decode into for
            	case DECODED_FORMAT_YUYV:  // computing the active metadata.
            	case DECODED_FORMAT_UYVY:
            		return CODEC_ERROR_OKAY;
            		break;
            	}
            }*/

            switch (format & 0x7ffffff)
            {
                case DECODED_FORMAT_RGB24: // Output buffer is too small to decode into for
                    if (decoder->use_active_metadata_decoder)
                    {
#if _THREADED
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sThruActiveMetadata);
                        return CODEC_ERROR_OKAY;
#endif
                    }
                    else
                    {
#if _THREADED
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sYUVtoRGB);
                        return CODEC_ERROR_OKAY;
#endif
                    }
                    break;
                case DECODED_FORMAT_YUYV:
                case DECODED_FORMAT_UYVY:
                    if (decoder->use_active_metadata_decoder)
                    {
#if _THREADED
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sThruActiveMetadata);
                        return CODEC_ERROR_OKAY;
#endif
                    }
                    else
                    {
#if _THREADED
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sToYUV);
                        return CODEC_ERROR_OKAY;
#endif
                    }
                    break;

                //Handle sizes that are smaller than the interim decode buffer //DAN20081222
                case DECODED_FORMAT_CbYCrY_10bit_2_8:
                    decoder->upper_plane = output;
                    decoder->lower_plane = output + decoder->frame.width * decoder->frame.height / 2;

                    // Use the address and pitch of the lower plane
                    output = decoder->lower_plane;
                    pitch = decoder->frame.width * 2;

                // Fall through and compute the inverse spatial transform
                case DECODED_FORMAT_CbYCrY_16bit_2_14:
                case DECODED_FORMAT_CbYCrY_16bit_10_6:
                case DECODED_FORMAT_CbYCrY_8bit:
                case DECODED_FORMAT_CbYCrY_16bit:
                    if (decoder->use_active_metadata_decoder)
                    {
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sThruActiveMetadata);
                        return CODEC_ERROR_OKAY;
                    }
                    else
                    {
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sToOutput);
                        return CODEC_ERROR_OKAY;
                    }
                    break;

                case DECODED_FORMAT_V210:
                    if (decoder->use_active_metadata_decoder)
                    {
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sThruActiveMetadata);
                        return CODEC_ERROR_OKAY;
                    }
                    else
                    {
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalYUVStrip16sToYUVOutput);
                        return CODEC_ERROR_OKAY;
                    }
                    break;

                case DECODED_FORMAT_RGB32:
                case DECODED_FORMAT_RGB32_INVERTED:
                // As long as the outpitch is greater or equal to 4:2:2 16-bit YR16 this works.
                case DECODED_FORMAT_RG48:
                case DECODED_FORMAT_RG64:
                case DECODED_FORMAT_R210:
                case DECODED_FORMAT_DPX0:
                case DECODED_FORMAT_RG30:
                case DECODED_FORMAT_AR10:
                case DECODED_FORMAT_AB10:
                case DECODED_FORMAT_B64A:
                case DECODED_FORMAT_R408:
                case DECODED_FORMAT_V408:
                case DECODED_FORMAT_YU64:
                case DECODED_FORMAT_YR16:
                case DECODED_FORMAT_WP13:
                case DECODED_FORMAT_W13A:
                    if ((format & 0x7FFFFFFF) == DECODED_FORMAT_RGB32 && decoder->use_active_metadata_decoder == false)
                    {

#if _THREADED
                        TransformInverseSpatialThreadedYUV422ToBuffer(decoder,
                                frame, num_channels, output, pitch,
                                &info2, chroma_offset, precision);
#elif 0
                        TransformInverseSpatialToBuffer(decoder, transform_array, frame,
                                                        num_channels, output, pitch,
                                                        &info2, &decoder->scratch, chroma_offset, precision);
#else
                        TransformInverseSpatialYUV422ToOutput(decoder, transform_array,
                                                              frame, num_channels, output, pitch,
                                                              &info2, &decoder->scratch, chroma_offset, precision,
                                                              InvertHorizontalStripYUV16sToPackedRGB32);
#endif
                        return CODEC_ERROR_OKAY;
                    }

#if _THREADED
                    if (decoder->use_active_metadata_decoder)
                    {
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sThruActiveMetadata);
                        return CODEC_ERROR_OKAY;
                    }
                    else
                    {
                        TransformInverseSpatialUniversalThreadedToRow16u(decoder, frame,
                                num_channels, output, pitch,
                                &info2, chroma_offset, precision);

                        ConvertRow16uToOutput(decoder, frame, num_channels, output, pitch,
                                              &info2, chroma_offset, precision);
                        return CODEC_ERROR_OKAY;
                    }
#endif
                    break;


                default:
                    if (decoder->use_active_metadata_decoder)
                    {
#if _THREADED
                        TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                output, pitch,
                                info, chroma_offset, precision,
                                InvertHorizontalStrip16sThruActiveMetadata);
                        return CODEC_ERROR_OKAY;
#endif
                    }
                    // else Return the error code for unsupported output format
                    break;
            }
        }
    }
    else
    {
        // The video source was interlaced (the first transform was a frame transform)

        if (resolution == DECODED_RESOLUTION_FULL || resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
        {
            bool inverted = false;
            if (format == DECODED_FORMAT_RGB32 || format == DECODED_FORMAT_RGB24)
            {
                //		info->format = DECODED_FORMAT_RGB32_INVERTED; //DAN20080702 vertically flips QT decodes if active.
                inverted = true;
            }
#if 1
            // Have the output location and pitch been inverted?
            if (inverted && pitch > 0)
            {
                int height = info->height;
                output += (height - 1) * pitch;		// Start at the bottom row
                pitch = NEG(pitch);					// Negate the pitch to go up
            }
#endif

            switch (format & 0x7ffffff)
            {
                case DECODED_FORMAT_NV12:
                case DECODED_FORMAT_RGB24: // Output buffer is too small to decode into for
                case DECODED_FORMAT_YUYV:
                case DECODED_FORMAT_UYVY:
                case DECODED_FORMAT_V210:  // only supported with use_active_metadata_decoder
                    if (decoder->use_active_metadata_decoder)
                    {
                        int frame_size = info->width * info->height * 4;
                        if (decoder->RGBFilterBuffer16 == NULL || decoder->RGBFilterBufferSize < frame_size)
                        {

#if _ALLOCATOR
                            if (decoder->RGBFilterBuffer16)
                            {
                                FreeAligned(decoder->allocator, decoder->RGBFilterBuffer16);
                                decoder->RGBFilterBuffer16 = NULL;
                            }
                            decoder->RGBFilterBuffer16 = (PIXEL16U *)AllocAligned(allocator, frame_size, 16);
#else
                            if (decoder->RGBFilterBuffer16)
                            {
                                MEMORY_ALIGNED_FREE(decoder->RGBFilterBuffer16);
                                decoder->RGBFilterBuffer16 = NULL;
                            }
                            decoder->RGBFilterBuffer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(frame_size, 16);
#endif
                            assert(decoder->RGBFilterBuffer16 != NULL);
                            if (! (decoder->RGBFilterBuffer16 != NULL))
                            {
                                return CODEC_ERROR_MEMORY_ALLOC;
                            }
                            decoder->RGBFilterBufferSize = frame_size;
                        }

                        //TransformInverseSpatialUniversalThreadedToRow16u(
                        //	decoder, frame, num_channels,
                        //	(uint8_t *)decoder->RGBFilterBuffer16, info->width * 3 * 2,
                        //	info, chroma_offset, precision);

#if _INTERLACED_WORKER_THREADS
                        StartInterlaceWorkerThreads(decoder);

                        //TODO: support new threading
                        // Send the upper and lower rows of the transforms to the worker threads
                        TransformInverseFrameThreadedToRow16u(decoder, frame, num_channels,
                                                              (PIXEL16U *)decoder->RGBFilterBuffer16,
                                                              info->width * 4,
                                                              info, chroma_offset, precision);
#else
                        // Transform the wavelets for each channel to the output image (not threaded)
                        TransformInverseFrameToRow16u(decoder, transform_array, frame, num_channels,
                                                      (PIXEL16U *)decoder->RGBFilterBuffer16,
                                                      info->width * 4, info,
                                                      &decoder->scratch, chroma_offset, precision);
#endif

#if _THREADED
                        {
                            WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
                            if (decoder->worker_thread.pool.thread_count == 0)
                            {
                                CreateLock(&decoder->worker_thread.lock);
                                // Initialize the pool of transform worker threads
                                ThreadPoolCreate(&decoder->worker_thread.pool,
                                                 decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                                 WorkerThreadProc,
                                                 decoder);
                            }
#endif
                            // Post a message to the mailbox
                            mailbox->output = output;
                            mailbox->pitch = pitch;
                            memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
                            mailbox->jobType = JOB_TYPE_OUTPUT;
                            decoder->RGBFilterBufferPhase = 2; // yuv

                            // Set the work count to the number of rows to process
                            ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

                            // Start the transform worker threads
                            ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                            // Wait for all of the worker threads to finish
                            ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

                            decoder->RGBFilterBufferPhase = 0;
                        }
#endif
                        return CODEC_ERROR_OKAY;
                    }
            }



            switch (format)
            {
                // As long as the outpitch is greater or equal to 4:2:2 16-bit YR16 this works.
                case DECODED_FORMAT_WP13: //DAN20110203 - missing
                case DECODED_FORMAT_W13A: //DAN20110203 - missing
                case DECODED_FORMAT_RG48:
                case DECODED_FORMAT_RG64:
                case DECODED_FORMAT_R210:
                case DECODED_FORMAT_DPX0:
                case DECODED_FORMAT_RG30:
                case DECODED_FORMAT_AR10:
                case DECODED_FORMAT_AB10:
                case DECODED_FORMAT_B64A:
                case DECODED_FORMAT_RGB32:  //32-bit format can fit the interim YR16 decode into
                case DECODED_FORMAT_R408:   //the output buffer
                case DECODED_FORMAT_V408:
                case DECODED_FORMAT_YU64:
                case DECODED_FORMAT_YR16:

#if _INTERLACED_WORKER_THREADS
                    StartInterlaceWorkerThreads(decoder);

                    //TODO: support new threading
                    // Send the upper and lower rows of the transforms to the worker threads
                    TransformInverseFrameThreadedToRow16u(decoder, frame, num_channels,
                                                          (PIXEL16U *)output, pitch,
                                                          info, chroma_offset, precision);

                    ConvertRow16uToOutput(decoder, frame, num_channels, output, pitch,
                                          info, chroma_offset, precision);
#else
                    // Transform the wavelets for each channel to the output image (not threaded)
                    TransformInverseFrameToRow16u(decoder, transform_array, frame, num_channels,
                                                  (PIXEL16U *)output, pitch, info,
                                                  &decoder->scratch, chroma_offset, precision);

                    ConvertRow16uToOutput(decoder, frame, num_channels, output, pitch,
                                          info, chroma_offset, precision);

                    //Old code converts 4:2:2 directly to RGBA (single threaded.)
                    //TransformInverseFrameToBuffer(transform_array, frame, num_channels, output, pitch,
                    //							  info, &decoder->scratch, chroma_offset, precision);
#endif
                    return CODEC_ERROR_OKAY;

                default:
                    // else Return the error code for unsupported output format
                    break;
            }
        }
    }

    // The output format is not supported by this routine
    error = CODEC_ERROR_UNSUPPORTED_FORMAT;

    return error;
}



// Routines for converting the new encoded formats to the requested output format
CODEC_ERROR ReconstructSampleFrameRGB444ToBuffer(DECODER *decoder, int frame, uint8_t *output, int pitch)
{
    CODEC_ERROR error = CODEC_ERROR_OKAY;
#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    FRAME_INFO *info = &decoder->frame;

    CODEC_STATE *codec = &decoder->codec;
    int num_channels = codec->num_channels;
    //int progressive = codec->progressive;

    TRANSFORM **transform_array = decoder->transform;
    //IMAGE *lowpass_images[TRANSFORM_MAX_CHANNELS];
    //IMAGE *wavelet;
    //int wavelet_width;
    //int wavelet_height;
    int decoded_width = 0;
    int decoded_height = 0;
    int resolution = info->resolution;
    //int chroma_offset = decoder->codec.chroma_offset;
    //int decoded_scale;

#if _ALLOCATOR
    ALLOCATOR *allocator = decoder->allocator;
#endif

    //TODO: Eliminate use of the chroma offset

    if (decoder == NULL)
    {
        return CODEC_ERROR_INVALID_ARGUMENT;
    }

    // This routine should only be called for progressive frames
    assert(codec->progressive);

    // The decoder can decode a video sample without returning a frame
    if (output == NULL || pitch == 0)
    {
        return CODEC_ERROR_OKAY;
    }

    // Does this frame have to be reconstructed?
    if ((decoder->flags & DECODER_FLAGS_RENDER) == 0)
    {
        return CODEC_ERROR_OKAY;
    }

    // Check that the requested frame is within the limits of the group of frames
    assert(0 <= frame && frame < decoder->gop_length);

    // Check that the frame resolution is valid
    assert(IsValidFrameResolution(resolution));
    if (!IsValidFrameResolution(resolution))
    {
        return CODEC_ERROR_RESOLUTION;
    }

    // Compute the decoded width and height
    ComputeOutputDimensions(decoder, frame, &decoded_width, &decoded_height);
    assert(decoded_width > 0 && decoded_height > 0);

    if (info->format == DECODED_FORMAT_RGB24 || info->format == DECODED_FORMAT_RGB32)
    {
        output += (info->height - 1) * pitch;
        pitch = -pitch;
    }

#if (0 && DEBUG)
    if (logfile)
    {
        IMAGE *wavelet = transform[0]->wavelet[frame];
        int band = 0;
        fprintf(logfile, "Luminance wavelet, frame: %d, band: %d\n", frame, band);
        DumpArray16s("Lowpass Band", wavelet->band[band], wavelet->width, wavelet->height, wavelet->pitch, logfile);
    }
#endif

    // Check that the requested frame is large enough to hold the decoded frame
#if (0 && DEBUG)
    //if (! (info->width >= decoded_width))
    {
        if (logfile)
        {
            //fprintf(logfile, "Requested frame not large enough to hold decoded frame: %d < %d\n", info->width, decoded_width);
            fprintf(logfile, "Output frame width: %d, decoded frame width: %d\n", info->width, decoded_width);
        }
    }
#endif
    assert(info->width >= decoded_width);
    if (!(info->width >= decoded_width))
    {
        return CODEC_ERROR_FRAMESIZE;
    }
    //	assert((info->height+7)/8 >= (decoded_height+7)/8);
    //	if (!(info->height+7)/8 >= (decoded_height+7)/8) {
    //		return CODEC_ERROR_FRAMESIZE;
    //	}

    START(tk_convert);

    if (resolution == DECODED_RESOLUTION_LOWPASS_ONLY)
    {
        //int precision = codec->precision;
        int scale = 13;
        int channel;
        IMAGE *lowpass_images[TRANSFORM_MAX_CHANNELS];
        int chroma_offset = decoder->codec.chroma_offset;

        //DAN20081203 -- fix for 444 decodes in AE32-bit float
        decoder->frame.white_point = 16;
        //decoder->frame.signed_pixels = 0;

        for (channel = 0; channel < num_channels; channel++)
        {
            lowpass_images[channel] = transform_array[channel]->wavelet[5];
            if (lowpass_images[channel] == NULL) // therefore IntreFrame compressed.
            {
                scale = 12;
                lowpass_images[channel] = transform_array[channel]->wavelet[2];
            }
        }

        CopyLowpass16sToBuffer(decoder, lowpass_images, num_channels, output, pitch, info, chroma_offset,
                               scale, decoder->codec.encoded_format, decoder->frame.white_point);
    }
    else
        // Quarter resolution
        if (resolution == DECODED_RESOLUTION_QUARTER)
        {
            // Output quarter resolution for the two frame GOP
            int precision = codec->precision;

            // Reconstruct the frame to quarter resolution
            ReconstructQuarterFrame(decoder, num_channels, frame, output, pitch,
                                    info, &decoder->scratch, precision);

            // Quarter resolution one frame GOP is handled in DecodeSampleIntraFrame
        }
        else
            // Half resolution
            if (resolution == DECODED_RESOLUTION_HALF)
            {
                IMAGE *wavelet_array[TRANSFORM_MAX_CHANNELS];
                int precision = codec->precision;
                int chroma_offset = 0;
                int channel;

                if (decoder->use_active_metadata_decoder)
                {
#if _THREADED
                    {
                        WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
                        if (decoder->worker_thread.pool.thread_count == 0)
                        {
                            CreateLock(&decoder->worker_thread.lock);
                            // Initialize the pool of transform worker threads
                            ThreadPoolCreate(&decoder->worker_thread.pool,
                                             decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                             WorkerThreadProc,
                                             decoder);
                        }
#endif
                        // Post a message to the mailbox
                        mailbox->output = output;
                        mailbox->pitch = pitch;
                        mailbox->framenum = frame;
                        memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
                        mailbox->jobType = JOB_TYPE_OUTPUT;
                        decoder->RGBFilterBufferPhase = 1;

                        // Set the work count to the number of rows to process
                        ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

                        // Start the transform worker threads
                        ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                        // Wait for all of the worker threads to finish
                        ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

                        decoder->RGBFilterBufferPhase = 0;
                    }
#endif
                }
                else
                {
                    //DAN20081203 -- fix for 444 decodes in AE32-bit float
                    decoder->frame.white_point = 16;
                    //decoder->frame.signed_pixels = 0;

                    // Get the first level wavelet in each channel
                    for (channel = 0; channel < num_channels; channel++)
                    {
                        wavelet_array[channel] = transform_array[channel]->wavelet[frame];
                    }

                    // Pack the pixels from the lowpass band in each channel into the output buffer
                    CopyLowpassRGB444ToBuffer(decoder, wavelet_array, num_channels, output, pitch,
                                              info, chroma_offset, precision);
                }
            }

    // Full resolution or half horizontal
            else
            {
                int chroma_offset = 0;
                int precision = codec->precision;

                // Reconstruct the output frame from a full resolution decode
                //assert(resolution == DECODED_RESOLUTION_FULL);

                if (decoder->use_active_metadata_decoder)
                {
                    int frame_size, channels = 3;
                    if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
                        channels = 4;

                    frame_size = info->width * info->height * channels * 2;


                    if (decoder->RGBFilterBuffer16 == NULL || decoder->RGBFilterBufferSize < frame_size)
                    {
#if _ALLOCATOR
                        if (decoder->RGBFilterBuffer16)
                        {
                            FreeAligned(decoder->allocator, decoder->RGBFilterBuffer16);
                            decoder->RGBFilterBuffer16 = NULL;
                        }
                        decoder->RGBFilterBuffer16 = (PIXEL16U *)AllocAligned(allocator, frame_size, 16);
#else
                        if (decoder->RGBFilterBuffer16)
                        {
                            MEMORY_ALIGNED_FREE(decoder->RGBFilterBuffer16);
                            decoder->RGBFilterBuffer16 = NULL;
                        }
                        decoder->RGBFilterBuffer16 = (PIXEL16U *)MEMORY_ALIGNED_ALLOC(frame_size, 16);
#endif
                        assert(decoder->RGBFilterBuffer16 != NULL);
                        if (! (decoder->RGBFilterBuffer16 != NULL))
                        {
                            return CODEC_ERROR_MEMORY_ALLOC;
                        }
                        decoder->RGBFilterBufferSize = frame_size;
                    }

#if _THREADED
                    TransformInverseSpatialUniversalThreadedToRow16u(decoder, frame, num_channels,
                            (uint8_t *)decoder->RGBFilterBuffer16, info->width * channels * 2,
                            info, chroma_offset, precision);
#else
                    // Decode that last transform to rows of Bayer data (one row per channel)
                    TransformInverseSpatialToRow16u(transform_array, frame, num_channels,
                                                    (uint8_t *)decoder->RGBFilterBuffer16, info->width * channels * 2,
                                                    info, &decoder->scratch, chroma_offset, precision);
#endif


#if _THREADED
                    {
                        WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

#if _DELAY_THREAD_START
                        if (decoder->worker_thread.pool.thread_count == 0)
                        {
                            CreateLock(&decoder->worker_thread.lock);
                            // Initialize the pool of transform worker threads
                            ThreadPoolCreate(&decoder->worker_thread.pool,
                                             decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                                             WorkerThreadProc,
                                             decoder);
                        }
#endif
                        // Post a message to the mailbox
                        mailbox->output = output;
                        mailbox->pitch = pitch;
                        memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
                        mailbox->jobType = JOB_TYPE_OUTPUT;
                        decoder->RGBFilterBufferPhase = 1;

                        // Set the work count to the number of rows to process
                        ThreadPoolSetWorkCount(&decoder->worker_thread.pool, info->height);

                        // Start the transform worker threads
                        ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

                        // Wait for all of the worker threads to finish
                        ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

                        decoder->RGBFilterBufferPhase = 0;
                    }
#endif
                }
                else
                {

                    //DAN20081203 -- fix for 444 decodes in AE32-bit float
                    decoder->frame.white_point = 16;
                    //decoder->frame.signed_pixels = 0;


                    switch (info->format)
                    {
                        case DECODED_FORMAT_B64A:
#if _THREADED
                            TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                    output, pitch,
                                    info, chroma_offset, precision,
                                    InvertHorizontalStrip16sRGB2B64A);
#else
                            TransformInverseRGB444ToB64A(transform_array, frame, num_channels, output, pitch,
                                                         info, &decoder->scratch, chroma_offset, precision);
#endif
                            break;

                        case DECODED_FORMAT_YU64: //TODO : Threading
                            TransformInverseRGB444ToYU64(transform_array, frame, num_channels, output, pitch,
                                                         info, &decoder->scratch, chroma_offset, precision);
                            break;

                        case DECODED_FORMAT_RGB24:
                        case DECODED_FORMAT_RGB24_INVERTED:
                        case DECODED_FORMAT_RGB32:
                        case DECODED_FORMAT_RGB32_INVERTED://TODO, needs to be threaded. WIP
                            TransformInverseRGB444ToRGB32(transform_array, frame, num_channels, output, pitch,
                                                          info, &decoder->scratch, chroma_offset, precision);
                            break;

                        case DECODED_FORMAT_RG48:
                        case DECODED_FORMAT_RG64: //TODO, needs to be threaded. WIP
                            TransformInverseRGB444ToRGB48(transform_array, frame, num_channels, output, pitch,
                                                          info, &decoder->scratch, chroma_offset, precision);
                            break;

                        case DECODED_FORMAT_R210:
                        case DECODED_FORMAT_DPX0:
                        case DECODED_FORMAT_RG30:
                        case DECODED_FORMAT_AR10:
                        case DECODED_FORMAT_AB10:
#if _THREADED
                            TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                    output, pitch,
                                    info, chroma_offset, precision,
                                    InvertHorizontalStrip16sRGB2RG30);
#else
                            TransformInverseRGB444ToRGB48(transform_array, frame, num_channels, output, pitch,
                                                          info, &decoder->scratch, chroma_offset, precision);
#endif
                            break;


                        case DECODED_FORMAT_YUYV:
                        case DECODED_FORMAT_UYVY:
#if _THREADED
                            TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                    output, pitch,
                                    info, chroma_offset, precision,
                                    InvertHorizontalStrip16sRGB2YUV);
#else
                            TransformInverseSpatialYUV422ToOutput(decoder, transform_array, frame, num_channels, output, pitch,
                                                                  info, &decoder->scratch, chroma_offset, precision,
                                                                  InvertHorizontalStripRGB16sToPackedYUV8u);
#endif
                            break;


                        case DECODED_FORMAT_R408:
                        case DECODED_FORMAT_V408:

#if _THREADED
                            TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                    output, pitch,
                                    info, chroma_offset, precision,
                                    InvertHorizontalStrip16sRGBA2YUVA);
#else
                            assert(0);
#endif
                            break;

                        case DECODED_FORMAT_YR16:
#if _THREADED
                            TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                    output, pitch,
                                    info, chroma_offset, precision,
                                    InvertHorizontalStrip16sRGB2YR16);
#else
                            assert(0);// missing non-threaded version
#endif
                            break;

                        case DECODED_FORMAT_V210:
#if _THREADED
                            TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                    output, pitch,
                                    info, chroma_offset, precision,
                                    InvertHorizontalStrip16sRGB2v210);
#else
                            assert(0);// missing non-threaded version
#endif
                            break;

                        case DECODED_FORMAT_CbYCrY_8bit:		// DECODED_FORMAT_CT_UCHAR
#if _THREADED
                            TransformInverseSpatialUniversalThreadedToOutput(decoder, frame, num_channels,
                                    output, pitch,
                                    info, chroma_offset, precision,
                                    InvertHorizontalStrip16sRGB2YUV);
#else
                            assert(0);// missing non-threaded version
#endif
                            break;

                        //TODO: Add code to handle other Avid pixel formats
                        case DECODED_FORMAT_CbYCrY_16bit:		// DECODED_FORMAT_CT_SHORT
                        case DECODED_FORMAT_CbYCrY_10bit_2_8:	// DECODED_FORMAT_CT_10Bit_2_8
                        case DECODED_FORMAT_CbYCrY_16bit_2_14:	// DECODED_FORMAT_CT_SHORT_2_14
                        case DECODED_FORMAT_CbYCrY_16bit_10_6:	// DECODED_FORMAT_CT_USHORT_10_6
                            assert(0);
                            break;

                        default:
#if (1 && DEBUG)
                            if (logfile)
                            {
                                fprintf(logfile, "Invalid decoded format: %d\n", info->format);
                            }
#endif
                            assert(0);
                            error = CODEC_ERROR_INVALID_FORMAT;
                            break;
                    }
                }
            }

    STOP(tk_convert);

    return error;
}




// Convert 16-bit signed lowpass data into the requested output format
void CopyLowpassRGB444ToBuffer(DECODER *decoder, IMAGE *image_array[], int num_channels,
                               uint8_t *output_buffer, int32_t output_pitch,
                               FRAME_INFO *info, int chroma_offset,
                               int precision)
{
    bool inverted = false;
    int output_width = info->width;
    int output_height = info->height;
    int format = info->format;

    // Left shift to scale the pixels to 16 bits minus the shift already in the lowpass values
    const int shift = 16 - precision - PRESCALE_LUMA;

    START(tk_convert);

#if 0
    // Fill the output buffer with blank values
    EraseOutputBuffer(output_buffer, info->width, info->height, output_pitch, info->format);
#endif

    // Determine the type of conversion
    switch (info->format)
    {
        case DECODED_FORMAT_RGB24:
        case DECODED_FORMAT_RGB32:
            inverted = true;
        case DECODED_FORMAT_RGB24_INVERTED:
        case DECODED_FORMAT_RGB32_INVERTED:
        case DECODED_FORMAT_B64A:
        case DECODED_FORMAT_R210:
        case DECODED_FORMAT_DPX0:
        case DECODED_FORMAT_RG30:
        case DECODED_FORMAT_AR10:
        case DECODED_FORMAT_AB10:
        case DECODED_FORMAT_RG48:
        case DECODED_FORMAT_RG64: //WIP
            ConvertLowpassRGB444ToRGB(image_array, output_buffer, output_width, output_height,
                                      output_pitch, format, inverted, shift, num_channels);
            break;
        case DECODED_FORMAT_YUYV:
        case DECODED_FORMAT_UYVY:
        {
            IMAGE *g_image = image_array[0];
            IMAGE *r_image = image_array[1];
            IMAGE *b_image = image_array[2];

            if (info->format == COLOR_FORMAT_YUYV)
            {
                ConvertRGB2YUV(r_image->band[0], g_image->band[0], b_image->band[0],
                               r_image->pitch, g_image->pitch, b_image->pitch,
                               output_buffer, output_pitch,
                               output_width, output_height, 14,
                               info->colorspace, info->format);
            }
            else if (info->format == COLOR_FORMAT_UYVY)
            {
                ConvertRGB2UYVY(r_image->band[0], g_image->band[0], b_image->band[0],
                                r_image->pitch, g_image->pitch, b_image->pitch,
                                output_buffer, output_pitch,
                                output_width, output_height, 14,
                                info->colorspace, info->format);
            }
        }
        break;

        default:
        {
            int y;
            IMAGE *g_image = image_array[0];
            IMAGE *r_image = image_array[1];
            IMAGE *b_image = image_array[2];
            IMAGE *a_image = image_array[3];
            unsigned short *scanline = (unsigned short *)decoder->scratch.free_ptr;
            //unsigned short *scanline2 = scanline + output_width*3;
            uint8_t *newline = (uint8_t *)output_buffer;
            unsigned short *Rptr, *Gptr, *Bptr, *Aptr = NULL;

            Rptr = (unsigned short *)r_image->band[0];
            Gptr = (unsigned short *)g_image->band[0];
            Bptr = (unsigned short *)b_image->band[0];

            if (decoder->codec.encoded_format == ENCODED_FORMAT_RGBA_4444 && ALPHAOUTPUT(decoder->frame.format))
            {
                Aptr = (unsigned short *)a_image->band[0];
                for (y = 0; y < output_height; y++)
                {
                    int flags = (ACTIVEMETADATA_PLANAR);
                    int whitebitdepth = 14;

                    memcpy(scanline, Rptr, info->width * 2);
                    memcpy(scanline + info->width, Gptr, info->width * 2);
                    memcpy(scanline + info->width * 2, Bptr, info->width * 2);
                    memcpy(scanline + info->width * 3, Aptr, info->width * 2);
                    Rptr += r_image->pitch / 2;
                    Gptr += g_image->pitch / 2;
                    Bptr += b_image->pitch / 2;
                    Aptr += a_image->pitch / 2;

                    Convert4444LinesToOutput(decoder, info->width, 1, y, scanline,
                                             newline, output_pitch, info->format, whitebitdepth, flags);

                    newline += output_pitch;
                }
            }
            else
            {
                for (y = 0; y < output_height; y++)
                {
                    int flags = (ACTIVEMETADATA_PLANAR);
                    int whitebitdepth = 14;

                    memcpy(scanline, Rptr, info->width * 2);
                    memcpy(scanline + info->width, Gptr, info->width * 2);
                    memcpy(scanline + info->width * 2, Bptr, info->width * 2);
                    Rptr += r_image->pitch / 2;
                    Gptr += g_image->pitch / 2;
                    Bptr += b_image->pitch / 2;


                    ConvertLinesToOutput(decoder, info->width, 1, y, scanline,
                                         newline, output_pitch, info->format, whitebitdepth, flags);

                    newline += output_pitch;
                }
            }
        }
            //assert(0);
        break;
    }

    STOP(tk_convert);
}


#if _THREADED

// Threaded inverse transform using the new threads API
void TransformInverseSpatialThreadedYUV422ToBuffer(DECODER *decoder, int frame_index, int num_channels,
        uint8_t *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    //TODO: Add support for more output formats
    int format = DECODED_FORMAT_RGB32;

    // The upper and lower spatial transforms only share the middle rows
    int transform_height = (((info->height + 7) / 8) * 8) / 2;
    int middle_row_count = transform_height;

    // Data structure for passing information to the worker threads
    WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

    // Inverse horizontal filter that outputs the desired format
    HorizontalInverseFilterOutputProc horizontal_filter_proc;

#if _DELAY_THREAD_START
    if (decoder->worker_thread.pool.thread_count == 0)
    {
        CreateLock(&decoder->worker_thread.lock);
        // Initialize the pool of transform worker threads
        ThreadPoolCreate(&decoder->worker_thread.pool,
                         decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                         WorkerThreadProc,
                         decoder);
    }
#endif
    // Choose the correct inverse horizontal filter for the output format
    switch (format)
    {
        case DECODED_FORMAT_RGB32:
            horizontal_filter_proc = InvertHorizontalStripYUV16sToPackedRGB32;
            break;

        default:
            assert(0);
            return;
    }

    // Post a message to the mailbox
    mailbox->horizontal_filter_proc = horizontal_filter_proc;
    mailbox->frame = frame_index;
    mailbox->num_channels = num_channels;
    mailbox->output = output;
    mailbox->pitch = pitch;
    memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
    mailbox->chroma_offset = chroma_offset;
    mailbox->precision = precision;
    mailbox->jobType = JOB_TYPE_WAVELET;

    // Set the work count to the number of rows to process
    ThreadPoolSetWorkCount(&decoder->worker_thread.pool, middle_row_count);

    // Start the transform worker threads
    ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

    // Wait for all of the worker threads to finish
    ThreadPoolWaitAllDone(&decoder->worker_thread.pool);

#if (1 && DEBUG)
    if (logfile)
    {
        fprintf(logfile, "All worker threads signalled done\n");
    }
#endif
}


// Threaded inverse transform using the new threads API
// Convert RGB RGBA or BAYER (4 channel) data to a 16-bit planar format
void TransformInverseSpatialUniversalThreadedToRow16u(DECODER *decoder, int frame_index, int num_channels,
        uint8_t *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    // The upper and lower spatial transforms only share the middle rows
    int transform_height = (((info->height + 7) / 8) * 8) / 2;
    int middle_row_count = transform_height;

    // Data structure for passing information to the worker threads
    WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

    // Inverse horizontal filter that outputs the desired format
    HorizontalInverseFilterOutputProc horizontal_filter_proc;
    horizontal_filter_proc = InvertHorizontalStrip16sToRow16uPlanar;
#if _DELAY_THREAD_START
    if (decoder->worker_thread.pool.thread_count == 0)
    {
        CreateLock(&decoder->worker_thread.lock);
        // Initialize the pool of transform worker threads
        ThreadPoolCreate(&decoder->worker_thread.pool,
                         decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                         WorkerThreadProc,
                         decoder);
    }
#endif

    // Post a message to the mailbox
    mailbox->horizontal_filter_proc = horizontal_filter_proc;
    mailbox->frame = frame_index;
    mailbox->num_channels = num_channels;
    mailbox->output = output;
    mailbox->pitch = pitch;
    memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
    mailbox->chroma_offset = chroma_offset;
    mailbox->precision = precision;
    mailbox->jobType = JOB_TYPE_WAVELET;

    // Set the work count to the number of rows to process
    ThreadPoolSetWorkCount(&decoder->worker_thread.pool, middle_row_count);

    // Start the transform worker threads
    ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

    // Wait for all of the worker threads to finish
    ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
}



// Threaded inverse transform using the new threads API
// Convert RGB RGBA or BAYER (4 channel) data to a 16-bit planar format
void TransformInverseSpatialUniversalThreadedToOutput(
    DECODER *decoder, int frame_index, int num_channels,
    uint8_t *output, int pitch, FRAME_INFO *info,
    int chroma_offset, int precision,
    HorizontalInverseFilterOutputProc horizontal_filter_proc)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif

    // The upper and lower spatial transforms only share the middle rows
    int transform_height = (((info->height + 7) / 8) * 8) / 2;
    int middle_row_count = transform_height;

    // Data structure for passing information to the worker threads
    WORKER_THREAD_DATA *mailbox = &decoder->worker_thread.data;

    // Inverse horizontal filter that outputs the desired format
#if _DELAY_THREAD_START
    if (decoder->worker_thread.pool.thread_count == 0)
    {
        CreateLock(&decoder->worker_thread.lock);
        // Initialize the pool of transform worker threads
        ThreadPoolCreate(&decoder->worker_thread.pool,
                         decoder->thread_cntrl.capabilities >> 16/*cpus*/,
                         WorkerThreadProc,
                         decoder);
    }
#endif

    // Post a message to the mailbox
    mailbox->horizontal_filter_proc = horizontal_filter_proc;
    mailbox->frame = frame_index;
    mailbox->num_channels = num_channels;
    mailbox->output = output;
    mailbox->pitch = pitch;
    memcpy(&mailbox->info, info, sizeof(FRAME_INFO));
    mailbox->chroma_offset = chroma_offset;
    mailbox->precision = precision;
    mailbox->jobType = JOB_TYPE_WAVELET;

    // Set the work count to the number of rows to process
    ThreadPoolSetWorkCount(&decoder->worker_thread.pool, middle_row_count);

    // Start the transform worker threads
    ThreadPoolSendMessage(&decoder->worker_thread.pool, THREAD_MESSAGE_START);

    // Wait for all of the worker threads to finish
    ThreadPoolWaitAllDone(&decoder->worker_thread.pool);
}

// Routines for the worker threads that use the new threads API

void TransformInverseSpatialSectionToOutput(DECODER *decoder, int thread_index,
        int frame_index, int num_channels,
        uint8_t *output_buffer, int output_pitch, FRAME_INFO *info,
        int chroma_offset, int precision,
        HorizontalInverseFilterOutputProc horizontal_filter_proc)
{

#if (1 && DEBUG)
    FILE *logfile = decoder->logfile;
#endif
    TRANSFORM **transform = decoder->transform;
    const SCRATCH *scratch = &decoder->scratch;

    PIXEL *lowlow_band[CODEC_MAX_CHANNELS];
    PIXEL *lowhigh_band[CODEC_MAX_CHANNELS];
    PIXEL *highlow_band[CODEC_MAX_CHANNELS];
    PIXEL *highhigh_band[CODEC_MAX_CHANNELS];

    int lowlow_pitch[CODEC_MAX_CHANNELS];
    int lowhigh_pitch[CODEC_MAX_CHANNELS];
    int highlow_pitch[CODEC_MAX_CHANNELS];
    int highhigh_pitch[CODEC_MAX_CHANNELS];

    int channel_width[CODEC_MAX_CHANNELS];

    uint8_t *output_row_ptr;
    uint8_t *plane_array[TRANSFORM_MAX_CHANNELS];
    int plane_pitch[TRANSFORM_MAX_CHANNELS];
    int output_width = info->width;
    int output_height = info->height;
    int half_height = output_height / 2;
    int luma_band_width;
    ROI strip;
    char *bufptr;
    int last_row;
    int last_display_row;
    int last_line;
    int channel;
    int row;
    int odd_display_lines = 0;

    THREAD_ERROR error;

    // Push the scratch space state to allocate a new section
    char *buffer = scratch->free_ptr;
    size_t buffer_size = scratch->free_size;

    //TODO: Replace uses of buffer variables with calls to the scratch space API

    // This version is for 16-bit pixels
    assert(sizeof(PIXEL) == 2);

    // Must have a valid inverse horizontal filter
    assert(horizontal_filter_proc != NULL);

    // Check for enough space in the local array allocations
    //	assert(num_channels <= CODEC_NUM_CHANNELS);
    assert(num_channels <= TRANSFORM_MAX_CHANNELS);

    // Divide the buffer space between the four threads
    buffer_size /= decoder->worker_thread.pool.thread_count;  // used to assume max of 4
    buffer += buffer_size * thread_index;

    // Round the buffer pointer up to the next cache line
    buffer_size -= (_CACHE_LINE_SIZE - ((uintptr_t)buffer & _CACHE_LINE_MASK));
    bufptr = (char *)ALIGN(buffer, _CACHE_LINE_SIZE);

    // Allocate buffer space for the output rows from each channel
    for (channel = 0; channel < num_channels; channel++)
    {
        // Get the row width for this channel
        IMAGE *wavelet = transform[channel]->wavelet[frame_index];
        int width = wavelet->width;
        int height = wavelet->height;
        //int pitch = wavelet->pitch;
        size_t channel_buffer_size;

        // Compute the width and pitch for the output rows stored in this buffer
        int buffer_width = 2 * width;
        int buffer_height = 2;
        int buffer_pitch = ALIGN16(buffer_width);

        // Compute the total allocation for this channel
        channel_buffer_size = buffer_height * buffer_pitch;

        // Check that there is enough space available
        assert(channel_buffer_size <= buffer_size);

        // Allocate the buffer for this channel
        plane_array[channel] = (uint8_t *)bufptr;

        // Remember the pitch for rows in this channel
        plane_pitch[channel] = buffer_pitch;

        // Advance the buffer pointer past the allocated space for this channel
        bufptr += channel_buffer_size;

        // Reduce the amount of space remaining in the buffer
        buffer_size -= channel_buffer_size;

        // The dimensions of the output image are the same as the luma channel
        if (channel == 0)
        {
            strip.width = buffer_width;
            strip.height = buffer_height;
            last_row = height;
            //DAN20050606 Added to fix issue with non-div by 8 heihts.
            last_display_row = (info->height + 1) / 2; // DAN20090215 -- fix for odd display lines.
            odd_display_lines = info->height & 1;

            // Remember the width of the wavelet bands for luma
            luma_band_width = width;
        }

        // Save the bands per channel for routines that process all channels at once
        lowlow_band[channel] = wavelet->band[0];
        lowhigh_band[channel] = wavelet->band[1];
        highlow_band[channel] = wavelet->band[2];
        highhigh_band[channel] = wavelet->band[3];

        lowlow_pitch[channel] = wavelet->pitch;
        lowhigh_pitch[channel] = wavelet->pitch;
        highlow_pitch[channel] = wavelet->pitch;
        highhigh_pitch[channel] = wavelet->pitch;

        // Remember the width of the wavelet for this channel
        channel_width[channel] = width;
    }

    // Use the remaining buffer space for intermediate results
    buffer_size -= (_CACHE_LINE_SIZE - ((uintptr_t)bufptr & _CACHE_LINE_MASK));
    buffer = (char *)ALIGN(bufptr, _CACHE_LINE_SIZE);

    if (last_row == last_display_row)
    {
        last_line = half_height - 1;
    }
    else
    {
        last_line = half_height;
    }

    if (odd_display_lines)
        last_line++;


    if (thread_index == TRANSFORM_WORKER_TOP_THREAD)
    {
        // Process the first row
        row = 0;

        output_row_ptr = output_buffer;

#if (0 && DEBUG)
        if (logfile)
        {
            fprintf(logfile, "Thread: %d, processing row: %d\n", thread_index, row);
        }
#endif
        // Process the first row using special border filters for the top row
        InvertSpatialTopRow16sToOutput(decoder, thread_index, lowlow_band, lowlow_pitch,
                                       lowhigh_band, lowhigh_pitch,
                                       highlow_band, highlow_pitch,
                                       highhigh_band, highhigh_pitch,
                                       output_row_ptr, output_pitch,
                                       output_width, info->format, info->colorspace,
                                       row, channel_width,
                                       (PIXEL *)buffer, buffer_size,
                                       precision,
                                       horizontal_filter_proc);
    }

    if (thread_index == TRANSFORM_WORKER_BOTTOM_THREAD || decoder->worker_thread.pool.thread_count == 1)
    {
        if (last_row == last_display_row) //DAN20071218 -- Added as old 1080 RAW files would crash
        {
            int pitch = output_pitch;
            // Process the last row
            row = last_row - 1;

            if (decoder->channel_decodes > 1 && decoder->frame.format == DECODED_FORMAT_YUYV) // 3d work
                if (decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC)
                    pitch >>= 1;
            // Begin filling the last output row with results
            output_row_ptr = output_buffer + row * 2 * pitch;

#if (0 && DEBUG)
            if (logfile)
            {
                fprintf(logfile, "Thread: %d, processing row: %d\n", thread_index, row);
            }
#endif
            // Process the last row using special border filters for the bottom row

            if (decoder->channel_decodes > 1 && decoder->frame.format == DECODED_FORMAT_YUYV)
                if (decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC || decoder->channel_blend_type == BLEND_LINE_INTERLEAVED) // 3d Work TODO Fix
                    output_row_ptr -= output_pitch;

            InvertSpatialBottomRow16sToOutput(decoder, thread_index, lowlow_band, lowlow_pitch,
                                              lowhigh_band, lowhigh_pitch,
                                              highlow_band, highlow_pitch,
                                              highhigh_band, highhigh_pitch,
                                              output_row_ptr, output_pitch,
                                              output_width, info->format, info->colorspace,
                                              row, channel_width,
                                              (PIXEL *)buffer, buffer_size,
                                              precision, odd_display_lines,
                                              horizontal_filter_proc);
        }
    }

    // Loop until all of the middle rows have been processed
    for (;;)
    {
        int work_index;
        int row;

        // Wait for one row from each channel to process
        error = PoolThreadWaitForWork(&decoder->worker_thread.pool, &work_index, thread_index);

        // Is there another row to process?
        if (error == THREAD_ERROR_OKAY)
        {
            int pitch = output_pitch;
            // Compute the next row to process from the work index
            row = work_index + 1;

            if (decoder->channel_decodes > 1 && decoder->frame.format == DECODED_FORMAT_YUYV) // 3d work
                if (decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC) // stacked
                    pitch >>= 1;

            // Compute the output row corresponding to this row index
            output_row_ptr = output_buffer + row * 2 * pitch;
        }
        else
        {
            // No more work to do
            return;
        }

        // Is the row inside the top and bottom border?
        if (0 < row && row < last_line)
        {
            int outputlines = 2;

#if (0 && DEBUG)
            if (logfile)
            {
                fprintf(logfile, "Thread: %d, processing row: %d\n", thread_index, row);
            }
#endif
            if (odd_display_lines && row == last_line - 1)
            {
                outputlines = 1;
            }

            // Process the middle row using the normal wavelet filters
            InvertSpatialMiddleRow16sToOutput(decoder, thread_index,
                                              lowlow_band, lowlow_pitch,
                                              lowhigh_band, lowhigh_pitch,
                                              highlow_band, highlow_pitch,
                                              highhigh_band, highhigh_pitch,
                                              output_row_ptr, output_pitch,
                                              output_width, info->format, info->colorspace,
                                              row, channel_width,
                                              (PIXEL *)buffer, buffer_size,
                                              precision,
                                              horizontal_filter_proc,
                                              outputlines);
        }
    }
}


#endif //_THREADED


bool GetTuplet(unsigned char *data, int datasize,
               unsigned short findtag, unsigned short *retvalue)
{
    bool ret = false;
    BITSTREAM myinput, *pinput;
    TAGVALUE segment;
    TAGWORD tag, value;
    int error = 0;
    //char t[100];

    InitBitstream(&myinput);
    myinput.lpCurrentWord = data;
    myinput.nWordsUsed = datasize;
    pinput = &myinput;

    do
    {
        bool optional = false;
        int chunksize = 0;

        // Read the next tag value pair from the bitstream
        segment = GetSegment(pinput);

        tag = segment.tuple.tag;
        value = segment.tuple.value;


        // Is this an optional tag?
        if (tag < 0)
        {
            tag = NEG(tag);
            optional = true;
        }



        if (tag & 0x2000)
        {
            chunksize = value;
            chunksize &= 0xffff;
            chunksize += ((tag & 0xff) << 16);
        }
        else if (tag & 0x4000)
        {
            chunksize = value;
            chunksize &= 0xffff;
        }
        else if (tag == CODEC_TAG_INDEX)
        {
            chunksize = value;
            chunksize &= 0xffff;
        }
        else
        {
            chunksize = 0;
        }

        if ((int)(tag) <= ((int)CODEC_TAG_LAST_NON_SIZED) || tag & 0x6000)
        {
            int skip = 1;
            error = 0;

            if (tag == (int)findtag)
            {
                *retvalue = value;
                ret = true;
                break;
            }

            if ((tag & 0xff00) == 0x2200) //sample size
            {
                chunksize = 0; // don't test against pinput->nWordsUsed, as we might be only reader enough for metadata only.
                skip = 0;
            }
            if ((tag & 0xff00) == 0x2300) //uncompressed sample size
            {
                skip = 1;
            }
            if ((tag & 0xff00) == 0x2100) //level
                skip = 0;


            if (chunksize)
            {
                if (chunksize * 4 > pinput->nWordsUsed || chunksize < 0)
                {
                    break;
                }

                if (skip)
                {
                    //unsigned int *iptr =  (unsigned int *)pinput->lpCurrentWord;

                    pinput->lpCurrentWord += chunksize * 4;
                    pinput->nWordsUsed -= chunksize * 4;
                }

            }
        }
        else
        {
            error = 1;
        }
    } while (tag != CODEC_TAG_GROUP_TRAILER &&
             tag != CODEC_TAG_FRAME_TRAILER &&
             pinput->nWordsUsed > 0 && !error);

    return ret;
}

uint8_t *GetTupletAddr(uint8_t *data,
                       int datasize,
                       uint16_t findtag,
                       int16_t *retvalue)
{
    unsigned char *ret = NULL;
    BITSTREAM myinput, *pinput;
    TAGVALUE segment;
    TAGWORD tag, value;
    int error = 0;

    if (data == NULL || datasize == 0)
    {
        return NULL;
    }

    //InitBitstream(&myinput);
    memset(&myinput, 0, sizeof(BITSTREAM));
    myinput.lpCurrentWord = data;
    myinput.nWordsUsed = datasize;
    myinput.nBitsFree = BITSTREAM_LONG_SIZE;
    pinput = &myinput;

    do
    {
        //BOOL optional = FALSE;
        bool optional = false;
        int chunksize = 0;

        // Read the next tag value pair from the bitstream
        segment = GetSegment(pinput);

        tag = segment.tuple.tag;
        value = segment.tuple.value;


        // Is this an optional tag?
        if (tag < 0)
        {
            tag = NEG(tag);
            //optional = TRUE;
            optional = true;
        }

        if (tag & 0x2000)
        {
            chunksize = value;
            chunksize &= 0xffff;
            chunksize += ((tag & 0xff) << 16);
        }
        else if (tag & 0x4000)
        {
            chunksize = value;
            chunksize &= 0xffff;
        }
        else if (tag == CODEC_TAG_INDEX)
        {
            chunksize = value;
            chunksize &= 0xffff;
        }
        else
        {
            chunksize = 0;
        }

        if ((int)(tag) <= ((int)CODEC_TAG_LAST_NON_SIZED) || tag & 0x6000)
        {
            int skip = 1;
            error = 0;

            if (tag == (int)findtag)
            {
                *retvalue = value;
                ret = pinput->lpCurrentWord;
                break;
            }

            if ((tag & 0xff00) == 0x2200) //sample size
            {
                chunksize = 0; // don't test against pinput->nWordsUsed, as we might be only reader enough for metadata only.
                skip = 0;
            }
            if ((tag & 0xff00) == 0x2300) //uncompressed sample size
            {
                skip = 1;
            }
            if ((tag & 0xff00) == 0x2100) //level
                skip = 0;


            if (chunksize)
            {
                if (chunksize * 4 > pinput->nWordsUsed || chunksize < 0)
                {
                    break;
                }

                if (skip)
                {
                    //unsigned int *iptr =  (unsigned int *)pinput->lpCurrentWord;

                    pinput->lpCurrentWord += chunksize * 4;
                    pinput->nWordsUsed -= chunksize * 4;
                }

            }
        }
        else
        {
            error = 1;
        }
    } while (tag != CODEC_TAG_GROUP_TRAILER &&
             tag != CODEC_TAG_FRAME_TRAILER &&
             pinput->nWordsUsed > 0 && !error);

    return ret;
}
