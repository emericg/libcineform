/*! @file decoder.h

*  @brief
*
*  @version 1.0.0
*
*  (C) Copyright 2017 GoPro Inc (http://gopro.com/).
*
*  Licensed under either:
*  - Apache License, Version 2.0, http://www.apache.org/licenses/LICENSE-2.0
*  - MIT license, http://opensource.org/licenses/MIT
*  at your option.
*
*  Unless required by applicable law or agreed to in writing, software
*  distributed under the License is distributed on an "AS IS" BASIS,
*  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*  See the License for the specific language governing permissions and
*  limitations under the License.
*
*/

#ifndef _DECODER_H
#define _DECODER_H

#ifdef _WINDOWS
#include <windows.h>
#elif __APPLE__
#include "macdefs.h"
#endif

#include <stdio.h>
#include "config.h"
#include "codec.h"
#include "color.h"
#include "bitstream.h"
#include "../Common/AVIExtendedHeader.h"

#if _THREADED
#include "thread.h"
#endif


// Should move decoder definition here

#define DECODER_FLAGS_NORMAL 		0x00000000		// Default flags
#define DECODER_FLAGS_RENDER 		0x00000001		// The decoded frame will be rendered
#define DECODER_FLAGS_YUV709 		0x00000002		// Using BT.709
#define DECODER_FLAGS_VIDEO_RGB 	0x00000004		// Use 16-235 RGB vs sRGB
#define DECODER_FLAGS_HIGH_QUALITY 	0x00000008		// Use green ripple filtering for CineForm RAW clips

#define DECODED_FLAGS_NORENDER		0x00000000		// The decoded frame will not be rendered

// Output formats that will be supported by the decoder
typedef enum decoded_format
{
    DECODED_FORMAT_UNSUPPORTED = 0,

    DECODED_FORMAT_YUYV = COLOR_FORMAT_YUYV,
    DECODED_FORMAT_UYVY = COLOR_FORMAT_UYVY,

    DECODED_FORMAT_RGB32 = COLOR_FORMAT_RGB32,
    DECODED_FORMAT_RGB24 = COLOR_FORMAT_RGB24,

    DECODED_FORMAT_RGB32_INVERTED = MAKE_FORMAT(FRAME_FORMAT_INVERTED, COLOR_FORMAT_RGB32),
    DECODED_FORMAT_RGB24_INVERTED = MAKE_FORMAT(FRAME_FORMAT_INVERTED, COLOR_FORMAT_RGB24),

    DECODED_FORMAT_V210 = COLOR_FORMAT_V210,
    DECODED_FORMAT_YU64 = COLOR_FORMAT_YU64,

    DECODED_FORMAT_ROW16U = COLOR_FORMAT_YR16,

    DECODED_FORMAT_YUVA = COLOR_FORMAT_YUVA,

    // The following two formats are not currently implemented
    DECODED_FORMAT_RG48 = COLOR_FORMAT_RG48,		//encoded as RGB
    DECODED_FORMAT_WP13 = COLOR_FORMAT_WP13,		//encoded as RGB
    DECODED_FORMAT_W13A = COLOR_FORMAT_W13A,		//encoded as RGBA
    DECODED_FORMAT_RG64 = COLOR_FORMAT_RG64,		//encoded as RGBA
    DECODED_FORMAT_RG30 = COLOR_FORMAT_RG30,		//encoded as RG30 (packed RGB48)
    DECODED_FORMAT_R210 = COLOR_FORMAT_R210,		//encoded as RG30 (packed RGB48)
    DECODED_FORMAT_DPX0 = COLOR_FORMAT_DPX0,		//encoded as RG30 (packed RGB48)
    DECODED_FORMAT_AR10 = COLOR_FORMAT_AR10,		//
    DECODED_FORMAT_AB10 = COLOR_FORMAT_AB10,		//

    // YUV 4:2:0 formats used by MPEG codecs
    DECODED_FORMAT_NV12 = COLOR_FORMAT_NV12,
    DECODED_FORMAT_YV12 = COLOR_FORMAT_YV12,

    // Bayer formats
    DECODED_FORMAT_BYR1 = COLOR_FORMAT_BYR1,
    DECODED_FORMAT_BYR2 = COLOR_FORMAT_BYR2,
    DECODED_FORMAT_BYR3 = COLOR_FORMAT_BYR3,
    DECODED_FORMAT_BYR4 = COLOR_FORMAT_BYR4,
    DECODED_FORMAT_BYR5 = COLOR_FORMAT_BYR5,

    // QuickTime formats
    DECODED_FORMAT_B64A = COLOR_FORMAT_B64A,
    DECODED_FORMAT_R4FL = COLOR_FORMAT_R4FL,
    DECODED_FORMAT_2VUY = COLOR_FORMAT_UYVY,
    DECODED_FORMAT_R408 = COLOR_FORMAT_R408,
    DECODED_FORMAT_V408 = COLOR_FORMAT_V408,

    // Avid formats (used internally because these definitions are more precise)
    DECODED_FORMAT_CbYCrY_8bit = COLOR_FORMAT_CbYCrY_8bit,
    DECODED_FORMAT_CbYCrY_16bit = COLOR_FORMAT_CbYCrY_16bit,
    DECODED_FORMAT_CbYCrY_10bit_2_8 = COLOR_FORMAT_CbYCrY_10bit_2_8,
    DECODED_FORMAT_CbYCrY_16bit_2_14 = COLOR_FORMAT_CbYCrY_16bit_2_14,
    DECODED_FORMAT_CbYCrY_16bit_10_6 = COLOR_FORMAT_CbYCrY_16bit_10_6,

    // Alternate names using the Avid naming conventions
    DECODED_FORMAT_CT_UCHAR = DECODED_FORMAT_CbYCrY_8bit,
    DECODED_FORMAT_CT_SHORT = DECODED_FORMAT_CbYCrY_16bit,
    DECODED_FORMAT_CT_10Bit_2_8 = DECODED_FORMAT_CbYCrY_10bit_2_8,
    DECODED_FORMAT_CT_SHORT_2_14 = DECODED_FORMAT_CbYCrY_16bit_2_14,
    DECODED_FORMAT_CT_USHORT_10_6 = DECODED_FORMAT_CbYCrY_16bit_10_6,

    // Alternative names
    DECODED_FORMAT_RGBA = DECODED_FORMAT_RGB32,
    DECODED_FORMAT_RGBa = DECODED_FORMAT_RGB32_INVERTED,
    DECODED_FORMAT_YR16 = DECODED_FORMAT_ROW16U,

    //NOTE: After the YUVA format is fully supported, change the
    // entry for the maximum decoded format to the new YUVA format.
    DECODED_FORMAT_MINIMUM = DECODED_FORMAT_UYVY,
    DECODED_FORMAT_MAXIMUM = DECODED_FORMAT_ROW16U,

} DECODED_FORMAT;

// Range of valid color formats encountered during decoding
#define MAX_DECODED_COLOR_FORMAT	13

typedef enum decoded_resolution
{
    DECODED_RESOLUTION_UNSUPPORTED = 0,			// Unknown decoded resolution
    DECODED_RESOLUTION_FULL = 1,				// Full resolution decoding
    DECODED_RESOLUTION_HALF,					// Half resolution decoding
    DECODED_RESOLUTION_QUARTER,					// Quarter resolution decoding at full frame rate
    DECODED_RESOLUTION_LOWPASS_ONLY,			// Lowest resolution decoding

    DECODED_RESOLUTION_FULL_DEBAYER,
    DECODED_RESOLUTION_HALF_NODEBAYER,			// Decode 4K RAW at 2K into BYR2 (requires fake bayer reconstruction)
    DECODED_RESOLUTION_QUARTER_NODEBAYER_SCALED,// To allow uncompressed RAW to decode at Quarter res.
    DECODED_RESOLUTION_HALF_HORIZONTAL_DEBAYER,

    // Useful for 3D
    DECODED_RESOLUTION_HALF_HORIZONTAL,		// Decode 1920x1080 at 960x1080 using fewer subbands in the inverse wavelet
    DECODED_RESOLUTION_HALF_VERTICAL,		// Decode 1920x1080 at 1920x540 using fewer subbands in the inverse wavelet

    // Add more entries here

    // Older code used this SD definition for half resolution
    DECODED_RESOLUTION_SIF = DECODED_RESOLUTION_HALF

} DECODED_RESOLUTION;

// Encoded samples must be aligned on a four byte boundary
#define ENCODED_SAMPLE_ALIGNMENT	4

typedef struct sample_header
{
    // Errors code for parsing the sample header
    CODEC_ERROR error;

    // Dimensions of the encoded frames
    uint32_t width;
    uint32_t height;
    uint32_t display_height;

    // One channel for 2D, two channels for 3D
    uint32_t videoChannels;

    // Version number: major << 16 | minor << 8 | revision (no build number)
    uint32_t encoder_version;

    int key_frame;
    int difference_frame;
    int droppable_frame;

    // Is the video interlaced or progressive?
    int hdr_progressive;
    int hdr_uncompressed;

    // Original format of the encoded frames
    COLOR_FORMAT input_format;

    // Internal representation of the encoded data
    ENCODED_FORMAT encoded_format;

    uint32_t encode_quality;

    // Frame number of the sample (used for debugging)
    uint32_t frame_number;

    // Interlaced field information
    int interlaced_flags;

    // Size of the left stereo sample and offset to the right stereo sample (in bytes)
    int left_sample_size;

    // Find the low pass bands
    int find_lowpass_bands;
    int thumbnail_channel_offsets[CODEC_MAX_CHANNELS];
    int thumbnail_channel_offsets_2nd_Eye[CODEC_MAX_CHANNELS];

    //TODO: Modify the CHANNEL_OFFSET struct if the channels offset definitions change

} SAMPLE_HEADER;

#ifdef __cplusplus
extern "C" {
#endif

//extern int PixelSize[];

#if (0 && _DEBUG)
extern char *decoded_format_string[];
#endif

// Find the codec tag (not the metadata tag) in the specified buffer
bool GetTuplet(unsigned char *data, int datasize,
               unsigned short findtag, unsigned short *retvalue);

// Return the address of the codec tag (not the metadata tag)
uint8_t *GetTupletAddr(uint8_t *data, int datasize,
                       uint16_t findtag, int16_t *retvalue);

#if 0
unsigned char *GetTupletAddr(unsigned char *data, int datasize,
                             unsigned short findtag, unsigned short *retvalue);
#endif

void InitDecoder(DECODER *decoder, FILE *logfile, CODESET *cs);
void ClearDecoder(DECODER *decoder);

#if _ALLOCATOR
bool DecodeInit(ALLOCATOR *allocator, DECODER *decoder, int width, int height, int format, int resolution, FILE *logfile);
#else
bool DecodeInit(DECODER *decoder, int width, int height, int format, int resolution, FILE *logfile);
#endif
size_t DecoderSize();

void DecodeEntropyInit(DECODER *decoder);

bool DecodeOverrides(DECODER *decoder, unsigned char *overrideData, int overrideSize);
bool DecodeSample(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams, CFHDDATA *cfhddata);
void DecodeRelease(DECODER *decoder, TRANSFORM **transform, int num_transforms);
void DecodeForceMetadataRefresh(DECODER *decoder);

// Decode a sample that encoded a group of frames (return the first frame)
bool DecodeSampleGroup(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams);

// Decode a sample that represents the second frame in a group
bool DecodeSampleFrame(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams);

// Decode a sample that represents an isolated frame
bool DecodeSampleIntraFrame(DECODER *decoder, BITSTREAM *input, uint8_t *output, int pitch, ColorParam *colorparams);

bool ParseSampleHeader(BITSTREAM *sample, SAMPLE_HEADER *header);
bool DumpSampleHeader(BITSTREAM *input, FILE *logfile);

// Return the pixel size of the decoded format (in bytes)
int DecodedPixelSize(DECODED_FORMAT format);

void GetDisplayAspectRatio(DECODER *decoder, int *w, int *h);

// Compute the resolution corresponding to the specified combination of input and output dimensions
int DecodedResolution(int input_width, int input_height, int output_width, int output_height);

// Compute the decoded resolution that is closest to the output dimensions (for scaling)
int DecodedScale(int input_width, int input_height, int output_width, int output_height);

// Compute the dimensions of the decoded image from the encoded dimensions and decoding resolution
void ComputeDecodedDimensions(int encoded_width, int encoded_height, int decoded_resolution,
                              int *decoded_width_out, int *decoded_height_out);

// Return true if the specified resolution is supported
bool IsDecodedResolution(int resolution);

// Return true if the encoded sample is a key frame
bool IsSampleKeyFrame(uint8_t *sample, size_t size);

// Return true if this decoder can decode to quarter resolution
bool IsQuarterResolutionEnabled(DECODER *decoder);

// Return the number of the more recent decoded frame
uint32_t DecodedFrameNumber(DECODER *decoder);

void SetDecoderFormat(DECODER *decoder, int width, int height, int format, int resolution);
void SetDecoderCapabilities(DECODER *decoder);
int GetDecoderCapabilities(DECODER *decoder);
bool SetDecoderColorFlags(DECODER *decoder, uint32_t color_flags);
void SetDecoderFlags(DECODER *decoder, uint32_t flags);
bool ResizeDecoderBuffer(DECODER *decoder, int width, int height, int format);

IMAGE *DecodeNextFrame(DECODER *decoder, BITSTREAM *input);
#ifdef _WINDOWS
bool DecodeFile(DECODER *decoder, HANDLE file);
#endif
bool DecodeSequence(DECODER *decoder, BITSTREAM *input);
bool DecodeGroup(DECODER *decoder, BITSTREAM *input, int sample_type, ColorParam *colorparams);
bool DecodeGroupTransform(DECODER *decoder, BITSTREAM *input, int sample_type, ColorParam *colorparams);
bool DecodeHighPassBand8s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int index, int band, int subband, int channel, ColorParam *colorparams);
bool SkipHighPassBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int index, int band, int subband, int channel, ColorParam *colorparams);
bool DecodeHighPassBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int index, int band, int subband, int channel, ColorParam *colorparams);
bool SkipHighPassBands(DECODER *decoder, BITSTREAM *stream);
bool DecodeEmptyHighPassBand(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, int index, int band, int subband, int channel, ColorParam *colorparams);
bool DecodeBandCodes(DECODER *ecoder, BITSTREAM *stream, IMAGE *wavelet,
                     int band_index, int width, int height, int quantization);
bool DecodeBandRuns(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                    int band_index, int width, int height, int quantization);

// Decode the highpass band in a temporal transform, then perform dequantization
// and compute the inverse temporal transform in one pass for reduced memory usage.
bool DecodeTemporalBand8s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet, IMAGE *lowpass[],
                          int index, int band, int subband, int channel,
                          PIXEL *buffer, size_t buffer_size, ColorParam *colorparams);

// Optimized decoding routine
bool DecodeFastRuns(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                    int band_index, int width, int height, int quantization);

// Finite state machine decoder for run length encoded coefficients
bool DecodeFastRunsFSM(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                       int band_index, int width, int height, int quantization);
bool DecodeFastRunsFSM8s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                         int band_index, int width, int height);
bool DecodeFastRunsFSM16s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                          int band_index, int width, int height, int threading);
bool SkipFastRunsFSM(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                     int band_index, int width, int height);

// Start of a routine that combines highpass band decoding with temporal inverse transform
bool DecodeBandRunsFSM8s(DECODER *decoder, BITSTREAM *stream, IMAGE *wavelet,
                         int band_index, int width, int height,
                         IMAGE *even, IMAGE *odd);


void CopyLowpass16sToBuffer(DECODER *decoder, IMAGE *images[], int num_channels,
                            uint8_t *output_buffer, int32_t output_pitch,
                            struct frame_info *info, int chroma_offset,
                            int precision, int encoded_format, int whitebitdepthint);

// Update the codec state with the information in a tag value pair
CODEC_ERROR UpdateCodecState(DECODER *decoder, BITSTREAM *input, CODEC_STATE *codec, TAGWORD tag, TAGWORD value);

// Update the transform data structure using the information in the codec state
void UpdateCodecTransform(TRANSFORM *transform, CODEC_STATE *codec);
bool DecodeSampleSubband(DECODER *decoder, BITSTREAM *input, int subband);
bool DecodeSampleChannelHeader(DECODER *decoder, BITSTREAM *input);

void DeQuantFSM(FSM *fsm, int quant);

// Routines that combine inverse wavelet transforms with color conversion

// Apply the inverse horizontal-temporal transform to reconstruct the output frame
void ReconstructFrameToBuffer(DECODER *decoder, TRANSFORM *transform[],
                              int frame, uint8_t *output, int pitch);

// Invert the wavelet to reconstruct the lower wavelet in the transform
#if 0
void ReconstructWaveletBand(TRANSFORM *transform, int channel, IMAGE *wavelet, int index,
                            int precision, PIXEL *buffer, size_t buffer_size);
#else
void ReconstructWaveletBand(DECODER *decoder, TRANSFORM *transform, int channel,
                            IMAGE *wavelet, int index,
                            int precision, const SCRATCH *scratch,
                            int allocations_only /* for queued work */);
#endif

// Apply the inverse horizontal-temporal transform and pack the output into a buffer
void TransformInverseFrameToYUV(TRANSFORM *transform[], int frame, int num_channels,
                                uint8_t *output, int pitch, FRAME_INFO *info,
                                const SCRATCH *scratch, int chroma_offset, int precision);

// Apply the inverse horizontal-temporal transform and output rows of luma and chroma
void TransformInverseFrameToRow16u(DECODER *decoder, TRANSFORM *transform[], int frame_index, int num_channels,
                                   PIXEL16U *output, int output_pitch, FRAME_INFO *frame,
                                   const SCRATCH *scratch, int chroma_offset,
                                   int precision);

// Apply the inverse horizontal-temporal transform and pack the output into a buffer
#if 0
void TransformInverseFrameToBuffer(TRANSFORM *transform[], int frame_index, int num_channels,
                                   uint8_t *output, int output_pitch, FRAME_INFO *frame,
                                   char *buffer, size_t buffer_size, int chroma_offset,
                                   int precision);
#else
void TransformInverseFrameToBuffer(TRANSFORM *transform[], int frame_index, int num_channels,
                                   uint8_t *output, int output_pitch, FRAME_INFO *frame,
                                   const SCRATCH *scratch, int chroma_offset, int precision);
#endif

// Routines that perform color conversion and pack the pixels in the output buffer

// Copy image to buffer with specified output format
void CopyImageToBuffer(IMAGE *image, uint8_t *output_buffer, int32_t output_pitch, int format);

void ConvertYUVStripPlanarToBuffer(uint8_t *planar_output[], int planar_pitch[], ROI roi,
                                   uint8_t *output_buffer, int output_pitch, int frame_width,
                                   int format, int colorspace);

void ConvertRow16uToDitheredBuffer(DECODER *decoder, uint8_t *planar_output[], int planar_pitch[], ROI roi,
                                   uint8_t *output_buffer, int output_pitch, int frame_width,
                                   int format, int colorspace);

// Convert one row of packed YUYV to the specified color
void ConvertRowYUYV(uint8_t *input, uint8_t *output, int length, int format, int colorspace, int precision);

#if _DEBUG
bool DecodeBandFSM8sNoGap(FSM *fsm, BITSTREAM *stream, PIXEL8S *image, int width, int height, int pitch);
#endif

#if _THREADED_DECODER

//DWORD ThreadedBandMask(int transform_type, int index);
//IMAGE *ThreadOutputWavelet(TRANSFORM *transform, IMAGE *wavelet, int index);
//void SetThreadNextWavelet(DECODER *decoder, TRANSFORM *transform, int index);

IMAGE *GetWaveletThreadSafe(DECODER *decoder, TRANSFORM *transform, int index,
                            int width, int height, int level, int type);

void UpdateWaveletBandValidFlags(DECODER *decoder, IMAGE *wavelet, int band);
void UpdateWaveletBandStartedFlags(DECODER *decoder, IMAGE *wavelet, int band);
bool DecodedBandsValid(IMAGE *wavelet, int index, int transform_type);
void QueueThreadedTransform(DECODER *decoder, int channel, int wavelet_index);
bool VerifyTransformQueue(DECODER *decoder);
void WaitForTransformThread(DECODER *decoder);
THREAD_PROC(TransformThreadProc, lpParam);

#endif

enum	// Types of transforms supported by the worker threads
{
    THREAD_TRANSFORM_FRAME_YUV = 1, // interlaced
    THREAD_TRANSFORM_FRAME_ROW16U,
    /*	THREAD_TRANSFORM_SPATIAL_YUV,  // progressive formats moved to the new threading model
    	THREAD_TRANSFORM_SPATIAL_ROW16U,
    	THREAD_TRANSFORM_SPATIAL_BAYER2YUV,
    	THREAD_TRANSFORM_SPATIAL_BAYER_3DLUT_YUV,
    	THREAD_TRANSFORM_SPATIAL_RGB2YUV,
    	THREAD_TRANSFORM_SPATIAL_RGB2YR16,
    	THREAD_TRANSFORM_SPATIAL_RGB2RG30,
    	THREAD_TRANSFORM_SPATIAL_RGB2r210,
    	THREAD_TRANSFORM_SPATIAL_RGB32,
    	THREAD_TRANSFORM_SPATIAL_BAYER_NEW3DLUT,
    	THREAD_TRANSFORM_SPATIAL_RGB2B64A,
    */
};

#if _INTERLACED_WORKER_THREADS

// Routines that invoke the worker threads to perform the transforms

void TransformInverseFrameThreadedToYUV(DECODER *decoder, int frame_index, int num_channels,
                                        uint8_t *output, int pitch, FRAME_INFO *info,
                                        int chroma_offset, int precision);

void TransformInverseFrameThreadedToRow16u(DECODER *decoder, int frame_index, int num_channels,
        PIXEL16U *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision);

// Routines that perform the threaded transforms

DWORD WINAPI InterlacedWorkerThreadProc(LPVOID lpParam);

void TransformInverseFrameSectionToYUV(DECODER *decoder, int thread_index, int frame_index, int num_channels,
                                       uint8_t *output, int output_pitch, FRAME_INFO *info,
                                       int chroma_offset, int precision);

void TransformInverseFrameSectionToRow16u(DECODER *decoder, int thread_index, int frame_index, int num_channels,
        PIXEL16U *output, int output_pitch, FRAME_INFO *info,
        int chroma_offset, int precision);
#endif


#if _THREADED

// Threaded inverse transform using the new threads API
void TransformInverseSpatialThreadedYUV422ToBuffer(DECODER *decoder, int frame_index, int num_channels,
        uint8_t *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision);

void TransformInverseSpatialUniversalThreadedToRow16u(DECODER *decoder, int frame_index, int num_channels,
        uint8_t *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision);

void TransformInverseSpatialUniversalThreadedToOutput(DECODER *decoder, int frame_index, int num_channels,
        uint8_t *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision,
        HorizontalInverseFilterOutputProc horizontal_filter_proc);


// Routines for the worker threads that use the new threads API

THREAD_PROC(TransformWorkerThreadProc, lpParam);
THREAD_PROC(WorkerThreadProc, lpParam);
THREAD_PROC(EntropyWorkerThreadProc, lpParam);
THREAD_PROC(ParallelThreadProc, lpParam);

void TransformInverseSpatialSectionToBuffer(DECODER *decoder, int thread_index,
        int frame_index, int num_channels,
        uint8_t *output, int pitch, FRAME_INFO *info,
        int chroma_offset, int precision, int type);


#endif

#ifdef __cplusplus
}
#endif

#endif
