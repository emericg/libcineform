/*! @file spatial.c

*  @brief Wavelet tools
*
*  @version 1.0.0
*
*  (C) Copyright 2017 GoPro Inc (http://gopro.com/).
*
*  Licensed under either:
*  - Apache License, Version 2.0, http://www.apache.org/licenses/LICENSE-2.0
*  - MIT license, http://opensource.org/licenses/MIT
*  at your option.
*
*  Unless required by applicable law or agreed to in writing, software
*  distributed under the License is distributed on an "AS IS" BASIS,
*  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*  See the License for the specific language governing permissions and
*  limitations under the License.
*
*/

#include "config.h"
#include "timing.h"

#ifndef DEBUG
#define DEBUG  (1 && _DEBUG)
#endif
#define TIMING (1 && _TIMING)
#define XMMOPT (1 && _XMMOPT)

#define PREFETCH (1 && _PREFETCH)

#include <assert.h>
#include <math.h>
#include <limits.h>
#include <emmintrin.h>		// SSE2 intrinsics

#include "spatial.h"
#include "filter.h"			// Declarations of filter routines
//#include "image.h"		// Image processing data types
//#include "ipp.h"			// Use Intel Performance Primitives
//#include "debug.h"
#include "codec.h"
#include "buffer.h"
#include "quantize.h"
#include "convert.h"
#include "decoder.h"
#include "bayer.h"
#include "swap.h"
#include <memory.h>


//TODO: Replace uses of _bswap with SwapInt32


#define _PREROLL 1		// Enable loop preprocessing for memory alignment

// Forward reference (to avoid including encoder.h)
//typedef struct encoder ENCODER;
struct encoder;


#if DEBUG
// Make the logfile available for debugging
#include <stdio.h>
extern FILE *logfile;
#endif

#ifndef _QUANTIZE_SPATIAL_LOWPASS
#define _QUANTIZE_SPATIAL_LOWPASS	0
#endif

//#ifndef _UNALIGNED
//#define _UNALIGNED	0
//#endif
#ifndef _UNALIGNED
#define _UNALIGNED	0
//#elif (_UNALIGNED == 1)    // Hack for VS2012 and beyond as default behavior for VS sets _UNALIGNED == __unaligned keyword)
//do nothing
#else
#undef _UNALIGNED
#define _UNALIGNED	0
#endif

#ifndef _FASTLOOP
#define _FASTLOOP	1
#endif


// Shifts used to remove prescaling in the thumbnail spatial transform
#define V210_HORIZONTAL_SHIFT	2
#define V210_VERTICAL_SHIFT		0

#if 0
static void PrescaleRow16s(PIXEL *rowptr, int width, int prescale)
{
#if (1 && XMMOPT)
    int column_step = 4;
    int post_column = width - (width % column_step);
    __m64 *mm_ptr = (__m64 *)rowptr;
    __m64 in_pi16;
#endif
    int column;

    // Return now if no prescaling is needed
    if (prescale == 0) return;

    // Start at the first column
    column = 0;

#if (1 && XMMOPT)
    for (; column < post_column; column += column_step)
    {
        in_pi16 = *mm_ptr;
        *mm_ptr++ = _mm_sra_pi16(in_pi16, _mm_cvtsi32_si64(prescale));
    }

    //_mm_empty();

    assert(column == post_column);
#endif

    for (; column < width; column++)
        rowptr[column] = (rowptr[column] >> prescale);
}
#endif
#if 0
static void PrescaleRow8s(PIXEL8S *rowptr, int width, int prescale)
{
#if (1 && XMMOPT)
    int column_step = 8;
    int post_column = width - (width % column_step);
    __m64 *mm_ptr = (__m64 *)rowptr;
    __m64 in1_pi16, in2_pi16;
    __m64 in_pi8;
    __m64 sign_pi8;
#endif
    int column;

    // Return now if no prescaling is needed
    if (prescale == 0) return;

    // Start at the first column
    column = 0;

#if (1 && XMMOPT)
    for (; column < post_column; column += column_step)
    {
        in_pi8 = *mm_ptr;

        // Compute the sign for unpacking
        sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), in_pi8);

        // Unpack the lower and upper bytes
        in1_pi16 = _mm_unpacklo_pi8(in_pi8, sign_pi8);
        in2_pi16 = _mm_unpackhi_pi8(in_pi8, sign_pi8);

        // Prescale the lower and upper bytes
        in1_pi16 = _mm_sra_pi16(in1_pi16, _mm_cvtsi32_si64(prescale));
        in2_pi16 = _mm_sra_pi16(in2_pi16, _mm_cvtsi32_si64(prescale));

        // Pack the lower and upper bytes
        in_pi8 = _mm_packs_pi16(in1_pi16, in2_pi16);

        // Store the result
        *mm_ptr++ = in_pi8;
    }

    //_mm_empty();

    assert(column == post_column);
#endif

    for (; column < width; column++)
        rowptr[column] = rowptr[column] >> prescale;
}
#endif
#if 0
static void PrescaleLowpassRow16s(PIXEL *input, PIXEL *output, int width)
{
#if (1 && XMMOPT)
    int column_step = 4;
    int post_column = width - (width % column_step);
    __m64 *input_ptr = (__m64 *)input;
    __m64 *output_ptr = (__m64 *)output;
    __m64 group_pi16;
    __m64 round_pi16 = _mm_set1_pi16(1);
#endif

    // Start at the first column
    int column = 0;

#if (1 && XMMOPT)
    for (; column < post_column; column += column_step)
    {
        group_pi16 = *(input_ptr++);
        group_pi16 = _mm_srai_pi16(group_pi16, _LOWPASS_PRESCALE);
        group_pi16 = _mm_adds_pi16(group_pi16, round_pi16);
        *(output_ptr++) = group_pi16;
    }

    // Check that the loop terminated at the post processing column
    assert(column == post_column);

    //_mm_empty();	// Clear the mmx register state

#endif

    for (; column < width; column++)
    {
        //DAN 9/12/02 Fix for chroma/luma shift
        output[column] = ((input[column]) >> _LOWPASS_PRESCALE) + 1;
    }
}
#endif

#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the lowpass and highpass horizontal filters to one row
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
    //FilterHorizontalRowPrescaled16s(input, lowpass, highpass, width, NULL);
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

#if 1

// Apply the lowpass and highpass horizontal filters to one row
// Original version with the loop unrolled to allow use of prefetched loads
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m128i *input_ptr = (__m128i *)input;
    __m128i *lowpass_ptr;
    __m128i *highpass_ptr;
    __m128i input1_epi16;
    __m128i mask_epi16;

    int highpass_value;

    // The highpass filter on the left border uses different coefficients
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    highpass_value = SATURATE(sum);

    // Set the input pointer for the fast loop
    input_ptr = (__m128i *)&input[column];

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowptr;
    highpass_ptr = (__m128i *)highptr;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpass_ptr));
    assert(ISALIGNED16(highpass_ptr));

    // Intialize the mask used for downsampling the convolution results
    mask_epi16 = _mm_set1_epi32(0x0000FFFF);

#if (1 && XMMOPT)
    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m128i input2_epi16;
        __m128i shift2_epi16;
        __m128i half_epi16;		// Half of the divisor for rounding
        __m128i sum1_epi16;
        __m128i sum2_epi16;
        __m128i sum1b_epi16;
        __m128i sum2b_epi16;
        __m128i low1_epi16;
        __m128i low2_epi16;


        /***** Process the first four output points *****/

        // Initialize the highpass sum
        sum1_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low1_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
#if 1
        low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
        low1_epi16 = _mm_srai_epi32(low1_epi16, 16);
#else
        low1_epi16 = _mm_and_si128(low1_epi16, mask_epi16);
#endif
        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
        sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

        sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

        // Expand the even output points to a full doubleword
        sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
        sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

        // The second eight input points become the current input points
        input1_epi16 = input2_epi16;


        /***** Process the second four output points *****/

        // Initialize the highpass sum
        sum2_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low2_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
#if 1
        low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
        low2_epi16 = _mm_srai_epi32(low2_epi16, 16);
#else
        low2_epi16 = _mm_and_si128(low2_epi16, mask_epi16);
#endif
        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
        sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

        sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);

        // Expand the even output points to a full doubleword
        sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
        sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


        /***** Combine the output points *****/

        low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
        sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


        // Store the four lowpass output points
        _mm_store_si128(lowpass_ptr++, low1_epi16);

        // Get the last highpass coefficient in the group
        sum2_epi16 = _mm_srli_si128(sum1_epi16, 7 * 2);

        // Shift the extra highpass coefficient into the output
        sum1_epi16 = _mm_slli_si128(sum1_epi16, 1 * 2);
        sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

        // Save the last highpass coefficient for the next loop iteration
        highpass_value = _mm_cvtsi128_si32(sum2_epi16);

        // Store the four highpass output points
        _mm_store_si128(highpass_ptr++, sum1_epi16);

        // The second set of eight input pixels becomes the working set
        input1_epi16 = input2_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;

#else
    sum = input[column] + input[column + 1];
    *(lowptr++) = SATURATE(sum);
    *(highptr++) = SATURATE(highpass_value);
    column += 2;
#endif

    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        sum = input[column] + input[column + 1];

        // Store the lowpass sum
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass sum
        sum = 0;
        sum -= input[column - 2];
        sum -= input[column - 1];
        sum += input[column + 2];
        sum += input[column + 3];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum += input[column + 0];
        sum -= input[column + 1];

        // Store the highpass sum
        *(highptr++) = SATURATE(sum);
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    sum = input[column] + input[column + 1];

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    *(highptr++) = SATURATE(sum);
}

#elif 1

// Apply the lowpass and highpass horizontal filters to one row
// New version that uses shorter shift operations
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m128i *input_ptr = (__m128i *)input;
    __m128i *lowpass_ptr;
    __m128i *highpass_ptr;
    __m128i input1_epi16;

    int highpass_value;

    // The highpass filter on the left border uses different coefficients
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    highpass_value = SATURATE(sum);

    // Set the input pointer for the fast loop
    input_ptr = (__m128i *)&input[column];

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowptr;
    highpass_ptr = (__m128i *)highptr;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpass_ptr));
    assert(ISALIGNED16(highpass_ptr));


#if (1 && XMMOPT)
    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m128i input2_epi16;
        __m128i shift1_epi16;
        __m128i shift2_epi16;
        __m128i shift3_epi16;
        __m128i shift4_epi16;
        __m128i shift5_epi16;
        __m128i mask_epi16;
        __m128i sign_epi16;
        __m128i half_epi16;		// Half of the divisor for rounding
        __m128i sum1_epi16;
        __m128i sum2_epi16;
        __m128i sum1b_epi16;
        __m128i sum2b_epi16;
        __m128i low1_epi16;
        __m128i low2_epi16;


        // Intialize the mask used for downsampling the convoution results
        mask_epi16 = _mm_set1_epi32(0x0000FFFF);


        /***** Process the first four output points *****/

        // Initialize the highpass sum
        sum1_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low1_epi16 = input1_epi16;

        // Generate shifted versions of the second set of input values
        shift5_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        shift4_epi16 = _mm_slli_si128(shift5_epi16, 1 * 2);
        shift3_epi16 = _mm_slli_si128(shift4_epi16, 1 * 2);
        shift2_epi16 = _mm_slli_si128(shift3_epi16, 1 * 2);
        shift1_epi16 = _mm_slli_si128(shift2_epi16, 1 * 2);

        // Shift the first pixel from the second set into the working set
        //shift2_epi16 = _mm_slli_si128(input2_epi16, 7*2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift1_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
#if 0
        low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
        low1_epi16 = _mm_srai_epi32(low1_epi16, 16);
#else
        low1_epi16 = _mm_and_si128(low1_epi16, mask_epi16);
#endif
        // Shift the second pixel from the second set into the working set
        //shift2_epi16 = _mm_slli_si128(input2_epi16, 6*2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        //shift2_epi16 = _mm_slli_si128(input2_epi16, 5*2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift3_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        //shift2_epi16 = _mm_slli_si128(input2_epi16, 4*2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift4_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        //shift2_epi16 = _mm_slli_si128(input2_epi16, 3*2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift5_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
        sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

        sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

        // Expand the even output points to a full doubleword
        sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
        sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

        // The second eight input points become the current input points
        input1_epi16 = input2_epi16;


        /***** Process the second four output points *****/

        // Initialize the highpass sum
        sum2_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low2_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);
#if 0
        // Expand the lowpass output points to a full doubleword
        low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
        low2_epi16 = _mm_srai_epi32(low2_epi16, 16);
#else
        low2_epi16 = _mm_and_si128(low2_epi16, mask_epi16);
#endif
        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
        sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

        sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


        // Expand the even output points to a full doubleword
        sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
        sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


        /***** Combine the output points *****/

        low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
        sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);

        // Store the four lowpass output points
        _mm_store_si128(lowpass_ptr++, low1_epi16);

        // Get the last highpass coefficient in the group
        sum2_epi16 = _mm_srli_si128(sum1_epi16, 7 * 2);

        // Shift the extra highpass coefficient into the output
        sum1_epi16 = _mm_slli_si128(sum1_epi16, 1 * 2);
        sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

        // Save the last highpass coefficient for the next loop iteration
        highpass_value = _mm_cvtsi128_si32(sum2_epi16);

        // Store the four highpass output points
        _mm_store_si128(highpass_ptr++, sum1_epi16);

        // The second set of eight input pixels becomes the working set
        input1_epi16 = input2_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;

#else
    sum = input[column] + input[column + 1];
    *(lowptr++) = SATURATE(sum);
    *(highptr++) = SATURATE(highpass_value);
    column += 2;
#endif

    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        sum = input[column] + input[column + 1];

        // Store the lowpass sum
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass sum
        sum = 0;
        sum -= input[column - 2];
        sum -= input[column - 1];
        sum += input[column + 2];
        sum += input[column + 3];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum += input[column + 0];
        sum -= input[column + 1];

        // Store the highpass sum
        *(highptr++) = SATURATE(sum);
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    sum = input[column] + input[column + 1];

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    *(highptr++) = SATURATE(sum);
}

#else

// Apply the lowpass and highpass horizontal filters to one row
// Version that replaces shift operations with extract and insert operations
void FilterHorizontalRow16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m128i *input_ptr = (__m128i *)input;
    __m128i *lowpass_ptr;
    __m128i *highpass_ptr;
    __m128i input1_epi16;

    int highpass_value;

    // The highpass filter on the left border uses different coefficients
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    highpass_value = SATURATE(sum);

    // Set the input pointer for the fast loop
    input_ptr = (__m128i *)&input[column];

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowptr;
    highpass_ptr = (__m128i *)highptr;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpass_ptr));
    assert(ISALIGNED16(highpass_ptr));


#if (1 && XMMOPT)
    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m128i input2_epi16;
        __m128i shift2_epi16;
        __m128i mask_epi16;
        __m128i sign_epi16;
        __m128i half_epi16;		// Half of the divisor for rounding
        __m128i sum1_epi16;
        __m128i sum2_epi16;
        __m128i sum1b_epi16;
        __m128i sum2b_epi16;
        __m128i low1_epi16;
        __m128i low2_epi16;


        /***** Process the first four output points *****/

        // Initialize the highpass sum
        sum1_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low1_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 0), 7);

        // Apply the second filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
        low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

        // Shift the second pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 1), 7);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 2), 7);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 3), 7);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 4), 7);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
        sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

        sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

        // Expand the even output points to a full doubleword
        sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
        sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

        // The second eight input points become the current input points
        input1_epi16 = input2_epi16;


        /***** Process the second four output points *****/

        // Initialize the highpass sum
        sum2_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low2_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 0), 7);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
        low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

        // Shift the second pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 1), 7);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 2), 7);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 3), 7);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_insert_epi16(input1_epi16, _mm_extract_epi16(input2_epi16, 4), 7);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
        sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

        sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


        // Expand the even output points to a full doubleword
        sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
        sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


        /***** Combine the output points *****/

        low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
        sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


        // Store the four lowpass output points
        _mm_store_si128(lowpass_ptr++, low1_epi16);

        // Get the last highpass coefficient in the group
        sum2_epi16 = _mm_srli_si128(sum1_epi16, 7 * 2);

        // Shift the extra highpass coefficient into the output
        sum1_epi16 = _mm_slli_si128(sum1_epi16, 1 * 2);
        sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

        // Save the last highpass coefficient for the next loop iteration
        highpass_value = _mm_cvtsi128_si32(sum2_epi16);

        // Store the four highpass output points
        _mm_store_si128(highpass_ptr++, sum1_epi16);

        // The second set of eight input pixels becomes the working set
        input1_epi16 = input2_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;

#else
    sum = input[column] + input[column + 1];
    *(lowptr++) = SATURATE(sum);
    *(highptr++) = SATURATE(highpass_value);
    column += 2;
#endif

    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        sum = input[column] + input[column + 1];

        // Store the lowpass sum
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass sum
        sum = 0;
        sum -= input[column - 2];
        sum -= input[column - 1];
        sum += input[column + 2];
        sum += input[column + 3];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum += input[column + 0];
        sum -= input[column + 1];

        // Store the highpass sum
        *(highptr++) = SATURATE(sum);
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    sum = input[column] + input[column + 1];

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    *(highptr++) = SATURATE(sum);
}

#endif

#endif


// Apply the lowpass and highpass horizontal filters to one row
void FilterHorizontalRowBYR3_16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t g, g2, sumGG, sumRG, sumBG, sumDG;
    PIXEL *lineR, *lineG;
    PIXEL *lineg, *lineB;

    // Start at the left end of the row
    PIXEL *lowptrGG;  //GG =  Green1 + Green2
    PIXEL *highptrGG;
    PIXEL *lowptrRG;  //RG =  Red - GG;
    PIXEL *highptrRG;
    PIXEL *lowptrBG;  //BG =  Blue - GG;
    PIXEL *highptrBG;
    PIXEL *lowptrDG;  //DG (difference G) =  Green1 - Green2
    PIXEL *highptrDG;
    int column = 0;

#if 0
    // This version caused a compiler warning
    __m128i *inputR_ptr = (__m128i *)lineR;
    __m128i *inputG_ptr = (__m128i *)lineG;
    __m128i *inputg_ptr = (__m128i *)lineg;
    __m128i *inputB_ptr = (__m128i *)lineB;
#else
    __m128i *inputR_ptr;
    __m128i *inputG_ptr;
    __m128i *inputg_ptr;
    __m128i *inputB_ptr;
#endif
    __m128i *lowpassGG_ptr;
    __m128i *lowpassRG_ptr;
    __m128i *lowpassBG_ptr;
    __m128i *lowpassDG_ptr;
    __m128i *highpassGG_ptr;
    __m128i *highpassRG_ptr;
    __m128i *highpassBG_ptr;
    __m128i *highpassDG_ptr;
    __m128i inputR_epi16;
    __m128i inputG_epi16;
    __m128i inputg_epi16;
    __m128i inputB_epi16;

    int highpass_valueGG;
    int highpass_valueRG;
    int highpass_valueBG;
    int highpass_valueDG;

    lineR = input;
    lineG = input + (width);
    lineg = input + (width) * 2;
    lineB = input + (width) * 3;
    lowptrGG = lowpass;
    lowptrRG = lowpass + (width >> 1);
    lowptrBG = lowpass + (width >> 1) * 2;
    lowptrDG = lowpass + (width >> 1) * 3;
    highptrGG = highpass;
    highptrRG = highpass + (width >> 1);
    highptrBG = highpass + (width >> 1) * 2;
    highptrDG = highpass + (width >> 1) * 3;

    // The highpass filter on the left border uses different coefficients
    sumGG = sumRG = sumBG = sumDG = 0;

    //sum +=  5 * lineR[column + 0];
    g = (lineG[column + 0] + lineg[column + 0]) >> 1;
    sumGG +=  5 * g;
    sumRG +=  5 * (((lineR[column + 0] - g) >> 1) + 512);
    sumBG +=  5 * (((lineB[column + 0] - g) >> 1) + 512);
    sumDG +=  5 * ((lineG[column + 0] - lineg[column + 0] + 1024) >> 1);

    //sum -= 11 * lineR[column + 1];
    g = (lineG[column + 1] + lineg[column + 1]) >> 1;
    sumGG -=  11 * g;
    sumRG -=  11 * (((lineR[column + 1] - g) >> 1) + 512);
    sumBG -=  11 * (((lineB[column + 1] - g) >> 1) + 512);
    sumDG -=  11 * ((lineG[column + 1] - lineg[column + 1] + 1024) >> 1);

    //sum +=  4 * lineR[column + 2];
    g = (lineG[column + 2] + lineg[column + 2]) >> 1;
    sumGG +=  4 * g;
    sumRG +=  4 * (((lineR[column + 2] - g) >> 1) + 512);
    sumBG +=  4 * (((lineB[column + 2] - g) >> 1) + 512);
    sumDG +=  4 * ((lineG[column + 2] - lineg[column + 2] + 1024) >> 1);

    //sum +=  4 * lineR[column + 3];
    g = (lineG[column + 3] + lineg[column + 3]) >> 1;
    sumGG +=  4 * g;
    sumRG +=  4 * (((lineR[column + 3] - g) >> 1) + 512);
    sumBG +=  4 * (((lineB[column + 3] - g) >> 1) + 512);
    sumDG +=  4 * ((lineG[column + 3] - lineg[column + 3] + 1024) >> 1);

    //sum -=  1 * lineR[column + 4];
    g = (lineG[column + 4] + lineg[column + 4]) >> 1;
    sumGG -=  1 * g;
    sumRG -=  1 * (((lineR[column + 4] - g) >> 1) + 512);
    sumBG -=  1 * (((lineB[column + 4] - g) >> 1) + 512);
    sumDG -=  1 * ((lineG[column + 4] - lineg[column + 4] + 1024) >> 1);

    //sum -=  1 * lineR[column + 5];
    g = (lineG[column + 5] + lineg[column + 5]) >> 1;
    sumGG -=  1 * g;
    sumRG -=  1 * (((lineR[column + 5] - g) >> 1) + 512);
    sumBG -=  1 * (((lineB[column + 5] - g) >> 1) + 512);
    sumDG -=  1 * ((lineG[column + 5] - lineg[column + 5] + 1024) >> 1);

    //sum += ROUNDING(sum,8);
    sumGG += ROUNDING(sumGG, 8);
    sumRG += ROUNDING(sumRG, 8);
    sumBG += ROUNDING(sumBG, 8);
    sumDG += ROUNDING(sumDG, 8);

    //sum = DivideByShift(sum, 3);
    sumGG = DivideByShift(sumGG, 3);
    sumRG = DivideByShift(sumRG, 3);
    sumBG = DivideByShift(sumBG, 3);
    sumDG = DivideByShift(sumDG, 3);

    //highpass_value = SATURATE(sum);
    highpass_valueGG = SATURATE(sumGG);
    highpass_valueRG = SATURATE(sumRG);
    highpass_valueBG = SATURATE(sumBG);
    highpass_valueDG = SATURATE(sumDG);

    // Set the input pointer for the fast loop
    inputR_ptr = (__m128i *)&lineR[column];
    inputG_ptr = (__m128i *)&lineG[column];
    inputg_ptr = (__m128i *)&lineg[column];
    inputB_ptr = (__m128i *)&lineB[column];

    // Initialize the output pointers
    lowpassGG_ptr = (__m128i *)lowptrGG;
    lowpassRG_ptr = (__m128i *)lowptrRG;
    lowpassBG_ptr = (__m128i *)lowptrBG;
    lowpassDG_ptr = (__m128i *)lowptrDG;
    highpassGG_ptr = (__m128i *)highptrGG;
    highpassRG_ptr = (__m128i *)highptrRG;
    highpassBG_ptr = (__m128i *)highptrBG;
    highpassDG_ptr = (__m128i *)highptrDG;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpassGG_ptr));
    assert(ISALIGNED16(lowpassRG_ptr));
    assert(ISALIGNED16(lowpassBG_ptr));
    assert(ISALIGNED16(lowpassDG_ptr));
    assert(ISALIGNED16(highpassGG_ptr));
    assert(ISALIGNED16(highpassRG_ptr));
    assert(ISALIGNED16(highpassBG_ptr));
    assert(ISALIGNED16(highpassDG_ptr));

#if 1
    {
        __m128i GG1_epi16;
        __m128i RG1_epi16;
        __m128i BG1_epi16;
        __m128i DG1_epi16;

        const __m128i rounding_epi16 = _mm_set1_epi16(512);


        // Preload the first set of four pixels for fast processing
        inputR_epi16 = _mm_load_si128(inputR_ptr++);
        inputG_epi16 = _mm_load_si128(inputG_ptr++);
        inputg_epi16 = _mm_load_si128(inputg_ptr++);
        inputB_epi16 = _mm_load_si128(inputB_ptr++);


        GG1_epi16 = _mm_adds_epi16(inputG_epi16, inputg_epi16);
        GG1_epi16 = _mm_srai_epi16(GG1_epi16, 1);

        RG1_epi16 = _mm_subs_epi16(inputR_epi16, GG1_epi16);
        RG1_epi16 = _mm_srai_epi16(RG1_epi16, 1);
        RG1_epi16 = _mm_adds_epi16(RG1_epi16, rounding_epi16);

        BG1_epi16 = _mm_subs_epi16(inputB_epi16, GG1_epi16);
        BG1_epi16 = _mm_srai_epi16(BG1_epi16, 1);
        BG1_epi16 = _mm_adds_epi16(BG1_epi16, rounding_epi16);

        DG1_epi16 = _mm_subs_epi16(inputG_epi16, inputg_epi16);
        DG1_epi16 = _mm_adds_epi16(DG1_epi16, rounding_epi16);
        DG1_epi16 = _mm_adds_epi16(DG1_epi16, rounding_epi16);
        DG1_epi16 = _mm_srai_epi16(DG1_epi16, 1);


        // Process two sets of four input pixels to get one set of four output pixels
        for (; column < post_column; column += column_step)
        {
            __m128i shiftGG_epi16;
            __m128i shiftRG_epi16;
            __m128i shiftBG_epi16;
            __m128i shiftDG_epi16;
            __m128i half_epi16;		// Half of the divisor for rounding
            __m128i sumGG1_epi16;
            __m128i sumRG1_epi16;
            __m128i sumBG1_epi16;
            __m128i sumDG1_epi16;
            __m128i sumGG2_epi16;
            __m128i sumRG2_epi16;
            __m128i sumBG2_epi16;
            __m128i sumDG2_epi16;
            __m128i lowGG1_epi16;
            __m128i lowRG1_epi16;
            __m128i lowBG1_epi16;
            __m128i lowDG1_epi16;
            __m128i lowGG2_epi16;
            __m128i lowRG2_epi16;
            __m128i lowBG2_epi16;
            __m128i lowDG2_epi16;

            __m128i sumGG1b_epi16;
            __m128i sumRG1b_epi16;
            __m128i sumBG1b_epi16;
            __m128i sumDG1b_epi16;
            __m128i sumGG2b_epi16;
            __m128i sumRG2b_epi16;
            __m128i sumBG2b_epi16;
            __m128i sumDG2b_epi16;

            __m128i GG2_epi16;
            __m128i RG2_epi16;
            __m128i BG2_epi16;
            __m128i DG2_epi16;


            /***** Process the first four output points *****/

            // Initialize the highpass sum
            sumGG1_epi16 = _mm_setzero_si128();
            sumRG1_epi16 = _mm_setzero_si128();
            sumBG1_epi16 = _mm_setzero_si128();
            sumDG1_epi16 = _mm_setzero_si128();

            // Apply the first filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
            sumRG1_epi16 = _mm_subs_epi16(sumRG1_epi16, RG1_epi16);
            sumBG1_epi16 = _mm_subs_epi16(sumBG1_epi16, BG1_epi16);
            sumDG1_epi16 = _mm_subs_epi16(sumDG1_epi16, DG1_epi16);

            // Check that the pointer to the next group of pixels is properly aligned
            assert(ISALIGNED16(inputR_ptr));
            assert(ISALIGNED16(inputG_ptr));
            assert(ISALIGNED16(inputg_ptr));
            assert(ISALIGNED16(inputB_ptr));

            // Load the next eight pixels
            inputR_epi16 = _mm_load_si128(inputR_ptr++);
            inputG_epi16 = _mm_load_si128(inputG_ptr++);
            inputg_epi16 = _mm_load_si128(inputg_ptr++);
            inputB_epi16 = _mm_load_si128(inputB_ptr++);

            GG2_epi16 = _mm_adds_epi16(inputG_epi16, inputg_epi16);
            GG2_epi16 = _mm_srai_epi16(GG2_epi16, 1);

            RG2_epi16 = _mm_subs_epi16(inputR_epi16, GG2_epi16);
            RG2_epi16 = _mm_srai_epi16(RG2_epi16, 1);
            RG2_epi16 = _mm_adds_epi16(RG2_epi16, rounding_epi16);

            BG2_epi16 = _mm_subs_epi16(inputB_epi16, GG2_epi16);
            BG2_epi16 = _mm_srai_epi16(BG2_epi16, 1);
            BG2_epi16 = _mm_adds_epi16(BG2_epi16, rounding_epi16);

            DG2_epi16 = _mm_subs_epi16(inputG_epi16, inputg_epi16);
            DG2_epi16 = _mm_adds_epi16(DG2_epi16, rounding_epi16);
            DG2_epi16 = _mm_adds_epi16(DG2_epi16, rounding_epi16);
            DG2_epi16 = _mm_srai_epi16(DG2_epi16, 1);


            // Initialize the lowpass sum
            lowGG1_epi16 = GG1_epi16;
            lowRG1_epi16 = RG1_epi16;
            lowBG1_epi16 = BG1_epi16;
            lowDG1_epi16 = DG1_epi16;

            // Shift the first pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 7 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 7 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 7 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the second filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
            sumRG1_epi16 = _mm_subs_epi16(sumRG1_epi16, RG1_epi16);
            sumBG1_epi16 = _mm_subs_epi16(sumBG1_epi16, BG1_epi16);
            sumDG1_epi16 = _mm_subs_epi16(sumDG1_epi16, DG1_epi16);

            // Add adjacent points to compute the lowpass sum
            lowGG1_epi16 = _mm_adds_epi16(lowGG1_epi16, GG1_epi16);
            lowRG1_epi16 = _mm_adds_epi16(lowRG1_epi16, RG1_epi16);
            lowBG1_epi16 = _mm_adds_epi16(lowBG1_epi16, BG1_epi16);
            lowDG1_epi16 = _mm_adds_epi16(lowDG1_epi16, DG1_epi16);

            // Expand the lowpass output points to a full doubleword
            lowGG1_epi16 = _mm_slli_epi32(lowGG1_epi16, 16);
            lowRG1_epi16 = _mm_slli_epi32(lowRG1_epi16, 16);
            lowBG1_epi16 = _mm_slli_epi32(lowBG1_epi16, 16);
            lowDG1_epi16 = _mm_slli_epi32(lowDG1_epi16, 16);
            lowGG1_epi16 = _mm_srai_epi32(lowGG1_epi16, 16);
            lowRG1_epi16 = _mm_srai_epi32(lowRG1_epi16, 16);
            lowBG1_epi16 = _mm_srai_epi32(lowBG1_epi16, 16);
            lowDG1_epi16 = _mm_srai_epi32(lowDG1_epi16, 16);

            // Shift the second pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 6 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 6 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 6 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the third filter coefficient to each pixel and sum the result
            sumGG1b_epi16 = GG1_epi16;
            sumRG1b_epi16 = RG1_epi16;
            sumBG1b_epi16 = BG1_epi16;
            sumDG1b_epi16 = DG1_epi16;

            // Shift the third pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 5 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 5 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 5 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the fourth filter coefficient to each pixel and sum the result
            sumGG1b_epi16 = _mm_subs_epi16(sumGG1b_epi16, GG1_epi16);
            sumRG1b_epi16 = _mm_subs_epi16(sumRG1b_epi16, RG1_epi16);
            sumBG1b_epi16 = _mm_subs_epi16(sumBG1b_epi16, BG1_epi16);
            sumDG1b_epi16 = _mm_subs_epi16(sumDG1b_epi16, DG1_epi16);

            // Shift the fourth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 4 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 4 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 4 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the fifth filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
            sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, RG1_epi16);
            sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, BG1_epi16);
            sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, DG1_epi16);

            // Shift the fifth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 3 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 3 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 3 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the sixth (last) filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
            sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, RG1_epi16);
            sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, BG1_epi16);
            sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, DG1_epi16);

            //DAN20050915 -- reversibility
            half_epi16 = _mm_set1_epi16(4);
            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, half_epi16);
            sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, half_epi16);
            sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, half_epi16);
            sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, half_epi16);
            sumGG1_epi16 = _mm_srai_epi16(sumGG1_epi16, 3);
            sumRG1_epi16 = _mm_srai_epi16(sumRG1_epi16, 3);
            sumBG1_epi16 = _mm_srai_epi16(sumBG1_epi16, 3);
            sumDG1_epi16 = _mm_srai_epi16(sumDG1_epi16, 3);

            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, sumGG1b_epi16);
            sumRG1_epi16 = _mm_adds_epi16(sumRG1_epi16, sumRG1b_epi16);
            sumBG1_epi16 = _mm_adds_epi16(sumBG1_epi16, sumBG1b_epi16);
            sumDG1_epi16 = _mm_adds_epi16(sumDG1_epi16, sumDG1b_epi16);

            // Expand the even output points to a full doubleword
            sumGG1_epi16 = _mm_slli_epi32(sumGG1_epi16, 16);
            sumRG1_epi16 = _mm_slli_epi32(sumRG1_epi16, 16);
            sumBG1_epi16 = _mm_slli_epi32(sumBG1_epi16, 16);
            sumDG1_epi16 = _mm_slli_epi32(sumDG1_epi16, 16);
            sumGG1_epi16 = _mm_srai_epi32(sumGG1_epi16, 16);
            sumRG1_epi16 = _mm_srai_epi32(sumRG1_epi16, 16);
            sumBG1_epi16 = _mm_srai_epi32(sumBG1_epi16, 16);
            sumDG1_epi16 = _mm_srai_epi32(sumDG1_epi16, 16);

            // The second eight input points become the current input points
            GG1_epi16 = GG2_epi16;
            RG1_epi16 = RG2_epi16;
            BG1_epi16 = BG2_epi16;
            DG1_epi16 = DG2_epi16;


            /***** Process the second four output points *****/

            // Initialize the highpass sum
            sumGG2_epi16 = _mm_setzero_si128();
            sumRG2_epi16 = _mm_setzero_si128();
            sumBG2_epi16 = _mm_setzero_si128();
            sumDG2_epi16 = _mm_setzero_si128();

            // Apply the first filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
            sumRG2_epi16 = _mm_subs_epi16(sumRG2_epi16, RG1_epi16);
            sumBG2_epi16 = _mm_subs_epi16(sumBG2_epi16, BG1_epi16);
            sumDG2_epi16 = _mm_subs_epi16(sumDG2_epi16, DG1_epi16);

            // Check that the pointer to the next group of pixels is properly aligned
            assert(ISALIGNED16(inputR_ptr));
            assert(ISALIGNED16(inputG_ptr));
            assert(ISALIGNED16(inputg_ptr));
            assert(ISALIGNED16(inputB_ptr));

            // Load the next eight pixels
            inputR_epi16 = _mm_load_si128(inputR_ptr++);
            inputG_epi16 = _mm_load_si128(inputG_ptr++);
            inputg_epi16 = _mm_load_si128(inputg_ptr++);
            inputB_epi16 = _mm_load_si128(inputB_ptr++);

            GG2_epi16 = _mm_adds_epi16(inputG_epi16, inputg_epi16);
            GG2_epi16 = _mm_srai_epi16(GG2_epi16, 1);

            RG2_epi16 = _mm_subs_epi16(inputR_epi16, GG2_epi16);
            RG2_epi16 = _mm_srai_epi16(RG2_epi16, 1);
            RG2_epi16 = _mm_adds_epi16(RG2_epi16, rounding_epi16);

            BG2_epi16 = _mm_subs_epi16(inputB_epi16, GG2_epi16);
            BG2_epi16 = _mm_srai_epi16(BG2_epi16, 1);
            BG2_epi16 = _mm_adds_epi16(BG2_epi16, rounding_epi16);

            DG2_epi16 = _mm_subs_epi16(inputG_epi16, inputg_epi16);
            DG2_epi16 = _mm_adds_epi16(DG2_epi16, rounding_epi16);
            DG2_epi16 = _mm_adds_epi16(DG2_epi16, rounding_epi16);
            DG2_epi16 = _mm_srai_epi16(DG2_epi16, 1);



            // Initialize the lowpass sum
            lowGG2_epi16 = GG1_epi16;
            lowRG2_epi16 = RG1_epi16;
            lowBG2_epi16 = BG1_epi16;
            lowDG2_epi16 = DG1_epi16;

            // Shift the first pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 7 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 7 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 7 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the second filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
            sumRG2_epi16 = _mm_subs_epi16(sumRG2_epi16, RG1_epi16);
            sumBG2_epi16 = _mm_subs_epi16(sumBG2_epi16, BG1_epi16);
            sumDG2_epi16 = _mm_subs_epi16(sumDG2_epi16, DG1_epi16);

            // Add adjacent points to compute the lowpass sum
            lowGG2_epi16 = _mm_adds_epi16(lowGG2_epi16, GG1_epi16);
            lowRG2_epi16 = _mm_adds_epi16(lowRG2_epi16, RG1_epi16);
            lowBG2_epi16 = _mm_adds_epi16(lowBG2_epi16, BG1_epi16);
            lowDG2_epi16 = _mm_adds_epi16(lowDG2_epi16, DG1_epi16);

            // Expand the lowpass output points to a full doubleword
            lowGG2_epi16 = _mm_slli_epi32(lowGG2_epi16, 16);
            lowRG2_epi16 = _mm_slli_epi32(lowRG2_epi16, 16);
            lowBG2_epi16 = _mm_slli_epi32(lowBG2_epi16, 16);
            lowDG2_epi16 = _mm_slli_epi32(lowDG2_epi16, 16);
            lowGG2_epi16 = _mm_srai_epi32(lowGG2_epi16, 16);
            lowRG2_epi16 = _mm_srai_epi32(lowRG2_epi16, 16);
            lowBG2_epi16 = _mm_srai_epi32(lowBG2_epi16, 16);
            lowDG2_epi16 = _mm_srai_epi32(lowDG2_epi16, 16);

            // Shift the second pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 6 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 6 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 6 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the third filter coefficient to each pixel and sum the result
            sumGG2b_epi16 = GG1_epi16;
            sumRG2b_epi16 = RG1_epi16;
            sumBG2b_epi16 = BG1_epi16;
            sumDG2b_epi16 = DG1_epi16;

            // Shift the third pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 5 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 5 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 5 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the fourth filter coefficient to each pixel and sum the result
            sumGG2b_epi16 = _mm_subs_epi16(sumGG2b_epi16, GG1_epi16);
            sumRG2b_epi16 = _mm_subs_epi16(sumRG2b_epi16, RG1_epi16);
            sumBG2b_epi16 = _mm_subs_epi16(sumBG2b_epi16, BG1_epi16);
            sumDG2b_epi16 = _mm_subs_epi16(sumDG2b_epi16, DG1_epi16);

            // Shift the fourth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 4 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 4 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 4 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the fifth filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
            sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, RG1_epi16);
            sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, BG1_epi16);
            sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, DG1_epi16);

            // Shift the fifth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3 * 2);
            shiftRG_epi16 = _mm_slli_si128(RG2_epi16, 3 * 2);
            shiftBG_epi16 = _mm_slli_si128(BG2_epi16, 3 * 2);
            shiftDG_epi16 = _mm_slli_si128(DG2_epi16, 3 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RG1_epi16 = _mm_srli_si128(RG1_epi16, 1 * 2);
            BG1_epi16 = _mm_srli_si128(BG1_epi16, 1 * 2);
            DG1_epi16 = _mm_srli_si128(DG1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RG1_epi16 = _mm_or_si128(RG1_epi16, shiftRG_epi16);
            BG1_epi16 = _mm_or_si128(BG1_epi16, shiftBG_epi16);
            DG1_epi16 = _mm_or_si128(DG1_epi16, shiftDG_epi16);

            // Apply the sixth (last) filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
            sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, RG1_epi16);
            sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, BG1_epi16);
            sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, DG1_epi16);


            //DAN20050915 -- reversibility
            half_epi16 = _mm_set1_epi16(4);
            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, half_epi16);
            sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, half_epi16);
            sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, half_epi16);
            sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, half_epi16);
            sumGG2_epi16 = _mm_srai_epi16(sumGG2_epi16, 3);
            sumRG2_epi16 = _mm_srai_epi16(sumRG2_epi16, 3);
            sumBG2_epi16 = _mm_srai_epi16(sumBG2_epi16, 3);
            sumDG2_epi16 = _mm_srai_epi16(sumDG2_epi16, 3);

            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, sumGG2b_epi16);
            sumRG2_epi16 = _mm_adds_epi16(sumRG2_epi16, sumRG2b_epi16);
            sumBG2_epi16 = _mm_adds_epi16(sumBG2_epi16, sumBG2b_epi16);
            sumDG2_epi16 = _mm_adds_epi16(sumDG2_epi16, sumDG2b_epi16);


            // Expand the even output points to a full doubleword
            sumGG2_epi16 = _mm_slli_epi32(sumGG2_epi16, 16);
            sumRG2_epi16 = _mm_slli_epi32(sumRG2_epi16, 16);
            sumBG2_epi16 = _mm_slli_epi32(sumBG2_epi16, 16);
            sumDG2_epi16 = _mm_slli_epi32(sumDG2_epi16, 16);
            sumGG2_epi16 = _mm_srai_epi32(sumGG2_epi16, 16);
            sumRG2_epi16 = _mm_srai_epi32(sumRG2_epi16, 16);
            sumBG2_epi16 = _mm_srai_epi32(sumBG2_epi16, 16);
            sumDG2_epi16 = _mm_srai_epi32(sumDG2_epi16, 16);


            /***** Combine the output points *****/

            lowGG1_epi16 = _mm_packs_epi32(lowGG1_epi16, lowGG2_epi16);
            lowRG1_epi16 = _mm_packs_epi32(lowRG1_epi16, lowRG2_epi16);
            lowBG1_epi16 = _mm_packs_epi32(lowBG1_epi16, lowBG2_epi16);
            lowDG1_epi16 = _mm_packs_epi32(lowDG1_epi16, lowDG2_epi16);
            sumGG1_epi16 = _mm_packs_epi32(sumGG1_epi16, sumGG2_epi16);
            sumRG1_epi16 = _mm_packs_epi32(sumRG1_epi16, sumRG2_epi16);
            sumBG1_epi16 = _mm_packs_epi32(sumBG1_epi16, sumBG2_epi16);
            sumDG1_epi16 = _mm_packs_epi32(sumDG1_epi16, sumDG2_epi16);


            // Store the four lowpass output points
            _mm_store_si128(lowpassGG_ptr++, lowGG1_epi16);
            _mm_store_si128(lowpassRG_ptr++, lowRG1_epi16);
            _mm_store_si128(lowpassBG_ptr++, lowBG1_epi16);
            _mm_store_si128(lowpassDG_ptr++, lowDG1_epi16);

            // Get the last highpass coefficient in the group
            sumGG2_epi16 = _mm_srli_si128(sumGG1_epi16, 7 * 2);
            sumRG2_epi16 = _mm_srli_si128(sumRG1_epi16, 7 * 2);
            sumBG2_epi16 = _mm_srli_si128(sumBG1_epi16, 7 * 2);
            sumDG2_epi16 = _mm_srli_si128(sumDG1_epi16, 7 * 2);

            // Shift the extra highpass coefficient into the output
            sumGG1_epi16 = _mm_slli_si128(sumGG1_epi16, 1 * 2);
            sumRG1_epi16 = _mm_slli_si128(sumRG1_epi16, 1 * 2);
            sumBG1_epi16 = _mm_slli_si128(sumBG1_epi16, 1 * 2);
            sumDG1_epi16 = _mm_slli_si128(sumDG1_epi16, 1 * 2);
            sumGG1_epi16 = _mm_insert_epi16(sumGG1_epi16, highpass_valueGG, 0);
            sumRG1_epi16 = _mm_insert_epi16(sumRG1_epi16, highpass_valueRG, 0);
            sumBG1_epi16 = _mm_insert_epi16(sumBG1_epi16, highpass_valueBG, 0);
            sumDG1_epi16 = _mm_insert_epi16(sumDG1_epi16, highpass_valueDG, 0);

            // Save the last highpass coefficient for the next loop iteration
            highpass_valueGG = _mm_cvtsi128_si32(sumGG2_epi16);
            highpass_valueRG = _mm_cvtsi128_si32(sumRG2_epi16);
            highpass_valueBG = _mm_cvtsi128_si32(sumBG2_epi16);
            highpass_valueDG = _mm_cvtsi128_si32(sumDG2_epi16);

            // Store the four highpass output points
            _mm_store_si128(highpassGG_ptr++, sumGG1_epi16);
            _mm_store_si128(highpassRG_ptr++, sumRG1_epi16);
            _mm_store_si128(highpassBG_ptr++, sumBG1_epi16);
            _mm_store_si128(highpassDG_ptr++, sumDG1_epi16);

            // The second set of eight input pixels becomes the working set
            GG1_epi16 = GG2_epi16;
            RG1_epi16 = RG2_epi16;
            BG1_epi16 = BG2_epi16;
            DG1_epi16 = DG2_epi16;
        }
    }
    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptrGG = (PIXEL *)lowpassGG_ptr;
    lowptrRG = (PIXEL *)lowpassRG_ptr;
    lowptrBG = (PIXEL *)lowpassBG_ptr;
    lowptrDG = (PIXEL *)lowpassDG_ptr;
    highptrGG = (PIXEL *)highpassGG_ptr;
    highptrRG = (PIXEL *)highpassRG_ptr;
    highptrBG = (PIXEL *)highpassBG_ptr;
    highptrDG = (PIXEL *)highpassDG_ptr;

#endif
    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        //sum = input[column] + input[column + 1];
        g = (lineG[column + 0] + lineg[column + 0]) >> 1;
        g2 = (lineG[column + 1] + lineg[column + 1]) >> 1;
        sumGG = g + g2;
        sumRG = (((lineR[column + 0] - g) >> 1) + 512) + (((lineR[column + 1] - g2) >> 1) + 512);
        sumBG = (((lineB[column + 0] - g) >> 1) + 512) + (((lineB[column + 1] - g2) >> 1) + 512);
        sumDG = ((lineG[column + 0] - lineg[column + 0] + 1024) >> 1) + ((lineG[column + 1] - lineg[column + 1] + 1024) >> 1);

        // Store the lowpass sum
        *(lowptrGG++) = SATURATE(sumGG);
        *(lowptrRG++) = SATURATE(sumRG);
        *(lowptrBG++) = SATURATE(sumBG);
        *(lowptrDG++) = SATURATE(sumDG);

        // Compute the highpass sum
        //sum = 0;
        sumGG = sumRG = sumBG = sumDG = 0;

        //sum -= input[column - 2];
        g = (lineG[column - 2] + lineg[column - 2]) >> 1;
        sumGG -= g;
        sumRG -= (((lineR[column - 2] - g) >> 1) + 512);
        sumBG -= (((lineB[column - 2] - g) >> 1) + 512);
        sumDG -= ((lineG[column - 2] - lineg[column - 2] + 1024) >> 1);

        //sum -= input[column - 1];
        g = (lineG[column - 1] + lineg[column - 1]) >> 1;
        sumGG -= g;
        sumRG -= (((lineR[column - 1] - g) >> 1) + 512);
        sumBG -= (((lineB[column - 1] - g) >> 1) + 512);
        sumDG -= ((lineG[column - 1] - lineg[column - 1] + 1024) >> 1);

        //sum += input[column + 2];
        g = (lineG[column + 2] + lineg[column + 2]) >> 1;
        sumGG += g;
        sumRG += (((lineR[column + 2] - g) >> 1) + 512);
        sumBG += (((lineB[column + 2] - g) >> 1) + 512);
        sumDG += ((lineG[column + 2] - lineg[column + 2] + 1024) >> 1);

        //sum += input[column + 3];
        g = (lineG[column + 3] + lineg[column + 3]) >> 1;
        sumGG += g;
        sumRG += (((lineR[column + 3] - g) >> 1) + 512);
        sumBG += (((lineB[column + 3] - g) >> 1) + 512);
        sumDG += ((lineG[column + 3] - lineg[column + 3] + 1024) >> 1);

        //sum += ROUNDING(sum,8);
        sumGG += ROUNDING(sumGG, 8);
        sumRG += ROUNDING(sumRG, 8);
        sumBG += ROUNDING(sumBG, 8);
        sumDG += ROUNDING(sumDG, 8);

        //sum = DivideByShift(sum, 3);
        sumGG = DivideByShift(sumGG, 3);
        sumRG = DivideByShift(sumRG, 3);
        sumBG = DivideByShift(sumBG, 3);
        sumDG = DivideByShift(sumDG, 3);

        //sum += input[column + 0];
        g = (lineG[column + 0] + lineg[column + 0]) >> 1;
        sumGG += g;
        sumRG += (((lineR[column + 0] - g) >> 1) + 512);
        sumBG += (((lineB[column + 0] - g) >> 1) + 512);
        sumDG += ((lineG[column + 0] - lineg[column + 0] + 1024) >> 1);

        //sum -= input[column + 1];
        g = (lineG[column + 1] + lineg[column + 1]) >> 1;
        sumGG -= g;
        sumRG -= (((lineR[column + 1] - g) >> 1) + 512);
        sumBG -= (((lineB[column + 1] - g) >> 1) + 512);
        sumDG -= ((lineG[column + 1] - lineg[column + 1] + 1024) >> 1);

        // Store the highpass sum
        //*(highptr++) = SATURATE(sum);
        *(highptrGG++) = SATURATE(sumGG);
        *(highptrRG++) = SATURATE(sumRG);
        *(highptrBG++) = SATURATE(sumBG);
        *(highptrDG++) = SATURATE(sumDG);
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    //sum = input[column] + input[column + 1];
    g = (lineG[column + 0] + lineg[column + 0]) >> 1;
    g2 = (lineG[column + 1] + lineg[column + 1]) >> 1;
    sumGG = g + g2;
    sumRG = (((lineR[column + 0] - g) >> 1) + 512) + (((lineR[column + 1] - g2) >> 1) + 512);
    sumBG = (((lineB[column + 0] - g) >> 1) + 512) + (((lineB[column + 1] - g2) >> 1) + 512);
    sumDG = ((lineG[column + 0] - lineg[column + 0] + 1024) >> 1) + ((lineG[column + 1] - lineg[column + 1] + 1024) >> 1);

    // Store the lowpass sum
    *(lowptrGG++) = SATURATE(sumGG);
    *(lowptrRG++) = SATURATE(sumRG);
    *(lowptrBG++) = SATURATE(sumBG);
    *(lowptrDG++) = SATURATE(sumDG);

    // Compute the last highpass value using the special border coefficients
    //sum = 0;
    sumGG = sumRG = sumBG = sumDG = 0;

    //sum += 11 * input[column + 0];
    g = (lineG[column + 0] + lineg[column + 0]) >> 1;
    sumGG += 11 * g;
    sumRG += 11 * (((lineR[column + 0] - g) >> 1) + 512);
    sumBG += 11 * (((lineB[column + 0] - g) >> 1) + 512);
    sumDG += 11 * ((lineG[column + 0] - lineg[column + 0] + 1024) >> 1);

    //sum -=  5 * input[column + 1];
    g = (lineG[column + 1] + lineg[column + 1]) >> 1;
    sumGG -= 5 * g;
    sumRG -= 5 * (((lineR[column + 1] - g) >> 1) + 512);
    sumBG -= 5 * (((lineB[column + 1] - g) >> 1) + 512);
    sumDG -= 5 * ((lineG[column + 1] - lineg[column + 1] + 1024) >> 1);

    //sum -=  4 * input[column - 1];
    g = (lineG[column - 1] + lineg[column - 1]) >> 1;
    sumGG -= 4 * g;
    sumRG -= 4 * (((lineR[column - 1] - g) >> 1) + 512);
    sumBG -= 4 * (((lineB[column - 1] - g) >> 1) + 512);
    sumDG -= 4 * ((lineG[column - 1] - lineg[column - 1] + 1024) >> 1);

    //sum -=  4 * input[column - 2];
    g = (lineG[column - 2] + lineg[column - 2]) >> 1;
    sumGG -= 4 * g;
    sumRG -= 4 * (((lineR[column - 2] - g) >> 1) + 512);
    sumBG -= 4 * (((lineB[column - 2] - g) >> 1) + 512);
    sumDG -= 4 * ((lineG[column - 2] - lineg[column - 2] + 1024) >> 1);

    //sum +=  1 * input[column - 3];
    g = (lineG[column - 3] + lineg[column - 3]) >> 1;
    sumGG += 1 * g;
    sumRG += 1 * (((lineR[column - 3] - g) >> 1) + 512);
    sumBG += 1 * (((lineB[column - 3] - g) >> 1) + 512);
    sumDG += 1 * ((lineG[column - 3] - lineg[column - 3] + 1024) >> 1);

    //sum +=  1 * input[column - 4];
    g = (lineG[column - 4] + lineg[column - 4]) >> 1;
    sumGG += 1 * g;
    sumRG += 1 * (((lineR[column - 4] - g) >> 1) + 512);
    sumBG += 1 * (((lineB[column - 4] - g) >> 1) + 512);
    sumDG += 1 * ((lineG[column - 4] - lineg[column - 4] + 1024) >> 1);

    //sum +=  ROUNDING(sum,8);
    sumGG += ROUNDING(sumGG, 8);
    sumRG += ROUNDING(sumRG, 8);
    sumBG += ROUNDING(sumBG, 8);
    sumDG += ROUNDING(sumDG, 8);

    //sum = DivideByShift(sum, 3);
    sumGG = DivideByShift(sumGG, 3);
    sumRG = DivideByShift(sumRG, 3);
    sumBG = DivideByShift(sumBG, 3);
    sumDG = DivideByShift(sumDG, 3);

    //*(highptr++) = SATURATE(sum);
    *(highptrGG++) = SATURATE(sumGG);
    *(highptrRG++) = SATURATE(sumRG);
    *(highptrBG++) = SATURATE(sumBG);
    *(highptrDG++) = SATURATE(sumDG);
}




// Apply the lowpass and highpass horizontal filters to one row
void FilterHorizontalRowRGB30_16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width, int precision, int format)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sumGG, sumRR, sumBB;
    unsigned int *pixelptr = (unsigned int *)input;
    int shift = precision - 10;

    // Start at the left end of the row
    PIXEL *lowptrGG;
    PIXEL *highptrGG;
    PIXEL *lowptrRR;
    PIXEL *highptrRR;
    PIXEL *lowptrBB;
    PIXEL *highptrBB;
    int column = 0;

    __m128i *inputRGB_ptr;
    __m128i *lowpassGG_ptr;
    __m128i *lowpassRR_ptr;
    __m128i *lowpassBB_ptr;
    __m128i *highpassGG_ptr;
    __m128i *highpassRR_ptr;
    __m128i *highpassBB_ptr;

    int highpass_valueGG;
    int highpass_valueRR;
    int highpass_valueBB;

    lowptrGG = lowpass;
    lowptrRR = lowpass + (width >> 1);
    lowptrBB = lowpass + (width >> 1) * 2;
    highptrGG = highpass;
    highptrRR = highpass + (width >> 1);
    highptrBB = highpass + (width >> 1) * 2;

    // The highpass filter on the left border uses different coefficients
    sumGG = sumRR = sumBB = 0;

    switch (format)
    {
        case DECODED_FORMAT_AB10:
        case DECODED_FORMAT_RG30:
            //sum +=  5 * lineR[column + 0];
            sumRR +=  5 * ((pixelptr[column + 0]) & 0x3ff);
            sumGG +=  5 * ((pixelptr[column + 0] >> 10) & 0x3ff);
            sumBB +=  5 * ((pixelptr[column + 0] >> 20) & 0x3ff);

            //sum -= 11 * lineR[column + 1];
            sumRR -=  11 * ((pixelptr[column + 1]) & 0x3ff);
            sumGG -=  11 * ((pixelptr[column + 1] >> 10) & 0x3ff);
            sumBB -=  11 * ((pixelptr[column + 1] >> 20) & 0x3ff);

            //sum +=  4 * lineR[column + 2];
            sumRR +=  4 * ((pixelptr[column + 2]) & 0x3ff);
            sumGG +=  4 * ((pixelptr[column + 2] >> 10) & 0x3ff);
            sumBB +=  4 * ((pixelptr[column + 2] >> 20) & 0x3ff);

            //sum +=  4 * lineR[column + 3];
            sumRR +=  4 * ((pixelptr[column + 3]) & 0x3ff);
            sumGG +=  4 * ((pixelptr[column + 3] >> 10) & 0x3ff);
            sumBB +=  4 * ((pixelptr[column + 3] >> 20) & 0x3ff);

            //sum -=  1 * lineR[column + 4];
            sumRR -=  1 * ((pixelptr[column + 4]) & 0x3ff);
            sumGG -=  1 * ((pixelptr[column + 4] >> 10) & 0x3ff);
            sumBB -=  1 * ((pixelptr[column + 4] >> 20) & 0x3ff);

            //sum -=  1 * lineR[column + 5];
            sumRR -=  1 * ((pixelptr[column + 5]) & 0x3ff);
            sumGG -=  1 * ((pixelptr[column + 5] >> 10) & 0x3ff);
            sumBB -=  1 * ((pixelptr[column + 5] >> 20) & 0x3ff);
            break;

        case DECODED_FORMAT_AR10:
            //sum +=  5 * lineR[column + 0];
            sumRR +=  5 * ((pixelptr[column + 0] >> 20) & 0x3ff);
            sumGG +=  5 * ((pixelptr[column + 0] >> 10) & 0x3ff);
            sumBB +=  5 * ((pixelptr[column + 0]) & 0x3ff);

            //sum -= 11 * lineR[column + 1];
            sumRR -=  11 * ((pixelptr[column + 1] >> 20) & 0x3ff);
            sumGG -=  11 * ((pixelptr[column + 1] >> 10) & 0x3ff);
            sumBB -=  11 * ((pixelptr[column + 1]) & 0x3ff);

            //sum +=  4 * lineR[column + 2];
            sumRR +=  4 * ((pixelptr[column + 2] >> 20) & 0x3ff);
            sumGG +=  4 * ((pixelptr[column + 2] >> 10) & 0x3ff);
            sumBB +=  4 * ((pixelptr[column + 2]) & 0x3ff);

            //sum +=  4 * lineR[column + 3];
            sumRR +=  4 * ((pixelptr[column + 3] >> 20) & 0x3ff);
            sumGG +=  4 * ((pixelptr[column + 3] >> 10) & 0x3ff);
            sumBB +=  4 * ((pixelptr[column + 3]) & 0x3ff);

            //sum -=  1 * lineR[column + 4];
            sumRR -=  1 * ((pixelptr[column + 4] >> 20) & 0x3ff);
            sumGG -=  1 * ((pixelptr[column + 4] >> 10) & 0x3ff);
            sumBB -=  1 * ((pixelptr[column + 4]) & 0x3ff);

            //sum -=  1 * lineR[column + 5];
            sumRR -=  1 * ((pixelptr[column + 5] >> 20) & 0x3ff);
            sumGG -=  1 * ((pixelptr[column + 5] >> 10) & 0x3ff);
            sumBB -=  1 * ((pixelptr[column + 5]) & 0x3ff);
            break;

        case DECODED_FORMAT_R210:
        {
            unsigned int swap = _bswap(pixelptr[column + 0]);
            //sum +=  5 * lineR[column + 0];
            sumRR +=  5 * ((swap >> 20) & 0x3ff);
            sumGG +=  5 * ((swap >> 10) & 0x3ff);
            sumBB +=  5 * ((swap >> 0) & 0x3ff);

            swap = _bswap(pixelptr[column + 1]);
            //sum -= 11 * lineR[column + 1];
            sumRR -=  11 * ((swap >> 20) & 0x3ff);
            sumGG -=  11 * ((swap >> 10) & 0x3ff);
            sumBB -=  11 * ((swap >> 0)  & 0x3ff);

            swap = _bswap(pixelptr[column + 2]);
            //sum +=  4 * lineR[column + 2];
            sumRR +=  4 * ((swap >> 20) & 0x3ff);
            sumGG +=  4 * ((swap >> 10) & 0x3ff);
            sumBB +=  4 * ((swap >> 0)  & 0x3ff);

            swap = _bswap(pixelptr[column + 3]);
            //sum +=  4 * lineR[column + 3];
            sumRR +=  4 * ((swap >> 20) & 0x3ff);
            sumGG +=  4 * ((swap >> 10) & 0x3ff);
            sumBB +=  4 * ((swap >> 0)  & 0x3ff);

            swap = _bswap(pixelptr[column + 4]);
            //sum -=  1 * lineR[column + 4];
            sumRR -=  1 * ((swap >> 20) & 0x3ff);
            sumGG -=  1 * ((swap >> 10) & 0x3ff);
            sumBB -=  1 * ((swap >> 0)  & 0x3ff);

            swap = _bswap(pixelptr[column + 5]);
            //sum -=  1 * lineR[column + 5];
            sumRR -=  1 * ((swap >> 20) & 0x3ff);
            sumGG -=  1 * ((swap >> 10) & 0x3ff);
            sumBB -=  1 * ((swap >> 0)  & 0x3ff);
        }
        break;

        case DECODED_FORMAT_DPX0:
        {
            unsigned int swap = _bswap(pixelptr[column + 0]);
            //sum +=  5 * lineR[column + 0];
            sumRR +=  5 * ((swap >> 22) & 0x3ff);
            sumGG +=  5 * ((swap >> 12) & 0x3ff);
            sumBB +=  5 * ((swap >> 2) & 0x3ff);

            swap = _bswap(pixelptr[column + 1]);
            //sum -= 11 * lineR[column + 1];
            sumRR -=  11 * ((swap >> 22) & 0x3ff);
            sumGG -=  11 * ((swap >> 12) & 0x3ff);
            sumBB -=  11 * ((swap >> 2) & 0x3ff);

            swap = _bswap(pixelptr[column + 2]);
            //sum +=  4 * lineR[column + 2];
            sumRR +=  4 * ((swap >> 22) & 0x3ff);
            sumGG +=  4 * ((swap >> 12) & 0x3ff);
            sumBB +=  4 * ((swap >> 2) & 0x3ff);

            swap = _bswap(pixelptr[column + 3]);
            //sum +=  4 * lineR[column + 3];
            sumRR +=  4 * ((swap >> 22) & 0x3ff);
            sumGG +=  4 * ((swap >> 12) & 0x3ff);
            sumBB +=  4 * ((swap >> 2) & 0x3ff);

            swap = _bswap(pixelptr[column + 4]);
            //sum -=  1 * lineR[column + 4];
            sumRR -=  1 * ((swap >> 22) & 0x3ff);
            sumGG -=  1 * ((swap >> 12) & 0x3ff);
            sumBB -=  1 * ((swap >> 2) & 0x3ff);

            swap = _bswap(pixelptr[column + 5]);
            //sum -=  1 * lineR[column + 5];
            sumRR -=  1 * ((swap >> 22) & 0x3ff);
            sumGG -=  1 * ((swap >> 12) & 0x3ff);
            sumBB -=  1 * ((swap >> 2) & 0x3ff);
        }
        break;
    }


    sumRR <<= shift;
    sumGG <<= shift;
    sumBB <<= shift;

    //sum += ROUNDING(sum,8);
    sumRR += ROUNDING(sumRR, 8);
    sumGG += ROUNDING(sumGG, 8);
    sumBB += ROUNDING(sumBB, 8);

    //sum = DivideByShift(sum, 3);
    sumRR = DivideByShift(sumRR, 3);
    sumGG = DivideByShift(sumGG, 3);
    sumBB = DivideByShift(sumBB, 3);

    //highpass_value = SATURATE(sum);
    highpass_valueRR = SATURATE(sumRR);
    highpass_valueGG = SATURATE(sumGG);
    highpass_valueBB = SATURATE(sumBB);

    // Set the input pointer for the fast loop
    inputRGB_ptr = (__m128i *)&pixelptr[column];

    // Initialize the output pointers
    lowpassRR_ptr = (__m128i *)lowptrRR;
    lowpassGG_ptr = (__m128i *)lowptrGG;
    lowpassBB_ptr = (__m128i *)lowptrBB;
    highpassRR_ptr = (__m128i *)highptrRR;
    highpassGG_ptr = (__m128i *)highptrGG;
    highpassBB_ptr = (__m128i *)highptrBB;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpassGG_ptr));
    assert(ISALIGNED16(lowpassRR_ptr));
    assert(ISALIGNED16(lowpassBB_ptr));
    assert(ISALIGNED16(highpassGG_ptr));
    assert(ISALIGNED16(highpassRR_ptr));
    assert(ISALIGNED16(highpassBB_ptr));

#if 1
    {
        __m128i GG1_epi32;
        __m128i RR1_epi32;
        __m128i BB1_epi32;
        __m128i GG2_epi32;
        __m128i RR2_epi32;
        __m128i BB2_epi32;
        __m128i GG1_epi16;
        __m128i RR1_epi16;
        __m128i BB1_epi16;
        __m128i RR2_epi16;
        __m128i inputRGB_epi32;
        __m128i temp_epi32;

        const __m128i mask10bit_epi32 = _mm_set1_epi32(0x3ff);


        // Preload the first set of four pixels for fast processing
        inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

        switch (format)
        {
            case DECODED_FORMAT_AB10:
            case DECODED_FORMAT_RG30:
                RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

                inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                break;

            case DECODED_FORMAT_AR10:
                BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

                inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                break;

            case DECODED_FORMAT_R210:
                RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
                RR1_epi32 = _mm_slli_epi32(RR1_epi32, 4);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
                RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

                GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
                GG1_epi32 = _mm_srai_epi32(GG1_epi32, 2);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
                GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

                BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
                BB1_epi32 = _mm_srai_epi32(BB1_epi32, 8);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
                temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
                BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

                inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
                RR2_epi32 = _mm_slli_epi32(RR2_epi32, 4);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
                RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

                GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
                GG2_epi32 = _mm_srai_epi32(GG2_epi32, 2);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
                GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

                BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
                BB2_epi32 = _mm_srai_epi32(BB2_epi32, 8);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
                temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
                BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
                break;

            case DECODED_FORMAT_DPX0:

                RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
                RR1_epi32 = _mm_slli_epi32(RR1_epi32, 2);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
                RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

                GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
                GG1_epi32 = _mm_srai_epi32(GG1_epi32, 4);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
                GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

                BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
                BB1_epi32 = _mm_srai_epi32(BB1_epi32, 10);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
                temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
                BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

                inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
                RR2_epi32 = _mm_slli_epi32(RR2_epi32, 2);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
                RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

                GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
                GG2_epi32 = _mm_srai_epi32(GG2_epi32, 4);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
                temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
                GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

                BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
                BB2_epi32 = _mm_srai_epi32(BB2_epi32, 10);
                temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
                temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
                BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
                break;
        }


        RR1_epi16 = _mm_packs_epi32(RR1_epi32, RR2_epi32);
        GG1_epi16 = _mm_packs_epi32(GG1_epi32, GG2_epi32);
        BB1_epi16 = _mm_packs_epi32(BB1_epi32, BB2_epi32);



        // Process two sets of four input pixels to get one set of four output pixels
        for (; column < post_column; column += column_step)
        {
            __m128i shiftGG_epi16;
            __m128i shiftRR_epi16;
            __m128i shiftBB_epi16;
            __m128i half_epi16;		// Half of the divisor for rounding
            __m128i sumGG1_epi16;
            __m128i sumRR1_epi16;
            __m128i sumBB1_epi16;
            __m128i sumGG2_epi16;
            __m128i sumRR2_epi16;
            __m128i sumBB2_epi16;
            __m128i lowGG1_epi16;
            __m128i lowRR1_epi16;
            __m128i lowBB1_epi16;
            __m128i lowGG2_epi16;
            __m128i lowRR2_epi16;
            __m128i lowBB2_epi16;

            __m128i sumGG1b_epi16;
            __m128i sumRR1b_epi16;
            __m128i sumBB1b_epi16;
            __m128i sumGG2b_epi16;
            __m128i sumRR2b_epi16;
            __m128i sumBB2b_epi16;

            __m128i GG2_epi16;
            __m128i BB2_epi16;


            /***** Process the first four output points *****/

            // Initialize the highpass sum
            sumGG1_epi16 = _mm_setzero_si128();
            sumRR1_epi16 = _mm_setzero_si128();
            sumBB1_epi16 = _mm_setzero_si128();

            // Apply the first filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
            sumRR1_epi16 = _mm_subs_epi16(sumRR1_epi16, RR1_epi16);
            sumBB1_epi16 = _mm_subs_epi16(sumBB1_epi16, BB1_epi16);


            // Load the next eight pixels
            inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

            switch (format)
            {
                case DECODED_FORMAT_AB10:
                case DECODED_FORMAT_RG30:
                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    break;

                case DECODED_FORMAT_AR10:
                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    break;


                case DECODED_FORMAT_R210:
                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
                    RR1_epi32 = _mm_slli_epi32(RR1_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
                    RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
                    GG1_epi32 = _mm_srai_epi32(GG1_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
                    GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
                    BB1_epi32 = _mm_srai_epi32(BB1_epi32, 8);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
                    BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
                    RR2_epi32 = _mm_slli_epi32(RR2_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
                    RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
                    GG2_epi32 = _mm_srai_epi32(GG2_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
                    GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
                    BB2_epi32 = _mm_srai_epi32(BB2_epi32, 8);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
                    BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
                    break;

                case DECODED_FORMAT_DPX0:

                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
                    RR1_epi32 = _mm_slli_epi32(RR1_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
                    RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
                    GG1_epi32 = _mm_srai_epi32(GG1_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
                    GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
                    BB1_epi32 = _mm_srai_epi32(BB1_epi32, 10);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
                    BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
                    RR2_epi32 = _mm_slli_epi32(RR2_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
                    RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
                    GG2_epi32 = _mm_srai_epi32(GG2_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
                    GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
                    BB2_epi32 = _mm_srai_epi32(BB2_epi32, 10);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
                    BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
                    break;
            }

            RR2_epi16 = _mm_packs_epi32(RR1_epi32, RR2_epi32);
            GG2_epi16 = _mm_packs_epi32(GG1_epi32, GG2_epi32);
            BB2_epi16 = _mm_packs_epi32(BB1_epi32, BB2_epi32);





            // Initialize the lowpass sum
            lowGG1_epi16 = GG1_epi16;
            lowRR1_epi16 = RR1_epi16;
            lowBB1_epi16 = BB1_epi16;

            // Shift the first pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 7 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 7 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the second filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_subs_epi16(sumGG1_epi16, GG1_epi16);
            sumRR1_epi16 = _mm_subs_epi16(sumRR1_epi16, RR1_epi16);
            sumBB1_epi16 = _mm_subs_epi16(sumBB1_epi16, BB1_epi16);

            // Add adjacent points to compute the lowpass sum
            lowGG1_epi16 = _mm_adds_epi16(lowGG1_epi16, GG1_epi16);
            lowRR1_epi16 = _mm_adds_epi16(lowRR1_epi16, RR1_epi16);
            lowBB1_epi16 = _mm_adds_epi16(lowBB1_epi16, BB1_epi16);

            // shift for precision
            lowGG1_epi16 = _mm_slli_epi16(lowGG1_epi16, shift);
            lowRR1_epi16 = _mm_slli_epi16(lowRR1_epi16, shift);
            lowBB1_epi16 = _mm_slli_epi16(lowBB1_epi16, shift);

            // Expand the lowpass output points to a full doubleword
            lowGG1_epi16 = _mm_slli_epi32(lowGG1_epi16, 16);
            lowRR1_epi16 = _mm_slli_epi32(lowRR1_epi16, 16);
            lowBB1_epi16 = _mm_slli_epi32(lowBB1_epi16, 16);
            lowGG1_epi16 = _mm_srai_epi32(lowGG1_epi16, 16);
            lowRR1_epi16 = _mm_srai_epi32(lowRR1_epi16, 16);
            lowBB1_epi16 = _mm_srai_epi32(lowBB1_epi16, 16);

            // Shift the second pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 6 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 6 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the third filter coefficient to each pixel and sum the result
            sumGG1b_epi16 = GG1_epi16;
            sumRR1b_epi16 = RR1_epi16;
            sumBB1b_epi16 = BB1_epi16;

            // Shift the third pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 5 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 5 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the fourth filter coefficient to each pixel and sum the result
            sumGG1b_epi16 = _mm_subs_epi16(sumGG1b_epi16, GG1_epi16);
            sumRR1b_epi16 = _mm_subs_epi16(sumRR1b_epi16, RR1_epi16);
            sumBB1b_epi16 = _mm_subs_epi16(sumBB1b_epi16, BB1_epi16);

            // Shift the fourth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 4 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 4 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the fifth filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
            sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, RR1_epi16);
            sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, BB1_epi16);

            // Shift the fifth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 3 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 3 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the sixth (last) filter coefficient to each pixel and sum the result
            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, GG1_epi16);
            sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, RR1_epi16);
            sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, BB1_epi16);

            // shift for precision
            sumGG1_epi16 = _mm_slli_epi16(sumGG1_epi16, shift);
            sumRR1_epi16 = _mm_slli_epi16(sumRR1_epi16, shift);
            sumBB1_epi16 = _mm_slli_epi16(sumBB1_epi16, shift);
            sumGG1b_epi16 = _mm_slli_epi16(sumGG1b_epi16, shift);
            sumRR1b_epi16 = _mm_slli_epi16(sumRR1b_epi16, shift);
            sumBB1b_epi16 = _mm_slli_epi16(sumBB1b_epi16, shift);


            //DAN20050915 -- reversibility
            half_epi16 = _mm_set1_epi16(4);
            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, half_epi16);
            sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, half_epi16);
            sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, half_epi16);
            sumGG1_epi16 = _mm_srai_epi16(sumGG1_epi16, 3);
            sumRR1_epi16 = _mm_srai_epi16(sumRR1_epi16, 3);
            sumBB1_epi16 = _mm_srai_epi16(sumBB1_epi16, 3);

            sumGG1_epi16 = _mm_adds_epi16(sumGG1_epi16, sumGG1b_epi16);
            sumRR1_epi16 = _mm_adds_epi16(sumRR1_epi16, sumRR1b_epi16);
            sumBB1_epi16 = _mm_adds_epi16(sumBB1_epi16, sumBB1b_epi16);

            // Expand the even output points to a full doubleword
            sumGG1_epi16 = _mm_slli_epi32(sumGG1_epi16, 16);
            sumRR1_epi16 = _mm_slli_epi32(sumRR1_epi16, 16);
            sumBB1_epi16 = _mm_slli_epi32(sumBB1_epi16, 16);
            sumGG1_epi16 = _mm_srai_epi32(sumGG1_epi16, 16);
            sumRR1_epi16 = _mm_srai_epi32(sumRR1_epi16, 16);
            sumBB1_epi16 = _mm_srai_epi32(sumBB1_epi16, 16);

            // The second eight input points become the current input points
            GG1_epi16 = GG2_epi16;
            RR1_epi16 = RR2_epi16;
            BB1_epi16 = BB2_epi16;








            /***** Process the second four output points *****/

            // Initialize the highpass sum
            sumGG2_epi16 = _mm_setzero_si128();
            sumRR2_epi16 = _mm_setzero_si128();
            sumBB2_epi16 = _mm_setzero_si128();

            // Apply the first filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
            sumRR2_epi16 = _mm_subs_epi16(sumRR2_epi16, RR1_epi16);
            sumBB2_epi16 = _mm_subs_epi16(sumBB2_epi16, BB1_epi16);


            // Load the next eight pixels
            inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

            switch (format)
            {
                case DECODED_FORMAT_AB10:
                case DECODED_FORMAT_RG30:
                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    break;

                case DECODED_FORMAT_AR10:
                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    inputRGB_epi32 = _mm_srai_epi32(inputRGB_epi32, 10);
                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, mask10bit_epi32);
                    break;

                case DECODED_FORMAT_R210:
                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
                    RR1_epi32 = _mm_slli_epi32(RR1_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
                    RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
                    GG1_epi32 = _mm_srai_epi32(GG1_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
                    GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
                    BB1_epi32 = _mm_srai_epi32(BB1_epi32, 8);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
                    BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f));
                    RR2_epi32 = _mm_slli_epi32(RR2_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 12);
                    RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x0f00));
                    GG2_epi32 = _mm_srai_epi32(GG2_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00fc0000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 18);
                    GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x30000));
                    BB2_epi32 = _mm_srai_epi32(BB2_epi32, 8);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 24);
                    BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
                    break;


                case DECODED_FORMAT_DPX0:

                    RR1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
                    RR1_epi32 = _mm_slli_epi32(RR1_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
                    RR1_epi32 = _mm_or_si128(RR1_epi32, temp_epi32);

                    GG1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
                    GG1_epi32 = _mm_srai_epi32(GG1_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
                    GG1_epi32 = _mm_or_si128(GG1_epi32, temp_epi32);

                    BB1_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
                    BB1_epi32 = _mm_srai_epi32(BB1_epi32, 10);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
                    BB1_epi32 = _mm_or_si128(BB1_epi32, temp_epi32);

                    inputRGB_epi32 = _mm_load_si128(inputRGB_ptr++);

                    RR2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xff));
                    RR2_epi32 = _mm_slli_epi32(RR2_epi32, 2);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xc000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 14);
                    RR2_epi32 = _mm_or_si128(RR2_epi32, temp_epi32);

                    GG2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x3f00));
                    GG2_epi32 = _mm_srai_epi32(GG2_epi32, 4);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0x00f00000));
                    temp_epi32 = _mm_srai_epi32(temp_epi32, 20);
                    GG2_epi32 = _mm_or_si128(GG2_epi32, temp_epi32);

                    BB2_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xf0000));
                    BB2_epi32 = _mm_srai_epi32(BB2_epi32, 10);
                    temp_epi32 = _mm_and_si128(inputRGB_epi32, _mm_set1_epi32(0xfc000000));
                    temp_epi32 = _mm_srli_epi32(temp_epi32, 26);
                    BB2_epi32 = _mm_or_si128(BB2_epi32, temp_epi32);
                    break;
            }


            RR2_epi16 = _mm_packs_epi32(RR1_epi32, RR2_epi32);
            GG2_epi16 = _mm_packs_epi32(GG1_epi32, GG2_epi32);
            BB2_epi16 = _mm_packs_epi32(BB1_epi32, BB2_epi32);



            // Initialize the lowpass sum
            lowGG2_epi16 = GG1_epi16;
            lowRR2_epi16 = RR1_epi16;
            lowBB2_epi16 = BB1_epi16;

            // Shift the first pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 7 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 7 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 7 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the second filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_subs_epi16(sumGG2_epi16, GG1_epi16);
            sumRR2_epi16 = _mm_subs_epi16(sumRR2_epi16, RR1_epi16);
            sumBB2_epi16 = _mm_subs_epi16(sumBB2_epi16, BB1_epi16);

            // Add adjacent points to compute the lowpass sum
            lowGG2_epi16 = _mm_adds_epi16(lowGG2_epi16, GG1_epi16);
            lowRR2_epi16 = _mm_adds_epi16(lowRR2_epi16, RR1_epi16);
            lowBB2_epi16 = _mm_adds_epi16(lowBB2_epi16, BB1_epi16);

            // shift for precision
            lowGG2_epi16 = _mm_slli_epi16(lowGG2_epi16, shift);
            lowRR2_epi16 = _mm_slli_epi16(lowRR2_epi16, shift);
            lowBB2_epi16 = _mm_slli_epi16(lowBB2_epi16, shift);

            // Expand the lowpass output points to a full doubleword
            lowGG2_epi16 = _mm_slli_epi32(lowGG2_epi16, 16);
            lowRR2_epi16 = _mm_slli_epi32(lowRR2_epi16, 16);
            lowBB2_epi16 = _mm_slli_epi32(lowBB2_epi16, 16);
            lowGG2_epi16 = _mm_srai_epi32(lowGG2_epi16, 16);
            lowRR2_epi16 = _mm_srai_epi32(lowRR2_epi16, 16);
            lowBB2_epi16 = _mm_srai_epi32(lowBB2_epi16, 16);

            // Shift the second pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 6 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 6 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 6 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the third filter coefficient to each pixel and sum the result
            sumGG2b_epi16 = GG1_epi16;
            sumRR2b_epi16 = RR1_epi16;
            sumBB2b_epi16 = BB1_epi16;

            // Shift the third pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 5 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 5 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 5 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the fourth filter coefficient to each pixel and sum the result
            sumGG2b_epi16 = _mm_subs_epi16(sumGG2b_epi16, GG1_epi16);
            sumRR2b_epi16 = _mm_subs_epi16(sumRR2b_epi16, RR1_epi16);
            sumBB2b_epi16 = _mm_subs_epi16(sumBB2b_epi16, BB1_epi16);

            // Shift the fourth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 4 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 4 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 4 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the fifth filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
            sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, RR1_epi16);
            sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, BB1_epi16);

            // Shift the fifth pixel from the second set into the working set
            shiftGG_epi16 = _mm_slli_si128(GG2_epi16, 3 * 2);
            shiftRR_epi16 = _mm_slli_si128(RR2_epi16, 3 * 2);
            shiftBB_epi16 = _mm_slli_si128(BB2_epi16, 3 * 2);
            GG1_epi16 = _mm_srli_si128(GG1_epi16, 1 * 2);
            RR1_epi16 = _mm_srli_si128(RR1_epi16, 1 * 2);
            BB1_epi16 = _mm_srli_si128(BB1_epi16, 1 * 2);
            GG1_epi16 = _mm_or_si128(GG1_epi16, shiftGG_epi16);
            RR1_epi16 = _mm_or_si128(RR1_epi16, shiftRR_epi16);
            BB1_epi16 = _mm_or_si128(BB1_epi16, shiftBB_epi16);

            // Apply the sixth (last) filter coefficient to each pixel and sum the result
            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, GG1_epi16);
            sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, RR1_epi16);
            sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, BB1_epi16);


            // shift for precision
            sumGG2_epi16 = _mm_slli_epi16(sumGG2_epi16, shift);
            sumRR2_epi16 = _mm_slli_epi16(sumRR2_epi16, shift);
            sumBB2_epi16 = _mm_slli_epi16(sumBB2_epi16, shift);
            sumGG2b_epi16 = _mm_slli_epi16(sumGG2b_epi16, shift);
            sumRR2b_epi16 = _mm_slli_epi16(sumRR2b_epi16, shift);
            sumBB2b_epi16 = _mm_slli_epi16(sumBB2b_epi16, shift);

            //DAN20050915 -- reversibility
            half_epi16 = _mm_set1_epi16(4);
            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, half_epi16);
            sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, half_epi16);
            sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, half_epi16);
            sumGG2_epi16 = _mm_srai_epi16(sumGG2_epi16, 3);
            sumRR2_epi16 = _mm_srai_epi16(sumRR2_epi16, 3);
            sumBB2_epi16 = _mm_srai_epi16(sumBB2_epi16, 3);

            sumGG2_epi16 = _mm_adds_epi16(sumGG2_epi16, sumGG2b_epi16);
            sumRR2_epi16 = _mm_adds_epi16(sumRR2_epi16, sumRR2b_epi16);
            sumBB2_epi16 = _mm_adds_epi16(sumBB2_epi16, sumBB2b_epi16);


            // Expand the even output points to a full doubleword
            sumGG2_epi16 = _mm_slli_epi32(sumGG2_epi16, 16);
            sumRR2_epi16 = _mm_slli_epi32(sumRR2_epi16, 16);
            sumBB2_epi16 = _mm_slli_epi32(sumBB2_epi16, 16);
            sumGG2_epi16 = _mm_srai_epi32(sumGG2_epi16, 16);
            sumRR2_epi16 = _mm_srai_epi32(sumRR2_epi16, 16);
            sumBB2_epi16 = _mm_srai_epi32(sumBB2_epi16, 16);


            /***** Combine the output points *****/

            lowGG1_epi16 = _mm_packs_epi32(lowGG1_epi16, lowGG2_epi16);
            lowRR1_epi16 = _mm_packs_epi32(lowRR1_epi16, lowRR2_epi16);
            lowBB1_epi16 = _mm_packs_epi32(lowBB1_epi16, lowBB2_epi16);
            sumGG1_epi16 = _mm_packs_epi32(sumGG1_epi16, sumGG2_epi16);
            sumRR1_epi16 = _mm_packs_epi32(sumRR1_epi16, sumRR2_epi16);
            sumBB1_epi16 = _mm_packs_epi32(sumBB1_epi16, sumBB2_epi16);


            // Store the four lowpass output points
            _mm_store_si128(lowpassGG_ptr++, lowGG1_epi16);
            _mm_store_si128(lowpassRR_ptr++, lowRR1_epi16);
            _mm_store_si128(lowpassBB_ptr++, lowBB1_epi16);

            // Get the last highpass coefficient in the group
            sumGG2_epi16 = _mm_srli_si128(sumGG1_epi16, 7 * 2);
            sumRR2_epi16 = _mm_srli_si128(sumRR1_epi16, 7 * 2);
            sumBB2_epi16 = _mm_srli_si128(sumBB1_epi16, 7 * 2);

            // Shift the extra highpass coefficient into the output
            sumGG1_epi16 = _mm_slli_si128(sumGG1_epi16, 1 * 2);
            sumRR1_epi16 = _mm_slli_si128(sumRR1_epi16, 1 * 2);
            sumBB1_epi16 = _mm_slli_si128(sumBB1_epi16, 1 * 2);
            sumGG1_epi16 = _mm_insert_epi16(sumGG1_epi16, highpass_valueGG, 0);
            sumRR1_epi16 = _mm_insert_epi16(sumRR1_epi16, highpass_valueRR, 0);
            sumBB1_epi16 = _mm_insert_epi16(sumBB1_epi16, highpass_valueBB, 0);

            // Save the last highpass coefficient for the next loop iteration
            highpass_valueGG = _mm_cvtsi128_si32(sumGG2_epi16);
            highpass_valueRR = _mm_cvtsi128_si32(sumRR2_epi16);
            highpass_valueBB = _mm_cvtsi128_si32(sumBB2_epi16);

            // Store the four highpass output points
            _mm_store_si128(highpassGG_ptr++, sumGG1_epi16);
            _mm_store_si128(highpassRR_ptr++, sumRR1_epi16);
            _mm_store_si128(highpassBB_ptr++, sumBB1_epi16);

            // The second set of eight input pixels becomes the working set
            GG1_epi16 = GG2_epi16;
            RR1_epi16 = RR2_epi16;
            BB1_epi16 = BB2_epi16;
        }
    }
    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptrGG = (PIXEL *)lowpassGG_ptr;
    lowptrRR = (PIXEL *)lowpassRR_ptr;
    lowptrBB = (PIXEL *)lowpassBB_ptr;
    highptrGG = (PIXEL *)highpassGG_ptr;
    highptrRR = (PIXEL *)highpassRR_ptr;
    highptrBB = (PIXEL *)highpassBB_ptr;
#else


    switch (format)
    {
        case DECODED_FORMAT_AB10:
        case DECODED_FORMAT_RG30:
            sumRR = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff)) << shift);
            sumGG = ((((pixelptr[column + 0] >> 10) & 0x3ff) + ((pixelptr[column + 1] >> 10) & 0x3ff)) << shift);
            sumBB = ((((pixelptr[column + 0] >> 20) & 0x3ff) + ((pixelptr[column + 1] >> 20) & 0x3ff)) << shift);
            break;

        case DECODED_FORMAT_AR10:
            sumRR = ((((pixelptr[column + 0] >> 20) & 0x3ff) + ((pixelptr[column + 1] >> 20) & 0x3ff)) << shift);
            sumGG = ((((pixelptr[column + 0] >> 10) & 0x3ff) + ((pixelptr[column + 1] >> 10) & 0x3ff)) << shift);
            sumBB = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff)) << shift);
            break;

        case DECODED_FORMAT_R210:
        {
            unsigned int swap = _bswap(pixelptr[column + 0]);
            unsigned int swap1 = _bswap(pixelptr[column + 1]);

            sumRR = ((((swap >> 20) & 0x3ff) + ((swap1 >> 20) & 0x3ff)) << shift);
            sumGG = ((((swap >> 10) & 0x3ff) + ((swap1 >> 10) & 0x3ff)) << shift);
            sumBB = ((((swap >> 0 ) & 0x3ff) + ((swap1 >> 0) & 0x3ff)) << shift);
        }
        break;

        case DECODED_FORMAT_DPX0:
        {
            unsigned int swap = _bswap(pixelptr[column + 0]);
            unsigned int swap1 = _bswap(pixelptr[column + 1]);

            sumRR = ((((swap >> 22) & 0x3ff) + ((swap1 >> 22) & 0x3ff)) << shift);
            sumGG = ((((swap >> 12) & 0x3ff) + ((swap1 >> 12) & 0x3ff)) << shift);
            sumBB = ((((swap >> 2) & 0x3ff) + ((swap1 >> 2) & 0x3ff)) << shift);
        }
        break;
    }


    // Store the lowpass sum
    *(lowptrGG++) = SATURATE(sumGG);
    *(lowptrRR++) = SATURATE(sumRR);
    *(lowptrBB++) = SATURATE(sumBB);

    //*(highptr++) = SATURATE(sum);
    *(highptrGG++) = highpass_valueGG;
    *(highptrRR++) = highpass_valueRR;
    *(highptrBB++) = highpass_valueBB;

    column += 2;

#endif
    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        //sum = input[column] + input[column + 1];

        switch (format)
        {
            case DECODED_FORMAT_AB10:
            case DECODED_FORMAT_RG30:
                sumRR = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff)) << shift);
                sumGG = ((((pixelptr[column + 0] >> 10) & 0x3ff) + ((pixelptr[column + 1] >> 10) & 0x3ff)) << shift);
                sumBB = ((((pixelptr[column + 0] >> 20) & 0x3ff) + ((pixelptr[column + 1] >> 20) & 0x3ff)) << shift);

                // Store the lowpass sum
                *(lowptrGG++) = SATURATE(sumGG);
                *(lowptrRR++) = SATURATE(sumRR);
                *(lowptrBB++) = SATURATE(sumBB);

                // Compute the highpass sum
                //sum = 0;
                sumGG = sumRR = sumBB = 0;

                //sum -= input[column - 2];
                sumRR -= ((pixelptr[column - 2]) & 0x3ff);
                sumGG -= ((pixelptr[column - 2] >> 10) & 0x3ff);
                sumBB -= ((pixelptr[column - 2] >> 20) & 0x3ff);

                //sum -= input[column - 1];
                sumRR -= ((pixelptr[column - 1]) & 0x3ff);
                sumGG -= ((pixelptr[column - 1] >> 10) & 0x3ff);
                sumBB -= ((pixelptr[column - 1] >> 20) & 0x3ff);

                //sum += input[column + 2];
                sumRR += ((pixelptr[column + 2]) & 0x3ff);
                sumGG += ((pixelptr[column + 2] >> 10) & 0x3ff);
                sumBB += ((pixelptr[column + 2] >> 20) & 0x3ff);

                //sum += input[column + 3];
                sumRR += ((pixelptr[column + 3]) & 0x3ff);
                sumGG += ((pixelptr[column + 3] >> 10) & 0x3ff);
                sumBB += ((pixelptr[column + 3] >> 20) & 0x3ff);

                sumRR <<= shift;
                sumGG <<= shift;
                sumBB <<= shift;

                //sum += ROUNDING(sum,8);
                sumRR += ROUNDING(sumRR, 8);
                sumGG += ROUNDING(sumGG, 8);
                sumBB += ROUNDING(sumBB, 8);

                //sum = DivideByShift(sum, 3);
                sumRR = DivideByShift(sumRR, 3);
                sumGG = DivideByShift(sumGG, 3);
                sumBB = DivideByShift(sumBB, 3);

                //sum += input[column + 0];
                sumRR += ((pixelptr[column + 0]) & 0x3ff) << shift;
                sumGG += ((pixelptr[column + 0] >> 10) & 0x3ff) << shift;
                sumBB += ((pixelptr[column + 0] >> 20) & 0x3ff) << shift;

                //sum -= input[column + 1];
                sumRR -= ((pixelptr[column + 1]) & 0x3ff) << shift;
                sumGG -= ((pixelptr[column + 1] >> 10) & 0x3ff) << shift;
                sumBB -= ((pixelptr[column + 1] >> 20) & 0x3ff) << shift;
                break;

            case DECODED_FORMAT_AR10:
                sumBB = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff)) << shift);
                sumGG = ((((pixelptr[column + 0] >> 10) & 0x3ff) + ((pixelptr[column + 1] >> 10) & 0x3ff)) << shift);
                sumRR = ((((pixelptr[column + 0] >> 20) & 0x3ff) + ((pixelptr[column + 1] >> 20) & 0x3ff)) << shift);

                // Store the lowpass sum
                *(lowptrGG++) = SATURATE(sumGG);
                *(lowptrRR++) = SATURATE(sumRR);
                *(lowptrBB++) = SATURATE(sumBB);

                // Compute the highpass sum
                //sum = 0;
                sumGG = sumRR = sumBB = 0;

                //sum -= input[column - 2];
                sumBB -= ((pixelptr[column - 2]) & 0x3ff);
                sumGG -= ((pixelptr[column - 2] >> 10) & 0x3ff);
                sumRR -= ((pixelptr[column - 2] >> 20) & 0x3ff);

                //sum -= input[column - 1];
                sumBB -= ((pixelptr[column - 1]) & 0x3ff);
                sumGG -= ((pixelptr[column - 1] >> 10) & 0x3ff);
                sumRR -= ((pixelptr[column - 1] >> 20) & 0x3ff);

                //sum += input[column + 2];
                sumBB += ((pixelptr[column + 2]) & 0x3ff);
                sumGG += ((pixelptr[column + 2] >> 10) & 0x3ff);
                sumRR += ((pixelptr[column + 2] >> 20) & 0x3ff);

                //sum += input[column + 3];
                sumBB += ((pixelptr[column + 3]) & 0x3ff);
                sumGG += ((pixelptr[column + 3] >> 10) & 0x3ff);
                sumRR += ((pixelptr[column + 3] >> 20) & 0x3ff);

                sumRR <<= shift;
                sumGG <<= shift;
                sumBB <<= shift;

                //sum += ROUNDING(sum,8);
                sumRR += ROUNDING(sumRR, 8);
                sumGG += ROUNDING(sumGG, 8);
                sumBB += ROUNDING(sumBB, 8);

                //sum = DivideByShift(sum, 3);
                sumRR = DivideByShift(sumRR, 3);
                sumGG = DivideByShift(sumGG, 3);
                sumBB = DivideByShift(sumBB, 3);

                //sum += input[column + 0];
                sumBB += ((pixelptr[column + 0]) & 0x3ff) << shift;
                sumGG += ((pixelptr[column + 0] >> 10) & 0x3ff) << shift;
                sumRR += ((pixelptr[column + 0] >> 20) & 0x3ff) << shift;

                //sum -= input[column + 1];
                sumBB -= ((pixelptr[column + 1]) & 0x3ff) << shift;
                sumGG -= ((pixelptr[column + 1] >> 10) & 0x3ff) << shift;
                sumRR -= ((pixelptr[column + 1] >> 20) & 0x3ff) << shift;
                break;

            case DECODED_FORMAT_R210:
            {
                unsigned int swap = _bswap(pixelptr[column + 0]);
                unsigned int swap1 = _bswap(pixelptr[column + 1]);
                unsigned int swap2 = _bswap(pixelptr[column + 2]);
                unsigned int swap3 = _bswap(pixelptr[column + 3]);
                unsigned int swap1n = _bswap(pixelptr[column - 1]);
                unsigned int swap2n = _bswap(pixelptr[column - 2]);
                sumRR = ((((swap >> 20) & 0x3ff) + ((swap1 >> 20) & 0x3ff)) << shift);
                sumGG = ((((swap >> 10) & 0x3ff) + ((swap1 >> 10) & 0x3ff)) << shift);
                sumBB = ((((swap >> 0) & 0x3ff) + ((swap1 >> 0) & 0x3ff)) << shift);

                // Store the lowpass sum
                *(lowptrGG++) = SATURATE(sumGG);
                *(lowptrRR++) = SATURATE(sumRR);
                *(lowptrBB++) = SATURATE(sumBB);

                // Compute the highpass sum
                //sum = 0;
                sumGG = sumRR = sumBB = 0;

                //sum -= input[column - 2];
                sumRR -= ((swap2n >> 20) & 0x3ff);
                sumGG -= ((swap2n >> 10) & 0x3ff);
                sumBB -= ((swap2n >> 0 ) & 0x3ff);

                //sum -= input[column - 1];
                sumRR -= ((swap1n >> 20) & 0x3ff);
                sumGG -= ((swap1n >> 10) & 0x3ff);
                sumBB -= ((swap1n >> 0 ) & 0x3ff);

                //sum += input[column + 2];
                sumRR += ((swap2 >> 20) & 0x3ff);
                sumGG += ((swap2 >> 10) & 0x3ff);
                sumBB += ((swap2 >> 0 ) & 0x3ff);

                //sum += input[column + 3];
                sumRR += ((swap3 >> 20) & 0x3ff);
                sumGG += ((swap3 >> 10) & 0x3ff);
                sumBB += ((swap3 >> 0 ) & 0x3ff);

                sumRR <<= shift;
                sumGG <<= shift;
                sumBB <<= shift;

                //sum += ROUNDING(sum,8);
                sumRR += ROUNDING(sumRR, 8);
                sumGG += ROUNDING(sumGG, 8);
                sumBB += ROUNDING(sumBB, 8);

                //sum = DivideByShift(sum, 3);
                sumRR = DivideByShift(sumRR, 3);
                sumGG = DivideByShift(sumGG, 3);
                sumBB = DivideByShift(sumBB, 3);

                //sum += input[column + 0];
                sumRR += ((swap >> 20) & 0x3ff) << shift;
                sumGG += ((swap >> 10) & 0x3ff) << shift;
                sumBB += ((swap >> 0 ) & 0x3ff) << shift;

                //sum -= input[column + 1];
                sumRR -= ((swap1 >> 20) & 0x3ff) << shift;
                sumGG -= ((swap1 >> 10) & 0x3ff) << shift;
                sumBB -= ((swap1 >> 0 ) & 0x3ff) << shift;

            }
            break;

            case DECODED_FORMAT_DPX0:
            {
                unsigned int swap = _bswap(pixelptr[column + 0]);
                unsigned int swap1 = _bswap(pixelptr[column + 1]);
                unsigned int swap2 = _bswap(pixelptr[column + 2]);
                unsigned int swap3 = _bswap(pixelptr[column + 3]);
                unsigned int swap1n = _bswap(pixelptr[column - 1]);
                unsigned int swap2n = _bswap(pixelptr[column - 2]);
                sumRR = ((((swap >> 22) & 0x3ff) + ((swap1 >> 22) & 0x3ff)) << shift);
                sumGG = ((((swap >> 12) & 0x3ff) + ((swap1 >> 12) & 0x3ff)) << shift);
                sumBB = ((((swap >> 2) & 0x3ff) + ((swap1 >> 2) & 0x3ff)) << shift);

                // Store the lowpass sum
                *(lowptrGG++) = SATURATE(sumGG);
                *(lowptrRR++) = SATURATE(sumRR);
                *(lowptrBB++) = SATURATE(sumBB);

                // Compute the highpass sum
                //sum = 0;
                sumGG = sumRR = sumBB = 0;

                //sum -= input[column - 2];
                sumRR -= ((swap2n >> 22) & 0x3ff);
                sumGG -= ((swap2n >> 12) & 0x3ff);
                sumBB -= ((swap2n >> 2 ) & 0x3ff);

                //sum -= input[column - 1];
                sumRR -= ((swap1n >> 22) & 0x3ff);
                sumGG -= ((swap1n >> 12) & 0x3ff);
                sumBB -= ((swap1n >> 2 ) & 0x3ff);

                //sum += input[column + 2];
                sumRR += ((swap2 >> 22) & 0x3ff);
                sumGG += ((swap2 >> 12) & 0x3ff);
                sumBB += ((swap2 >> 2 ) & 0x3ff);

                //sum += input[column + 3];
                sumRR += ((swap3 >> 22) & 0x3ff);
                sumGG += ((swap3 >> 12) & 0x3ff);
                sumBB += ((swap3 >> 2 ) & 0x3ff);

                sumRR <<= shift;
                sumGG <<= shift;
                sumBB <<= shift;

                //sum += ROUNDING(sum,8);
                sumRR += ROUNDING(sumRR, 8);
                sumGG += ROUNDING(sumGG, 8);
                sumBB += ROUNDING(sumBB, 8);

                //sum = DivideByShift(sum, 3);
                sumRR = DivideByShift(sumRR, 3);
                sumGG = DivideByShift(sumGG, 3);
                sumBB = DivideByShift(sumBB, 3);

                //sum += input[column + 0];
                sumRR += ((swap >> 22) & 0x3ff) << shift;
                sumGG += ((swap >> 12) & 0x3ff) << shift;
                sumBB += ((swap >> 2 ) & 0x3ff) << shift;

                //sum -= input[column + 1];
                sumRR -= ((swap1 >> 22) & 0x3ff) << shift;
                sumGG -= ((swap1 >> 12) & 0x3ff) << shift;
                sumBB -= ((swap1 >> 2 ) & 0x3ff) << shift;

            }
            break;
        }

        // Store the highpass sum
        //*(highptr++) = SATURATE(sum);
        *(highptrGG++) = SATURATE(sumGG);
        *(highptrRR++) = SATURATE(sumRR);
        *(highptrBB++) = SATURATE(sumBB);
    }

    // Should be at the last column
    assert(column == last_column);


    switch (format)
    {
        case DECODED_FORMAT_AB10:
        case DECODED_FORMAT_RG30:
            // Compute the last lowpass value
            //sum = input[column] + input[column + 1];
            sumRR = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff)) << shift);
            sumGG = ((((pixelptr[column + 0] >> 10) & 0x3ff) + ((pixelptr[column + 1] >> 10) & 0x3ff)) << shift);
            sumBB = ((((pixelptr[column + 0] >> 20) & 0x3ff) + ((pixelptr[column + 1] >> 20) & 0x3ff)) << shift);

            // Store the lowpass sum
            *(lowptrGG++) = SATURATE(sumGG);
            *(lowptrRR++) = SATURATE(sumRR);
            *(lowptrBB++) = SATURATE(sumBB);

            // Compute the last highpass value using the special border coefficients
            //sum = 0;
            sumGG = sumRR = sumBB = 0;

            //sum += 11 * input[column + 0];
            sumRR += 11 * ((pixelptr[column + 0]) & 0x3ff);
            sumGG += 11 * ((pixelptr[column + 0] >> 10) & 0x3ff);
            sumBB += 11 * ((pixelptr[column + 0] >> 20) & 0x3ff);

            //sum -=  5 * input[column + 1];
            sumRR -= 5 * ((pixelptr[column + 1]) & 0x3ff);
            sumGG -= 5 * ((pixelptr[column + 1] >> 10) & 0x3ff);
            sumBB -= 5 * ((pixelptr[column + 1] >> 20) & 0x3ff);

            //sum -=  4 * input[column - 1];
            sumRR -= 4 * ((pixelptr[column - 1]) & 0x3ff);
            sumGG -= 4 * ((pixelptr[column - 1] >> 10) & 0x3ff);
            sumBB -= 4 * ((pixelptr[column - 1] >> 20) & 0x3ff);

            //sum -=  4 * input[column - 2];
            sumRR -= 4 * ((pixelptr[column - 2]) & 0x3ff);
            sumGG -= 4 * ((pixelptr[column - 2] >> 10) & 0x3ff);
            sumBB -= 4 * ((pixelptr[column - 2] >> 20) & 0x3ff);

            //sum +=  1 * input[column - 3];
            sumRR += 1 * ((pixelptr[column - 3]) & 0x3ff);
            sumGG += 1 * ((pixelptr[column - 3] >> 10) & 0x3ff);
            sumBB += 1 * ((pixelptr[column - 3] >> 20) & 0x3ff);

            //sum +=  1 * input[column - 4];
            sumRR += 1 * ((pixelptr[column - 4]) & 0x3ff);
            sumGG += 1 * ((pixelptr[column - 4] >> 10) & 0x3ff);
            sumBB += 1 * ((pixelptr[column - 4] >> 20) & 0x3ff);
            break;

        case DECODED_FORMAT_AR10:
            // Compute the last lowpass value
            //sum = input[column] + input[column + 1];
            sumBB = ((((pixelptr[column + 0]) & 0x3ff) + ((pixelptr[column + 1]) & 0x3ff)) << shift);
            sumGG = ((((pixelptr[column + 0] >> 10) & 0x3ff) + ((pixelptr[column + 1] >> 10) & 0x3ff)) << shift);
            sumRR = ((((pixelptr[column + 0] >> 20) & 0x3ff) + ((pixelptr[column + 1] >> 20) & 0x3ff)) << shift);

            // Store the lowpass sum
            *(lowptrGG++) = SATURATE(sumGG);
            *(lowptrRR++) = SATURATE(sumRR);
            *(lowptrBB++) = SATURATE(sumBB);

            // Compute the last highpass value using the special border coefficients
            //sum = 0;
            sumGG = sumRR = sumBB = 0;

            //sum += 11 * input[column + 0];
            sumBB += 11 * ((pixelptr[column + 0]) & 0x3ff);
            sumGG += 11 * ((pixelptr[column + 0] >> 10) & 0x3ff);
            sumRR += 11 * ((pixelptr[column + 0] >> 20) & 0x3ff);

            //sum -=  5 * input[column + 1];
            sumBB -= 5 * ((pixelptr[column + 1]) & 0x3ff);
            sumGG -= 5 * ((pixelptr[column + 1] >> 10) & 0x3ff);
            sumRR -= 5 * ((pixelptr[column + 1] >> 20) & 0x3ff);

            //sum -=  4 * input[column - 1];
            sumBB -= 4 * ((pixelptr[column - 1]) & 0x3ff);
            sumGG -= 4 * ((pixelptr[column - 1] >> 10) & 0x3ff);
            sumRR -= 4 * ((pixelptr[column - 1] >> 20) & 0x3ff);

            //sum -=  4 * input[column - 2];
            sumBB -= 4 * ((pixelptr[column - 2]) & 0x3ff);
            sumGG -= 4 * ((pixelptr[column - 2] >> 10) & 0x3ff);
            sumRR -= 4 * ((pixelptr[column - 2] >> 20) & 0x3ff);

            //sum +=  1 * input[column - 3];
            sumBB += 1 * ((pixelptr[column - 3]) & 0x3ff);
            sumGG += 1 * ((pixelptr[column - 3] >> 10) & 0x3ff);
            sumRR += 1 * ((pixelptr[column - 3] >> 20) & 0x3ff);

            //sum +=  1 * input[column - 4];
            sumBB += 1 * ((pixelptr[column - 4]) & 0x3ff);
            sumGG += 1 * ((pixelptr[column - 4] >> 10) & 0x3ff);
            sumRR += 1 * ((pixelptr[column - 4] >> 20) & 0x3ff);
            break;

        case DECODED_FORMAT_R210:
        {
            unsigned int swap = _bswap(pixelptr[column + 0]);
            unsigned int swap1 = _bswap(pixelptr[column + 1]);
            unsigned int swap1n = _bswap(pixelptr[column - 1]);
            unsigned int swap2n = _bswap(pixelptr[column - 2]);
            unsigned int swap3n = _bswap(pixelptr[column - 3]);
            unsigned int swap4n = _bswap(pixelptr[column - 4]);

            // Compute the last lowpass value
            //sum = input[column] + input[column + 1];
            sumRR = ((((swap >> 20) & 0x3ff) + ((swap1 >> 20) & 0x3ff)) << shift);
            sumGG = ((((swap >> 10) & 0x3ff) + ((swap1 >> 10) & 0x3ff)) << shift);
            sumBB = ((((swap >> 0 ) & 0x3ff) + ((swap1 >> 0 ) & 0x3ff)) << shift);

            // Store the lowpass sum
            *(lowptrGG++) = SATURATE(sumGG);
            *(lowptrRR++) = SATURATE(sumRR);
            *(lowptrBB++) = SATURATE(sumBB);

            // Compute the last highpass value using the special border coefficients
            //sum = 0;
            sumGG = sumRR = sumBB = 0;

            //sum += 11 * input[column + 0];
            sumRR += 11 * ((swap >> 20) & 0x3ff);
            sumGG += 11 * ((swap >> 10) & 0x3ff);
            sumBB += 11 * ((swap >> 0 ) & 0x3ff);

            //sum -=  5 * input[column + 1];
            sumRR -= 5 * ((swap1 >> 20) & 0x3ff);
            sumGG -= 5 * ((swap1 >> 10) & 0x3ff);
            sumBB -= 5 * ((swap1 >> 0 ) & 0x3ff);

            //sum -=  4 * input[column - 1];
            sumRR -= 4 * ((swap1n >> 20) & 0x3ff);
            sumGG -= 4 * ((swap1n >> 10) & 0x3ff);
            sumBB -= 4 * ((swap1n >> 0 ) & 0x3ff);

            //sum -=  4 * input[column - 2];
            sumRR -= 4 * ((swap2n >> 20) & 0x3ff);
            sumGG -= 4 * ((swap2n >> 10) & 0x3ff);
            sumBB -= 4 * ((swap2n >> 0 ) & 0x3ff);

            //sum +=  1 * input[column - 3];
            sumRR += 1 * ((swap3n >> 20) & 0x3ff);
            sumGG += 1 * ((swap3n >> 10) & 0x3ff);
            sumBB += 1 * ((swap3n >> 0 ) & 0x3ff);

            //sum +=  1 * input[column - 4];
            sumRR += 1 * ((swap4n >> 20) & 0x3ff);
            sumGG += 1 * ((swap4n >> 10) & 0x3ff);
            sumBB += 1 * ((swap4n >> 0 ) & 0x3ff);
        }
        break;
        case DECODED_FORMAT_DPX0:
        {
            unsigned int swap = _bswap(pixelptr[column + 0]);
            unsigned int swap1 = _bswap(pixelptr[column + 1]);
            unsigned int swap1n = _bswap(pixelptr[column - 1]);
            unsigned int swap2n = _bswap(pixelptr[column - 2]);
            unsigned int swap3n = _bswap(pixelptr[column - 3]);
            unsigned int swap4n = _bswap(pixelptr[column - 4]);

            // Compute the last lowpass value
            //sum = input[column] + input[column + 1];
            sumRR = ((((swap >> 22) & 0x3ff) + ((swap1 >> 22) & 0x3ff)) << shift);
            sumGG = ((((swap >> 12) & 0x3ff) + ((swap1 >> 12) & 0x3ff)) << shift);
            sumBB = ((((swap >> 2 ) & 0x3ff) + ((swap1 >> 2 ) & 0x3ff)) << shift);

            // Store the lowpass sum
            *(lowptrGG++) = SATURATE(sumGG);
            *(lowptrRR++) = SATURATE(sumRR);
            *(lowptrBB++) = SATURATE(sumBB);

            // Compute the last highpass value using the special border coefficients
            //sum = 0;
            sumGG = sumRR = sumBB = 0;

            //sum += 11 * input[column + 0];
            sumRR += 11 * ((swap >> 22) & 0x3ff);
            sumGG += 11 * ((swap >> 12) & 0x3ff);
            sumBB += 11 * ((swap >> 2 ) & 0x3ff);

            //sum -=  5 * input[column + 1];
            sumRR -= 5 * ((swap1 >> 22) & 0x3ff);
            sumGG -= 5 * ((swap1 >> 12) & 0x3ff);
            sumBB -= 5 * ((swap1 >> 2 ) & 0x3ff);

            //sum -=  4 * input[column - 1];
            sumRR -= 4 * ((swap1n >> 22) & 0x3ff);
            sumGG -= 4 * ((swap1n >> 12) & 0x3ff);
            sumBB -= 4 * ((swap1n >> 2 ) & 0x3ff);

            //sum -=  4 * input[column - 2];
            sumRR -= 4 * ((swap2n >> 22) & 0x3ff);
            sumGG -= 4 * ((swap2n >> 12) & 0x3ff);
            sumBB -= 4 * ((swap2n >> 2 ) & 0x3ff);

            //sum +=  1 * input[column - 3];
            sumRR += 1 * ((swap3n >> 22) & 0x3ff);
            sumGG += 1 * ((swap3n >> 12) & 0x3ff);
            sumBB += 1 * ((swap3n >> 2 ) & 0x3ff);

            //sum +=  1 * input[column - 4];
            sumRR += 1 * ((swap4n >> 22) & 0x3ff);
            sumGG += 1 * ((swap4n >> 12) & 0x3ff);
            sumBB += 1 * ((swap4n >> 2 ) & 0x3ff);
        }
        break;
    }

    sumRR <<= shift;
    sumGG <<= shift;
    sumBB <<= shift;

    //sum +=  ROUNDING(sum,8);
    sumGG += ROUNDING(sumGG, 8);
    sumRR += ROUNDING(sumRR, 8);
    sumBB += ROUNDING(sumBB, 8);

    //sum = DivideByShift(sum, 3);
    sumGG = DivideByShift(sumGG, 3);
    sumRR = DivideByShift(sumRR, 3);
    sumBB = DivideByShift(sumBB, 3);

    //*(highptr++) = SATURATE(sum);
    *(highptrGG++) = SATURATE(sumGG);
    *(highptrRR++) = SATURATE(sumRR);
    *(highptrBB++) = SATURATE(sumBB);
}






#define CONVOLVE_SHIFT	1


void FilterHorizontalRow10bit16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass, int width, PIXEL *buffer)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m128i *input_ptr = (__m128i *)input;
    __m128i *lowpass_ptr;
    __m128i *highpass_ptr;
    __m128i input1_epi16;
    __m128i mask_epi16;
    __m128i three = _mm_set1_epi16(3);

    int highpass_value;

    // The highpass filter on the left border uses different coefficients
    sum = 0;
    sum +=  5 * ((input[column + 0] + 3) >> V210_HORIZONTAL_SHIFT);
    sum -= 11 * ((input[column + 1] + 3) >> V210_HORIZONTAL_SHIFT);
    sum +=  4 * ((input[column + 2] + 3) >> V210_HORIZONTAL_SHIFT);
    sum +=  4 * ((input[column + 3] + 3) >> V210_HORIZONTAL_SHIFT);
    sum -=  1 * ((input[column + 4] + 3) >> V210_HORIZONTAL_SHIFT);
    sum -=  1 * ((input[column + 5] + 3) >> V210_HORIZONTAL_SHIFT);
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    highpass_value = SATURATE(sum);

    // Set the input pointer for the fast loop
    input_ptr = (__m128i *)&input[column];

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);
    input1_epi16 = _mm_adds_epi16(input1_epi16, three);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowptr;
    highpass_ptr = (__m128i *)highptr;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpass_ptr));
    assert(ISALIGNED16(highpass_ptr));

    // Intialize the mask used for downsampling the convolution results
    mask_epi16 = _mm_set1_epi32(0x0000FFFF);

#if (1 && XMMOPT)
    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m128i input2_epi16;
        __m128i shift2_epi16;
        __m128i half_epi16;		// Half of the divisor for rounding
        __m128i sum1_epi16;
        __m128i sum2_epi16;
        __m128i sum1b_epi16;
        __m128i sum2b_epi16;
        __m128i low1_epi16;
        __m128i low2_epi16;
        __m128i tmp_epi16;


        /***** Process the first four output points *****/

        // Initialize the highpass sum
        sum1_epi16 = _mm_setzero_si128();



        // Apply the first filter coefficient to each pixel and sum the result

        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, tmp_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);
        input2_epi16 = _mm_adds_epi16(input2_epi16, three);

        // Initialize the lowpass sum
        low1_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, tmp_epi16);

        // Add adjacent points to compute the lowpass sum
        low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);
        low1_epi16 = _mm_subs_epi16(low1_epi16, three);
        low1_epi16 = _mm_srai_epi16(low1_epi16, V210_HORIZONTAL_SHIFT);

        // Expand the lowpass output points to a full doubleword
        low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
        low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum1b_epi16 = tmp_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, tmp_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, tmp_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, tmp_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
        sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

        sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

        // Expand the even output points to a full doubleword
        sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
        sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

        // The second eight input points become the current input points
        input1_epi16 = input2_epi16;


        /***** Process the second four output points *****/

        // Initialize the highpass sum
        sum2_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, tmp_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);
        input2_epi16 = _mm_adds_epi16(input2_epi16, three);

        // Initialize the lowpass sum
        low2_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, tmp_epi16);

        // Add adjacent points to compute the lowpass sum
        low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);
        low2_epi16 = _mm_subs_epi16(low2_epi16, three);
        low2_epi16 = _mm_srai_epi16(low2_epi16, V210_HORIZONTAL_SHIFT);

        // Expand the lowpass output points to a full doubleword
        low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
        low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum2b_epi16 = tmp_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, tmp_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, tmp_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        tmp_epi16 = _mm_srai_epi16(input1_epi16, V210_HORIZONTAL_SHIFT);
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, tmp_epi16);

        //DAN20050915 -- reversibility
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
        sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

        sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);

        // Expand the even output points to a full doubleword
        sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
        sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


        /***** Combine the output points *****/

        low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
        sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


        // Store the four lowpass output points
        _mm_store_si128(lowpass_ptr++, low1_epi16);

        // Get the last highpass coefficient in the group
        sum2_epi16 = _mm_srli_si128(sum1_epi16, 7 * 2);

        // Shift the extra highpass coefficient into the output
        sum1_epi16 = _mm_slli_si128(sum1_epi16, 1 * 2);
        sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

        // Save the last highpass coefficient for the next loop iteration
        highpass_value = _mm_cvtsi128_si32(sum2_epi16);

        // Store the four highpass output points
        _mm_store_si128(highpass_ptr++, sum1_epi16);

        // The second set of eight input pixels becomes the working set
        input1_epi16 = input2_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;

#else
    sum = input[column] + input[column + 1];
    *(lowptr++) = SATURATE(sum);
    *(highptr++) = SATURATE(highpass_value);
    column += 2;
#endif

    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        sum = (input[column] + input[column + 1] + 3) >> V210_HORIZONTAL_SHIFT;

        // Store the lowpass sum
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass sum
        sum = 0;
        sum -= (input[column - 2] + 3) >> V210_HORIZONTAL_SHIFT;
        sum -= (input[column - 1] + 3) >> V210_HORIZONTAL_SHIFT;
        sum += (input[column + 2] + 3) >> V210_HORIZONTAL_SHIFT;
        sum += (input[column + 3] + 3) >> V210_HORIZONTAL_SHIFT;
        sum += 4;
        sum >>= 3;
        sum += (input[column + 0] + 3) >> V210_HORIZONTAL_SHIFT;
        sum -= (input[column + 1] + 3) >> V210_HORIZONTAL_SHIFT;

        // Store the highpass sum
        *(highptr++) = SATURATE(sum);
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    sum = (input[column] + input[column + 1] + 3) >> V210_HORIZONTAL_SHIFT;

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * ((input[column + 0] + 3) >> V210_HORIZONTAL_SHIFT);
    sum -=  5 * ((input[column + 1] + 3) >> V210_HORIZONTAL_SHIFT);
    sum -=  4 * ((input[column - 1] + 3) >> V210_HORIZONTAL_SHIFT);
    sum -=  4 * ((input[column - 2] + 3) >> V210_HORIZONTAL_SHIFT);
    sum +=  1 * ((input[column - 3] + 3) >> V210_HORIZONTAL_SHIFT);
    sum +=  1 * ((input[column - 4] + 3) >> V210_HORIZONTAL_SHIFT);
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    *(highptr++) = SATURATE(sum);
}



// Apply the lowpass and highpass horizontal filters to one row of packed data
void FilterHorizontalRowYUV16s(uint8_t *input, PIXEL *lowpass, PIXEL *highpass,
                               int width, int channel, PIXEL *buffer, size_t buffer_size,
                               FRAME_INFO *frame, int precision, int limit_yuv, int conv_601_709)
{
    size_t row_size = width * sizeof(PIXEL);
    PIXEL *unpacking_buffer;
    //PIXEL *prescaling_buffer;
    int shift = precision - 8;

    //	assert(shift == 0 || shift == 2);

    // Round up the row size to an integral number of cache lines
    row_size = ALIGN(row_size, _CACHE_LINE_SIZE);

    // Check that the buffer is large enough to unpack and prescale the pixels
    //assert(2 * row_size <= buffer_size);
    assert(row_size <= buffer_size);

    //buffer_width = row_size/sizeof(PIXEL);

    // Allocate buffer space for unpacking and prescaling
    unpacking_buffer = buffer;
    //prescaling_buffer = &buffer[buffer_width];
    //prescaling_buffer = NULL;

    //unpacking_buffer = (PIXEL *)ALIGN16(unpacking_buffer);

    // Unpack the row of pixel values for the specified channel
    UnpackRowYUV16s(input, unpacking_buffer, width, channel, frame->format, shift, limit_yuv, conv_601_709);

    // Apply the horizontal wavelet filter to the row
    //FilterHorizontalRowPrescaled16s(unpacking_buffer, lowpass, highpass, width, prescaling_buffer);
    FilterHorizontalRow16s(unpacking_buffer, lowpass, highpass, width);
}


#if PREFETCH
volatile uint32_t dummy1 = 0;
#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))


//
//
//   WARNING-- maybe not revisible
//
//
void FilterHorizontalRowScaled16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
                                  int width, int lowpass_scale, int highpass_scale)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

//
//
//   WARNING-- maybe not revisible
//
//
// Apply the lowpass and highpass horizontal filters to one row and scale the results
void FilterHorizontalRowScaled16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
                                  int width, int lowpass_scale, int highpass_scale)
{
    int column_step = 8;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m64 *input_ptr = (__m64 *)input;
    __m64 *lowpass_ptr;
    __m64 *highpass_ptr;
    __m64 input1_pi16;

    // Process the first highpass column as a special case
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    *(highptr++) = SATURATE(sum);

    // Check that the pointer to the next group of pixels is properly aligned
    //assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_pi16 = *(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m64 *)lowpass;
    highpass_ptr = (__m64 *)highptr;

    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m64 input2_pi16;
        __m64 shift2_pi16;
        __m64 mask_pi16;
        __m64 sign_pi16;
        __m64 half_pi16;		// Half of the divisor for rounding
        //__m64 lsb_pi16;		// Least significant bit for rounding
        __m64 sum1_pi16;
        __m64 sum2_pi16;
        __m64 sum1b_pi16;
        __m64 sum2b_pi16;
        __m64 low1_pi16;
        __m64 low2_pi16;


        // First two output points //

        // Initialize the highpass sum
        sum1_pi16 = _mm_setzero_si64();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

        // Load the next four pixels
        input2_pi16 = *(input_ptr++);

        // Initialize the lowpass sum
        low1_pi16 = input1_pi16;

        // Shift the first pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

        // Add adjacent points to compute the lowpass sum
        low1_pi16 = _mm_adds_pi16(low1_pi16, input1_pi16);

        // Expand the lowpass output points to a full doubleword
        low1_pi16 = _mm_slli_pi32(low1_pi16, 16);
        low1_pi16 = _mm_srai_pi32(low1_pi16, 16);

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum1b_pi16 = input1_pi16;

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum1b_pi16 = _mm_subs_pi16(sum1b_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = input2_pi16;

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

        //DAN20050915 -- reversibility
        half_pi16 = _mm_set1_pi16(4);
        sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
        sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

        sum1_pi16 = _mm_adds_pi16(sum1_pi16, sum1b_pi16);


        // Expand the even output points to a full doubleword
        sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
        sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);

        // The second four input points become the first four input points
        input1_pi16 = input2_pi16;


        // Second two output points //

        // Initialize the highpass sum
        sum2_pi16 = _mm_setzero_si64();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

        // Load the next four pixels
        input2_pi16 = *(input_ptr++);

        // Initialize the lowpass sum
        low2_pi16 = input1_pi16;

        // Shift the first pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

        // Add adjacent points to compute the lowpass sum
        low2_pi16 = _mm_adds_pi16(low2_pi16, input1_pi16);

        // Expand the lowpass output points to a full doubleword
        low2_pi16 = _mm_slli_pi32(low2_pi16, 16);
        low2_pi16 = _mm_srai_pi32(low2_pi16, 16);

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum2b_pi16 = input1_pi16;

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum2b_pi16 = _mm_subs_pi16(sum2b_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = input2_pi16;

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

        //DAN20050915 -- reversibility
        half_pi16 = _mm_set1_pi16(4);
        sum2_pi16 = _mm_adds_pi16(sum2_pi16, half_pi16);
        sum2_pi16 = _mm_srai_pi16(sum2_pi16, 3);

        sum2_pi16 = _mm_adds_pi16(sum2_pi16, sum2b_pi16);


        // Expand the even output points to a full doubleword
        sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
        sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


        // Combine the output points //

        low1_pi16 = _mm_packs_pi32(low1_pi16, low2_pi16);
        sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);


        half_pi16 = _mm_set1_pi16(4);
        sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
        sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

        /*	if (lowpass_scale > 0)
        	{
        		// Scale the lowpass results
        		half_pi16 = _mm_set1_pi16(1 << (lowpass_scale - 1));
        		low1_pi16 = _mm_adds_pi16(low1_pi16, half_pi16);
        		low1_pi16 = _mm_sra_pi16(low1_pi16, _mm_cvtsi32_si64(lowpass_scale));
        	}*/

        // Store the four lowpass output points
        *(lowpass_ptr++) = low1_pi16;

        /*	if (highpass_scale > 0)
        	{
        		// Scale the highpass results
        		half_pi16 = _mm_set1_pi16(1 << (highpass_scale - 1));
        		sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
        		sum1_pi16 = _mm_sra_pi16(sum1_pi16, _mm_cvtsi32_si64(highpass_scale));
        	}*/

        // Store the four highpass output points
        *(highpass_ptr++) = sum1_pi16;

        // The second set of eight input pixels becomes the working set
        input1_pi16 = input2_pi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;

    // The lowpass results are behind by one column
    sum = input[column] + input[column + 1];

    /*	if (lowpass_scale > 0)
    	{
    		// Scale the lowpass results
    		sum += (1 << (lowpass_scale - 1));
    		sum >>= lowpass_scale;
    	}*/

    *(lowptr++) = SATURATE(sum);

    // The fast processing loop is out of phase by two columns
    if (column < last_column) column += 2;
    else highptr--;

    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        sum = input[column] + input[column + 1];

        /*	if (lowpass_scale > 0)
        	{
        		// Scale the lowpass results
        		sum += (1 << (lowpass_scale - 1));
        		sum >>= lowpass_scale;
        	}*/

        // Store the lowpass sum
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass sum
        sum = 0;
        sum -= input[column - 2];
        sum -= input[column - 1];
        sum += input[column + 2];
        sum += input[column + 3];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum += input[column + 0];
        sum -= input[column + 1];

        /*	if (highpass_scale > 0)
        	{
        		// Scale the highpass results
        		sum += (1 << (highpass_scale - 1));
        		sum >>= highpass_scale;
        	}*/

        // Store the highpass sum
        *(highptr++) = SATURATE(sum);
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    sum = input[column] + input[column + 1];

    /*	if (lowpass_scale > 0)
    	{
    		// Scale the lowpass results
    		sum += (1 << (lowpass_scale - 1));
    		sum >>= lowpass_scale;
    	}*/

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    /*	if (highpass_scale > 0)
    	{
    		// Scale the highpass results
    		sum += (1 << (highpass_scale - 1));
    		sum >>= highpass_scale;
    	}*/

    *(highptr++) = SATURATE(sum);

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

//
//
//   WARNING-- maybe not revisible
//
//
// Apply the lowpass and highpass horizontal filters to one row and scale the results.
// The lowpass and highpass scale factors are either zero or the frame prescale and
// are not used if the compile-time constant for the frame prescale is zero.
void FilterHorizontalRowScaled16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
                                  int width, int lowpass_scale, int highpass_scale)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum;
    //int32_t lsb;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m128i *input_ptr = (__m128i *)input;
    __m128i *lowpass_ptr;
    __m128i *highpass_ptr;
    __m128i input1_epi16;

    int highpass_value;

    // Prescaling is performed by quantization
    assert(lowpass_scale == 0 && highpass_scale == 0);

#if _PREROLL

    // Preprocess the first lowpass and highpass columns for memory alignment

#if 0
    sum = input[column] + input[column + 1];
    *(lowptr++) = SATURATE(sum);
#endif

    // The first highpass column is a special case
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    //*(highptr++) = SATURATE(sum);
    highpass_value = SATURATE(sum);

#if 0
    column += 2;

    while (!ISALIGNED16(highptr))
    {
        sum = input[column] + input[column + 1];
        *(lowptr++) = SATURATE(sum);

        sum = 0;
        sum -= input[column - 2];
        sum -= input[column - 1];
        sum += input[column + 2];
        sum += input[column + 3];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum += input[column + 0];
        sum -= input[column + 1];

        *(highptr++) = SATURATE(sum);

        column += 2;
    }
#endif

    // Set the input pointer for the fast loop
    input_ptr = (__m128i *)&input[column];

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowptr;
    highpass_ptr = (__m128i *)highptr;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpass_ptr));
    assert(ISALIGNED16(highpass_ptr));

#else

    // Process the first highpass column as a special case
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    *(highptr++) = SATURATE(sum);

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowpass;
    highpass_ptr = (__m128i *)highptr;

#endif


    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m128i input2_epi16;
        __m128i shift2_epi16;
        //__m128i mask_epi16;
        //__m128i sign_epi16;
        __m128i half_epi16;		// Half of the divisor for rounding
        //__m128i lsb_epi16;		// Least significant bit for rounding
        __m128i sum1_epi16;
        __m128i sum2_epi16;
        __m128i sum1b_epi16;
        __m128i sum2b_epi16;
        __m128i low1_epi16;
        __m128i low2_epi16;

        /***** Process the first four output points *****/

        // Initialize the highpass sum
        sum1_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low1_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
        low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum1b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);


        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
        sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

        sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);


        // Expand the even output points to a full doubleword
        sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
        sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

        // The second eight input points become the current input points
        input1_epi16 = input2_epi16;


        /***** Process the second four output points *****/

        // Initialize the highpass sum
        sum2_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low2_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
        low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum2b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
        sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

        sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);

        // Expand the even output points to a full doubleword
        sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
        sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


        /***** Combine the output points *****/

        low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
        sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


        // Store the four lowpass output points
        _mm_store_si128(lowpass_ptr++, low1_epi16);

#if _PREROLL
        // Get the last highpass coefficient in the group
        sum2_epi16 = _mm_srli_si128(sum1_epi16, 7 * 2);

        // Shift the extra highpass coefficient into the output
        sum1_epi16 = _mm_slli_si128(sum1_epi16, 1 * 2);
        sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

        // Save the last highpass coefficient for the next loop iteration
        highpass_value = _mm_cvtsi128_si32(sum2_epi16);

        // Store the four highpass output points
        _mm_store_si128(highpass_ptr++, sum1_epi16);
#else
        // Store the four highpass output points (may be unaligned without preroll)
        _mm_storeu_si128(highpass_ptr++, sum1_epi16);
#endif

        // The second set of eight input pixels becomes the working set
        input1_epi16 = input2_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;

#if !_PREROLL
    // The lowpass results are behind by one column
    sum = input[column] + input[column + 1];

#if 0
    if (lowpass_scale > 0)
    {
        // Scale the lowpass results
        sum += (1 << (lowpass_scale - 1));
        sum >>= lowpass_scale;
    }
#endif

    *(lowptr++) = SATURATE(sum);

    // The fast processing loop is out of phase by two columns
    if (column < last_column) column += 2;
    else highptr--;

#endif

    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        sum = input[column] + input[column + 1];

#if 0
        if (lowpass_scale > 0)
        {
            // Scale the lowpass results
            sum += (1 << (lowpass_scale - 1));
            sum >>= lowpass_scale;
        }
#endif
        // Store the lowpass sum
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass sum
        sum = 0;
        sum -= input[column - 2];
        sum -= input[column - 1];
        sum += input[column + 2];
        sum += input[column + 3];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum += input[column + 0];
        sum -= input[column + 1];
#if 0
        if (highpass_scale > 0)
        {
            // Scale the highpass results
            sum += (1 << (highpass_scale - 1));
            sum >>= highpass_scale;
        }
#endif
        // Store the highpass sum
        *(highptr++) = SATURATE(sum);
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    sum = input[column] + input[column + 1];

#if 0
    if (lowpass_scale > 0)
    {
        // Scale the lowpass results
        sum += (1 << (lowpass_scale - 1));
        sum >>= lowpass_scale;
    }
#endif

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

#if 0
    if (highpass_scale > 0)
    {
        // Scale the highpass results
        sum += (1 << (highpass_scale - 1));
        sum >>= highpass_scale;
    }
#endif

    *(highptr++) = SATURATE(sum);
}

#endif  //P4





//TODO:  get rid of the global.
extern int g_midpoint_prequant; //HACK


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))
//
//
//   WARNING-- maybe not revisible
//
//
void FilterHorizontalRowScaled16sDifferenceFiltered(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
        int width, int lowpass_scale, int highpass_scale, int lp_divisor)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif
//
//
//   WARNING-- maybe not revisible
//
//
// Apply the lowpass and highpass horizontal filters to one row and scale the results
void FilterHorizontalRowScaled16sDifferenceFiltered(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
        int width, int lowpass_scale, int highpass_scale,
        int lowpass_divisor)
{
    int column_step = 8;				// Number of input pixels processed per loop iteration
    int last_column = width - 2;		// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum, lastsum;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m64 *input_ptr = (__m64 *)input;
    __m64 *lowpass_ptr;
    __m64 *highpass_ptr;
    __m64 input1_pi16;

    int lastsumvalue = 0;
    int delta;
    int highpass_value;

    // Change division to multiplication by a fraction
    int multiplier = (uint32_t)(1 << 16) / lowpass_divisor;
    __m64 quant_pi16 = _mm_set1_pi16(multiplier);
    __m64 sign_pi16;
    __m64 offset_pi16 = _mm_set1_pi16(0);

#if MIDPOINT_PREQUANT
    int prequant_midpoint = 0;// divisor/2;
    if (g_midpoint_prequant >= 2 && g_midpoint_prequant < 9)
        prequant_midpoint = lowpass_divisor / g_midpoint_prequant;

    offset_pi16 = _mm_set1_pi16(prequant_midpoint);
#endif

    // Process the first highpass column as a special case
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    *(highptr++) = SATURATE(sum);

    // Check that the pointer to the next group of pixels is properly aligned
    //assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_pi16 = *(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m64 *)lowpass;
    highpass_ptr = (__m64 *)highptr;

    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m64 input2_pi16;
        __m64 shift2_pi16;
        __m64 mask_pi16;
        __m64 sign_pi16;
        __m64 half_pi16;		// Half of the divisor for rounding
        __m64 sum1_pi16;
        __m64 sum2_pi16;
        __m64 low1_pi16;
        __m64 low2_pi16;
        __m64 temp_pi16;
        __m64 sum1b_pi16;
        __m64 sum2b_pi16;


        /***** First two output points *****/

        // Initialize the highpass sum
        sum1_pi16 = _mm_setzero_si64();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

        // Load the next four pixels
        input2_pi16 = *(input_ptr++);

        // Initialize the lowpass sum
        low1_pi16 = input1_pi16;

        // Shift the first pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the second filter coefficient to each pixel and sum the result
        //sum -= input[column - 1];
        sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

        // Add adjacent points to compute the lowpass sum
        low1_pi16 = _mm_adds_pi16(low1_pi16, input1_pi16);

        // Expand the lowpass output points to a full doubleword
        low1_pi16 = _mm_slli_pi32(low1_pi16, 16);
        low1_pi16 = _mm_srai_pi32(low1_pi16, 16);

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum1b_pi16 = input1_pi16;

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum1b_pi16 = _mm_subs_pi16(sum1b_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = input2_pi16;

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

        //DAN20050915 -- reversibility
        half_pi16 = _mm_set1_pi16(4);
        sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
        sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

        sum1_pi16 = _mm_adds_pi16(sum1_pi16, sum1b_pi16);

        // Expand the even output points to a full doubleword
        sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
        sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);

        // The second four input points become the first four input points
        input1_pi16 = input2_pi16;


        /***** Second two output points *****/

        // Initialize the highpass sum
        sum2_pi16 = _mm_setzero_si64();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

        // Load the next four pixels
        input2_pi16 = *(input_ptr++);

        // Initialize the lowpass sum
        low2_pi16 = input1_pi16;

        // Shift the first pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

        // Add adjacent points to compute the lowpass sum
        low2_pi16 = _mm_adds_pi16(low2_pi16, input1_pi16);

        // Expand the lowpass output points to a full doubleword
        low2_pi16 = _mm_slli_pi32(low2_pi16, 16);
        low2_pi16 = _mm_srai_pi32(low2_pi16, 16);

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum2b_pi16 = input1_pi16;

        // Shift the next pixel from the second set into the working set
        shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
        input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum2b_pi16 = _mm_subs_pi16(sum2b_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = input2_pi16;

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

        // Shift the next pixel from the second set into the working set
        input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

        //DAN20050915 -- reversibility
        sum2_pi16 = _mm_adds_pi16(sum2_pi16, half_pi16);
        sum2_pi16 = _mm_srai_pi16(sum2_pi16, 3);

        sum2_pi16 = _mm_adds_pi16(sum2_pi16, sum2b_pi16);

        // Expand the even output points to a full doubleword
        sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
        sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


        /***** Combine the output points *****/

        low1_pi16 = _mm_packs_pi32(low1_pi16, low2_pi16);
        sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);

        if (lowpass_divisor > 1)
        {
            ///////////////////////////////////////////////////
            // Quantize the passlow BEFORE it is differenced.//
            ///////////////////////////////////////////////////

            // Compute the absolute value
            sign_pi16 = _mm_cmpgt_pi16(_mm_setzero_si64(), low1_pi16);
            low1_pi16 = _mm_xor_si64(low1_pi16, sign_pi16);
            low1_pi16 = _mm_sub_pi16(low1_pi16, sign_pi16);

#if MIDPOINT_PREQUANT
            // Add the prequant_midpoint for quantization rounding
            low1_pi16 = _mm_add_pi16(low1_pi16, offset_pi16);
#endif
            // Multiply by the quantization factor
            low1_pi16 = _mm_mulhi_pu16(low1_pi16, quant_pi16);

            // Restore the sign
            low1_pi16 = _mm_xor_si64(low1_pi16, sign_pi16);
            low1_pi16 = _mm_sub_pi16(low1_pi16, sign_pi16);
        }

        ///////////////////////////////////////////////////
        // New differencing engine                       //
        // this code makes the low-pass difference data. //
        ///////////////////////////////////////////////////
        temp_pi16 = _mm_slli_si64(low1_pi16, 16);
        temp_pi16 = _mm_insert_pi16(temp_pi16, lastsumvalue, 0);
        lastsumvalue = _mm_extract_pi16(low1_pi16, 3);
        low1_pi16 = _mm_sub_pi16(low1_pi16, temp_pi16);

        // Store the four lowpass output points
        *(lowpass_ptr++) = low1_pi16;

#if 0
        if (highpass_scale > 0)
        {
            // Scale the highpass results
            half_pi16 = _mm_set1_pi16(1 << (highpass_scale - 1));
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
            sum1_pi16 = _mm_sra_pi16(sum1_pi16, _mm_cvtsi32_si64(highpass_scale));
        }
#endif

        // Store the four highpass output points
        *(highpass_ptr++) = sum1_pi16;

        // The second set of eight input pixels becomes the working set
        input1_pi16 = input2_pi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;


    if (column < last_column)
    {
        int sign, tmp, lastsum = 0;

        if (column > 0)
        {
            lastsum = input[column - 2] + input[column - 1]; // previous sum
            if (lastsum < 0)
            {
                lastsum = -lastsum;
#if MIDPOINT_PREQUANT
                lastsum += prequant_midpoint;
#endif
                lastsum *= multiplier; // quantize
                lastsum >>= 16;
                lastsum = -lastsum;
            }
            else
            {
#if MIDPOINT_PREQUANT
                lastsum += prequant_midpoint;
#endif
                lastsum *= multiplier; // quantize
                lastsum >>= 16;
            }
        }

        // Process the last group of columns as a special case to handle the border
        for (; column < last_column; column += 2)
        {
            // Compute the lowpass sum
            sum = input[column] + input[column + 1];

            if (sum < 0)
            {
                sum = -sum;
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
                sum = -sum;
            }
            else
            {
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
            }

            tmp = sum;
            sum -= lastsum;
            lastsum = tmp;

            // Store the lowpass sum
            *(lowptr++) = SATURATE(sum);

            // Compute the highpass sum
            sum = 0;
            sum -= input[column - 2];
            sum -= input[column - 1];
            sum += input[column + 2];
            sum += input[column + 3];
            sum += 4;
            sum >>= 3;
            sum += input[column + 0];
            sum -= input[column + 1];

            // Store the highpass sum
            *(highptr++) = SATURATE(sum);
        }
    }

    // Should be at the last column
    assert(column == last_column);

    // Compute the last lowpass value
    lastsum = (input[column - 2] + input[column + 1 - 2]);
    if (lastsum < 0)
    {
        lastsum = -lastsum;
#if MIDPOINT_PREQUANT
        lastsum += prequant_midpoint;
#endif
        lastsum *= multiplier; // quantize
        lastsum >>= 16;
        lastsum = -lastsum;
    }
    else
    {
#if MIDPOINT_PREQUANT
        lastsum += prequant_midpoint;
#endif
        lastsum *= multiplier; // quantize
        lastsum >>= 16;
    }


    sum = (input[column] + input[column + 1]);
    if (sum < 0)
    {
        sum = -sum;
#if MIDPOINT_PREQUANT
        sum += prequant_midpoint;
#endif
        sum *= multiplier; // quantize
        sum >>= 16;
        sum = -sum;
    }
    else
    {
#if MIDPOINT_PREQUANT
        sum += prequant_midpoint;
#endif
        sum *= multiplier; // quantize
        sum >>= 16;
    }

    sum -= lastsum;

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    *(highptr++) = SATURATE(sum);

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

void FilterHorizontalRowScaled16sDifferenceFiltered(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
        int width, int lowpass_scale, int highpass_scale, int lp_divisor)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width;			// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum, lastsum;
    //int32_t lsb;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m128i *input_ptr = (__m128i *)input;
    __m128i *lowpass_ptr;
    __m128i *highpass_ptr;
    __m128i input1_epi16;
    int lastsumvalue = 0;

    int highpass_value;

    __m128i quant_epi16;
    __m128i offset_epi16;
    __m128i zero_epi16;
    //__m128i sign_epi16;

    int multiplier;

#if MIDPOINT_PREQUANT
    int prequant_midpoint = 0;// divisor/2;
    if (g_midpoint_prequant >= 2 && g_midpoint_prequant < 9)
        prequant_midpoint = lp_divisor / g_midpoint_prequant;
#endif

    // Change division to multiplication by a fraction
    multiplier = (uint32_t)(1 << 16) / lp_divisor;
    quant_epi16 = _mm_set1_epi16(multiplier);
    zero_epi16 = _mm_set1_epi16(0);

#if MIDPOINT_PREQUANT
    offset_epi16 = _mm_set1_epi16(prequant_midpoint);
#endif


    // Prescaling is performed by quantization
    assert(lowpass_scale == 0 && highpass_scale == 0);

    // Preprocess the first lowpass and highpass columns for memory alignment

    // The first highpass column is a special case
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    //*(highptr++) = SATURATE(sum);
    highpass_value = SATURATE(sum);


    // Set the input pointer for the fast loop
    input_ptr = (__m128i *)&input[column];

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowptr;
    highpass_ptr = (__m128i *)highptr;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpass_ptr));
    assert(ISALIGNED16(highpass_ptr));


#if (1 && XMMOPT) // SSE2
    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m128i input2_epi16;
        __m128i shift2_epi16;
        __m128i sign_epi16;
        __m128i half_epi16;		// Half of the divisor for rounding
        __m128i sum1_epi16;
        __m128i sum2_epi16;
        __m128i sum1b_epi16;
        __m128i sum2b_epi16;
        __m128i low1_epi16;
        __m128i low2_epi16;
        __m128i tmp_epi16;


        /***** Process the first four output points *****/

        // Initialize the highpass sum
        sum1_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low1_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
        low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_adds_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum1_epi16 = _mm_subs_epi16(sum1_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
        sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

        sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

        // Expand the even output points to a full doubleword
        sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
        sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

        // The second eight input points become the current input points
        input1_epi16 = input2_epi16;


        /***** Process the second four output points *****/

        // Initialize the highpass sum
        sum2_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low2_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
        low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_adds_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        //sum2_epi16 = _mm_subs_epi16(sum2_epi16, _mm_slli_epi16(input1_epi16, 3));
        sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
        sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

        sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


        // Expand the even output points to a full doubleword
        sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
        sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


        /***** Combine the output points *****/

        low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
        sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);


        ///////////////////////////////////////////////////
        // Quantize the passlow BEFORE it is differenced.//
        ///////////////////////////////////////////////////

        if (lp_divisor > 1) // Fix for LOSSLESS
        {
            // Compute the absolute value
            sign_epi16 = _mm_cmpgt_epi16(zero_epi16, low1_epi16);
            low1_epi16 = _mm_xor_si128(low1_epi16, sign_epi16);
            low1_epi16 = _mm_sub_epi16(low1_epi16, sign_epi16);

#if MIDPOINT_PREQUANT
            // Add the prequant_midpoint for quantization rounding
            low1_epi16 = _mm_add_epi16(low1_epi16, offset_epi16);
#endif
            // Multiply by the quantization factor
            low1_epi16 = _mm_mulhi_epu16(low1_epi16, quant_epi16);

            // Restore the sign
            low1_epi16 = _mm_xor_si128(low1_epi16, sign_epi16);
            low1_epi16 = _mm_sub_epi16(low1_epi16, sign_epi16);
        }

        ///////////////////////////////////////////////////
        // New differencing engine                       //
        // this code makes the low-pass difference data. //
        ///////////////////////////////////////////////////
        tmp_epi16 = _mm_slli_si128(low1_epi16, 1 * 2);
        tmp_epi16 = _mm_insert_epi16(tmp_epi16, lastsumvalue, 0);
        lastsumvalue = _mm_extract_epi16(low1_epi16, 7);
        low1_epi16 = _mm_sub_epi16(low1_epi16, tmp_epi16);

        // Store the four lowpass output points
        _mm_store_si128(lowpass_ptr++, low1_epi16);

        // Get the last highpass coefficient in the group
        sum2_epi16 = _mm_srli_si128(sum1_epi16, 7 * 2);

        // Shift the extra highpass coefficient into the output
        sum1_epi16 = _mm_slli_si128(sum1_epi16, 1 * 2);
        sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

        // Save the last highpass coefficient for the next loop iteration
        highpass_value = _mm_cvtsi128_si32(sum2_epi16);

        // Store the four highpass output points
        _mm_store_si128(highpass_ptr++, sum1_epi16);

        // The second set of eight input pixels becomes the working set
        input1_epi16 = input2_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;
#endif

#if !_PREROLL
    // The lowpass results are behind by one column
    sum = input[column] + input[column + 1];

    *(lowptr++) = SATURATE(sum);

    // The fast processing loop is out of phase by two columns
    if (column < last_column)
        column += 2;
    else
        highptr--;
#endif

    /* // used for test non-MMX
    	if(column == 0)
    	{
    		sum = input[column] + input[column + 1];

    		*(lowptr++) = SATURATE(sum);
    		*(highptr++) = SATURATE(highpass_value);

    		column += 2;
    	}
    */

    if (column < last_column)
    {
        int tmp, lastsum = 0;

        if (column > 0)
        {
            lastsum = input[column - 2] + input[column - 1]; // previous sum
            if (lastsum < 0)
            {
                lastsum = -lastsum;
#if MIDPOINT_PREQUANT
                lastsum += prequant_midpoint;
#endif
                lastsum *= multiplier; // quantize
                lastsum >>= 16;
                lastsum = -lastsum;
            }
            else
            {
#if MIDPOINT_PREQUANT
                lastsum += prequant_midpoint;
#endif
                lastsum *= multiplier; // quantize
                lastsum >>= 16;
            }
        }

        // Process the last group of columns as a special case to handle the border
        for (; column < last_column; column += 2)
        {
            // Compute the lowpass sum
            sum = input[column] + input[column + 1];

            if (sum < 0)
            {
                sum = -sum;
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
                sum = -sum;
            }
            else
            {
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
            }

            tmp = sum;
            sum -= lastsum;
            lastsum = tmp;

            // Store the lowpass sum
            *(lowptr++) = SATURATE(sum);

            // Compute the highpass sum
            sum = 0;
            sum -= input[column - 2];
            sum -= input[column - 1];
            sum += input[column + 2];
            sum += input[column + 3];
            sum += 4;
            sum >>= 3;
            sum += input[column + 0];
            sum -= input[column + 1];

            // Store the highpass sum
            *(highptr++) = SATURATE(sum);
        }
    }

    // Should be at the last column
    assert(column == last_column);

    //DAN20050503 this the point should was missing for for fix the end condition so that is would over right other buffer data.
    // if is only require when push the SSE/MMX to process the very last pixel in the row (like this version.)
    column = last_column - 2; // Redo the last two pixels for the edge
    highptr--;
    lowptr--;

    // Compute the last lowpass value
    lastsum = (input[column - 2] + input[column + 1 - 2]);
    if (lastsum < 0)
    {
        lastsum = -lastsum;
#if MIDPOINT_PREQUANT
        lastsum += prequant_midpoint;
#endif
        lastsum *= multiplier; // quantize
        lastsum >>= 16;
        lastsum = -lastsum;
    }
    else
    {
#if MIDPOINT_PREQUANT
        lastsum += prequant_midpoint;
#endif
        lastsum *= multiplier; // quantize
        lastsum >>= 16;
    }


    sum = (input[column] + input[column + 1]);
    if (sum < 0)
    {
        sum = -sum;
#if MIDPOINT_PREQUANT
        sum += prequant_midpoint;
#endif
        sum *= multiplier; // quantize
        sum >>= 16;
        sum = -sum;
    }
    else
    {
#if MIDPOINT_PREQUANT
        sum += prequant_midpoint;
#endif
        sum *= multiplier; // quantize
        sum >>= 16;
    }

    sum -= lastsum;

    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    *(highptr++) = SATURATE(sum);
}


#endif // _PROCESSOR_PENTIUM_4


void FilterHorizontalRowQuant16s(PIXEL *input, PIXEL *lowpass, PIXEL *highpass,
                                 int width, int lp_div, int hp_div)
{
    int column_step = 16;				// Number of input pixels processed per loop iteration
    int last_column = width;//DAN08092004  - 2;		// Column at which right border processing is done
    int sign = 1;

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    int32_t sum;
    //int32_t lsb;

    // Start at the left end of the row
    PIXEL *lowptr = lowpass;
    PIXEL *highptr = highpass;
    int column = 0;

    __m128i *input_ptr = (__m128i *)input;
    __m128i *lowpass_ptr;
    __m128i *highpass_ptr;
    __m128i input1_epi16;

    int highpass_value;

    // Prescaling is performed by quantization

    uint32_t lp_multiplier = (uint32_t)(1 << 16) / lp_div;
    uint32_t hp_multiplier = (uint32_t)(1 << 16) / hp_div;

    int lp_prequant_midpoint = lp_div / 2;
    int hp_prequant_midpoint = hp_div / 2;

    __m128i lp_quant_epi16 = _mm_set1_epi16(lp_multiplier);
    __m128i hp_quant_epi16 = _mm_set1_epi16(hp_multiplier);

    __m128i lp_offset_epi16 = _mm_set1_epi16(lp_prequant_midpoint);
    __m128i hp_offset_epi16 = _mm_set1_epi16(hp_prequant_midpoint);
    __m128i zero_si128 = _mm_setzero_si128();


    // Preprocess the first lowpass and highpass columns for memory alignment

    // The first highpass column is a special case
    sum = 0;
    sum +=  5 * input[column + 0];
    sum -= 11 * input[column + 1];
    sum +=  4 * input[column + 2];
    sum +=  4 * input[column + 3];
    sum -=  1 * input[column + 4];
    sum -=  1 * input[column + 5];
    sum += ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);
    //*(highptr++) = SATURATE(sum);
    highpass_value = SATURATE(sum);


    // Set the input pointer for the fast loop
    input_ptr = (__m128i *)&input[column];

    // Check that the pointer to the next group of pixels is properly aligned
    assert(ISALIGNED16(input_ptr));

    // Preload the first set of four pixels for fast processing
    input1_epi16 = _mm_load_si128(input_ptr++);

    // Initialize the output pointers
    lowpass_ptr = (__m128i *)lowptr;
    highpass_ptr = (__m128i *)highptr;

    // Check that the output pointers are properly aligned
    assert(ISALIGNED16(lowpass_ptr));
    assert(ISALIGNED16(highpass_ptr));


    // Process two sets of four input pixels to get one set of four output pixels
    for (; column < post_column; column += column_step)
    {
        __m128i input2_epi16;
        __m128i shift2_epi16;
        __m128i half_epi16;		// Half of the divisor for rounding
        //__m128i lsb_epi16;		// Least significant bit for rounding
        __m128i sum1_epi16;
        __m128i sum2_epi16;
        __m128i low1_epi16;
        __m128i low2_epi16;
        __m128i sign1_epi16;

        __m128i sum1b_epi16;
        __m128i sum2b_epi16;


        /***** Process the first four output points *****/

        // Initialize the highpass sum
        sum1_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low1_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_subs_epi16(sum1_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low1_epi16 = _mm_adds_epi16(low1_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low1_epi16 = _mm_slli_epi32(low1_epi16, 16);
        low1_epi16 = _mm_srai_epi32(low1_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum1b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum1b_epi16 = _mm_subs_epi16(sum1b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum1_epi16 = _mm_adds_epi16(sum1_epi16, half_epi16);
        sum1_epi16 = _mm_srai_epi16(sum1_epi16, 3);

        sum1_epi16 = _mm_adds_epi16(sum1_epi16, sum1b_epi16);

        // Expand the even output points to a full doubleword
        sum1_epi16 = _mm_slli_epi32(sum1_epi16, 16);
        sum1_epi16 = _mm_srai_epi32(sum1_epi16, 16);

        // The second eight input points become the current input points
        input1_epi16 = input2_epi16;


        /***** Process the second four output points *****/

        // Initialize the highpass sum
        sum2_epi16 = _mm_setzero_si128();

        // Apply the first filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Check that the pointer to the next group of pixels is properly aligned
        assert(ISALIGNED16(input_ptr));

        // Load the next eight pixels
        input2_epi16 = _mm_load_si128(input_ptr++);

        // Initialize the lowpass sum
        low2_epi16 = input1_epi16;

        // Shift the first pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the second filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_subs_epi16(sum2_epi16, input1_epi16);

        // Add adjacent points to compute the lowpass sum
        low2_epi16 = _mm_adds_epi16(low2_epi16, input1_epi16);

        // Expand the lowpass output points to a full doubleword
        low2_epi16 = _mm_slli_epi32(low2_epi16, 16);
        low2_epi16 = _mm_srai_epi32(low2_epi16, 16);

        // Shift the second pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the third filter coefficient to each pixel and sum the result
        sum2b_epi16 = input1_epi16;

        // Shift the third pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fourth filter coefficient to each pixel and sum the result
        sum2b_epi16 = _mm_subs_epi16(sum2b_epi16, input1_epi16);

        // Shift the fourth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the fifth filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        // Shift the fifth pixel from the second set into the working set
        shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
        input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
        input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

        // Apply the sixth (last) filter coefficient to each pixel and sum the result
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, input1_epi16);

        //DAN20050915 -- reversibility
        half_epi16 = _mm_set1_epi16(4);
        sum2_epi16 = _mm_adds_epi16(sum2_epi16, half_epi16);
        sum2_epi16 = _mm_srai_epi16(sum2_epi16, 3);

        sum2_epi16 = _mm_adds_epi16(sum2_epi16, sum2b_epi16);


        // Expand the even output points to a full doubleword
        sum2_epi16 = _mm_slli_epi32(sum2_epi16, 16);
        sum2_epi16 = _mm_srai_epi32(sum2_epi16, 16);


        /***** Combine the output points *****/

        low1_epi16 = _mm_packs_epi32(low1_epi16, low2_epi16);
        sum1_epi16 = _mm_packs_epi32(sum1_epi16, sum2_epi16);

        // Do the quantization
        if (lp_div > 1)
        {
            sign1_epi16 = _mm_cmpgt_epi16(zero_si128, low1_epi16);

            // Compute the absolute value
            low1_epi16 = _mm_xor_si128(low1_epi16, sign1_epi16);
            low1_epi16 = _mm_sub_epi16(low1_epi16, sign1_epi16);

            // Add the prequant_midpoint for quantization rounding
            low1_epi16 = _mm_add_epi16(low1_epi16, lp_offset_epi16);

            // Multiply by the quantization factor
            low1_epi16 = _mm_mulhi_epu16(low1_epi16, lp_quant_epi16);

            // Restore the sign
            low1_epi16 = _mm_xor_si128(low1_epi16, sign1_epi16);
            low1_epi16 = _mm_sub_epi16(low1_epi16, sign1_epi16);

        }



        // Store the four lowpass output points
        _mm_store_si128(lowpass_ptr++, low1_epi16);

#if _PREROLL
        // Get the last highpass coefficient in the group
        sum2_epi16 = _mm_srli_si128(sum1_epi16, 7 * 2);

        // Shift the extra highpass coefficient into the output
        sum1_epi16 = _mm_slli_si128(sum1_epi16, 1 * 2);
        sum1_epi16 = _mm_insert_epi16(sum1_epi16, highpass_value, 0);

        // Save the last highpass coefficient for the next loop iteration
        highpass_value = _mm_cvtsi128_si32(sum2_epi16);



        // Do the quantization
        sign1_epi16 = _mm_cmpgt_epi16(zero_si128, sum1_epi16);

        // Compute the absolute value
        sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
        sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);

        // Add the prequant_midpoint for quantization rounding
        sum1_epi16 = _mm_add_epi16(sum1_epi16, hp_offset_epi16);

        // Multiply by the quantization factor
        sum1_epi16 = _mm_mulhi_epu16(sum1_epi16, hp_quant_epi16);

        // Restore the sign
        sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
        sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);




        // Store the four highpass output points
        _mm_store_si128(highpass_ptr++, sum1_epi16);
#else


        // Do the quantization
        sign1_epi16 = _mm_cmpgt_epi16(zero_si128, sum1_epi16);

        // Compute the absolute value
        sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
        sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);

        // Add the prequant_midpoint for quantization rounding
        sum1_epi16 = _mm_add_epi16(sum1_epi16, hp_offset_epi16);

        // Multiply by the quantization factor
        sum1_epi16 = _mm_mulhi_epu16(sum1_epi16, hp_quant_epi16);

        // Restore the sign
        sum1_epi16 = _mm_xor_si128(sum1_epi16, sign1_epi16);
        sum1_epi16 = _mm_sub_epi16(sum1_epi16, sign1_epi16);




        // Store the four highpass output points (may be unaligned without preroll)
        _mm_storeu_si128(highpass_ptr++, sum1_epi16);
#endif

        // The second set of eight input pixels becomes the working set
        input1_epi16 = input2_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

    lowptr = (PIXEL *)lowpass_ptr;
    highptr = (PIXEL *)highpass_ptr;

#if !_PREROLL
    // The lowpass results are behind by one column
    sum = input[column] + input[column + 1];

    sum *= lp_multiplier;
    sum >>= 16;
    *(lowptr++) = SATURATE(sum);

    // The fast processing loop is out of phase by two columns
    if (column < last_column) column += 2;
    else highptr--;

#endif

    // Process the last group of columns as a special case to handle the border
    for (; column < last_column; column += 2)
    {
        // Compute the lowpass sum
        sum = input[column] + input[column + 1];

        sum *= lp_multiplier;
        sum >>= 16;
        // Store the lowpass sum
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass sum
        sum = 0;
        sum -= input[column - 2];
        sum -= input[column - 1];
        sum += input[column + 2];
        sum += input[column + 3];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum += input[column + 0];
        sum -= input[column + 1];

        sign = 1;
        if (sum < 0)
        {
            sign = -1;
            sum = -sum;
        }

        sum *= hp_multiplier;
        sum >>= 16;

        sum *= sign;

        // Store the highpass sum
        *(highptr++) = SATURATE(sum);
    }

    // Should be at the last column
    assert(column == last_column);


    //DAN20050503 this the point should was missing for for fix the end condition so that is would over right other buffer data.
    // if is only require when push the SSE/MMX to process the very last pixel in the row (like this version.)
    column = last_column - 2; // Redo the last two pixels for the edge
    highptr--;
    lowptr--;


    // Compute the last lowpass value
    sum = input[column] + input[column + 1];

    sum *= lp_multiplier;
    sum >>= 16;
    *(lowptr++) = SATURATE(sum);

    // Compute the last highpass value using the special border coefficients
    sum = 0;
    sum += 11 * input[column + 0];
    sum -=  5 * input[column + 1];
    sum -=  4 * input[column - 1];
    sum -=  4 * input[column - 2];
    sum +=  1 * input[column - 3];
    sum +=  1 * input[column - 4];
    sum +=  ROUNDING(sum, 8);
    sum = DivideByShift(sum, 3);

    sign = 1;
    if (sum < 0)
    {
        sign = -1;
        sum = -sum;
    }

    sum *= hp_multiplier;
    sum >>= 16;

    sum *= sign;

    *(highptr++) = SATURATE(sum);
}







#if 0
// Apply the lowpass and highpass horizontal filters to the input image
void FilterHorizontal(PIXEL *input, int input_pitch,
                      PIXEL *lowpass, int lowpass_pitch,
                      PIXEL *highpass, int highpass_pitch,
                      ROI roi, int input_scale)
{
    PIXEL *rowptr = input;
    PIXEL *lowrow = lowpass;
    PIXEL *highrow = highpass;
    PIXEL *lowptr;
    PIXEL *highptr;
    int column_step = 8;							// Number of pixels to process per iteration
    int post_column = roi.width - column_step;		// Last column before post processing
    int last_column = roi.width - 2;
    int row, column;

    bool fastmode = (input_scale < 16) ? true : false;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        int32_t sum;
        int32_t lsb;
        __m128i *colptr = (__m128i *)rowptr;
        __m128i input1_epi16;

        // Start at the left end of the row
        column = 0;
        lowptr = lowrow;
        highptr = highrow;

        // Process the first column as a special case to handle the highpass border

        // Apply the highpass filter to the beginning of the row
        sum = 0;
        sum +=  5 * rowptr[column + 0];
        sum -= 11 * rowptr[column + 1];
        sum +=  4 * rowptr[column + 2];
        sum +=  4 * rowptr[column + 3];
        sum -=  1 * rowptr[column + 4];
        sum -=  1 * rowptr[column + 5];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(highptr++) = SATURATE(sum);

        // Skip a column to downsample the filter output
        column += 2;

        // Does the input data require full range arithmetic?
        if (!fastmode)
        {
            // Perform the lowpass and highpass convolutions using full precision arithmetic
            for (; column < last_column; column += 2)
            {
                int32_t sum;
                //int32_t lsb;

                // Apply the lowpass filter
                sum = 0;
                sum += rowptr[column + 0];
                sum += rowptr[column + 1];
                *(lowptr++) = SATURATE(sum);

                // Apply the highpass filter
                sum = 0;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(highptr++) = SATURATE(sum);
            }
        }
        else
        {
            // Check that the pointer to the next group of pixels is properly aligned
            assert(ISALIGNED16(colptr));

            // Preload the first set of eight pixels for fast processing
            //input1_epi16 = *(colptr++);
            input1_epi16 = _mm_load_si128(colptr++);

            // Process two sets of eight input pixels to get one set of four output pixels
            for (; column < post_column; column += column_step)
            {
                __m128i input2_epi16;
                __m128i shift2_epi16;
                __m128i mask_epi16;
                __m128i half_epi16;		// Half of the divisor for rounding
                __m128i lsb_epi16;		// Least significant bit for rounding
                __m128i sum_epi16;
                __m128i low_epi16;

                // Load input eight pixels
                //input1_epi16 = *(colptr++);

                // Compute four lowpass results
                low_epi16 = _mm_srli_epi32(input1_epi16, 16);
                low_epi16 = _mm_adds_epi16(input1_epi16, low_epi16);

                // Combine and store the eight lowpass results
                low_epi16 = _mm_shufflehi_epi16(low_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                low_epi16 = _mm_shufflelo_epi16(low_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                low_epi16 = _mm_shuffle_epi32(low_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                _mm_storel_epi64((__m128i *)lowptr, low_epi16);
                lowptr += 4;

                // Initialize the sum for the highpass filter
                sum_epi16 = _mm_setzero_si128();

                // Apply the first filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Load the next eight pixels
                //input2_epi16 = *(colptr++);
                input2_epi16 = _mm_load_si128(colptr++);

                // Shift the first pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sumb_epi16 = input1_epi16;

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                //  Divide the result by eight
                half_epi16 = _mm_set1_epi16(4);
                sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
                sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

                sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);


                // Downsample and store the results
                sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                _mm_storel_epi64((__m128i *)highptr, sum_epi16);
                highptr += 4;

                // The second set of eight input pixels becomes the working set
                input1_epi16 = input2_epi16;
            }

            // Process the last group of columns as a special case to handle the border
            for (; column < last_column; column += 2)
            {
                // Apply the lowpass filter
                sum = 0;
                sum += rowptr[column + 0];
                sum += rowptr[column + 1];
                *(lowptr++) = SATURATE(sum);

                // Apply the highpass filter
                sum = 0;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(highptr++) = SATURATE(sum);
            }
        }

        // Process the last column as a special case to handle the highpass border

        // Apply the lowpass filter to the beginning of the row
        sum = 0;
        sum += rowptr[column + 0];
        sum += rowptr[column + 1];
        *(lowptr++) = SATURATE(sum);

        // Apply the highpass filter to the beginning of the row
        sum = 0;
        sum += 11 * rowptr[column + 0];
        sum -=  5 * rowptr[column + 1];
        sum -=  4 * rowptr[column - 1];
        sum -=  4 * rowptr[column - 2];
        sum +=  1 * rowptr[column - 3];
        sum +=  1 * rowptr[column - 4];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(highptr++) = SATURATE(sum);

        // Advance to the next row
        rowptr += input_pitch;
        lowrow += lowpass_pitch;
        highrow += highpass_pitch;
    }

    //_mm_empty();	// Clear the mmx register state
}
#endif

#if 0
// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassHorizontal(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi, int prescale)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    int row, column;

    // The input width must be an even number to allow downsampling
    assert((roi.width % 2) == 0);
    roi.width -= (roi.width % 2);

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        // Load eight pixels and produce four output pixels per iteration
        const int column_step = 8;

        // Column at which end of row processing must begin
        const int post_column = roi.width - (roi.width % column_step);

        __m64 *input_ptr = (__m64 *)rowptr;
        __m64 *output_ptr = (__m64 *)outrow;
        PIXEL *outptr;

        // The post processing column must correspond to an integral number of loop iterations
        assert((post_column % column_step) == 0);

        // Read eight pixels and sum adjacent values into four output pixels
        for (column = 0; column < post_column; column += column_step)
        {
            __m64 quad1_pi16;		// First set of four pixels
            __m64 quad2_pi16;		// Second set of four pixels
            __m64 sum1_pi16;		// First sum of pairs of pixels
            __m64 sum2_pi16;		// Second sum of pairs of pixels

            // Load the first four pixels
            quad1_pi16 = *(input_ptr++);

            // Sum the first two pixels and the second two pixels in the quadword
            sum1_pi16 = _mm_shuffle_pi16(quad1_pi16, _MM_SHUFFLE(2, 3, 0, 1));
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);

            // Shuffle the pair of sums into adjacent words
            sum1_pi16 = _mm_shuffle_pi16(sum1_pi16, _MM_SHUFFLE(3, 1, 2, 0));

            // Load the next four pixels
            quad2_pi16 = *(input_ptr++);

            // Sum the first two pixels and the second two pixels in the quadword
            sum2_pi16 = _mm_shuffle_pi16(quad2_pi16, _MM_SHUFFLE(2, 3, 0, 1));
            sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

            // Shuffle the pair of sums into adjacent words
            sum2_pi16 = _mm_shuffle_pi16(sum2_pi16, _MM_SHUFFLE(3, 1, 2, 0));

            // Combine the sums into a single quadword
            sum1_pi16 = _mm_unpacklo_pi32(sum1_pi16, sum2_pi16);

            // Store the four results
            *(output_ptr++) = sum1_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

        // Process the rest of the row
        outptr = (PIXEL *)output_ptr;
        while (column < roi.width)
        {
            *(outptr++) = rowptr[column++] + rowptr[column++];
        }

        // Advance to the next row
        rowptr += input_pitch;
        outrow += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state

#if (0 && DEBUG && _WIN32)
    _CrtCheckMemory();
#endif
}
#endif


#if 0
#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void FilterHighpassHorizontal(PIXEL *input, int input_pitch,
                              PIXEL *output, int output_pitch,
                              ROI roi, int input_scale, int prescale)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal(PIXEL *input, int input_pitch,
                              PIXEL *output, int output_pitch,
                              ROI roi, int input_scale, int prescale)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    int row, column;
    int column_step = 8;				// Number of input pixels processed per loop iteration
    int last_column = roi.width - 2;	// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    // Cannot use 16-bit arithmetic if the input scale is too large
    bool fastmode = (input_scale < 16) ? true : false;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        int32_t sum;
        int32_t lsb;
        __m64 *input_ptr = (__m64 *)rowptr;
        __m64 input1_pi16;

        // Start at the left end of the row
        outptr = outrow;
        column = 0;

        // Process the first column as a special case
        sum = 0;
        sum +=  5 * rowptr[column + 0];
        sum -= 11 * rowptr[column + 1];
        sum +=  4 * rowptr[column + 2];
        sum +=  4 * rowptr[column + 3];
        sum -=  1 * rowptr[column + 4];
        sum -=  1 * rowptr[column + 5];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Does the input data require full range arithmetic?
        if (!fastmode)
        {
            // Already processed the first two columns using the left border formulas
            column += 2;

            // Perform the convolution using full precision arithmetic
            for (; column < last_column; column += 2)
            {
                int32_t sum = 0;
                int32_t lsb;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(outptr++) = SATURATE(sum);
            }
        }
        else
        {
            __m64 *output_ptr = (__m64 *)outptr;

            // Check that the pointer to the next group of pixels is properly aligned
            //assert(ISALIGNED16(input_ptr));

            // Preload the first set of four pixels for fast processing
            input1_pi16 = *(input_ptr++);

            // Process two sets of four input pixels to get one set of four output pixels
            for (; column < post_column; column += column_step)
            {
                __m64 input2_pi16;
                __m64 shift2_pi16;
                __m64 mask_pi16;
                __m64 sign_pi16;
                __m64 half_pi16;		// Half of the divisor for rounding
                __m64 lsb_pi16;			// Least significant bit for rounding
                __m64 sum1_pi16;
                __m64 sum2_pi16;


                // First two output points //

                // Initialize the sum
                sum1_pi16 = _mm_setzero_si64();

                // Apply the first filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

                // Load the next four pixels
                input2_pi16 = *(input_ptr++);

                // Shift the first pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_subs_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                input1_pi16 = input2_pi16;

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

                // Expand the even output points to a full doubleword
                sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
                sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);

                // The second four input points become the first four input points
                input1_pi16 = input2_pi16;


                // Second two output points //

                // Initialize the sum
                sum2_pi16 = _mm_setzero_si64();

                // Apply the first filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

                // Load the next four pixels
                input2_pi16 = *(input_ptr++);

                // Shift the first pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_adds_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_subs_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                input1_pi16 = input2_pi16;

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

                // Expand the even output points to a full doubleword
                sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
                sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


                // Combine the output points //

                sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);

                //	mask_pi16 = _mm_cmpgt_pi16(_mm_setzero_si64(), sum1_pi16);
                half_pi16 = _mm_set1_pi16(4);
                sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);

                // Store the four output points
                *(output_ptr++) = sum1_pi16;

                // The second set of eight input pixels becomes the working set
                input1_pi16 = input2_pi16;
            }

            // Should have exited the loop at the post processing column
            assert(column == post_column);

            outptr = (PIXEL *)output_ptr;

            // The fast processing loop is out of phase by two columns
            if (column < last_column) column += 2;
            else outptr--;

            // Process the last group of columns as a special case to handle the border
            for (; column < last_column; column += 2)
            {
                sum = 0;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(outptr++) = SATURATE(sum);
            }
        }

        // Should be at the last column
        assert(column == last_column);

        // Process the last column using the special border coefficients
        sum = 0;
        sum += 11 * rowptr[column + 0];
        sum -=  5 * rowptr[column + 1];
        sum -=  4 * rowptr[column - 1];
        sum -=  4 * rowptr[column - 2];
        sum +=  1 * rowptr[column - 3];
        sum +=  1 * rowptr[column - 4];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Advance to the next column
        rowptr += input_pitch;
        outrow += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state

#if (0 && DEBUG && _WIN32)
    _CrtCheckMemory();
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal(PIXEL *input, int input_pitch,
                              PIXEL *output, int output_pitch,
                              ROI roi, int input_scale, int prescale)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    int row, column;
    int column_step = 8;				// Number of pixels processed per loop iteration
    int last_column = roi.width - 2;	// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    // Cannot use 16-bit arithmetic if the input scale is too large
    bool fastmode = (input_scale < 16) ? true : FALSE;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        int32_t sum;
        int32_t lsb;
        __m128i *colptr = (__m128i *)rowptr;
        __m128i input1_epi16;

        // Start at the left end of the row
        outptr = outrow;
        column = 0;

        // Process the first column as a special case
        sum = 0;
        sum +=  5 * rowptr[column + 0];
        sum -= 11 * rowptr[column + 1];
        sum +=  4 * rowptr[column + 2];
        sum +=  4 * rowptr[column + 3];
        sum -=  1 * rowptr[column + 4];
        sum -=  1 * rowptr[column + 5];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Does the input data require full range arithmetic?
        if (!fastmode)
        {
            // Already processed the first two columns using the left border formulas
            column += 2;

            // Perform the convolution using full precision arithmetic
            for (; column < last_column; column += 2)
            {
                int32_t sum = 0;
                int32_t lsb;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(outptr++) = SATURATE(sum);
            }
        }
        else
        {
            // Check that the pointer to the next group of pixels is properly aligned
            assert(ISALIGNED16(colptr));

            // Preload the first set of eight pixels for fast processing
            input1_epi16 = _mm_load_si128(colptr++);

            // Process two sets of eight input pixels to get one set of four output pixels
            for (; column < post_column; column += column_step)
            {
                __m128i input2_epi16;
                __m128i shift2_epi16;
                __m128i mask_epi16;
                __m128i sign_epi16;
                __m128i half_epi16;		// Half of the divisor for rounding
                __m128i lsb_epi16;		// Least significant bit for rounding
                __m128i sum_epi16;

                // Initialize the sum
                sum_epi16 = _mm_setzero_si128();

                // Apply the first filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Load the next eight pixels
                //input2_epi16 = *(colptr++);
                input2_epi16 = _mm_load_si128(colptr++);

                // Shift the first pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sumb_epi16 = input1_epi16;

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                half_epi16 = _mm_set1_epi16(4);
                sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
                sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

                sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);


                // Downsample and store the results
                sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                _mm_storel_epi64((__m128i *)outptr, sum_epi16);
                outptr += 4;

                // The second set of eight input pixels becomes the working set
                input1_epi16 = input2_epi16;
            }

            // Should have exited the loop at the post processing column
            assert(column == post_column);

            // The fast processing loop is out of phase by two columns
            if (column < last_column) column += 2;
            else outptr--;

            // Process the last group of columns as a special case to handle the border
            for (; column < last_column; column += 2)
            {
                sum = 0;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(outptr++) = SATURATE(sum);
            }
        }

        // Should be at the last column
        assert(column == last_column);

        // Process the last column using the special border coefficients
        sum = 0;
        sum += 11 * rowptr[column + 0];
        sum -=  5 * rowptr[column + 1];
        sum -=  4 * rowptr[column - 1];
        sum -=  4 * rowptr[column - 2];
        sum +=  1 * rowptr[column - 3];
        sum +=  1 * rowptr[column - 4];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Advance to the next column
        rowptr += input_pitch;
        outrow += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state

#if (0 && DEBUG && _WIN32)
    _CrtCheckMemory();
#endif
}

#endif //P4
#endif


#if 0
// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassHorizontal8s(PIXEL8S *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi, int prescale)
{
    PIXEL8S *rowptr = input;
    PIXEL *outrow = output;
    int row, column;

    // The input width must be an even number to allow downsampling
    assert((roi.width % 2) == 0);
    roi.width -= (roi.width % 2);

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        // Load eight pixels and produce four output pixels per iteration
        const int column_step = 8;

        // Column at which end of row processing must begin
        const int post_column = roi.width - (roi.width % column_step);

        __m64 *input_ptr = (__m64 *)rowptr;
        __m64 *output_ptr = (__m64 *)outrow;
        PIXEL *outptr;

        // The post processing column must correspond to an integral number loop iterations
        assert((post_column % column_step) == 0);

        // Read eight pixels and sum adjacent values into four output pixels
        for (column = 0; column < post_column; column += column_step)
        {
            __m64 quad_pi8;			// Set of eight pixels
            __m64 sign_pi8;
            __m64 quad1_pi16;		// First set of four pixels
            __m64 quad2_pi16;		// Second set of four pixels
            __m64 sum1_pi16;		// First sum of pairs of pixels
            __m64 sum2_pi16;		// Second sum of pairs of pixels

            // Load eight pixels
            quad_pi8 = *(input_ptr++);

            // Unpack the first four pixels
            sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), quad_pi8);
            quad1_pi16 = _mm_unpacklo_pi8(quad_pi8, sign_pi8);

            // Prescale the input
            quad1_pi16 = _mm_srai_pi16(quad1_pi16, prescale);

            // Sum the first two pixels and the second two pixels in the quadword
            sum1_pi16 = _mm_shuffle_pi16(quad1_pi16, _MM_SHUFFLE(2, 3, 0, 1));
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);

            // Shuffle the pair of sums into adjacent words
            sum1_pi16 = _mm_shuffle_pi16(sum1_pi16, _MM_SHUFFLE(3, 1, 2, 0));

            // Unpack the next four pixels
            quad2_pi16 = _mm_unpackhi_pi8(quad_pi8, sign_pi8);

            // Prescale the input
            quad2_pi16 = _mm_srai_pi16(quad2_pi16, prescale);

            // Sum the first two pixels and the second two pixels in the quadword
            sum2_pi16 = _mm_shuffle_pi16(quad2_pi16, _MM_SHUFFLE(2, 3, 0, 1));
            sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

            // Shuffle the pair of sums into adjacent words
            sum2_pi16 = _mm_shuffle_pi16(sum2_pi16, _MM_SHUFFLE(3, 1, 2, 0));

            // Combine the sums into a single quadword
            sum1_pi16 = _mm_unpacklo_pi32(sum1_pi16, sum2_pi16);

            // Store the four results
            *(output_ptr++) = sum1_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

        // Process the rest of the row
        outptr = (PIXEL *)output_ptr;
        while (column < roi.width)
            *(outptr++) = (rowptr[column++] >> prescale) + (rowptr[column++] >> prescale);

        rowptr += input_pitch;
        outrow += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state
}
#endif


#if 0
#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void FilterHighpassHorizontal8s(PIXEL8S *input, int input_pitch,
                                PIXEL *output, int output_pitch,
                                ROI roi, int input_scale, int prescale)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal8s(PIXEL8S *input, int input_pitch,
                                PIXEL *output, int output_pitch,
                                ROI roi, int input_scale, int prescale)
{
    PIXEL8S *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    int row, column;
    int column_step = 8;				// Number of pixels processed per loop iteration
    int last_column = roi.width - 2;	// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    // Cannot use 16-bit arithmetic if the input scale is too large
    bool fastmode = (input_scale < 16) ? true : FALSE;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        int32_t sum;
        int32_t lsb;
        __m64 *input_ptr = (__m64 *)rowptr;
        __m64 input_pi8;
        __m64 sign_pi8;
        __m64 input1_pi16;

        // Start at the left end of the row
        outptr = outrow;
        column = 0;

        // Prescale the row of input data
        PrescaleRow8s(rowptr, roi.width, prescale);

        // Process the first column as a special case
        sum = 0;
        sum +=  5 * rowptr[column + 0];
        sum -= 11 * rowptr[column + 1];
        sum +=  4 * rowptr[column + 2];
        sum +=  4 * rowptr[column + 3];
        sum -=  1 * rowptr[column + 4];
        sum -=  1 * rowptr[column + 5];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Does the input data require full range arithmetic?
        if (!fastmode)
        {
            // Already processed the first two columns using the left border formulas
            column += 2;

            // Perform the convolution using full precision arithmetic
            for (; column < last_column; column += 2)
            {
                int32_t sum = 0;
                int32_t lsb;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(outptr++) = SATURATE(sum);
            }
        }
        else
        {
            __m64 *output_ptr = (__m64 *)outptr;

            // Check that the pointer to the next group of pixels is properly aligned
            //assert(ISALIGNED16(input_ptr));

            // Preload the first set of eight pixels for fast processing
            input_pi8 = *(input_ptr++);
            sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), input_pi8);

            // Unpack the first four pixels
            input1_pi16 = _mm_unpacklo_pi8(input_pi8, sign_pi8);

            // Process four sets of four input pixels to get two sets of four output pixels
            for (; column < post_column; column += column_step)
            {
                __m64 input2_pi16;
                __m64 shift2_pi16;
                __m64 mask_pi16;
                __m64 sign_pi16;
                __m64 half_pi16;	// Half of the divisor for rounding
                __m64 lsb_pi16;		// Least significant bit for rounding
                __m64 sum1_pi16;
                __m64 sum2_pi16;


                // Calculate the first set of outputs //

                // Initialize the sum
                sum1_pi16 = _mm_setzero_si64();

                // Apply the first filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

                // Unpack the next four pixels
                input2_pi16 = _mm_unpackhi_pi8(input_pi8, sign_pi8);

                // Shift the first pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_subs_pi16(sum1_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_subs_pi16(sum1_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                input1_pi16 = input2_pi16;

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, input1_pi16);

                // Expand the even output points to a full doubleword
                sum1_pi16 = _mm_slli_pi32(sum1_pi16, 16);
                sum1_pi16 = _mm_srai_pi32(sum1_pi16, 16);


                // Prepare the next set of input pixels //

                // The second four input pixels becomes the working set
                input1_pi16 = input2_pi16;

                // Load the second set of eight pixels
                input_pi8 = *(input_ptr++);
                sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), input_pi8);


                // Calculate the second set of outputs //

                // Initialize the sum
                sum2_pi16 = _mm_setzero_si64();

                // Apply the first filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

                // Unpack the next four pixels
                input2_pi16 = _mm_unpacklo_pi8(input_pi8, sign_pi8);

                // Shift the first pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 3 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_subs_pi16(sum2_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 2 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_adds_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                shift2_pi16 = _mm_slli_si64(input2_pi16, 1 * 16);
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);
                input1_pi16 = _mm_or_si64(input1_pi16, shift2_pi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_subs_pi16(sum2_pi16, _mm_slli_pi16(input1_pi16, 3));

                // Shift the next pixel from the second set into the working set
                input1_pi16 = input2_pi16;

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

                // Shift the next pixel from the second set into the working set
                input1_pi16 = _mm_srli_si64(input1_pi16, 1 * 16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum2_pi16 = _mm_adds_pi16(sum2_pi16, input1_pi16);

                // Expand the even output points to a full doubleword
                sum2_pi16 = _mm_slli_pi32(sum2_pi16, 16);
                sum2_pi16 = _mm_srai_pi32(sum2_pi16, 16);


                // Combine the two pairs of output points //

                sum1_pi16 = _mm_packs_pi32(sum1_pi16, sum2_pi16);

                half_pi16 = _mm_set1_pi16(4);
                sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);
                sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);

                // Store the four output points
                *(output_ptr++) = sum1_pi16;

                // The second set of eight input pixels becomes the working set
                input1_pi16 = input2_pi16;
            }

            // Should have exited the loop at the post processing column
            assert(column == post_column);

            outptr = (PIXEL *)output_ptr;

            // The fast processing loop is out of phase by two columns
            if (column < last_column) column += 2;
            else outptr--;

            // Process the last group of columns as a special case to handle the border
            for (; column < last_column; column += 2)
            {
                sum = 0;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];
                *(outptr++) = SATURATE(sum);
            }
        }

        // Should be at the last column
        assert(column == last_column);

        // Process the last column using the special border coefficients
        sum = 0;
        sum += 11 * rowptr[column + 0];
        sum -=  5 * rowptr[column + 1];
        sum -=  4 * rowptr[column - 1];
        sum -=  4 * rowptr[column - 2];
        sum +=  1 * rowptr[column - 3];
        sum +=  1 * rowptr[column - 4];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Advance to the next column
        rowptr += input_pitch;
        outrow += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassHorizontal8s(PIXEL8S *input, int input_pitch,
                                PIXEL *output, int output_pitch,
                                ROI roi, int input_scale, int prescale)
{
    PIXEL8S *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    int row, column;
    int column_step = 16;				// Number of pixels processed per loop iteration
    int last_column = roi.width - 2;	// Column at which right border processing is done

    // The post column is the column at which end of column processing must begin
    int post_column = last_column - (last_column % column_step);

    // Cannot use 16-bit arithmetic if the input scale is too large
    bool fastmode = (input_scale < 16) ? true : FALSE;

    //	post_column -= column_step;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        int32_t sum;
        int32_t lsb;
        __m128i *colptr = (__m128i *)rowptr;
        __m128i input_epi8;
        __m128i sign_epi8;
        __m128i input1_epi16;

        // Start at the left end of the row
        outptr = outrow;
        column = 0;

        // Prescale the row of input data
        PrescaleRow8s(rowptr, roi.width, prescale);

        // Process the first column as a special case
        sum = 0;
        sum +=  5 * rowptr[column + 0];
        sum -= 11 * rowptr[column + 1];
        sum +=  4 * rowptr[column + 2];
        sum +=  4 * rowptr[column + 3];
        sum -=  1 * rowptr[column + 4];
        sum -=  1 * rowptr[column + 5];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Does the input data require full range arithmetic?
        if (!fastmode)
        {
            // Already processed the first two columns using the left border formulas
            column += 2;

            // Perform the convolution using full precision arithmetic
            for (; column < last_column; column += 2)
            {
                int32_t sum = 0;
                int32_t lsb;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(outptr++) = SATURATE(sum);
            }
        }
        else
        {
            // Check that the pointer to the next group of pixels is properly aligned
            assert(ISALIGNED16(colptr));

            // Preload the first set of sixteen pixels for fast processing
            input_epi8 = _mm_load_si128(colptr++);
            sign_epi8 = _mm_cmpgt_epi8(_mm_setzero_si128(), input_epi8);

            // Unpack the first eight pixels
            input1_epi16 = _mm_unpacklo_epi8(input_epi8, sign_epi8);

            // Process four sets of eight input pixels to get two sets of four output pixels
            for (; column < post_column; column += column_step)
            {
                __m128i input2_epi16;
                __m128i shift2_epi16;
                __m128i mask_epi16;
                __m128i sign_epi16;
                __m128i half_epi16;		// Half of the divisor for rounding
                __m128i lsb_epi16;		// Least significant bit for rounding
                __m128i sum_epi16;

                // Calculate the first set of outputs //

                // Initialize the sum
                sum_epi16 = _mm_setzero_si128();

                // Apply the first filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Unpack the next eight pixels
                //input2_epi16 = *(colptr++);
                input2_epi16 = _mm_unpackhi_epi8(input_epi8, sign_epi8);

                // Shift the first pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sumb_epi16 = input1_epi16;

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                //	mask_epi16 = _mm_cmplt_epi16(sum_epi16, _mm_setzero_si128());
                half_epi16 = _mm_set1_epi16(4);
                sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
                sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

                sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);

                // Downsample and store the results
                sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                _mm_storel_epi64((__m128i *)outptr, sum_epi16);
                outptr += 4;

                // The second set of eight input pixels becomes the working set
                input1_epi16 = input2_epi16;


                // Calculate the second set of outputs //


                // Preload the next set of sixteen pixels for fast processing
                input_epi8 = _mm_load_si128(colptr++);
                sign_epi8 = _mm_cmpgt_epi8(_mm_setzero_si128(), input_epi8);


                // Initialize the sum
                sum_epi16 = _mm_setzero_si128();

                // Apply the first filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Unpack the first eight pixels
                input2_epi16 = _mm_unpacklo_epi8(input_epi8, sign_epi8);

                // Shift the first pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 7 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the second filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_subs_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 6 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the third filter coefficient to each pixel and sum the result
                sumb_epi16 = input1_epi16;

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 5 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fourth filter coefficient to each pixel and sum the result
                sumb_epi16 = _mm_subs_epi16(sumb_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 4 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the fifth filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                // Shift the next pixel from the second set into the working set
                shift2_epi16 = _mm_slli_si128(input2_epi16, 3 * 2);
                input1_epi16 = _mm_srli_si128(input1_epi16, 1 * 2);
                input1_epi16 = _mm_or_si128(input1_epi16, shift2_epi16);

                // Apply the sixth (last) filter coefficient to each pixel and sum the result
                sum_epi16 = _mm_adds_epi16(sum_epi16, input1_epi16);

                //	mask_epi16 = _mm_cmplt_epi16(sum_epi16, _mm_setzero_si128());
                half_epi16 = _mm_set1_epi16(4);
                sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
                sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

                sum_epi16 = _mm_adds_epi16(sum_epi16, sumb_epi16);

                // Downsample and store the results
                sum_epi16 = _mm_shufflehi_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shufflelo_epi16(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                sum_epi16 = _mm_shuffle_epi32(sum_epi16, _MM_SHUFFLE(3, 1, 2, 0));
                _mm_storel_epi64((__m128i *)outptr, sum_epi16);
                outptr += 4;

                // The second set of eight input pixels becomes the working set
                input1_epi16 = input2_epi16;
            }

            // Should have exited the loop at the post processing column
            assert(column == post_column);

            // The fast processing loop is out of phase by two columns
            if (column < last_column) column += 2;
            else outptr--;

            // Process the last group of columns as a special case to handle the border
            for (; column < last_column; column += 2)
            {
                sum = 0;
                sum -= rowptr[column - 2];
                sum -= rowptr[column - 1];
                sum += rowptr[column + 2];
                sum += rowptr[column + 3];
                sum += ROUNDING(sum, 8);
                sum = DivideByShift(sum, 3);
                sum += rowptr[column + 0];
                sum -= rowptr[column + 1];

                *(outptr++) = SATURATE(sum);
            }
        }

        // Should be at the last column
        assert(column == last_column);

        // Process the last column using the special border coefficients
        sum = 0;
        sum += 11 * rowptr[column + 0];
        sum -=  5 * rowptr[column + 1];
        sum -=  4 * rowptr[column - 1];
        sum -=  4 * rowptr[column - 2];
        sum +=  1 * rowptr[column - 3];
        sum +=  1 * rowptr[column - 4];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);

        // Advance to the next column
        rowptr += input_pitch;
        outrow += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state
}

#endif //p4
#endif


#if 0
// Apply the lowpass and highpass vertical filters in one pass
void FilterVertical(PIXEL *input, int input_pitch,
                    PIXEL *lowpass, int lowpass_pitch,
                    PIXEL *highpass, int highpass_pitch,
                    ROI roi)
{
    PIXEL *rowptr = input;
    PIXEL *lowpass_row_ptr = lowpass;
    PIXEL *highpass_row_ptr = highpass;
    PIXEL *lowptr;
    PIXEL *highptr;
    int last_row = roi.height - 2;
    int row, column;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL);

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Need to optimize the first and last rows //

    // Use border filters for the first row
    row = 0;
    lowptr = lowpass_row_ptr;
    highptr = highpass_row_ptr;

    for (column = 0; column < roi.width; column++)
    {
        int32_t sum;

        // Apply the lowpass filter
        sum  = rowptr[column + 0 * input_pitch];
        sum += rowptr[column + 1 * input_pitch];
        *(lowptr++) = SATURATE(sum);

        // Apply the highpass filter
        sum  =  5 * rowptr[column + 0 * input_pitch];
        sum -= 11 * rowptr[column + 1 * input_pitch];
        sum +=  4 * rowptr[column + 2 * input_pitch];
        sum +=  4 * rowptr[column + 3 * input_pitch];
        sum -=  1 * rowptr[column + 4 * input_pitch];
        sum -=  1 * rowptr[column + 5 * input_pitch];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(highptr++) = SATURATE(sum);
    }

    lowpass_row_ptr += lowpass_pitch;		// Advance to the next lowpass row
    highpass_row_ptr += highpass_pitch;		// Advance to the next highpass row
    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        int column_step = 4;
        int post_column = roi.width - (roi.width % column_step);
        int quad_pitch = (input_pitch * sizeof(PIXEL)) / sizeof(__m64);
        __m64 *lowpass_ptr = (__m64 *)lowpass_row_ptr;
        __m64 *highpass_ptr = (__m64 *)highpass_row_ptr;
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 *quad_ptr = (__m64 *)&rowptr[column];
            __m64 low_pi16;
            __m64 sum_pi16 = _mm_setzero_si64();
            __m64 quad_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;
            //__m64 lsb_pi16;

            // Load first row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the third row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Compute and store the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
            *(lowpass_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *quad_ptr;

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Approximate division by eight
            half_pi16 = _mm_set1_pi16(4);
            sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

            // Store the four highpass results
            *(highpass_ptr++) = sum_pi16;
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the column
        lowptr = &lowpass_row_ptr[column];
        highptr = &highpass_row_ptr[column];

        for (; column < roi.width; column++)
        {
            int32_t sum;

            // Compute the lowpass result
            sum  = rowptr[column + 0 * input_pitch];
            sum += rowptr[column + 1 * input_pitch];
            *(lowptr++) = SATURATE(sum);

            // Compute the highpass result
            sum  = rowptr[column + 0 * input_pitch];
            sum -= rowptr[column + 1 * input_pitch];
            sum += rowptr[column + 4 * input_pitch];
            sum += rowptr[column + 5 * input_pitch];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum += rowptr[column + 2 * input_pitch];
            sum -= rowptr[column + 3 * input_pitch];
            *(highptr++) = SATURATE(sum);
        }

        // Advance to the next input and output row
        rowptr += 2 * input_pitch;
        lowpass_row_ptr += lowpass_pitch;
        highpass_row_ptr += highpass_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

#if (1 && XMMOPT)
    // Need to advance the row pointer if using SIMD instructions
    rowptr += 2 * input_pitch;
#endif

    // Use the border filters for the last row
    lowptr = lowpass_row_ptr;
    highptr = highpass_row_ptr;

    for (column = 0; column < roi.width; column++)
    {
        int32_t sum;

        // Compute the lowpass result
        sum  = rowptr[column + 0 * input_pitch];
        sum += rowptr[column + 1 * input_pitch];
        *(lowptr++) = SATURATE(sum);

        // Compute the highpass result
        sum  = 11 * rowptr[column + 0 * input_pitch];
        sum -=  5 * rowptr[column + 1 * input_pitch];
        sum -=  4 * rowptr[column - 1 * input_pitch];
        sum -=  4 * rowptr[column - 2 * input_pitch];
        sum +=  1 * rowptr[column - 3 * input_pitch];
        sum +=  1 * rowptr[column - 4 * input_pitch];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(highptr++) = SATURATE(sum);
    }

    //_mm_empty();	// Clear the mmx register state
}
#endif


#if 0

// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    int row, column;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row += 2)
    {
#if (1 && XMMOPT)
        __m64 *quad1_ptr = (__m64 *)rowptr;
        __m64 *quad2_ptr = (__m64 *)&rowptr[input_pitch];
        __m64 *outptr = (__m64 *)outrow;

        // Process four pixels per iteration
        int column_step = 4;

        // Read four pixels from two rows and sum into four output pixels
        for (column = 0; column < roi.width; column += column_step)
        {
            __m64 quad_pi16;		// Quadword of four pixels
            __m64 sum_pi16;			// Sum of four of pixels

            // Load four pixels and advance to the next four pixels in the row
            sum_pi16 = *(quad1_ptr++);

            // Load four pixels from the next row and advance along that row
            quad_pi16 = *(quad2_ptr++);

            // Sum the two sets of four pixels
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Store the four sums
            *(outptr++) = sum_pi16;
        }
#else
        PIXEL *outptr = outrow;
        for (column = 0; column < roi.width; column++)
            *(outptr++) = rowptr[column] + rowptr[column + input_pitch];
#endif
        rowptr += 2 * input_pitch;		// Skip the next row of input pixels
        outrow += output_pitch;			// Advance to the next output row
    }

    //_mm_empty();	// Clear the mmx register state
}
#endif

#if 0

// Apply the lowpass vertical filter and quantize the results to eight bit pixels
void FilterLowpassVerticalQuant(PIXEL *input, int input_pitch, PIXEL8S *output, int output_pitch,
                                ROI roi, int quantization)
{
    PIXEL *rowptr = input;
    PIXEL8S *outrow = output;
    int row;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL8S);

    for (row = 0; row < roi.height; row += 2)
    {
        int column = 0;

#if (1 && XMMOPT)

        __m64 *quad1_ptr = (__m64 *)rowptr;
        __m64 *quad2_ptr = (__m64 *)&rowptr[input_pitch];
        __m64 *outptr = (__m64 *)outrow;

        // Process eight pixels per loop iteration
        int column_step = 8;
        int post_column = roi.width - (roi.width % column_step);

        // Read four pixels from two rows and sum into four output pixels
        for (; column < post_column; column += column_step)
        {
            __m64 quad_pi16;		// Quadword of four pixels
            __m64 sum1_pi16;		// Sum of four of pixels
            __m64 sum2_pi16;		// Sum of four of pixels
            __m64 sum_pi8;			// Packed sum of eight pixels

            // Load four pixels and advance to the next four pixels in the row
            sum1_pi16 = *(quad1_ptr++);

            // Load four pixels from the next row and advance along that row
            quad_pi16 = *(quad2_ptr++);

            // Sum the two sets of four pixels
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad_pi16);

            // Load four pixels and advance to the next four pixels in the row
            sum2_pi16 = *(quad1_ptr++);

            // Load four pixels from the next row and advance along that row
            quad_pi16 = *(quad2_ptr++);

            // Sum the two sets of four pixels
            sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad_pi16);

            // Pack the two vectors of four sums
            sum_pi8 = _mm_packs_pi16(sum1_pi16, sum2_pi16);

            // Need to perform quantization //

            // Store the eight packed sums
            *(outptr++) = sum_pi8;
        }

        //_mm_empty();	// Clear the mmx register state

        // Check that the loop terminated at the post processing column
        assert(column == post_column);
#endif

        // Process the rest of the output row
        for (; column < roi.width; column++)
        {
            outrow[column] = rowptr[column] + rowptr[column + input_pitch];
        }

        rowptr += 2 * input_pitch;		// Skip the next row of input pixels
        outrow += output_pitch;			// Advance to the next output row
    }
}
#endif


#if 0
#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void FilterHighpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    int last_row = roi.height - 2;
    int row, column;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Use border filters for the first row
    row = 0;
    outptr = outrow;
    for (column = 0; column < roi.width; column++)
    {
        int32_t sum = 0;
        sum +=  5 * rowptr[column + 0 * input_pitch];
        sum -= 11 * rowptr[column + 1 * input_pitch];
        sum +=  4 * rowptr[column + 2 * input_pitch];
        sum +=  4 * rowptr[column + 3 * input_pitch];
        sum -=  1 * rowptr[column + 4 * input_pitch];
        sum -=  1 * rowptr[column + 5 * input_pitch];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);
    }

#if 0
    // Advance to the second input row if not using the SIMD version below since
    // the SIMD version reads the previous (in this case the first) row again
    rowptr += 2 * input_pitch;
#endif
    outrow += output_pitch;		// Advance to the next output row
    row += 2;					// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        int column_step = 4;
        int post_column = roi.width - (roi.width % column_step);
        int quad_pitch = (input_pitch * sizeof(PIXEL)) / sizeof(__m64);
        __m64 *output_ptr = (__m64 *)outrow;
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 *quad_ptr = (__m64 *)&rowptr[column];
            __m64 sum_pi16 = _mm_setzero_si64();
            __m64 quad_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;
            __m64 lsb_pi16;

            // Load first row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the third row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the third filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *quad_ptr;
            quad_ptr += quad_pitch;

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *quad_ptr;

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Approximate division by eight
            half_pi16 = _mm_set1_pi16(4);
            sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

            // Store the four results
            *(output_ptr++) = sum_pi16;
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the column
        outptr = &outrow[column];
        for (; column < roi.width; column++)
        {
            int32_t sum = 0;
            sum -= rowptr[column + 0 * input_pitch];
            sum -= rowptr[column + 1 * input_pitch];
            sum += rowptr[column + 4 * input_pitch];
            sum += rowptr[column + 5 * input_pitch];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum += rowptr[column + 2 * input_pitch];
            sum -= rowptr[column + 3 * input_pitch];
            *(outptr++) = SATURATE(sum);
        }

        // Advance to the next input and output row
        rowptr += 2 * input_pitch;
        outrow += output_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

#if (1 && XMMOPT)
    // Need to advance the row pointer if using SIMD instructions
    rowptr += 2 * input_pitch;
#endif

    // Use the border filters for the last row
    outptr = outrow;
    for (column = 0; column < roi.width; column++)
    {
        int32_t sum = 0;
        sum += 11 * rowptr[column + 0 * input_pitch];
        sum -=  5 * rowptr[column + 1 * input_pitch];
        sum -=  4 * rowptr[column - 1 * input_pitch];
        sum -=  4 * rowptr[column - 2 * input_pitch];
        sum +=  1 * rowptr[column - 3 * input_pitch];
        sum +=  1 * rowptr[column - 4 * input_pitch];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);
    }

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// This version performs highpass convolution and downsampling in one pass
// and is optimized for the highpass coefficients used in the 2/6 wavelet
void FilterHighpassVertical(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    int last_row = roi.height - 2;
    int row, column;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Use border filters for the first row
    row = 0;
    outptr = outrow;
    for (column = 0; column < roi.width; column++)
    {
        int32_t sum = 0;
        sum +=  5 * rowptr[column + 0 * input_pitch];
        sum -= 11 * rowptr[column + 1 * input_pitch];
        sum +=  4 * rowptr[column + 2 * input_pitch];
        sum +=  4 * rowptr[column + 3 * input_pitch];
        sum -=  1 * rowptr[column + 4 * input_pitch];
        sum -=  1 * rowptr[column + 5 * input_pitch];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);
    }

#if 0
    // Advance to the second input row if not using the SIMD version below since
    // the SIMD version reads the previous (in this case the first) row again
    rowptr += 2 * input_pitch;
#endif
    outrow += output_pitch;		// Advance to the next output row
    row += 2;					// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        const int column_step = 8;
        const int post_column = roi.width - (roi.width % column_step);
        int group_pitch = (input_pitch * sizeof(PIXEL)) / sizeof(__m128i);
        __m128i *output_ptr = (__m128i *)outrow;

        // Can handle a row length that is not a multiple of the column step
        //assert((roi.width % column_step) == 0);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)
        // Process a group of eight pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m128i *group_ptr = (__m128i *)&rowptr[column];
            __m128i sum_epi16 = _mm_setzero_si128();
            __m128i group_epi16;
            __m128i mask_epi16;
            __m128i half_epi16;
            __m128i sign_epi16;
            __m128i lsb_epi16;

            // Check that the pointer to the next group of pixels is properly aligned
            assert(ISALIGNED16(group_ptr));

            // Check that the output pointer is properly aligned
            assert(ISALIGNED16(output_ptr));

            // Load the first row of eight pixels
            group_epi16 = _mm_load_si128(group_ptr);
            group_ptr += group_pitch;

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, group_epi16);

            // Load the second row of eight pixels
            group_epi16 = _mm_load_si128(group_ptr);
            group_ptr += group_pitch;

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, group_epi16);

            // Load the third row of four pixels
            group_epi16 = _mm_load_si128(group_ptr);
            group_ptr += group_pitch;

            // Multiply each pixel by the third filter coefficient and sum the result
            group_epi16 = _mm_slli_epi16(group_epi16, 3);
            sum_epi16 = _mm_adds_epi16(sum_epi16, group_epi16);

            // Load the fourth row of four pixels
            group_epi16 = _mm_load_si128(group_ptr);
            group_ptr += group_pitch;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            group_epi16 = _mm_slli_epi16(group_epi16, 3);
            sum_epi16 = _mm_subs_epi16(sum_epi16, group_epi16);

            // Load the fifth row of four pixels
            group_epi16 = _mm_load_si128(group_ptr);
            group_ptr += group_pitch;

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, group_epi16);

            // Load the sixth (last) row of four pixels
            group_epi16 = _mm_load_si128(group_ptr);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, group_epi16);

            // Divide  by eight
            half_epi16 = _mm_set1_epi16(4);
            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16);
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3);

            // Store the eight results
            _mm_store_si128(output_ptr++, sum_epi16);
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif
        // Process the remaining pixels to the end of the column
        outptr = (PIXEL *)output_ptr;
        for (; column < roi.width; column++)
        {
            int32_t sum = 0;
            //int32_t lsb;
            sum -= rowptr[column + 0 * input_pitch];
            sum -= rowptr[column + 1 * input_pitch];
            sum += rowptr[column + 4 * input_pitch];
            sum += rowptr[column + 5 * input_pitch];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum += rowptr[column + 2 * input_pitch];
            sum -= rowptr[column + 3 * input_pitch];

            *(outptr++) = SATURATE(sum);
        }

        rowptr += 2 * input_pitch;
        outrow += output_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

#if 1
    // Need to advance the row pointer if using SIMD instructions
    rowptr += 2 * input_pitch;
#endif

    // Use the border filters for the last row
    outptr = outrow;
    for (column = 0; column < roi.width; column++)
    {
        int32_t sum = 0;
        sum += 11 * rowptr[column + 0 * input_pitch];
        sum -=  5 * rowptr[column + 1 * input_pitch];
        sum -=  4 * rowptr[column - 1 * input_pitch];
        sum -=  4 * rowptr[column - 2 * input_pitch];
        sum +=  1 * rowptr[column - 3 * input_pitch];
        sum +=  1 * rowptr[column - 4 * input_pitch];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);
    }

    //_mm_empty();	// Clear the mmx register state
}

#endif //P4
#endif


#if 0

// This version performs lowpass convolution and downsampling in one pass
// and is optimized for the lowpass coefficients used in the 2/6 wavelet
void FilterLowpassVerticalScaled(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
    //	Ipp32s kernel[2] = {1, 1};
    int kernel_length = 2;
    int scale = 1;
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    int anchor = kernel_length - 1;
    int row, column;
    int half = scale / 2;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row += 2)
    {
        __m64 *quad1_ptr = (__m64 *)rowptr;
        __m64 *quad2_ptr = (__m64 *)&rowptr[input_pitch];
        __m64 *outptr = (__m64 *)outrow;

        // Process four pixels per iteration
        int column_step = 4;

        // Read four pixels from two rows and sum into four output pixels
        for (column = 0; column < roi.width; column += column_step)
        {
            __m64 quad_pi16;		// Quadword of four pixels
            __m64 sum_pi16;			// Sum of four of pixels

            // Load four pixels and advance to the next four pixels in the row
            sum_pi16 = *(quad1_ptr++);

            // Load four pixels from the next row and advance along that row
            quad_pi16 = *(quad2_ptr++);

            // Sum the two sets of four pixels
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Store the four sums
            *(outptr++) = sum_pi16;
        }
        rowptr += 2 * input_pitch;		// Skip the next row of input pixels
        outrow += output_pitch;			// Advance to the next output row
    }

    //_mm_empty();	// Clear the mmx register state
}
#endif

#if 0

// Apply the highpass vertical filter and quantize the results to eight bit pixels
void FilterHighpassVerticalQuant(PIXEL *input, int input_pitch, PIXEL8S *output, int output_pitch,
                                 ROI roi, int quantization)
{
    PIXEL *rowptr = input;
    PIXEL8S *outrow = output;
    PIXEL8S *outptr;
    int last_row = roi.height - 2;
    int row, column;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL8S);

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Use border filters for the first row
    row = 0;
    outptr = outrow;
    for (column = 0; column < roi.width; column++)
    {
        int32_t sum = 0;
        sum +=  5 * rowptr[column + 0 * input_pitch];
        sum -= 11 * rowptr[column + 1 * input_pitch];
        sum +=  4 * rowptr[column + 2 * input_pitch];
        sum +=  4 * rowptr[column + 3 * input_pitch];
        sum -=  1 * rowptr[column + 4 * input_pitch];
        sum -=  1 * rowptr[column + 5 * input_pitch];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        sum /= quantization;
        *(outptr++) = HIGHPASS(sum);
    }

#if 0
    // Advance to the second input row if not using the SIMD version below since
    // the SIMD version reads the previous (in this case the first) row again
    rowptr += 2 * input_pitch;
#endif
    outrow += output_pitch;		// Advance to the next output row
    row += 2;					// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        int column_step = 8;
        int post_column = roi.width - (roi.width % column_step);
        int quad_pitch = (input_pitch * sizeof(PIXEL)) / sizeof(__m64);
        __m64 *output_ptr = (__m64 *)outrow;
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)
        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 *quad_ptr = (__m64 *)&rowptr[column];
            __m64 sum1_pi16 = _mm_setzero_si64();
            __m64 sum2_pi16 = _mm_setzero_si64();
            __m64 quad1_pi16;
            __m64 quad2_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;
            //__m64 lsb_pi16;
            __m64 sum_pi8;

            // Load first row of eight pixels
            quad1_pi16 = *quad_ptr;
            quad2_pi16 = *(quad_ptr + 1);
            quad_ptr += quad_pitch;

            // Multiply each pixel by the first filter coefficient and sum the result
            sum1_pi16 = _mm_subs_pi16(sum1_pi16, quad1_pi16);
            sum2_pi16 = _mm_subs_pi16(sum2_pi16, quad2_pi16);

            // Load the second row of four pixels
            quad1_pi16 = *quad_ptr;
            quad2_pi16 = *(quad_ptr + 1);
            quad_ptr += quad_pitch;

            // Multiply each pixel by the second filter coefficient and sum the result
            sum1_pi16 = _mm_subs_pi16(sum1_pi16, quad1_pi16);
            sum2_pi16 = _mm_subs_pi16(sum2_pi16, quad2_pi16);

            // Load the third row of four pixels
            quad1_pi16 = *quad_ptr;
            quad2_pi16 = *(quad_ptr + 1);
            quad_ptr += quad_pitch;

            // Multiply each pixel by the third filter coefficient and sum the result
            quad1_pi16 = _mm_slli_pi16(quad1_pi16, 3);
            quad2_pi16 = _mm_slli_pi16(quad2_pi16, 3);
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);
            sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

            // Load the fourth row of four pixels
            quad1_pi16 = *quad_ptr;
            quad2_pi16 = *(quad_ptr + 1);
            quad_ptr += quad_pitch;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            quad1_pi16 = _mm_slli_pi16(quad1_pi16, 3);
            quad2_pi16 = _mm_slli_pi16(quad2_pi16, 3);
            sum1_pi16 = _mm_subs_pi16(sum1_pi16, quad1_pi16);
            sum2_pi16 = _mm_subs_pi16(sum2_pi16, quad2_pi16);

            // Load the fifth row of four pixels
            quad1_pi16 = *quad_ptr;
            quad2_pi16 = *(quad_ptr + 1);
            quad_ptr += quad_pitch;

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);
            sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

            // Load the sixth (last) row of four pixels
            quad1_pi16 = *quad_ptr;
            quad2_pi16 = *(quad_ptr + 1);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, quad1_pi16);
            sum2_pi16 = _mm_adds_pi16(sum2_pi16, quad2_pi16);

            // Approximate division of first four sums by eight
            half_pi16 = _mm_set1_pi16(4);
            sum1_pi16 = _mm_srai_pi16(sum1_pi16, 3);
            sum1_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);

            // Approximate division of second four sums by eight
            sum2_pi16 = _mm_srai_pi16(sum2_pi16, 3);
            sum2_pi16 = _mm_adds_pi16(sum1_pi16, half_pi16);

            // Need to perform quantization //

            // Pack and store the eight results
            sum_pi8 = _mm_packs_pi16(sum1_pi16, sum2_pi16);
            *(output_ptr++) = sum_pi8;
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the column
        outptr = &outrow[column];
        for (; column < roi.width; column++)
        {
            int32_t sum = 0;
            sum -= rowptr[column + 0 * input_pitch];
            sum -= rowptr[column + 1 * input_pitch];
            sum += rowptr[column + 4 * input_pitch];
            sum += rowptr[column + 5 * input_pitch];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum += rowptr[column + 2 * input_pitch];
            sum -= rowptr[column + 3 * input_pitch];
            *(outptr++) = SATURATE(sum);
        }

        // Add call to row quantization here //

        // Advance to the next input and output row
        rowptr += 2 * input_pitch;
        outrow += output_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

#if (1 && XMMOPT)
    // Need to advance the row pointer if using SIMD instructions
    rowptr += 2 * input_pitch;
#endif

    // Use the border filters for the last row
    outptr = outrow;
    for (column = 0; column < roi.width; column++)
    {
        int32_t sum = 0;
        sum += 11 * rowptr[column + 0 * input_pitch];
        sum -=  5 * rowptr[column + 1 * input_pitch];
        sum -=  4 * rowptr[column - 1 * input_pitch];
        sum -=  4 * rowptr[column - 2 * input_pitch];
        sum +=  1 * rowptr[column - 3 * input_pitch];
        sum +=  1 * rowptr[column - 4 * input_pitch];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        *(outptr++) = SATURATE(sum);
    }

    //_mm_empty();	// Clear the mmx register state
}
#endif



// Apply the horizontal inverse wavelet filter to 8-bit signed coefficients
void InvertHorizontal8s(PIXEL *lowpass, int lowpass_pitch,
                        PIXEL *highpass, int highpass_pitch,
                        PIXEL *output, int output_pitch,
                        ROI roi, bool fastmode)
{
    // Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S

    // Call the routine: InvertHorizontalRow8s()

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#if 0
// Optimized even reconstruction filter
void FilterEvenHorizontal(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    //int half = scale/2;
    int row, column;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        outptr = outrow;

        for (column = 0; column < roi.width; column++)
        {
            int32_t sum = 0;
            sum += rowptr[column + 0];
            sum -= rowptr[column + 2];
            sum += 4;
            sum >>= 3;
            sum += rowptr[column + 1];

            *(outptr++) = SATURATE(sum);
        }
        rowptr += input_pitch;
        outrow += output_pitch;
    }
}
#endif

#if 0
// Optimized odd reconstruction filter
void FilterOddHorizontal(PIXEL *input, int input_pitch, PIXEL *output, int output_pitch, ROI roi)
{
    PIXEL *rowptr = input;
    PIXEL *outrow = output;
    PIXEL *outptr;
    //int half = scale/2;
    int row, column;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        outptr = outrow;

        for (column = 0; column < roi.width; column++)
        {
            int32_t sum = 0;
            sum -= rowptr[column + 0];
            sum += rowptr[column + 2];
            sum += 4;
            sum >>= 3;
            sum += rowptr[column + 1];
            *(outptr++) = SATURATE(sum);
        }
        rowptr += input_pitch;
        outrow += output_pitch;
    }
}
#endif

#if 0
void FilterEvenLowHigh(PIXEL *lowpass, int lowpass_pitch,
                       PIXEL *highpass, int highpass_pitch, int highpass_border,
                       PIXEL *output, int output_pitch, ROI roi)
{
    int row, column;

    // Convert pitch from bytes to pixels
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        for (column = 0; column < roi.width; column++)
        {
            // Apply the even reconstruction filter to the lowpass band
            int32_t sum = 0;
            sum += lowpass[column + 0];
            sum -= lowpass[column + 2];
            sum += 4;
            sum >>= 3;
            sum += lowpass[column + 1];

            // Add the highpass correction
            sum += highpass[column];
            sum /= 2;

            // Place the result in an even column
            output[2 * column] = SATURATE(sum);
        }
        lowpass += lowpass_pitch;
        highpass += highpass_pitch;
        output += output_pitch;
    }
}
#endif

#if 0
void FilterOddLowHigh(PIXEL *lowpass, int lowpass_pitch,
                      PIXEL *highpass, int highpass_pitch, int highpass_border,
                      PIXEL *output, int output_pitch, ROI roi)
{
    int row, column;

    // Convert pitch from bytes to pixels
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        for (column = 0; column < roi.width; column++)
        {
            // Apply the odd reconstruction filter to the lowpass band
            int32_t sum = 0;
            sum -= lowpass[column + 0];
            sum += lowpass[column + 2];
            sum += ROUNDING(sum, 8);
            sum >>= 3;
            sum += lowpass[column + 1];

            // Subtract the highpass correction
            sum -= highpass[column];
            sum /= 2;

            // Place the result in an odd column
            output[2 * column + 1] = SATURATE(sum);
        }
        lowpass += lowpass_pitch;
        highpass += highpass_pitch;
        output += output_pitch;
    }
}
#endif

#if 0
#if 1

// Optimized version using MMX instructions

// Apply the vertical inverse wavelet filter
void InvertVertical16s(PIXEL *lowpass, int lowpass_pitch,
                       PIXEL *highpass, int highpass_pitch,
                       PIXEL *output, int output_pitch,
                       ROI roi)
{
    int cache_width = _CACHE_LINE_SIZE / sizeof(PIXEL);
    int last_row = roi.height - 1;
    int row, column;

    // Convert pitch from bytes to pixels
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Apply the border filter to the first row
    row = 0;

    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowpass[column + 0 * lowpass_pitch];
        even -=  4 * lowpass[column + 1 * lowpass_pitch];
        even +=  1 * lowpass[column + 2 * lowpass_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highpass[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        output[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowpass[column + 0 * lowpass_pitch];
        odd += 4 * lowpass[column + 1 * lowpass_pitch];
        odd -= 1 * lowpass[column + 2 * lowpass_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highpass[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        output[column + output_pitch] = SATURATE(odd);
    }

#if 0
    // Advance to the next input row if not using SIMD
    lowpass += lowpass_pitch;
#endif
    highpass += highpass_pitch;

    // Skip two output rows
    output += 2 * output_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the ordinary reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)

        int column_step = 4;
        int post_column = roi.width - (roi.width % column_step);
        int quad_pitch = (lowpass_pitch * sizeof(PIXEL)) / sizeof(__m64);
        __m64 *even_ptr = (__m64 *)&output[0];
        __m64 *odd_ptr = (__m64 *)&output[output_pitch];

#endif

        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *quad_ptr = (__m64 *)&lowpass[column];
            __m64 *high_ptr = (__m64 *)&highpass[column];
            __m64 quad_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;

            // Accumulate parallel sums for the even and odd filters

            quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
            quad_ptr += quad_pitch;		// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
            quad_ptr += quad_pitch;		// Advance to the next row

            // Multiply the lowpass coefficients by eight
            //DAN031304 -- wrong inverse filter
            assert(0); //fix filter
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            quad_pi16 = *quad_ptr;		// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *high_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Place the even result in the even row and the odd result in the odd row
            *(even_ptr++) = even_pi16;
            *(odd_ptr++) = odd_pi16;
        }

        // Should have finished the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the rest of the row
        for (; column < roi.width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter

            // Apply the even reconstruction filter to the lowpass band
            even += lowpass[column - 1 * lowpass_pitch];
            even -= lowpass[column + 1 * lowpass_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowpass[column + 0 * lowpass_pitch];

            // Add the highpass correction
            even += highpass[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            output[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowpass[column - 1 * lowpass_pitch];
            odd += lowpass[column + 1 * lowpass_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowpass[column + 0 * lowpass_pitch];

            // Subtract the highpass correction
            odd -= highpass[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            output[column + output_pitch] = SATURATE(odd);
        }

        // Advance to the next input rows and skip the next output row
        lowpass += lowpass_pitch;
        highpass += highpass_pitch;
        output += 2 * output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state

#if 1
    // Need to advance the lowpass pointer if using SIMD instructions
    lowpass += lowpass_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == (roi.height - 1));

    // Apply the border filter to the last row
    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowpass[column + 0 * lowpass_pitch];
        even += 4 * lowpass[column - 1 * lowpass_pitch];
        even -= 1 * lowpass[column - 2 * lowpass_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highpass[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        output[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowpass[column + 0 * lowpass_pitch];
        odd -=  4 * lowpass[column - 1 * lowpass_pitch];
        odd +=  1 * lowpass[column - 2 * lowpass_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highpass[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        output[column + output_pitch] = SATURATE(odd);
    }
}

#else

// Optimized version that processes the image by columns of cache lines

// Apply the vertical inverse wavelet filter
void InvertVertical16s(PIXEL *lowpass_array, int lowpass_pitch,
                       PIXEL *highpass_array, int highpass_pitch,
                       PIXEL *output_array, int output_pitch,
                       ROI roi)
{
    int cache_line_width = _CACHE_LINE_SIZE / sizeof(PIXEL);
    int last_row = roi.height - 1;
    int last_column = roi.width - 1;
    int start_column;
    int row, column;

    // Convert pitch from bytes to pixels
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Process the image by columns of cache lines
    for (start_column = 0; start_column < roi.width; start_column += cache_line_width)
    {
        // Compute pointers to the start of the cache line of coefficients
        PIXEL *lowpass = &lowpass_array[0];
        PIXEL *highpass = &highpass_array[0];
        PIXEL *output = &output_array[0];

        // Compute the last column in the current cache line
        int end_column = start_column + cache_line_width - 1;

        // May process fewer columns in last cache line
        if (end_column > last_column) end_column = last_column;

        // Apply the border filter to the first row
        row = 0;

        for (column = start_column; column <= end_column; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter

            // Apply the even reconstruction filter to the lowpass band
            even += 11 * lowpass[column + 0 * lowpass_pitch];
            even -=  4 * lowpass[column + 1 * lowpass_pitch];
            even +=  1 * lowpass[column + 2 * lowpass_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highpass[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            output[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 5 * lowpass[column + 0 * lowpass_pitch];
            odd += 4 * lowpass[column + 1 * lowpass_pitch];
            odd -= 1 * lowpass[column + 2 * lowpass_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highpass[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            output[column + output_pitch] = SATURATE(odd);
        }

#if 0
        // Advance to the next input row if not using SIMD
        lowpass += lowpass_pitch;
#endif
        highpass += highpass_pitch;

        // Skip two output rows
        output += 2 * output_pitch;

        // Advance the row index
        row++;

        // Process the middle rows using the ordinary reconstruction filters
        for (; row < last_row; row++)
        {
#if 0
            // Use the unoptimized version of the inverse vertical filter code
            for (column = start_column; column <= end_column; column++)
            {
                int32_t even = 0;		// Result of convolution with even filter
                int32_t odd = 0;		// Result of convolution with odd filter

                // Apply the even reconstruction filter to the lowpass band
                even += lowpass[column - 1 * lowpass_pitch];
                even -= lowpass[column + 1 * lowpass_pitch];
                even += ROUNDING(even, 8);
                even = DivideByShift(even, 3);
                even += lowpass[column + 0 * lowpass_pitch];

                // Add the highpass correction
                even += highpass[column];
                even = DivideByShift(even, 1);

                // Place the even result in the even row
                output[column] = SATURATE(even);

                // Apply the odd reconstruction filter to the lowpass band
                odd -= lowpass[column - 1 * lowpass_pitch];
                odd += lowpass[column + 1 * lowpass_pitch];
                odd += ROUNDING(odd, 8);
                odd = DivideByShift(odd, 3);
                odd += lowpass[column + 0 * lowpass_pitch];

                // Subtract the highpass correction
                odd -= highpass[column];
                odd = DivideByShift(odd, 1);

                // Place the odd result in the odd row
                output[column + output_pitch] = SATURATE(odd);
            }
#else
            // Use the optimized version of the inverse vertical filter code

            int column_step = 4;
            int quad_pitch = (lowpass_pitch * sizeof(PIXEL)) / sizeof(__m64);
            __m64 *even_ptr = (__m64 *)&output[start_column];
            __m64 *odd_ptr = (__m64 *)&output[start_column + output_pitch];

            // Check that the cache line can be processed in an integral number of iterations
            assert((cache_line_width % column_step) == 0);

            // Process groups of four coefficients along the row
            for (column = start_column; column <= end_column; column += column_step)
            {
                __m64 *quad_ptr = (__m64 *)&lowpass[column];
                __m64 *high_ptr = (__m64 *)&highpass[column];
                __m64 quad_pi16;
                __m64 even_pi16;
                __m64 odd_pi16;

                // Accumulate parallel sums for the even and odd filters

                quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
                quad_ptr += quad_pitch;		// Advance to the next row

                even_pi16 = quad_pi16;
                odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

                quad_pi16 = *quad_ptr;		// Get four lowpass coefficients
                quad_ptr += quad_pitch;		// Advance to the next row

                // Multiply the lowpass coefficients by eight
                //DAN031304 -- wrong inverse filter
                assert(0); //fix filter
                quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

                even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

                quad_pi16 = *quad_ptr;		// Get four lowpass coefficients

                even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

                // Apply the rounding adjustment
                even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
                // Divide by eight
                even_pi16 = _mm_srai_pi16(even_pi16, 3);

                // Apply the rounding adjustment
                odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
                // Divide by eight
                odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

                // Add the highpass correction to the even result and divide by two
                quad_pi16 = *high_ptr;
                even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
                even_pi16 = _mm_srai_pi16(even_pi16, 1);

                // Subtract the highpass correction from the odd result and divide by two
                odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
                odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

                // Place the even result in the even row and the odd result in the odd row
                *(even_ptr++) = even_pi16;
                *(odd_ptr++) = odd_pi16;
            }
#endif
            // Advance to the next input rows and skip the next output row
            lowpass += lowpass_pitch;
            highpass += highpass_pitch;
            output += 2 * output_pitch;
        }

#if 1
        // Need to advance the lowpass pointer if using SIMD instructions
        lowpass += lowpass_pitch;
#endif

        // Should have exited the loop at the last row
        assert(row == (roi.height - 1));

        // Apply the border filter to the last row
        for (column = start_column; column <= end_column; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter

            // Apply the even reconstruction filter to the lowpass band
            even += 5 * lowpass[column + 0 * lowpass_pitch];
            even += 4 * lowpass[column - 1 * lowpass_pitch];
            even -= 1 * lowpass[column - 2 * lowpass_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highpass[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            output[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * lowpass[column + 0 * lowpass_pitch];
            odd -=  4 * lowpass[column - 1 * lowpass_pitch];
            odd +=  1 * lowpass[column - 2 * lowpass_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highpass[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            output[column + output_pitch] = SATURATE(odd);
        }
    }

    //_mm_empty();	// Clear the mmx register state
}

#endif
#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

// Apply the frame (temporal and horizontal) transform to unsigned byte data
void FilterSpatialQuant16s(PIXEL *input_image, int input_pitch,
                           PIXEL *lowlow_band, int lowlow_pitch,
                           PIXEL *lowhigh_band, int lowhigh_pitch,
                           PIXEL *highlow_band, int highlow_pitch,
                           PIXEL *highhigh_band, int highhigh_pitch,
                           PIXEL *buffer, size_t buffer_size,
                           ROI roi, int quantization[4])
{
    // Stub routine for processor specific dispatch
}

#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuant16s(PIXEL *input_image, int input_pitch,
                           PIXEL *lowlow_band, int lowlow_pitch,
                           PIXEL *lowhigh_band, int lowhigh_pitch,
                           PIXEL *highlow_band, int highlow_pitch,
                           PIXEL *highhigh_band, int highhigh_pitch,
                           PIXEL *buffer, size_t buffer_size,
                           ROI roi, int quantization[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
    PIXEL16S *lowlow_row_ptr = lowlow_band;
    PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
    PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
    PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;
#endif

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    int row, column;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    //const int prescale = 2;
#if _TRANSFORM_PRESCALE
    int lowround = (lowscale > 0) ? (1 << (lowscale - 1)) : 0;
#endif
    int k;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
#else
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
#endif

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    if (lowlow_quantization > 1)
    {
        // The buffer must be large enough for twelve rows
        assert(buffer_size >= (12 * output_buffer_size));
    }
    else
    {
        // The buffer must be large enough for eleven rows
        assert(buffer_size >= (11 * output_buffer_size));
    }

    // Compute the allocated width of each buffer
    output_buffer_width = output_buffer_size / sizeof(PIXEL);

    // Allocate space in the buffer for the horizontal filter results
    bufptr = buffer;
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
    if (lowlow_quantization > 1)
    {
        lowlow_buffer = bufptr;
        bufptr += output_buffer_width;
    }
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
        //FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
        //assert(prescale == 0 && input_scale == 0);
        FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
        rowptr += input_pitch;
    }


    /***** Need to optimize the first and last row calculations *****/

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];

        // The lowpass prescale should be zero
        //assert(lowscale == 0);

        if (lowlow_quantization > 1)
        {
            lowlow_buffer[column] = SATURATE(sum);
        }
        else
        {
            lowlow_row_ptr[column] = SATURATE(sum);
        }

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
    if (lowlow_quantization > 1)
    {
        // Quantize the first row of 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    }
    // Quantize the first row of 8-bit highpass coefficients
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
    if (lowlow_quantization > 1)
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            //FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
            assert(prescale == 0 && input_scale == 0);
            FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
            rowptr += input_pitch;
        }
    }
#endif

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        __m64 *lowlow_ptr;
        __m64 *highlow_ptr = (__m64 *)highlow_buffer;
        __m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
        __m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

        int column_step = 4;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        if (lowlow_quantization > 1)
        {
            lowlow_ptr = (__m64 *)lowlow_buffer;
        }
        else
        {
            lowlow_ptr = (__m64 *)lowlow_row_ptr;
        }

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 low_pi16;
            __m64 sum_pi16;
            __m64 sum8_pi16;
            __m64 quad_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;


            // Apply the vertical filters to the horizontal lowpass results //

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[0][column]);

            // Initialize the highpass filter sum
            sum_pi16 = _mm_setzero_si64();

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[2][column]);

            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_pi16 = _mm_setzero_si64();
            sum8_pi16 = _mm_adds_pi16(sum8_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[3][column]);

            // Compute the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

            // Store the lowpass results
            *(lowlow_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_pi16 = _mm_subs_pi16(sum8_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Approximate division by eight
            half_pi16 = _mm_set1_pi16(4);
            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);
            sum_pi16 = _mm_srai_pi16(sum_pi16, 3);

            sum_pi16 = _mm_adds_pi16(sum_pi16, sum8_pi16);

            // Store the four highpass results
            *(highlow_ptr++) = sum_pi16;


            // Apply the vertical filters to the horizontal highpass results //

            sum_pi16 = _mm_setzero_si64();

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&highpass[0][column]);

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&highpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&highpass[2][column]);

            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_pi16 = _mm_setzero_si64();
            sum8_pi16 = _mm_adds_pi16(sum8_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[3][column]);

            // Compute and store the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
            *(lowhigh_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_pi16 = _mm_subs_pi16(sum8_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&highpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Approximate division by eight
            half_pi16 = _mm_set1_pi16(4);
            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);
            sum_pi16 = _mm_srai_pi16(sum_pi16, 3);

            sum_pi16 = _mm_adds_pi16(sum_pi16, sum8_pi16);

            // Store the four highpass results
            *(highhigh_ptr++) = sum_pi16;
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];

            // The lowpass prescale should be zero
            //assert(lowscale == 0);

            if (lowlow_quantization > 1)
            {
                lowlow_buffer[column] = SATURATE(sum);
            }
            else
            {
                lowlow_row_ptr[column] = SATURATE(sum);
            }

            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum +=  lowpass[2][column];
            sum += -lowpass[3][column];
            highlow_buffer[column] = SATURATE(sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum +=  highpass[2][column];
            sum += -highpass[3][column];
            highhigh_buffer[column] = SATURATE(sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                //FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
                //assert(prescale == 0 && input_scale == 0);
                FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
                rowptr += input_pitch;
            }
        }

#if _HIGHPASS_8S
        if (lowlow_quantization > 1)
        {
            // Quantize the current row of 16-bit lowpass coefficients
            QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
        }
        // Quantize the current row of 8-bit highpass coefficients
        QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
        // Quantize the current row of results for each 16-bit output band
        if (lowlow_quantization > 1)
            QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];

        // The lowpass prescale should be zero
        //assert(lowscale == 0);

        if (lowlow_quantization > 1)
        {
            lowlow_buffer[column] = SATURATE(sum);
        }
        else
        {
            lowlow_row_ptr[column] = SATURATE(sum);
        }

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
    if (lowlow_quantization > 1)
    {
        // Quantize the 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    }
    // Quantize the 8-bit highpass coefficients
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
    if (lowlow_quantization > 1)
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuant16s(PIXEL *input_image, int input_pitch,
                           PIXEL *lowlow_band, int lowlow_pitch,
                           PIXEL *lowhigh_band, int lowhigh_pitch,
                           PIXEL *highlow_band, int highlow_pitch,
                           PIXEL *highhigh_band, int highhigh_pitch,
                           PIXEL *buffer, size_t buffer_size,
                           ROI roi, int quantization[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
    PIXEL16S *lowlow_row_ptr = lowlow_band;
    PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
    PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
    PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;
#endif

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    int row, column;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    //const int prescale = 2;
    int k;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
#else
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
#endif

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;
    //output_width = ALIGN16(output_width);

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    if (lowlow_quantization > 1)
    {
        // The buffer must be large enough for twelve rows
        assert(buffer_size >= (12 * output_buffer_size));
    }
    else
    {
        // The buffer must be large enough for eleven rows
        assert(buffer_size >= (11 * output_buffer_size));
    }

    // Compute the allocated width of each buffer
    output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

    // Allocate space in the buffer for the horizontal filter results
    bufptr = buffer;
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
    if (lowlow_quantization > 1)
    {
        lowlow_buffer = bufptr;
        bufptr += output_buffer_width;
    }
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
        //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
        FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
        rowptr += input_pitch;
    }


    // Need to optimize the first and last row calculations //

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];

        // The lowpass prescale should be zero
        //assert(lowscale == 0);

        if (lowlow_quantization > 1)
        {
            lowlow_buffer[column] = SATURATE(sum);
        }
        else
        {
            lowlow_row_ptr[column] = SATURATE(sum);
        }

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
    if (lowlow_quantization > 1)
    {
        // Quantize the first row of 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    }
    // Quantize the first row of 8-bit highpass coefficients
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
    if (lowlow_quantization > 1)
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, NULL);
            FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale);
            rowptr += input_pitch;
        }
    }
#endif

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        __m128i *lowlow_ptr;
        __m128i *highlow_ptr = (__m128i *)highlow_buffer;
        __m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
        __m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

        int column_step = 8;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        if (lowlow_quantization > 1)
        {
            lowlow_ptr = (__m128i *)lowlow_buffer;
        }
        else
        {
            lowlow_ptr = (__m128i *)lowlow_row_ptr;
        }

        // Process a group of eight pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m128i low_epi16;
            __m128i sum_epi16;
            __m128i sum8_epi16;
            __m128i quad_epi16;
            __m128i half_epi16;


            /***** Apply the vertical filters to the horizontal lowpass results *****/

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

            // Initialize the highpass filter sum
            sum_epi16 = _mm_setzero_si128();

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

            // Compute the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

            // Store the lowpass results
            _mm_store_si128(lowlow_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6
            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

            // Store the four highpass results
            _mm_store_si128(highlow_ptr++, sum_epi16);


            /***** Apply the vertical filters to the horizontal highpass results *****/

            sum_epi16 = _mm_setzero_si128();

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

            // Compute and store the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
            _mm_store_si128(lowhigh_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


            // Store the four highpass results
            _mm_store_si128(highhigh_ptr++, sum_epi16);
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];

            if (lowlow_quantization > 1)
            {
                lowlow_buffer[column] = SATURATE(sum);
            }
            else
            {
                lowlow_row_ptr[column] = SATURATE(sum);
            }
            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * lowpass[2][column];
            sum += -1 * lowpass[3][column];

            highlow_buffer[column] = (sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = (sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * highpass[2][column];
            sum += -1 * highpass[3][column];
            highhigh_buffer[column] = (sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
                FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
                rowptr += input_pitch;
            }
        }

#if _HIGHPASS_8S
        if (lowlow_quantization > 1)
        {
            // Quantize the current row of 16-bit lowpass coefficients
            QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
        }
        // Quantize the current row of 8-bit highpass coefficients
        QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
        // Quantize the current row of results for each 16-bit output band
        if (lowlow_quantization > 1)
            QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];

        // The lowpass prescale should be zero
        //assert(lowscale == 0);

        if (lowlow_quantization > 1)
        {
            lowlow_buffer[column] = SATURATE(sum);
        }
        else
        {
            lowlow_row_ptr[column] = SATURATE(sum);
        }

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
    if (lowlow_quantization > 1)
    {
        // Quantize the 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    }
    // Quantize the 8-bit highpass coefficients
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
    if (lowlow_quantization > 1)
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif
}

#endif




#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

// Apply the frame (temporal and horizontal) transform to unsigned byte data
void FilterSpatialQuantDifferenceLL16s(PIXEL *input_image, int input_pitch,
                                       PIXEL *lowlow_band, int lowlow_pitch,
                                       PIXEL *lowhigh_band, int lowhigh_pitch,
                                       PIXEL *highlow_band, int highlow_pitch,
                                       PIXEL *highhigh_band, int highhigh_pitch,
                                       PIXEL *buffer, size_t buffer_size,
                                       ROI roi, int quantization[4])
{
    // Stub routine for processor specific dispatch
}

#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuantDifferenceLL16s(PIXEL *input_image, int input_pitch,
                                       PIXEL *lowlow_band, int lowlow_pitch,
                                       PIXEL *lowhigh_band, int lowhigh_pitch,
                                       PIXEL *highlow_band, int highlow_pitch,
                                       PIXEL *highhigh_band, int highhigh_pitch,
                                       PIXEL *buffer, size_t buffer_size,
                                       ROI roi, int quantization[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
    PIXEL16S *lowlow_row_ptr = lowlow_band;
    PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
    PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
    PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;
#endif

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    int row, column;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    //const int prescale = 2;
#if _TRANSFORM_PRESCALE
    int lowround = (lowscale > 0) ? (1 << (lowscale - 1)) : 0;
#endif
    int k;

    int this_has_not_been_modified_for_differencing_LL_yet = 0;
    assert(this_has_not_been_modified_for_differencing_LL_yet);

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
#else
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
#endif

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    if (lowlow_quantization > 1)
    {
        // The buffer must be large enough for twelve rows
        assert(buffer_size >= (12 * output_buffer_size));
    }
    else
    {
        // The buffer must be large enough for eleven rows
        assert(buffer_size >= (11 * output_buffer_size));
    }

    // Compute the allocated width of each buffer
    output_buffer_width = output_buffer_size / sizeof(PIXEL);

    // Allocate space in the buffer for the horizontal filter results
    bufptr = buffer;
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
    if (lowlow_quantization > 1)
    {
        lowlow_buffer = bufptr;
        bufptr += output_buffer_width;
    }
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
        //FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
        //assert(prescale == 0 && input_scale == 0);
        FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
        rowptr += input_pitch;
    }


    /***** Need to optimize the first and last row calculations *****/

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];

        // The lowpass prescale should be zero
        //assert(lowscale == 0);

        if (lowlow_quantization > 1)
        {
            lowlow_buffer[column] = SATURATE(sum);
        }
        else
        {
            lowlow_row_ptr[column] = SATURATE(sum);
        }

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
    if (lowlow_quantization > 1)
    {
        // Quantize the first row of 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    }
    // Quantize the first row of 8-bit highpass coefficients
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
    if (lowlow_quantization > 1)
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            //FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
            assert(prescale == 0 && input_scale == 0);
            FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
            rowptr += input_pitch;
        }
    }
#endif

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        __m64 *lowlow_ptr;
        __m64 *highlow_ptr = (__m64 *)highlow_buffer;
        __m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
        __m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

        int column_step = 4;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        if (lowlow_quantization > 1)
        {
            lowlow_ptr = (__m64 *)lowlow_buffer;
        }
        else
        {
            lowlow_ptr = (__m64 *)lowlow_row_ptr;
        }

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 low_pi16;
            __m64 sum_pi16;
            __m64 quad_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;


            // Apply the vertical filters to the horizontal lowpass results //

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[0][column]);

            // Initialize the highpass filter sum
            sum_pi16 = _mm_setzero_si64();

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[2][column]);

            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[3][column]);

            // Compute the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

            // Store the lowpass results
            *(lowlow_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Approximate division by eight
            half_pi16 = _mm_set1_pi16(4);
            sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

            // Store the four highpass results
            *(highlow_ptr++) = sum_pi16;


            // Apply the vertical filters to the horizontal highpass results //

            sum_pi16 = _mm_setzero_si64();

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&highpass[0][column]);

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&highpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&highpass[2][column]);

            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[3][column]);

            // Compute and store the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
            *(lowhigh_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&highpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Approximate division by eight
            half_pi16 = _mm_set1_pi16(4);
            sum_pi16 = _mm_srai_pi16(sum_pi16, 3);
            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16);

            // Store the four highpass results
            *(highhigh_ptr++) = sum_pi16;
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];

            // The lowpass prescale should be zero
            //assert(lowscale == 0);

            if (lowlow_quantization > 1)
            {
                lowlow_buffer[column] = SATURATE(sum);
            }
            else
            {
                lowlow_row_ptr[column] = SATURATE(sum);
            }

            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum +=  lowpass[2][column];
            sum += -lowpass[3][column];
            highlow_buffer[column] = SATURATE(sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum +=  highpass[2][column];
            sum += -highpass[3][column];
            highhigh_buffer[column] = SATURATE(sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                //FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width, input_scale, prescale);
                //assert(prescale == 0 && input_scale == 0);
                FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
                rowptr += input_pitch;
            }
        }

#if _HIGHPASS_8S
        if (lowlow_quantization > 1)
        {
            // Quantize the current row of 16-bit lowpass coefficients
            QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
        }
        // Quantize the current row of 8-bit highpass coefficients
        QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
        // Quantize the current row of results for each 16-bit output band
        if (lowlow_quantization > 1)
            QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];

        // The lowpass prescale should be zero
        //assert(lowscale == 0);

        if (lowlow_quantization > 1)
        {
            lowlow_buffer[column] = SATURATE(sum);
        }
        else
        {
            lowlow_row_ptr[column] = SATURATE(sum);
        }

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
    if (lowlow_quantization > 1)
    {
        // Quantize the 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    }
    // Quantize the 8-bit highpass coefficients
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
    if (lowlow_quantization > 1)
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the forward spatial (horizontal and vertical) transform with quantization
void FilterSpatialQuantDifferenceLL16s(PIXEL *input_image, int input_pitch,
                                       PIXEL *lowlow_band, int lowlow_pitch,
                                       PIXEL *lowhigh_band, int lowhigh_pitch,
                                       PIXEL *highlow_band, int highlow_pitch,
                                       PIXEL *highhigh_band, int highhigh_pitch,
                                       PIXEL *buffer, size_t buffer_size,
                                       ROI roi, int quantization[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    int row, column;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    //const int prescale = 2;
    int k;


    __m128i quant_epi16;
    __m128i offset_epi16;
    __m128i zero_epi16;
    __m128i sign_epi16;
    __m128i tmp_epi16;

    int lastsum;
    int multiplier;

    // Setup for differencing pre-quantization
    int prequant_midpoint = 0;// divisor/2;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

#if MIDPOINT_PREQUANT
    if (g_midpoint_prequant >= 2 && g_midpoint_prequant < 9)
        prequant_midpoint = lowlow_quantization / g_midpoint_prequant;
#endif

    // Change division to multiplication by a fraction
    multiplier = (uint32_t)(1 << 16) / lowlow_quantization;
    quant_epi16 = _mm_set1_epi16(multiplier);
    zero_epi16 = _mm_set1_epi16(0);
#if MIDPOINT_PREQUANT
    offset_epi16 = _mm_set1_epi16(prequant_midpoint);
#endif


    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;
    //output_width = ALIGN16(output_width);

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);


    // The buffer must be large enough for eleven rows
    assert(buffer_size >= (11 * output_buffer_size));


    // Compute the allocated width of each buffer
    output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

    // Allocate space in the buffer for the horizontal filter results
    bufptr = buffer;
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
        //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
        FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
        rowptr += input_pitch;
    }


    // Need to optimize the first and last row calculations //

    // Use border filters for the first row
    {
        int tmp;
        row = 0;
        lastsum = 0;

        for (column = 0; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[0][column];
            sum += lowpass[1][column];

            if (sum < 0)
            {
                sum = -sum;
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
                sum = -sum;
            }
            else
            {
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
            }

            tmp = sum;
            sum -= lastsum;
            lastsum = tmp;

            // The lowpass prescale should be zero
            //assert(lowscale == 0);

            lowlow_row_ptr[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  =  5 * lowpass[0][column];
            sum -= 11 * lowpass[1][column];
            sum +=  4 * lowpass[2][column];
            sum +=  4 * lowpass[3][column];
            sum -=  1 * lowpass[4][column];
            sum -=  1 * lowpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            highlow_buffer[column] = SATURATE(sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[0][column];
            sum += highpass[1][column];
            lowhigh_buffer[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  =  5 * highpass[0][column];
            sum -= 11 * highpass[1][column];
            sum +=  4 * highpass[2][column];
            sum +=  4 * highpass[3][column];
            sum -=  1 * highpass[4][column];
            sum -=  1 * highpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            highhigh_buffer[column] = SATURATE(sum);
        }
    }



    // Quantize the first row of results for each 16-bit output band
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);


    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
        int lastsumvalue = 0;

#if (1 && XMMOPT)
        __m128i *lowlow_ptr;
        __m128i *highlow_ptr = (__m128i *)highlow_buffer;
        __m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
        __m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

        int column_step = 8;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)
        lowlow_ptr = (__m128i *)lowlow_row_ptr;

        // Process a group of eight pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m128i low_epi16;
            __m128i sum_epi16;
            __m128i sum8_epi16;
            __m128i quad_epi16;
            __m128i half_epi16;


            /***** Apply the vertical filters to the horizontal lowpass results *****/

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

            // Initialize the highpass filter sum
            sum_epi16 = _mm_setzero_si128();

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

            // Compute the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);




            ///////////////////////////////////////////////////
            // Quantize the passlow BEFORE it is differenced.//
            ///////////////////////////////////////////////////
            sign_epi16 = _mm_cmpgt_epi16(zero_epi16, low_epi16);
            // Compute the absolute value
            low_epi16 = _mm_xor_si128(low_epi16, sign_epi16);
            low_epi16 = _mm_sub_epi16(low_epi16, sign_epi16);
#if MIDPOINT_PREQUANT
            // Add the prequant_midpoint for quantization rounding
            low_epi16 = _mm_add_epi16(low_epi16, offset_epi16);
#endif
            // Multiply by the quantization factor
            low_epi16 = _mm_mulhi_epu16(low_epi16, quant_epi16);
            // Restore the sign
            low_epi16 = _mm_xor_si128(low_epi16, sign_epi16);
            low_epi16 = _mm_sub_epi16(low_epi16, sign_epi16);



            ///////////////////////////////////////////////////
            // New differencing engine                       //
            // this code makes the low-pass difference data. //
            ///////////////////////////////////////////////////
            tmp_epi16 = _mm_slli_si128(low_epi16, 1 * 2);
            tmp_epi16 = _mm_insert_epi16(tmp_epi16, lastsumvalue, 0);
            lastsumvalue = _mm_extract_epi16(low_epi16, 7);
            low_epi16 = _mm_sub_epi16(low_epi16, tmp_epi16);




            // Store the lowpass results
            _mm_store_si128(lowlow_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6
            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

            // Store the four highpass results
            _mm_store_si128(highlow_ptr++, sum_epi16);


            /***** Apply the vertical filters to the horizontal highpass results *****/

            sum_epi16 = _mm_setzero_si128();

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

            // Compute and store the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
            _mm_store_si128(lowhigh_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


            // Store the four highpass results
            _mm_store_si128(highhigh_ptr++, sum_epi16);
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        lastsum = lowlow_row_ptr[column - 1];
        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum, tmp;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];

            if (sum < 0)
            {
                sum = -sum;
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
                sum = -sum;
            }
            else
            {
#if MIDPOINT_PREQUANT
                sum += prequant_midpoint;
#endif
                sum *= multiplier; // quantize
                sum >>= 16;
            }

            tmp = sum;
            sum -= lastsum;
            lastsum = tmp;

            lowlow_row_ptr[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * lowpass[2][column];
            sum += -1 * lowpass[3][column];

            highlow_buffer[column] = (sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = (sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * highpass[2][column];
            sum += -1 * highpass[3][column];
            highhigh_buffer[column] = (sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, NULL);
                FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
                rowptr += input_pitch;
            }
        }


        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    lastsum = 0;
    for (column = 0; column < output_width; column++)
    {
        int32_t sum, tmp;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];

        if (sum < 0)
        {
            sum = -sum;
#if MIDPOINT_PREQUANT
            sum += prequant_midpoint;
#endif
            sum *= multiplier; // quantize
            sum >>= 16;
            sum = -sum;
        }
        else
        {
#if MIDPOINT_PREQUANT
            sum += prequant_midpoint;
#endif
            sum *= multiplier; // quantize
            sum >>= 16;
        }

        tmp = sum;
        sum -= lastsum;
        lastsum = tmp;

        // The lowpass prescale should be zero
        //assert(lowscale == 0);

        lowlow_row_ptr[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

    // Quantize the first row of results for each 16-bit output band
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
}

#endif


#if 0 // FilterSpatialPrescaleQuant16s() removed

#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void FilterSpatialPrescaleQuant16s(PIXEL *input_image, int input_pitch,
                                   PIXEL *lowlow_band, int lowlow_pitch,
                                   PIXEL *lowhigh_band, int lowhigh_pitch,
                                   PIXEL *highlow_band, int highlow_pitch,
                                   PIXEL *highhigh_band, int highhigh_pitch,
                                   PIXEL *buffer, size_t buffer_size, ROI roi,
                                   int quantization[4])
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Compute the forward spatial transform with prescaling and quantization
void FilterSpatialPrescaleQuant16s(PIXEL *input_image, int input_pitch,
                                   PIXEL *lowlow_band, int lowlow_pitch,
                                   PIXEL *lowhigh_band, int lowhigh_pitch,
                                   PIXEL *highlow_band, int highlow_pitch,
                                   PIXEL *highhigh_band, int highhigh_pitch,
                                   PIXEL *buffer, size_t buffer_size, ROI roi,
                                   int quantization[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
    PIXEL16S *lowlow_row_ptr = lowlow_band;
    PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
    PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
    PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;
#endif

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    PIXEL *prescaling_buffer;
    size_t prescaling_buffer_size;
    int prescaling_buffer_width;
    int row, column;
    int k;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
#else
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
#endif

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    // Compute the size of the buffer for prescaling the input rows to avoid overflow
    prescaling_buffer_size = roi.width * sizeof(PIXEL);

    // Round tp the buffer size to an integer number of cache lines
    prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
    // The buffer must be large enough for twelve rows plus the prescaling buffer
    assert(buffer_size >= ((12 * output_buffer_size) + prescaling_buffer_size));
#else
    // The buffer must be large enough for eleven rows plus the prescaling buffer
    assert(buffer_size >= ((11 * output_buffer_size) + prescaling_buffer_size));
#endif

    // Computed the allocated width of each buffer
    output_buffer_width = output_buffer_size / sizeof(PIXEL);

    // Compute the allocated width of the prescaling buffer
    prescaling_buffer_width = prescaling_buffer_size / sizeof(PIXEL);

    // Start allocating intermediate buffers at the beginning of the supplied buffer
    bufptr = buffer;

    // Allocate space in the buffer for prescaling the input coefficients
    prescaling_buffer = bufptr;
    bufptr += prescaling_buffer_width;

    // Allocate space in the buffer for the horizontal filter results
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
    lowlow_buffer = bufptr;
    bufptr += output_buffer_width;
#endif
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
        FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
        rowptr += input_pitch;
    }


    // Need to optimize the first and last row calculations //

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the first row of results for each 8-bit output band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
            rowptr += input_pitch;
        }
    }
#endif

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
        __m64 *lowlow_ptr = (__m64 *)lowlow_buffer;
#else
        __m64 *lowlow_ptr = (__m64 *)lowlow_row_ptr;
#endif
        __m64 *highlow_ptr = (__m64 *)highlow_buffer;
        __m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
        __m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

        int column_step = 4;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 low_pi16;
            __m64 sum_pi16;
            __m64 quad_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;


            // Apply the vertical filters to the horizontal lowpass results //

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[0][column]);
            // Initialize the highpass filter sum
            sum_pi16 = _mm_setzero_si64();
            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[1][column]);
            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[4][column]);
            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[5][column]);
            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            half_pi16 = _mm_set1_pi16(4);
            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16); // +4 rounding

            sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8



            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[2][column]);
            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[3][column]);
            // Compute the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

            // Store the lowpass results
            *(lowlow_ptr++) = low_pi16;
            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


            // Store the four highpass results
            *(highlow_ptr++) = sum_pi16;


            // Apply the vertical filters to the horizontal highpass results //

            sum_pi16 = _mm_setzero_si64();

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&highpass[0][column]);
            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&highpass[1][column]);
            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[4][column]);
            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&highpass[5][column]);
            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            sum_pi16 = _mm_adds_pi16(sum_pi16, half_pi16); // +4 rounding

            sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8


            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&highpass[2][column]);
            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[3][column]);
            // Compute and store the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
            *(lowhigh_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


            // Store the four highpass results
            *(highhigh_ptr++) = sum_pi16;
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
            lowlow_buffer[column] = SATURATE(sum);
#else
            lowlow_row_ptr[column] = SATURATE(sum);
#endif
            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum +=  lowpass[2][column];
            sum += -lowpass[3][column];
            highlow_buffer[column] = SATURATE(sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            sum +=  highpass[2][column];
            sum += -highpass[3][column];
            highhigh_buffer[column] = SATURATE(sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
                rowptr += input_pitch;
            }
        }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
        // Quantize the current row 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        // Quantize the current row of results for each 8-bit highpass band
        QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
        // Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the last row of 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the last row of results for each 8-bit highpass band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the last row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

void FilterSpatialPrescaleQuant16s(PIXEL *input_image, int input_pitch,
                                   PIXEL *lowlow_band, int lowlow_pitch,
                                   PIXEL *lowhigh_band, int lowhigh_pitch,
                                   PIXEL *highlow_band, int highlow_pitch,
                                   PIXEL *highhigh_band, int highhigh_pitch,
                                   PIXEL *buffer, size_t buffer_size, ROI roi,
                                   int quantization[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
    PIXEL16S *lowlow_row_ptr = lowlow_band;
    PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
    PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
    PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;
#endif

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    PIXEL *prescaling_buffer;
    size_t prescaling_buffer_size;
    int prescaling_buffer_width;
    int row, column;
    int k;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
#else
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
#endif

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    // Compute the size of the buffer for prescaling the input rows to avoid overflow
    prescaling_buffer_size = roi.width * sizeof(PIXEL);

    // Round tp the buffer size to an integer number of cache lines
    prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
    // The buffer must be large enough for 16 output rows plus the prescaling buffer
    assert(buffer_size >= ((16 * output_buffer_size) + prescaling_buffer_size));
#else
    // The buffer must be large enough for 15 output rows plus the prescaling buffer
    assert(buffer_size >= ((15 * output_buffer_size) + prescaling_buffer_size));
#endif

    // Computed the allocated width of each buffer
    output_buffer_width = output_buffer_size / sizeof(PIXEL);

    // Compute the allocated width of the prescaling buffer
    prescaling_buffer_width = prescaling_buffer_size / sizeof(PIXEL);

    // Start allocating intermediate buffers at the beginning of the supplied buffer
    bufptr = buffer;

    // Allocate space in the buffer for prescaling the input coefficients
    prescaling_buffer = bufptr;
    bufptr += prescaling_buffer_width;

    // Allocate space in the buffer for the horizontal filter results
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
    lowlow_buffer = bufptr;
    bufptr += output_buffer_width;
#endif
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
        rowptr += input_pitch;
    }


    // Need to optimize the first and last row calculations //

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the first row of results for each 8-bit output band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
            rowptr += input_pitch;
        }
    }
#endif

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
        __m128i *lowlow_ptr = (__m128i *)lowlow_buffer;
#else
        __m128i *lowlow_ptr = (__m128i *)lowlow_row_ptr;
#endif
        __m128i *highlow_ptr = (__m128i *)highlow_buffer;
        __m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
        __m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

        int column_step = 8;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

        // Check that the input and output addresses are properly aligned
        for (k = 0; k < buffer_row_count; k++)
        {
            assert(ISALIGNED16(lowpass[k]));
            assert(ISALIGNED16(highpass[k]));
        }
        assert(ISALIGNED16(lowlow_ptr));
        assert(ISALIGNED16(lowhigh_ptr));
        assert(ISALIGNED16(highlow_ptr));
        assert(ISALIGNED16(highhigh_ptr));

#if (1 && XMMOPT)

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m128i low_epi16;
            __m128i sum_epi16;
            __m128i sum8_epi16;
            __m128i quad_epi16;
            __m128i mask_epi16;
            __m128i half_epi16;


            /***** Apply the vertical filters to the horizontal lowpass results *****/

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

            // Initialize the highpass filter sum
            sum_epi16 = _mm_setzero_si128();

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

            // Compute the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

            // Store the lowpass results
            _mm_store_si128(lowlow_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            half_epi16 = _mm_set1_epi16(4); //was 4
            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

            // Store the four highpass results
            _mm_store_si128(highlow_ptr++, sum_epi16);


            /***** Apply the vertical filters to the horizontal highpass results *****/

            sum_epi16 = _mm_setzero_si128();

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

            // Compute and store the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
            _mm_store_si128(lowhigh_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


            // Store the four highpass results
            _mm_store_si128(highhigh_ptr++, sum_epi16);
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
            lowlow_buffer[column] = SATURATE(sum);
#else
            lowlow_row_ptr[column] = SATURATE(sum);
#endif
            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * lowpass[2][column];
            sum += -1 * lowpass[3][column];

            highlow_buffer[column] = (sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = (sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * highpass[2][column];
            sum += -1 * highpass[3][column];
            highhigh_buffer[column] = (sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
                rowptr += input_pitch;
            }
        }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
        // Quantize the current row 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        // Quantize the current row of results for each 8-bit highpass band
        QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
        // Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the last row of 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the last row of results for each 8-bit highpass band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the last row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

    //_mm_empty();	// Clear the mmx register state
}

#endif

#endif //0  FilterSpatialPrescaleQuant16s() removed



// Forward spatial wavelet transform with prescaling for 10-bit video sources
// (Pentium 4 version only)
//#if BUILD_PROSPECT//10-bit for everyone

void FilterSpatialV210Quant16s(PIXEL *input_image, int input_pitch,
                               PIXEL *lowlow_band, int lowlow_pitch,
                               PIXEL *lowhigh_band, int lowhigh_pitch,
                               PIXEL *highlow_band, int highlow_pitch,
                               PIXEL *highhigh_band, int highhigh_pitch,
                               PIXEL *buffer, size_t buffer_size, ROI roi,
                               int quantization[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
    PIXEL16S *lowlow_row_ptr = lowlow_band;
    PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
    PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
    PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;
#endif

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    PIXEL *prescaling_buffer;
    size_t prescaling_buffer_size;
    int prescaling_buffer_width;
    int row, column;
    int k;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
#else
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
#endif

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    // Compute the size of the buffer for prescaling the input rows to avoid overflow
    prescaling_buffer_size = roi.width * sizeof(PIXEL);

    // Round tp the buffer size to an integer number of cache lines
    prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
    // The buffer must be large enough for twelve rows plus the prescaling buffer
    assert(buffer_size >= ((12 * output_buffer_size) + prescaling_buffer_size));
#else
    // The buffer must be large enough for eleven rows plus the prescaling buffer
    assert(buffer_size >= ((11 * output_buffer_size) + prescaling_buffer_size));
#endif

    // Computed the allocated width of each buffer
    output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

    // Compute the allocated width of the prescaling buffer
    prescaling_buffer_width = (int)prescaling_buffer_size / sizeof(PIXEL);

    // Start allocating intermediate buffers at the beginning of the supplied buffer
    bufptr = buffer;

    // Allocate space in the buffer for prescaling the input coefficients
    prescaling_buffer = bufptr;
    bufptr += prescaling_buffer_width;

    // Allocate space in the buffer for the horizontal filter results
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
    lowlow_buffer = bufptr;
    bufptr += output_buffer_width;
#endif
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        FilterHorizontalRow10bit16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
        rowptr += input_pitch;
    }


    /***** Need to optimize the first and last row calculations *****/

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the first row of results for each 8-bit output band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the first row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            FilterHorizontalRow10bit16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
            rowptr += input_pitch;
        }
    }
#endif

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
        __m128i *lowlow_ptr = (__m128i *)lowlow_buffer;
#else
        __m128i *lowlow_ptr = (__m128i *)lowlow_row_ptr;
#endif
        __m128i *highlow_ptr = (__m128i *)highlow_buffer;
        __m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
        __m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

        int column_step = 8;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

        // Check that the input and output addresses are properly aligned
        for (k = 0; k < buffer_row_count; k++)
        {
            assert(ISALIGNED16(lowpass[k]));
            assert(ISALIGNED16(highpass[k]));
        }
        assert(ISALIGNED16(lowlow_ptr));
        assert(ISALIGNED16(lowhigh_ptr));
        assert(ISALIGNED16(highlow_ptr));
        assert(ISALIGNED16(highhigh_ptr));

#if (1 && XMMOPT)

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m128i low_epi16;
            __m128i sum_epi16;
            __m128i sum8_epi16;
            __m128i quad_epi16;
            __m128i half_epi16;


            /***** Apply the vertical filters to the horizontal lowpass results *****/

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

            // Initialize the highpass filter sum
            sum_epi16 = _mm_setzero_si128();

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

            // Compute the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

            // Scale the lowpass result to eliminate overflows in the vertical transform
            low_epi16 = _mm_srli_epi16(low_epi16, V210_VERTICAL_SHIFT);

            // Store the lowpass results
            _mm_store_si128(lowlow_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            half_epi16 = _mm_set1_epi16(4); //was 4
            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

            // Store the four highpass results
            _mm_store_si128(highlow_ptr++, sum_epi16);


            /***** Apply the vertical filters to the horizontal highpass results *****/

            sum_epi16 = _mm_setzero_si128();

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

            // Compute and store the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
            _mm_store_si128(lowhigh_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);


            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);


            // Store the four highpass results
            _mm_store_si128(highhigh_ptr++, sum_epi16);
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];

            // Scale the lowpass result to eliminate overflows in the vertical transform
            sum >>= V210_VERTICAL_SHIFT;

#if _QUANTIZE_SPATIAL_LOWPASS
            lowlow_buffer[column] = SATURATE(sum);
#else
            lowlow_row_ptr[column] = SATURATE(sum);
#endif
            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * lowpass[2][column];
            sum += -1 * lowpass[3][column];

            highlow_buffer[column] = (sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = (sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * highpass[2][column];
            sum += -1 * highpass[3][column];
            highhigh_buffer[column] = (sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                FilterHorizontalRow10bit16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
                rowptr += input_pitch;
            }
        }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
        // Quantize the current row 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        // Quantize the current row of results for each 8-bit highpass band
        QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
        // Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the last row of 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the last row of results for each 8-bit highpass band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
    // Quantize the last row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif
}
//#endif //p4



#if _HIGHPASS_CODED

// Compute the forward spatial transform, quantize the coefficients, and encode
// the quantized coefficients using runs of zeros and variable length coding.
// Note that this routine is generic MMX, also need to code version for SSE2.
// The routine was adapted from FilterSpatialPrescaleQuant16s and may still include
// prescaling.

void FilterSpatialQuant16sToCoded(ENCODER *encoder,
                                  PIXEL *input_image, int input_pitch,
                                  PIXEL *lowlow_band, int lowlow_pitch,
                                  PIXEL *lowhigh_band, int lowhigh_pitch,
                                  PIXEL *highlow_band, int highlow_pitch,
                                  PIXEL *highhigh_band, int highhigh_pitch,
                                  PIXEL *buffer, size_t buffer_size, ROI roi,
                                  int quantization[4], int coded_size[4])
{
    PIXEL *rowptr = input_image;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    PIXEL *lowlow_row_ptr = lowlow_band;

    BITSTREAM lowhigh_stream;
    BITSTREAM highlow_stream;
    BITSTREAM highhigh_stream;

    int lowhigh_gap;
    int highlow_gap;
    int highhigh_gap;

    int lowhigh_zero_count = 0;
    int highlow_zero_count = 0;
    int highhigh_zero_count = 0;

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    //PIXEL *prescaling_buffer;
    //size_t prescaling_buffer_size;
    //int prescaling_buffer_width;
    int row, column;
    int k;

    // Compute the size of the highpass bands
    int output_height = roi.height / 2;
    size_t lowhigh_band_size = lowhigh_pitch * output_height;
    size_t highlow_band_size = highlow_pitch * output_height;
    size_t highhigh_band_size = highhigh_pitch * output_height;

    // Compute the width of each row of horizontal filter output
    assert((roi.width % 2) == 0);
    output_width = roi.width / 2;

    // Convert pitch from bytes to pixels
    input_pitch /= sizeof(PIXEL);
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);

    // Compute the gaps at the end of each band of highpass coefficients
    lowhigh_gap = lowhigh_pitch - output_width;
    highlow_gap = highlow_pitch - output_width;
    highhigh_gap = highhigh_pitch - output_width;

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    // Compute the size of the buffer for prescaling the input rows to avoid overflow
    prescaling_buffer_size = roi.width * sizeof(PIXEL);

    // Round tp the buffer size to an integer number of cache lines
    //prescaling_buffer_size = ALIGN(prescaling_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
    // The buffer must be large enough for twelve rows plus the prescaling buffer
    assert(buffer_size >= ((12 * output_buffer_size) + prescaling_buffer_size));
#else
    // The buffer must be large enough for eleven rows plus the prescaling buffer
    assert(buffer_size >= ((11 * output_buffer_size) + prescaling_buffer_size));
#endif

    // Computed the allocated width of each buffer
    output_buffer_width = output_buffer_size / sizeof(PIXEL);

    // Compute the allocated width of the prescaling buffer
    //prescaling_buffer_width = prescaling_buffer_size / sizeof(PIXEL);

    // Start allocating intermediate buffers at the beginning of the supplied buffer
    bufptr = buffer;

    // Allocate space in the buffer for prescaling the input coefficients
    //prescaling_buffer = bufptr;		bufptr += prescaling_buffer_width;

    // Allocate space in the buffer for the horizontal filter results
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
    lowlow_buffer = bufptr;
    bufptr += output_buffer_width;
#endif
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Initialize bitstream structures for the highpass bands
    InitBitstream(&lowhigh_stream);
    InitBitstream(&highlow_stream);
    InitBitstream(&highhigh_stream);

    // Bind the bitstreams to the highpass bands
    SetBitstreamBuffer(&lowhigh_stream, (uint8_t *)lowhigh_band, lowhigh_band_size, BITSTREAM_ACCESS_WRITE);
    SetBitstreamBuffer(&highlow_stream, (uint8_t *)highlow_band, highlow_band_size, BITSTREAM_ACCESS_WRITE);
    SetBitstreamBuffer(&highhigh_stream, (uint8_t *)highhigh_band, highhigh_band_size, BITSTREAM_ACCESS_WRITE);

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
        //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
        FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
        rowptr += input_pitch;
    }


    // Need to optimize the first and last row calculations

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

    // Quantize the first row of results for each 16-bit output band

#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

    QuantizeRow16sToCoded(encoder, &lowhigh_stream, lowhigh_buffer, output_width, lowhigh_gap,
                          lowhigh_quantization, &lowhigh_zero_count, FALSE);

    QuantizeRow16sToCoded(encoder, &highlow_stream, highlow_buffer, output_width, highlow_gap,
                          highlow_quantization, &highlow_zero_count, FALSE);

    QuantizeRow16sToCoded(encoder, &highhigh_stream, highhigh_buffer, output_width, highhigh_gap,
                          highhigh_quantization, &highhigh_zero_count, FALSE);

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
            FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
            rowptr += input_pitch;
        }
    }
#endif

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    //highlow_row_ptr += highlow_pitch;
    //lowhigh_row_ptr += lowhigh_pitch;
    //highhigh_row_ptr += highhigh_pitch;

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
        __m64 *lowlow_ptr = (__m64 *)lowlow_buffer;
#else
        __m64 *lowlow_ptr = (__m64 *)lowlow_row_ptr;
#endif
        __m64 *highlow_ptr = (__m64 *)highlow_buffer;
        __m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
        __m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

        int column_step = 4;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 low_pi16;
            __m64 sum_pi16;
            __m64 quad_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;


            // Apply the vertical filters to the horizontal lowpass results //

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[0][column]);
            // Initialize the highpass filter sum
            sum_pi16 = _mm_setzero_si64();
            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[1][column]);
            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[4][column]);
            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[5][column]);
            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8



            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[2][column]);
            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[3][column]);
            // Compute the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

            // Store the lowpass results
            *(lowlow_ptr++) = low_pi16;
            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


            // Store the four highpass results
            *(highlow_ptr++) = sum_pi16;


            // Apply the vertical filters to the horizontal highpass results //

            sum_pi16 = _mm_setzero_si64();

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&highpass[0][column]);
            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&highpass[1][column]);
            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[4][column]);
            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&highpass[5][column]);
            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8


            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&highpass[2][column]);
            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[3][column]);
            // Compute and store the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
            *(lowhigh_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


            // Store the four highpass results
            *(highhigh_ptr++) = sum_pi16;
        }

        //_mm_empty();	// Clear the MMX register state

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
            lowlow_buffer[column] = SATURATE(sum);
#else
            lowlow_row_ptr[column] = SATURATE(sum);
#endif
            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  8 * lowpass[2][column];
            sum += -8 * lowpass[3][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            highlow_buffer[column] = SATURATE(sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  8 * highpass[2][column];
            sum += -8 * highpass[3][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            highhigh_buffer[column] = SATURATE(sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                //FilterHorizontalRowPrescaled16s(rowptr, lowpass[k], highpass[k], roi.width, prescaling_buffer);
                FilterHorizontalRow16s(rowptr, lowpass[k], highpass[k], roi.width);
                rowptr += input_pitch;
            }
        }

#if _QUANTIZE_SPATIAL_LOWPASS
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

        QuantizeRow16sToCoded(encoder, &lowhigh_stream, lowhigh_buffer, output_width, lowhigh_gap,
                              lowhigh_quantization, &lowhigh_zero_count, FALSE);

        QuantizeRow16sToCoded(encoder, &highlow_stream, highlow_buffer, output_width, highlow_gap,
                              highlow_quantization, &highlow_zero_count, FALSE);

        QuantizeRow16sToCoded(encoder, &highhigh_stream, highhigh_buffer, output_width, highhigh_gap,
                              highhigh_quantization, &highhigh_zero_count, FALSE);

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        //highlow_row_ptr += highlow_pitch;
        //lowhigh_row_ptr += lowhigh_pitch;
        //highhigh_row_ptr += highhigh_pitch;
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

    QuantizeRow16sToCoded(encoder, &lowhigh_stream, lowhigh_buffer, output_width, lowhigh_gap,
                          lowhigh_quantization, &lowhigh_zero_count, true);

    QuantizeRow16sToCoded(encoder, &highlow_stream, highlow_buffer, output_width, highlow_gap,
                          highlow_quantization, &highlow_zero_count, true);

    QuantizeRow16sToCoded(encoder, &highhigh_stream, highhigh_buffer, output_width, highhigh_gap,
                          highhigh_quantization, &highhigh_zero_count, true);

    // Check that the last runs of zeros has been placed in each stream
    assert(lowhigh_zero_count == 0);
    assert(highlow_zero_count == 0);
    assert(highhigh_zero_count == 0);

    // Append the band end codeword to the encoded coefficients
    FinishEncodeBand(&lowhigh_stream, encoder->band_end_code[encoder->active_codebook], encoder->band_end_size[encoder->active_codebook]);
    FinishEncodeBand(&highlow_stream, encoder->band_end_code[encoder->active_codebook], encoder->band_end_size[encoder->active_codebook]);
    FinishEncodeBand(&highhigh_stream, encoder->band_end_code[encoder->active_codebook], encoder->band_end_size[encoder->active_codebook]);

    // Flush the bitstreams
    FlushBitstream(&lowhigh_stream);
    FlushBitstream(&highlow_stream);
    FlushBitstream(&highhigh_stream);

    // Leave the bitstreams aligned on a tag word boundary
    AlignBitsTag(&lowhigh_stream);
    AlignBitsTag(&highlow_stream);
    AlignBitsTag(&highhigh_stream);

    // Record the size of each encoded band
    coded_size[0] = 0;
    coded_size[1] = BitstreamByteCount(&lowhigh_stream);
    coded_size[2] = BitstreamByteCount(&highlow_stream);
    coded_size[3] = BitstreamByteCount(&highhigh_stream);

    // Check that the encoded bands did not overflow the available space
    assert(coded_size[1] <= lowhigh_band_size);
    assert(coded_size[2] <= highlow_band_size);
    assert(coded_size[3] <= highhigh_band_size);
}

#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void FilterSpatialYUVQuant16s(uint8_t *input_data, int input_pitch,
                              PIXEL *lowlow_band, int lowlow_pitch,
                              PIXEL *lowhigh_band, int lowhigh_pitch,
                              PIXEL *highlow_band, int highlow_pitch,
                              PIXEL *highhigh_band, int highhigh_pitch,
                              PIXEL *buffer, size_t buffer_size, ROI roi,
                              int channel, int quantization[4], FRAME_INFO *frame, int precision)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Compute the forward spatial transform with prescaling and quantization
void FilterSpatialYUVQuant16s(uint8_t *input_data, int input_pitch,
                              PIXEL *lowlow_band, int lowlow_pitch,
                              PIXEL *lowhigh_band, int lowhigh_pitch,
                              PIXEL *highlow_band, int highlow_pitch,
                              PIXEL *highhigh_band, int highhigh_pitch,
                              PIXEL *buffer, size_t buffer_size, ROI roi,
                              int channel, int quantization[4], FRAME_INFO *frame, int precision, int limit_yuv)
{
    uint8_t *rowptr = input_data;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Change the highpass output bands to be 8-bit pixels //

#if _HIGHPASS_8S
    PIXEL16S *lowlow_row_ptr = lowlow_band;
    PIXEL8S *lowhigh_row_ptr = (PIXEL8S *)lowhigh_band;
    PIXEL8S *highlow_row_ptr = (PIXEL8S *)highlow_band;
    PIXEL8S *highhigh_row_ptr = (PIXEL8S *)highhigh_band;
#else
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;
#endif

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    PIXEL *unpacking_buffer;
    size_t unpacking_buffer_size = 0;
    int unpacking_buffer_width;
    int row, column;
    int k;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
#if _HIGHPASS_8S
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
#else
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
#endif

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    // Compute the size of the buffer for prescaling the input rows to avoid overflow
    unpacking_buffer_size = roi.width * sizeof(PIXEL);

    // Round tp the buffer size to an integer number of cache lines
    unpacking_buffer_size = ALIGN(unpacking_buffer_size, _CACHE_LINE_SIZE);

#if _QUANTIZE_SPATIAL_LOWPASS
    // The buffer must be large enough for sixteen rows plus the unpacking buffer
    assert(buffer_size >= ((16 * output_buffer_size) + unpacking_buffer_size));
#else
    // The buffer must be large enough for fifteen rows plus the unpacking buffer
    assert(buffer_size >= ((15 * output_buffer_size) + unpacking_buffer_size));
#endif

    // Computed the allocated width of each buffer
    output_buffer_width = output_buffer_size / sizeof(PIXEL);

    // Compute the allocated width of the prescaling buffer
    unpacking_buffer_width = unpacking_buffer_size / sizeof(PIXEL);

    // Start allocating intermediate buffers at the beginning of the supplied buffer
    bufptr = buffer;

    // Allocate space in the buffer for prescaling the input coefficients
    unpacking_buffer = bufptr;
    bufptr += unpacking_buffer_width;

    // Allocate space in the buffer for the horizontal filter results
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
#if _QUANTIZE_SPATIAL_LOWPASS
    lowlow_buffer = bufptr;
    bufptr += output_buffer_width;
#endif
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
        FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
                                  unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
        rowptr += input_pitch;
    }


    /***** Need to optimize the first and last row calculations *****/

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the first row of results for each 8-bit output band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else

#if _PACK_RUNS_IN_BAND_16S
    // Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
    highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
#else
    // Quantize the first row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;
#endif
#endif





#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
            FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
                                      unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
            rowptr += input_pitch;
        }
    }
#endif


    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
#if _QUANTIZE_SPATIAL_LOWPASS
        __m64 *lowlow_ptr = (__m64 *)lowlow_buffer;
#else
        __m64 *lowlow_ptr = (__m64 *)lowlow_row_ptr;
#endif
        __m64 *highlow_ptr = (__m64 *)highlow_buffer;
        __m64 *lowhigh_ptr = (__m64 *)lowhigh_buffer;
        __m64 *highhigh_ptr = (__m64 *)highhigh_buffer;

        int column_step = 4;
        int post_column = output_width - (output_width % column_step);
#endif
        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process a group of four pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m64 low_pi16;
            __m64 sum_pi16;
            __m64 quad_pi16;
            __m64 mask_pi16;
            __m64 half_pi16;


            // Apply the vertical filters to the horizontal lowpass results //

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[0][column]);
            // Initialize the highpass filter sum
            sum_pi16 = _mm_setzero_si64();
            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[1][column]);
            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[4][column]);
            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[5][column]);
            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8



            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[2][column]);
            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&lowpass[3][column]);
            // Compute the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);

            // Store the lowpass results
            *(lowlow_ptr++) = low_pi16;
            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


            // Store the four highpass results
            *(highlow_ptr++) = sum_pi16;


            // Apply the vertical filters to the horizontal highpass results //

            sum_pi16 = _mm_setzero_si64();

            // Load the first row of four pixels
            quad_pi16 = *((__m64 *)&highpass[0][column]);
            // Multiply each pixel by the first filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the second row of four pixels
            quad_pi16 = *((__m64 *)&highpass[1][column]);
            // Multiply each pixel by the second filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);

            // Load the fifth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[4][column]);
            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the sixth (last) row of four pixels
            quad_pi16 = *((__m64 *)&highpass[5][column]);
            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            sum_pi16 = _mm_srai_pi16(sum_pi16, 3); // divided by 8 =   (-1a -1b +1e +1f) / 8


            // Load the third row of four pixels
            quad_pi16 = *((__m64 *)&highpass[2][column]);
            // Initialize the lowpass sum
            low_pi16 = quad_pi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum_pi16 = _mm_adds_pi16(sum_pi16, quad_pi16);

            // Load the fourth row of four pixels
            quad_pi16 = *((__m64 *)&highpass[3][column]);
            // Compute and store the four lowpass results
            low_pi16 = _mm_adds_pi16(low_pi16, quad_pi16);
            *(lowhigh_ptr++) = low_pi16;

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum_pi16 = _mm_subs_pi16(sum_pi16, quad_pi16);


            // Store the four highpass results
            *(highhigh_ptr++) = sum_pi16;
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];
#if _QUANTIZE_SPATIAL_LOWPASS
            lowlow_buffer[column] = SATURATE(sum);
#else
            lowlow_row_ptr[column] = SATURATE(sum);
#endif
            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  8 * lowpass[2][column];
            sum += -8 * lowpass[3][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            highlow_buffer[column] = SATURATE(sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  8 * highpass[2][column];
            sum += -8 * highpass[3][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum += ROUNDING(sum, 8);
            sum = DivideByShift(sum, 3);
            highhigh_buffer[column] = SATURATE(sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                //SplitRow16s(rowptr, roi.width, lowpass[k], highpass[k]);
                FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
                                          unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
                rowptr += input_pitch;
            }
        }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
        // Quantize the current row 16-bit lowpass coefficients
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        // Quantize the current row of results for each 8-bit highpass band
        QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
#if _PACK_RUNS_IN_BAND_16S
        // Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
        highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
#else
        // Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
        QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
#endif
#endif

    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];
#if _QUANTIZE_SPATIAL_LOWPASS
        lowlow_buffer[column] = SATURATE(sum);
#else
        lowlow_row_ptr[column] = SATURATE(sum);
#endif
        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _HIGHPASS_8S
#if _QUANTIZE_SPATIAL_LOWPASS
    // Quantize the last row of 16-bit lowpass coefficients
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif
    // Quantize the last row of results for each 8-bit highpass band
    QuantizeRow16sTo8s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo8s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo8s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#else
#if _PACK_RUNS_IN_BAND_16S
    // Quantize the current row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
    highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);
#else
    // Quantize the last row of results for each 16-bit output band
#if _QUANTIZE_SPATIAL_LOWPASS
    QuantizeRow16sTo16s(lowlow_buffer, lowlow_row_ptr, output_width, lowlow_quantization);
#endif

    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif
#endif

    //_mm_empty();	// Clear the mmx register state
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

void FilterSpatialYUVQuant16s(uint8_t *input_data, int input_pitch,
                              PIXEL *lowlow_band, int lowlow_pitch,
                              PIXEL *lowhigh_band, int lowhigh_pitch,
                              PIXEL *highlow_band, int highlow_pitch,
                              PIXEL *highhigh_band, int highhigh_pitch,
                              PIXEL *buffer, size_t buffer_size, ROI roi,
                              int channel, int quantization[4], FRAME_INFO *frame,
                              int precision, int limit_yuv, int conv_601_709)
{
    uint8_t *rowptr = input_data;

    // Six rows of lowpass and highpass horizontal results
    PIXEL *lowpass[6];
    PIXEL *highpass[6];

    //PIXEL *lowlow_buffer;
    PIXEL *lowhigh_buffer;
    PIXEL *highlow_buffer;
    PIXEL *highhigh_buffer;

    int lowlow_quantization;
    int lowhigh_quantization;
    int highlow_quantization;
    int highhigh_quantization;

    // Pointers to the rows of coefficients in the wavelet bands
    PIXEL *lowlow_row_ptr = lowlow_band;
    PIXEL *lowhigh_row_ptr = lowhigh_band;
    PIXEL *highlow_row_ptr = highlow_band;
    PIXEL *highhigh_row_ptr = highhigh_band;

    int last_row = roi.height - 2;
    int output_width;
    size_t output_buffer_size;
    int output_buffer_width;
    PIXEL *bufptr;
    const int buffer_row_count = sizeof(lowpass) / sizeof(lowpass[0]);
    PIXEL *unpacking_buffer;
    size_t unpacking_buffer_size;
    int unpacking_buffer_width;
    int row, column;
    int k;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);

    if (quantization != NULL)
    {
        lowlow_quantization = quantization[0];
        lowhigh_quantization = quantization[1];
        highlow_quantization = quantization[2];
        highhigh_quantization = quantization[3];
    }
    else
    {
        lowlow_quantization = 1;
        lowhigh_quantization = 1;
        highlow_quantization = 1;
        highhigh_quantization = 1;
    }

    // Must have an even number of rows
    assert((roi.height % 2) == 0);

    // Must have an even number of columns
    assert((roi.width % 2) == 0);

    // Compute the width of each row of horizontal filter output
    output_width = roi.width / 2;

    // Compute the size of each row of horizontal filter output in bytes
    output_buffer_size = output_width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    output_buffer_size = ALIGN(output_buffer_size, _CACHE_LINE_SIZE);

    // Compute the size of the buffer for unpacking the input rows
    unpacking_buffer_size = roi.width * sizeof(PIXEL);

    // Round up the buffer size to an integer number of cache lines
    unpacking_buffer_size = ALIGN(unpacking_buffer_size, _CACHE_LINE_SIZE);

    // The buffer must be large enough for fifteen rows plus the unpacking buffer
    assert(buffer_size >= ((15 * output_buffer_size) + unpacking_buffer_size));

    // Compute the allocated width of each wavelet band buffer
    output_buffer_width = (int)output_buffer_size / sizeof(PIXEL);

    // Compute the allocated width of the unpacking buffer
    unpacking_buffer_width = (int)unpacking_buffer_size / sizeof(PIXEL);

    // Start allocating intermediate buffers at the beginning of the supplied buffer
    bufptr = buffer;

    // Allocate space in the buffer for the horizontal filter results
    for (k = 0; k < buffer_row_count; k++)
    {
        lowpass[k] = bufptr;
        bufptr += output_buffer_width;
        highpass[k] = bufptr;
        bufptr += output_buffer_width;
    }

    // Allocate space in the buffer for the pre-quantized coefficients
    lowhigh_buffer = bufptr;
    bufptr += output_buffer_width;
    highlow_buffer = bufptr;
    bufptr += output_buffer_width;
    highhigh_buffer = bufptr;
    bufptr += output_buffer_width;

    // Allocate space in the buffer for unpacking the input coefficients
    unpacking_buffer = bufptr;
    bufptr += unpacking_buffer_width;

    // Compute the first six rows of horizontal filter output
    for (k = 0; k < buffer_row_count; k++)
    {
        FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
                                  unpacking_buffer, unpacking_buffer_size, frame,
                                  precision, limit_yuv, conv_601_709);
        rowptr += input_pitch;
    }

#if (0 && PREFETCH)
    // Prefetch the next two rows from the input image
    {
        const int cache_line_size = 64;
        size_t input_row_size = ALIGN(input_pitch, _CACHE_LINE_SIZE);
        int num_cache_lines = 2 * input_row_size / cache_line_size;
        uint8_t *prefetch = rowptr;
        DWORD dummy2 = 0;
        num_cache_lines--;
        for (; num_cache_lines > 0; --num_cache_lines)
        {
            dummy2 += prefetch[num_cache_lines * cache_line_size];
        }
        dummy1 += dummy2;
    }
#endif

    /***** Need to optimize the first and last row calculations *****/

    // Use border filters for the first row
    row = 0;

    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[0][column];
        sum += lowpass[1][column];
        lowlow_row_ptr[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  =  5 * lowpass[0][column];
        sum -= 11 * lowpass[1][column];
        sum +=  4 * lowpass[2][column];
        sum +=  4 * lowpass[3][column];
        sum -=  1 * lowpass[4][column];
        sum -=  1 * lowpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[0][column];
        sum += highpass[1][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  =  5 * highpass[0][column];
        sum -= 11 * highpass[1][column];
        sum +=  4 * highpass[2][column];
        sum +=  4 * highpass[3][column];
        sum -=  1 * highpass[4][column];
        sum -=  1 * highpass[5][column];
        sum += ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _PACK_RUNS_IN_BAND_16S
    // Quantize the current row of results for each 16-bit output band
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
    highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

    lowlow_row_ptr += lowlow_pitch;
#else
    // Quantize the first row of results for each 16-bit highpass band
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

    // Advance to the next output rows
    lowlow_row_ptr += lowlow_pitch;
    highlow_row_ptr += highlow_pitch;
    lowhigh_row_ptr += lowhigh_pitch;
    highhigh_row_ptr += highhigh_pitch;
#endif

#if 0
    // Advance to the next pair of input rows if not using the SIMD code since the
    // SIMD version uses the first two rows again to compute the second output row

    {
        // Rotate the horizontal filter results by two rows
        PIXEL *temp0 = lowpass[0];
        PIXEL *temp1 = lowpass[1];
        PIXEL *high0 = highpass[0];
        PIXEL *high1 = highpass[1];

        for (k = 0; k < buffer_row_count - 2; k++)
        {
            lowpass[k] = lowpass[k + 2];
            highpass[k] = highpass[k + 2];
        }

        lowpass[buffer_row_count - 2] = temp0;
        lowpass[buffer_row_count - 1] = temp1;
        highpass[buffer_row_count - 2] = high0;
        highpass[buffer_row_count - 1] = high1;

        // Compute the next two rows of horizontal filter results
        for (; k < buffer_row_count; k++)
        {
            FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
                                      unpacking_buffer, unpacking_buffer_size, frame, precision, limit_yuv);
            rowptr += input_pitch;
        }
    }
#endif

    row += 2;								// Advance the row being processed

    for (; row < last_row; row += 2)
    {
#if (1 && XMMOPT)
        __m128i *lowlow_ptr = (__m128i *)lowlow_row_ptr;
        __m128i *highlow_ptr = (__m128i *)highlow_buffer;
        __m128i *lowhigh_ptr = (__m128i *)lowhigh_buffer;
        __m128i *highhigh_ptr = (__m128i *)highhigh_buffer;

        int column_step = 8;
        int post_column = output_width - (output_width % column_step);
#endif

#if (0 && PREFETCH)
        size_t output_size = output_width * sizeof(PIXEL);
        const int cache_line_size = 64;
        int num_cache_lines = output_size / cache_line_size;
        uint8_t *prefetch;
        DWORD dummy2;
#endif

#if (0 && PREFETCH)
        // Prefetch the next two rows from the input image
        {
            const int cache_line_size = 64;
            size_t input_row_size = ALIGN(input_pitch, _CACHE_LINE_SIZE);
            int num_cache_lines = 2 * input_row_size / cache_line_size;
            uint8_t *prefetch = rowptr;
            DWORD dummy2 = 0;
            num_cache_lines--;
            for (; num_cache_lines > 0; --num_cache_lines)
            {
                dummy2 += prefetch[num_cache_lines * cache_line_size];
            }
            dummy1 += dummy2;
        }
#endif
        // Start at the first column
        column = 0;

        // Check that the input and output addresses are properly aligned
        for (k = 0; k < buffer_row_count; k++)
        {
            assert(ISALIGNED16(lowpass[k]));
            assert(ISALIGNED16(highpass[k]));
        }
        assert(ISALIGNED16(lowlow_ptr));
        assert(ISALIGNED16(lowhigh_ptr));
        assert(ISALIGNED16(highlow_ptr));
        assert(ISALIGNED16(highhigh_ptr));

#if (0 && PREFETCH)
        // Prefetch the row for the lowlow coefficients
        prefetch = (uint8_t *)lowlow_row_ptr;
        dummy2 = 0;
        num_cache_lines = output_size / cache_line_size;
        for (; num_cache_lines > 0; num_cache_lines -= 4)
        {
            dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
        }
        dummy1 += dummy2;

        // Prefetch the row for the lowhigh coefficients
        prefetch = (uint8_t *)lowhigh_row_ptr;
        dummy2 = 0;
        num_cache_lines = output_size / cache_line_size;
        for (; num_cache_lines > 0; num_cache_lines -= 4)
        {
            dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
        }
        dummy1 += dummy2;

        // Prefetch the row for the highlow coefficients
        prefetch = (uint8_t *)highlow_row_ptr;
        dummy2 = 0;
        num_cache_lines = output_size / cache_line_size;
        for (; num_cache_lines > 0; num_cache_lines -= 4)
        {
            dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
        }
        dummy1 += dummy2;

        // Prefetch the row for the highhigh coefficients
        prefetch = (uint8_t *)highhigh_row_ptr;
        dummy2 = 0;
        num_cache_lines = output_size / cache_line_size;
        for (; num_cache_lines > 0; num_cache_lines -= 4)
        {
            dummy2 += prefetch[(num_cache_lines - 0) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 1) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 2) * cache_line_size];
            dummy2 += prefetch[(num_cache_lines - 3) * cache_line_size];
        }
        dummy1 += dummy2;
#endif

#if (1 && XMMOPT)

        // Process a group of eight pixels at a time
        for (; column < post_column; column += column_step)
        {
            __m128i low_epi16;
            __m128i sum_epi16;
            __m128i sum8_epi16;
            __m128i quad_epi16;
            __m128i half_epi16;


            /***** Apply the vertical filters to the horizontal lowpass results *****/

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[0][column]);

            // Initialize the highpass filter sum
            sum_epi16 = _mm_setzero_si128();

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[3][column]);

            // Compute the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);

            // Store the lowpass results
            _mm_store_si128(lowlow_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&lowpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            half_epi16 = _mm_set1_epi16(4); //was 4
            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

            // Store the four highpass results
            _mm_store_si128(highlow_ptr++, sum_epi16);


            /***** Apply the vertical filters to the horizontal highpass results *****/

            sum_epi16 = _mm_setzero_si128();

            // Load the first row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[0][column]);

            // Multiply each pixel by the first filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the second row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[1][column]);

            // Multiply each pixel by the second filter coefficient and sum the result
            sum_epi16 = _mm_subs_epi16(sum_epi16, quad_epi16);

            // Load the third row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[2][column]);

            // Initialize the lowpass sum
            low_epi16 = quad_epi16;

            // Multiply each pixel by the third filter coefficient and sum the result
            sum8_epi16 = _mm_setzero_si128();
            sum8_epi16 = _mm_adds_epi16(sum8_epi16, quad_epi16);

            // Load the fourth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[3][column]);

            // Compute and store the four lowpass results
            low_epi16 = _mm_adds_epi16(low_epi16, quad_epi16);
            _mm_store_si128(lowhigh_ptr++, low_epi16);

            // Multiply each pixel by the fourth filter coefficient and sum the result
            sum8_epi16 = _mm_subs_epi16(sum8_epi16, quad_epi16);

            // Load the fifth row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[4][column]);

            // Multiply each pixel by the fifth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            // Load the sixth (last) row of four pixels
            quad_epi16 = _mm_load_si128((__m128i *)&highpass[5][column]);

            // Multiply each pixel by the sixth filter coefficient and sum the result
            sum_epi16 = _mm_adds_epi16(sum_epi16, quad_epi16);

            sum_epi16 = _mm_adds_epi16(sum_epi16, half_epi16); // +7 rounding
            sum_epi16 = _mm_srai_epi16(sum_epi16, 3); // divide 8

            sum_epi16 = _mm_adds_epi16(sum_epi16, sum8_epi16);

            // Store the four highpass results
            _mm_store_si128(highhigh_ptr++, sum_epi16);
        }

        // Should have terminated the fast loop at the post processing column
        assert(column == post_column);
#endif

        // Process the remaining pixels to the end of the row
        for (; column < output_width; column++)
        {
            int32_t sum;

            // Apply the lowpass vertical filter to the lowpass horizontal results
            sum  = lowpass[2][column];
            sum += lowpass[3][column];
            lowlow_row_ptr[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the lowpass horizontal results
            sum  = -1 * lowpass[0][column];
            sum += -1 * lowpass[1][column];
            sum +=  1 * lowpass[4][column];
            sum +=  1 * lowpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * lowpass[2][column];
            sum += -1 * lowpass[3][column];
            highlow_buffer[column] = SATURATE(sum);

            // Apply the lowpass vertical filter to the highpass horizontal results
            sum  = highpass[2][column];
            sum += highpass[3][column];
            lowhigh_buffer[column] = SATURATE(sum);

            // Apply the highpass vertical filter to the highpass horizontal results
            sum  = -1 * highpass[0][column];
            sum += -1 * highpass[1][column];
            sum +=  1 * highpass[4][column];
            sum +=  1 * highpass[5][column];
            sum +=	4;
            sum >>= 3;
            sum +=  1 * highpass[2][column];
            sum += -1 * highpass[3][column];
            highhigh_buffer[column] = SATURATE(sum);
        }

        if (row < (last_row - 2))
        {
            // Rotate the horizontal filter results by two rows
            PIXEL *temp0 = lowpass[0];
            PIXEL *temp1 = lowpass[1];
            PIXEL *high0 = highpass[0];
            PIXEL *high1 = highpass[1];

            for (k = 0; k < buffer_row_count - 2; k++)
            {
                lowpass[k] = lowpass[k + 2];
                highpass[k] = highpass[k + 2];
            }

            lowpass[buffer_row_count - 2] = temp0;
            lowpass[buffer_row_count - 1] = temp1;
            highpass[buffer_row_count - 2] = high0;
            highpass[buffer_row_count - 1] = high1;

            // Compute the next two rows of horizontal filter results
            for (; k < buffer_row_count; k++)
            {
                FilterHorizontalRowYUV16s(rowptr, lowpass[k], highpass[k], roi.width, channel,
                                          unpacking_buffer, unpacking_buffer_size, frame,
                                          precision, limit_yuv, conv_601_709);
                rowptr += input_pitch;
            }
        }

#if _PACK_RUNS_IN_BAND_16S
        // Quantize the current row of results for each 16-bit output band
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
        highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
#else
        // Quantize the current row of results for each 16-bit output band
        QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
        QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
        QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);

        // Advance to the next output rows
        lowlow_row_ptr += lowlow_pitch;
        highlow_row_ptr += highlow_pitch;
        lowhigh_row_ptr += lowhigh_pitch;
        highhigh_row_ptr += highhigh_pitch;
#endif
    }

    // Should have left the loop at the last row
    assert(row == last_row);

    // Use the border filters for the last row
    for (column = 0; column < output_width; column++)
    {
        int32_t sum;

        // Apply the lowpass vertical filter to the lowpass horizontal results
        sum  = lowpass[4][column];
        sum += lowpass[5][column];
        lowlow_row_ptr[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the lowpass horizontal results
        sum  = 11 * lowpass[4][column];
        sum -=  5 * lowpass[5][column];
        sum -=  4 * lowpass[3][column];
        sum -=  4 * lowpass[2][column];
        sum +=  1 * lowpass[1][column];
        sum +=  1 * lowpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highlow_buffer[column] = SATURATE(sum);

        // Apply the lowpass vertical filter to the highpass horizontal results
        sum  = highpass[4][column];
        sum += highpass[5][column];
        lowhigh_buffer[column] = SATURATE(sum);

        // Apply the highpass vertical filter to the highpass horizontal results
        sum  = 11 * highpass[4][column];
        sum -=  5 * highpass[5][column];
        sum -=  4 * highpass[3][column];
        sum -=  4 * highpass[2][column];
        sum +=  1 * highpass[1][column];
        sum +=  1 * highpass[0][column];
        sum +=  ROUNDING(sum, 8);
        sum = DivideByShift(sum, 3);
        highhigh_buffer[column] = SATURATE(sum);
    }

#if _PACK_RUNS_IN_BAND_16S
    // Quantize the current row of results for each 16-bit output band
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    lowhigh_row_ptr += PackRuns16s(lowhigh_row_ptr, output_width);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    highlow_row_ptr += PackRuns16s(highlow_row_ptr, output_width);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
    highhigh_row_ptr += PackRuns16s(highhigh_row_ptr, output_width);
#else
    // Quantize the last row of results for each 16-bit output band
    QuantizeRow16sTo16s(lowhigh_buffer, lowhigh_row_ptr, output_width, lowhigh_quantization);
    QuantizeRow16sTo16s(highlow_buffer, highlow_row_ptr, output_width, highlow_quantization);
    QuantizeRow16sTo16s(highhigh_buffer, highhigh_row_ptr, output_width, highhigh_quantization);
#endif
}

#endif


// Apply the forward spatial (horizontal and vertical) transform
void FilterSpatial8s(PIXEL *input_image, int input_pitch,
                     PIXEL *lowlow_band, int lowlow_pitch,
                     PIXEL *lowhigh_band, int lowhigh_pitch,
                     PIXEL *highlow_band, int highlow_pitch,
                     PIXEL *highhigh_band, int highhigh_pitch,
                     ROI roi, int input_scale)
{
    // Need to finish
    assert(0);
}


void InvertSpatialTopRow16s(PIXEL *lowlow_band, int lowlow_pitch,
                            PIXEL *lowhigh_band, int lowhigh_pitch,
                            PIXEL *highlow_band, int highlow_pitch,
                            PIXEL *highhigh_band, int highhigh_pitch,
                            uint8_t *output, int output_pitch,
                            int row, int width,
                            PIXEL *buffer, size_t buffer_size,
                            int precision, FRAME_INFO *info)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // This routine should be called for the first row
    assert(row == 0);

    // Apply the vertical border filter to the first row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh[column + 0 * lowhigh_pitch];
        even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
        even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
        odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
        odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    /*DANREMOVE	if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
    	{
    		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
    									 highpass, highpass_pitch,
    									 output, output_row_size, strip,
    									 precision);
    	}
    	else */
    {
        InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
                                         highpass, highpass_pitch,
                                         (PIXEL16U *)output, (int)output_row_size, strip,
                                         precision);
    }
}


#if 0

// Old version that uses MMX instructions
void InvertSpatialMiddleRow16s(PIXEL *lowlow_band, int lowlow_pitch,
                               PIXEL *lowhigh_band, int lowhigh_pitch,
                               PIXEL *highlow_band, int highlow_pitch,
                               PIXEL *highhigh_band, int highhigh_pitch,
                               uint8_t *output, int output_pitch,
                               int row, int width,
                               PIXEL *buffer, size_t buffer_size,
                               int precision, FRAME_INFO *info)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

#if (1 && XMMOPT)
    const int column_step = 4;
    int post_column = width - (width % column_step);

    __m64 *even_lowpass_ptr;
    __m64 *even_highpass_ptr;
    __m64 *odd_lowpass_ptr;
    __m64 *odd_highpass_ptr;
#endif

    // This routine should not be called to process the first row
    assert(row > 0);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += (row - 1) * lowlow_pitch;
    lowhigh += (row - 1) * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // Start at the first column
    column = 0;

#if (1 && XMMOPT)

    even_lowpass_ptr = (__m64 *)even_lowpass;
    even_highpass_ptr = (__m64 *)even_highpass;
    odd_lowpass_ptr = (__m64 *)odd_lowpass;
    odd_highpass_ptr = (__m64 *)odd_highpass;

    // Process groups of four coefficients along the row
    for (; column < post_column; column += column_step)
    {
        __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
        __m64 *highlow_ptr = (__m64 *)&highlow[column];
        __m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
        __m64 *highhigh_ptr = (__m64 *)&highhigh[column];
        __m64 quad_pi16;
        __m64 even_pi16;
        __m64 odd_pi16;
        __m64 mid_pi16;
        __m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


        /***** Compute the vertical inverse for the left two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        int quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

        // Accumulate parallel sums for the even and odd filters
        quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        even_pi16 = quad_pi16;
        odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

        mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

        even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

        even_pi16 = _mm_srai_pi16(even_pi16, 3);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


        // Add the highpass correction to the even result and divide by two
        quad_pi16 = *highlow_ptr;
        even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Store the even and odd groups of horizontal lowpass coefficients
        *(even_lowpass_ptr++) = even_pi16;
        *(odd_lowpass_ptr++) = odd_pi16;


        /***** Compute the vertical inverse for the right two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

        // Accumulate parallel sums for the even and odd filters
        quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        even_pi16 = quad_pi16;
        odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

        mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

        even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

        even_pi16 = _mm_srai_pi16(even_pi16, 3);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


        // Add the highpass correction to the even result and divide by two
        quad_pi16 = *highhigh_ptr;
        even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Store the even and odd groups of horizontal highpass coefficients
        *(even_highpass_ptr++) = even_pi16;
        *(odd_highpass_ptr++) = odd_pi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

#endif

    // Process the rest of the row
    for (; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += lowlow[column + 0 * lowlow_pitch];
        even -= lowlow[column + 2 * lowlow_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowlow[column + 1 * lowlow_pitch];

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowlow[column + 0 * lowlow_pitch];
        odd += lowlow[column + 2 * lowlow_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowlow[column + 1 * lowlow_pitch];

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += lowhigh[column + 0 * lowhigh_pitch];
        even -= lowhigh[column + 2 * lowhigh_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowhigh[column + 1 * lowhigh_pitch];

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowhigh[column + 0 * lowhigh_pitch];
        odd += lowhigh[column + 2 * lowhigh_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowhigh[column + 1 * lowhigh_pitch];

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    /*DANREMOVE		if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
    	{
    		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
    									 highpass, highpass_pitch,
    									 output, output_row_size, strip,
    									 precision);
    	}
    	else */
    {
        InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
                                         highpass, highpass_pitch,
                                         (PIXEL16U *)output, output_row_size, strip,
                                         precision);
    }

    //_mm_empty();	// Clear the mmx register state
}

#else

// New version optimized with SSE2 instructions
void InvertSpatialMiddleRow16s(PIXEL *lowlow_band, int lowlow_pitch,
                               PIXEL *lowhigh_band, int lowhigh_pitch,
                               PIXEL *highlow_band, int highlow_pitch,
                               PIXEL *highhigh_band, int highhigh_pitch,
                               uint8_t *output, int output_pitch,
                               int row, int width,
                               PIXEL *buffer, size_t buffer_size,
                               int precision, FRAME_INFO *info)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

#if (1 && XMMOPT)
    const int column_step = 8;
    int post_column = width - (width % column_step);

    __m128i *even_lowpass_ptr;
    __m128i *even_highpass_ptr;
    __m128i *odd_lowpass_ptr;
    __m128i *odd_highpass_ptr;
#endif

    // This routine should not be called to process the first row
    assert(row > 0);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += (row - 1) * lowlow_pitch;
    lowhigh += (row - 1) * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Start at the first column
    column = 0;

#if (1 && XMMOPT)

    even_lowpass_ptr = (__m128i *)even_lowpass;
    even_highpass_ptr = (__m128i *)even_highpass;
    odd_lowpass_ptr = (__m128i *)odd_lowpass;
    odd_highpass_ptr = (__m128i *)odd_highpass;

    // Process groups of four coefficients along the row
    for (; column < post_column; column += column_step)
    {
        __m128i *lowlow_ptr = (__m128i *)&lowlow[column];
        __m128i *highlow_ptr = (__m128i *)&highlow[column];
        __m128i *lowhigh_ptr = (__m128i *)&lowhigh[column];
        __m128i *highhigh_ptr = (__m128i *)&highhigh[column];
        __m128i quad_epi16;
        __m128i even_epi16;
        __m128i odd_epi16;
        __m128i mid_epi16;
        __m128i half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6


        /***** Compute the vertical inverse for the left two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        int quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);

        // Accumulate parallel sums for the even and odd filters
        quad_epi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        even_epi16 = quad_epi16;
        odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), quad_epi16);

        mid_epi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        quad_epi16 = *lowlow_ptr;	// Get four lowpass coefficients

        even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

        even_epi16 = _mm_srai_epi16(even_epi16, 3);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

        even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);


        // Add the highpass correction to the even result and divide by two
        quad_epi16 = *highlow_ptr;
        even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Store the even and odd groups of horizontal lowpass coefficients
        *(even_lowpass_ptr++) = even_epi16;
        *(odd_lowpass_ptr++) = odd_epi16;


        /***** Compute the vertical inverse for the right two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m128i);

        // Accumulate parallel sums for the even and odd filters
        quad_epi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        even_epi16 = quad_epi16;
        odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), quad_epi16);

        mid_epi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        quad_epi16 = *lowhigh_ptr;	// Get four lowpass coefficients

        even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

        even_epi16 = _mm_srai_epi16(even_epi16, 3);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

        even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);


        // Add the highpass correction to the even result and divide by two
        quad_epi16 = *highhigh_ptr;
        even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Store the even and odd groups of horizontal highpass coefficients
        *(even_highpass_ptr++) = even_epi16;
        *(odd_highpass_ptr++) = odd_epi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

#endif

    // Process the rest of the row
    for (; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += lowlow[column + 0 * lowlow_pitch];
        even -= lowlow[column + 2 * lowlow_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowlow[column + 1 * lowlow_pitch];

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowlow[column + 0 * lowlow_pitch];
        odd += lowlow[column + 2 * lowlow_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowlow[column + 1 * lowlow_pitch];

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += lowhigh[column + 0 * lowhigh_pitch];
        even -= lowhigh[column + 2 * lowhigh_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowhigh[column + 1 * lowhigh_pitch];

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowhigh[column + 0 * lowhigh_pitch];
        odd += lowhigh[column + 2 * lowhigh_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowhigh[column + 1 * lowhigh_pitch];

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    /*DANREMOVE		if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
    	{
    		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
    									 highpass, highpass_pitch,
    									 output, output_row_size, strip,
    									 precision);
    	}
    	else */
    {
        InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
                                         highpass, highpass_pitch,
                                         (PIXEL16U *)output, (int)output_row_size, strip,
                                         precision);
    }
}

#endif


void InvertSpatialBottomRow16s(PIXEL *lowlow_band, int lowlow_pitch,
                               PIXEL *lowhigh_band, int lowhigh_pitch,
                               PIXEL *highlow_band, int highlow_pitch,
                               PIXEL *highhigh_band, int highhigh_pitch,
                               uint8_t *output, int output_pitch,
                               int row, int width,
                               PIXEL *buffer, size_t buffer_size,
                               int precision, FRAME_INFO *info)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += row * lowlow_pitch;
    lowhigh += row * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh[column + 0 * lowhigh_pitch];
        even += 4 * lowhigh[column - 1 * lowhigh_pitch];
        even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
        odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
        odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    /*DANREMOVE	if(precision == 8 || _NODITHER || DECODEDFORMAT(info)==DECODED_FORMAT_YUYV || DECODEDFORMAT(info)==COLOR_FORMAT_UYVY)
    	{
    		InvertHorizontalStrip16sTo8u(lowpass, lowpass_pitch,
    									 highpass, highpass_pitch,
    									 output, output_row_size, strip,
    									 precision);
    	}
    	else */
    {
        InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
                                         highpass, highpass_pitch,
                                         (PIXEL16U *)output, (int)output_row_size, strip,
                                         precision);
    }
}





void InvertSpatialTopRow10bit16s(PIXEL *lowlow_band, int lowlow_pitch,
                                 PIXEL *lowhigh_band, int lowhigh_pitch,
                                 PIXEL *highlow_band, int highlow_pitch,
                                 PIXEL *highhigh_band, int highhigh_pitch,
                                 PIXEL *output, int output_pitch,
                                 int row, int width,
                                 PIXEL *buffer, size_t buffer_size)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // This routine should be called for the first row
    assert(row == 0);

    // Apply the vertical border filter to the first row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh[column + 0 * lowhigh_pitch];
        even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
        even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
        odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
        odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);
}

void InvertSpatialMiddleRow10bit16s(PIXEL *lowlow_band, int lowlow_pitch,
                                    PIXEL *lowhigh_band, int lowhigh_pitch,
                                    PIXEL *highlow_band, int highlow_pitch,
                                    PIXEL *highhigh_band, int highhigh_pitch,
                                    PIXEL *output, int output_pitch,
                                    int row, int width,
                                    PIXEL *buffer, size_t buffer_size)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // This routine should not be called to process the first row
    assert(row > 0);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += (row - 1) * lowlow_pitch;
    lowhigh += (row - 1) * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Process the middle rows using the interior reconstruction filters
    //for (; row < last_row; row++)
    {
#if (0 && XMMOPT) //DANREMOVED
        int column_step = 4;
        int post_column = width - (width % column_step);
        __m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
        __m64 *even_highpass_ptr = (__m64 *)even_highpass;
        __m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
        __m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
        __m64 half_pi16 = _mm_set1_pi16(4);
        int quad_pitch;
#endif

        // Start at the first column
        column = 0;

#if (0 && XMMOPT) //DANREMOVED

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
            __m64 *highlow_ptr = (__m64 *)&highlow[column];
            __m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
            __m64 *highhigh_ptr = (__m64 *)&highhigh[column];
            __m64 quad_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;
            __m64 mid_pi16;


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

            even_pi16 = _mm_srai_pi16(even_pi16, 3);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highlow_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);


            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
            lowhigh_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
            lowhigh_ptr += quad_pitch;	// Advance to the next row

            quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

            even_pi16 = _mm_srai_pi16(even_pi16, 3);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highhigh_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowlow[column + 1 * lowlow_pitch];

            // Add the highpass correction
            even += highlow[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowlow[column + 1 * lowlow_pitch];

            // Subtract the highpass correction
            odd -= highlow[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh[column + 0 * lowhigh_pitch];
            even -= lowhigh[column + 2 * lowhigh_pitch];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowhigh[column + 1 * lowhigh_pitch];

            // Add the highpass correction
            even += highhigh[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh[column + 0 * lowhigh_pitch];
            odd += lowhigh[column + 2 * lowhigh_pitch];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowhigh[column + 1 * lowhigh_pitch];

            // Subtract the highpass correction
            odd -= highhigh[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

        // Apply the inverse horizontal transform to the even and odd rows
        InvertHorizontalStrip16s10bitLimit(lowpass, lowpass_pitch,
                                           highpass, highpass_pitch,
                                           output, (int)output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        //lowlow += lowlow_pitch;
        //lowhigh += lowhigh_pitch;
        //highlow += highlow_pitch;
        //highhigh += highhigh_pitch;
        //output += 2 * output_pitch;
    }


#if (0 && XMMOPT) //DANREMOVED
    //_mm_empty();	// Clear the mmx register state
#endif
}

void InvertSpatialBottomRow10bit16s(PIXEL *lowlow_band, int lowlow_pitch,
                                    PIXEL *lowhigh_band, int lowhigh_pitch,
                                    PIXEL *highlow_band, int highlow_pitch,
                                    PIXEL *highhigh_band, int highhigh_pitch,
                                    PIXEL *output, int output_pitch,
                                    int row, int width,
                                    PIXEL *buffer, size_t buffer_size)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += row * lowlow_pitch;
    lowhigh += row * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh[column + 0 * lowhigh_pitch];
        even += 4 * lowhigh[column - 1 * lowhigh_pitch];
        even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
        odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
        odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);
}


void InvertSpatialTopRow16sToYUV16(PIXEL *lowlow_band, int lowlow_pitch,
                                   PIXEL *lowhigh_band, int lowhigh_pitch,
                                   PIXEL *highlow_band, int highlow_pitch,
                                   PIXEL *highhigh_band, int highhigh_pitch,
                                   PIXEL16U *output, int output_pitch,
                                   int row, int width,
                                   PIXEL *buffer, size_t buffer_size,
                                   int precision)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL16U);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // This routine should be called for the first row
    assert(row == 0);

    // Apply the vertical border filter to the first row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh[column + 0 * lowhigh_pitch];
        even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
        even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
        odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
        odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
                                     highpass, highpass_pitch,
                                     output, (int)output_row_size, strip,
                                     precision);
}

void InvertSpatialMiddleRow16sToYUV16(PIXEL *lowlow_band, int lowlow_pitch,
                                      PIXEL *lowhigh_band, int lowhigh_pitch,
                                      PIXEL *highlow_band, int highlow_pitch,
                                      PIXEL *highhigh_band, int highhigh_pitch,
                                      PIXEL16U *output, int output_pitch,
                                      int row, int width,
                                      PIXEL *buffer, size_t buffer_size,
                                      int precision)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

#if (0 && XMMOPT) //DANREMOVED
    const int column_step = 4;
    int post_column = width - (width % column_step);

    __m64 *even_lowpass_ptr;
    __m64 *even_highpass_ptr;
    __m64 *odd_lowpass_ptr;
    __m64 *odd_highpass_ptr;
#endif

    // This routine should not be called to process the first row
    assert(row > 0);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL16U);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += (row - 1) * lowlow_pitch;
    lowhigh += (row - 1) * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Start at the first column
    column = 0;

#if (0 && XMMOPT) //DANREMOVED

    even_lowpass_ptr = (__m64 *)even_lowpass;
    even_highpass_ptr = (__m64 *)even_highpass;
    odd_lowpass_ptr = (__m64 *)odd_lowpass;
    odd_highpass_ptr = (__m64 *)odd_highpass;

    // Process groups of four coefficients along the row
    for (; column < post_column; column += column_step)
    {
        __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
        __m64 *highlow_ptr = (__m64 *)&highlow[column];
        __m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
        __m64 *highhigh_ptr = (__m64 *)&highhigh[column];
        __m64 quad_pi16;
        __m64 even_pi16;
        __m64 odd_pi16;
        __m64 mid_pi16;
        __m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


        /***** Compute the vertical inverse for the left two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        int quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

        // Accumulate parallel sums for the even and odd filters
        quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        even_pi16 = quad_pi16;
        odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

        mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

        even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

        even_pi16 = _mm_srai_pi16(even_pi16, 3);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


        // Add the highpass correction to the even result and divide by two
        quad_pi16 = *highlow_ptr;
        even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Store the even and odd groups of horizontal lowpass coefficients
        *(even_lowpass_ptr++) = even_pi16;
        *(odd_lowpass_ptr++) = odd_pi16;


        /***** Compute the vertical inverse for the right two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

        // Accumulate parallel sums for the even and odd filters
        quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        even_pi16 = quad_pi16;
        odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

        mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

        even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

        even_pi16 = _mm_srai_pi16(even_pi16, 3);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


        // Add the highpass correction to the even result and divide by two
        quad_pi16 = *highhigh_ptr;
        even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Store the even and odd groups of horizontal highpass coefficients
        *(even_highpass_ptr++) = even_pi16;
        *(odd_highpass_ptr++) = odd_pi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

#endif

    // Process the rest of the row
    for (; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += lowlow[column + 0 * lowlow_pitch];
        even -= lowlow[column + 2 * lowlow_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowlow[column + 1 * lowlow_pitch];

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowlow[column + 0 * lowlow_pitch];
        odd += lowlow[column + 2 * lowlow_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowlow[column + 1 * lowlow_pitch];

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += lowhigh[column + 0 * lowhigh_pitch];
        even -= lowhigh[column + 2 * lowhigh_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowhigh[column + 1 * lowhigh_pitch];

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowhigh[column + 0 * lowhigh_pitch];
        odd += lowhigh[column + 2 * lowhigh_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowhigh[column + 1 * lowhigh_pitch];

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
                                     highpass, highpass_pitch,
                                     output, (int)output_row_size, strip,
                                     precision);

#if (0 && XMMOPT) //DANREMOVED
    //_mm_empty();	// Clear the mmx register state
#endif
}

void InvertSpatialBottomRow16sToYUV16(PIXEL *lowlow_band, int lowlow_pitch,
                                      PIXEL *lowhigh_band, int lowhigh_pitch,
                                      PIXEL *highlow_band, int highlow_pitch,
                                      PIXEL *highhigh_band, int highhigh_pitch,
                                      PIXEL16U *output, int output_pitch,
                                      int row, int width,
                                      PIXEL *buffer, size_t buffer_size,
                                      int precision)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL16U);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += row * lowlow_pitch;
    lowhigh += row * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh[column + 0 * lowhigh_pitch];
        even += 4 * lowhigh[column - 1 * lowhigh_pitch];
        even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
        odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
        odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16sToRow16u(lowpass, lowpass_pitch,
                                     highpass, highpass_pitch,
                                     output, (int)output_row_size, strip,
                                     precision);
}

#if 0
void InvertRGB444TopRow16sToB64A(PIXEL *lowlow_band, int lowlow_pitch,
                                 PIXEL *lowhigh_band, int lowhigh_pitch,
                                 PIXEL *highlow_band, int highlow_pitch,
                                 PIXEL *highhigh_band, int highhigh_pitch,
                                 PIXEL16U *output, int output_pitch,
                                 int row, int width,
                                 PIXEL *buffer, size_t buffer_size,
                                 int precision)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL16U);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // This routine should be called for the first row
    assert(row == 0);

    // Apply the vertical border filter to the first row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh[column + 0 * lowhigh_pitch];
        even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
        even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
        odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
        odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStripRGB444ToB64A(lowpass, lowpass_pitch,
                                      highpass, highpass_pitch,
                                      output, output_row_size, strip,
                                      precision);
}

void InvertRGB444MiddleRow16sToB64A(PIXEL *lowlow_band, int lowlow_pitch,
                                    PIXEL *lowhigh_band, int lowhigh_pitch,
                                    PIXEL *highlow_band, int highlow_pitch,
                                    PIXEL *highhigh_band, int highhigh_pitch,
                                    PIXEL16U *output, int output_pitch,
                                    int row, int width,
                                    PIXEL *buffer, size_t buffer_size,
                                    int precision)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

#if (1 && XMMOPT)
    const int column_step = 4;
    int post_column = width - (width % column_step);

    __m64 *even_lowpass_ptr;
    __m64 *even_highpass_ptr;
    __m64 *odd_lowpass_ptr;
    __m64 *odd_highpass_ptr;
#endif

    // This routine should not be called to process the first row
    assert(row > 0);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL16U);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += (row - 1) * lowlow_pitch;
    lowhigh += (row - 1) * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // Start at the first column
    column = 0;

#if (1 && XMMOPT)

    even_lowpass_ptr = (__m64 *)even_lowpass;
    even_highpass_ptr = (__m64 *)even_highpass;
    odd_lowpass_ptr = (__m64 *)odd_lowpass;
    odd_highpass_ptr = (__m64 *)odd_highpass;

    // Process groups of four coefficients along the row
    for (; column < post_column; column += column_step)
    {
        __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
        __m64 *highlow_ptr = (__m64 *)&highlow[column];
        __m64 *lowhigh_ptr = (__m64 *)&lowhigh[column];
        __m64 *highhigh_ptr = (__m64 *)&highhigh[column];
        __m64 quad_pi16;
        __m64 even_pi16;
        __m64 odd_pi16;
        __m64 mid_pi16;
        __m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


        /***** Compute the vertical inverse for the left two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        int quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

        // Accumulate parallel sums for the even and odd filters
        quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        even_pi16 = quad_pi16;
        odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

        mid_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
        lowlow_ptr += quad_pitch;	// Advance to the next row

        quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

        even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

        even_pi16 = _mm_srai_pi16(even_pi16, 3);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


        // Add the highpass correction to the even result and divide by two
        quad_pi16 = *highlow_ptr;
        even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Store the even and odd groups of horizontal lowpass coefficients
        *(even_lowpass_ptr++) = even_pi16;
        *(odd_lowpass_ptr++) = odd_pi16;


        /***** Compute the vertical inverse for the right two bands *****/

        // Set the pitch for the lowpass band used in this section of code
        quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

        // Accumulate parallel sums for the even and odd filters
        quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        even_pi16 = quad_pi16;
        odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

        mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
        lowhigh_ptr += quad_pitch;	// Advance to the next row

        quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

        even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

        even_pi16 = _mm_srai_pi16(even_pi16, 3);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
        odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


        // Add the highpass correction to the even result and divide by two
        quad_pi16 = *highhigh_ptr;
        even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Subtract the highpass correction from the odd result and divide by two
        odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Store the even and odd groups of horizontal highpass coefficients
        *(even_highpass_ptr++) = even_pi16;
        *(odd_highpass_ptr++) = odd_pi16;
    }

    // Should have exited the loop at the post processing column
    assert(column == post_column);

#endif

    // Process the rest of the row
    for (; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += lowlow[column + 0 * lowlow_pitch];
        even -= lowlow[column + 2 * lowlow_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowlow[column + 1 * lowlow_pitch];

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowlow[column + 0 * lowlow_pitch];
        odd += lowlow[column + 2 * lowlow_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowlow[column + 1 * lowlow_pitch];

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += lowhigh[column + 0 * lowhigh_pitch];
        even -= lowhigh[column + 2 * lowhigh_pitch];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowhigh[column + 1 * lowhigh_pitch];

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowhigh[column + 0 * lowhigh_pitch];
        odd += lowhigh[column + 2 * lowhigh_pitch];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowhigh[column + 1 * lowhigh_pitch];

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStripRGB444ToB64A(lowpass, lowpass_pitch,
                                      highpass, highpass_pitch,
                                      output, output_row_size, strip,
                                      precision);

    //_mm_empty();	// Clear the mmx register state
}

void InvertRGB444BottomRow16sToB64A(PIXEL *lowlow_band, int lowlow_pitch,
                                    PIXEL *lowhigh_band, int lowhigh_pitch,
                                    PIXEL *highlow_band, int highlow_pitch,
                                    PIXEL *highhigh_band, int highhigh_pitch,
                                    PIXEL16U *output, int output_pitch,
                                    int row, int width,
                                    PIXEL *buffer, size_t buffer_size,
                                    int precision)
{
    PIXEL *lowlow = lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int column;

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL16U);

    // Compute the address of the first row for processing in each wavelet band
    lowlow += row * lowlow_pitch;
    lowhigh += row * lowhigh_pitch;
    highlow += row * highlow_pitch;
    highhigh += row * highhigh_pitch;

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of coefficients
    assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh[column + 0 * lowhigh_pitch];
        even += 4 * lowhigh[column - 1 * lowhigh_pitch];
        even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
        odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
        odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStripRGB444ToB64A(lowpass, lowpass_pitch,
                                      highpass, highpass_pitch,
                                      output, output_row_size, strip,
                                      precision);
}
#endif

#if 0

// This subroutine differs from InvertHorizontalFast16s() in that the division by 2 operations are
// taken out. It is called only by InvertSpatial8s() and InvertSpatialQuant8s().

// Apply the horizontal inverse wavelet filter (fast mode)
static void InvertHorizontalNoShift16s(PIXEL *lowpass, int lowpass_pitch,
                                       PIXEL *highpass, int highpass_pitch,
                                       PIXEL *output, int output_pitch, ROI roi)
{
    int row, column;

    // Convert pitch from bytes to pixels
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        const int column_step = 4;
        const int last_column = roi.width - 1;
        int post_column = last_column - (last_column % column_step);

        __m64 low1_pi16;	// Lowpass coefficients
        __m64 low2_pi16;
        __m64 high1_pi16;	// Highpass coefficients
        __m64 high2_pi16;

        // The fast loop computes output points starting at the third column
        __m64 *outptr = (__m64 *)&output[2];

        PIXEL *colptr;

        int32_t even;
        int32_t odd;
        int32_t lsb;

        // Adjust the end of the fast loop if necessary
        if (post_column == last_column)
            post_column -= column_step;

        // Start processing at the beginning of the row
        column = 0;

        // Process the first two output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowpass[column + 0];
        even -=  4 * lowpass[column + 1];
        even +=  1 * lowpass[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highpass[column];
        //		even = DivideByShift(even, 1);

        // Place the even result in the even column
        output[0] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowpass[column + 0];
        odd += 4 * lowpass[column + 1];
        odd -= 1 * lowpass[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highpass[column];
        //		odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        output[1] = SATURATE(odd);

        // Preload the first four lowpass coefficients
        low1_pi16 = *((__m64 *)&lowpass[column]);

        // Preload the first four highpass coefficients
        high1_pi16 = *((__m64 *)&highpass[column]);

        // The reconstruction filters use pixels starting at the first column
        for (; column < post_column; column += column_step)
        {
            __m64 even_pi16;	// Result of convolution with even filter
            __m64 odd_pi16;		// Result of convolution with odd filter
            __m64 temp_pi16;
            __m64 out_pi16;		// Reconstructed data
            __m64 mask_pi16;
            __m64 half_pi16;
            __m64 lsb_pi16;
            __m64 sign_pi16;

            // Preload the next four lowpass coefficients
            low2_pi16 = *((__m64 *)&lowpass[column + 4]);


            // Compute the first two even and two odd output points //

            // Apply the even reconstruction filter to the lowpass band
            even_pi16 = low1_pi16;
            temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
            temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
            even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
            temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
            even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Shift the highpass correction by one column
            high1_pi16 = _mm_srli_si64(high1_pi16, 16);

            // Add the highpass correction
            even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
            //			even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
            odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
            temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
            odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
            odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Subtract the highpass correction
            odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
            //			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Interleave the even and odd results
            out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
            //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
            *(outptr++) = out_pi16;


            // Compute the second two even and two odd output points //

            // Preload the highpass correction
            high2_pi16 = *((__m64 *)&highpass[column + 4]);

            // Shift in the new pixels for the next stage of the loop
            low1_pi16 = _mm_srli_si64(low1_pi16, 32);
            temp_pi16 = _mm_slli_si64(low2_pi16, 32);
            low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

            // Apply the even reconstruction filter to the lowpass band
            even_pi16 = low1_pi16;
            temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
            temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
            even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
            temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
            even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Shift in the next two highpass coefficients
            high1_pi16 = _mm_srli_si64(high1_pi16, 2 * 16);
            high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

            // Add the highpass correction
            even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
            //			even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
            odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
            temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
            odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
            odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Subtract the highpass correction
            odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
            //			odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Interleave the even and odd results
            out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
            //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
            *(outptr++) = out_pi16;

            // The second four lowpass coefficients will be the current values
            low1_pi16 = low2_pi16;

            // The second four highpass coefficients will be the current values
            high1_pi16 = high2_pi16;
        }

        // Should have exited the loop with the column equal to the post processing column
        assert(column == post_column);

        // The fast processing loop is one column behind the actual column
        column++;

        // Process the rest of the columns up to the last column in the row
        colptr = (PIXEL *)outptr;

        for (; column < last_column; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter

            // Apply the even reconstruction filter to the lowpass band
            even += lowpass[column - 1];
            even -= lowpass[column + 1];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowpass[column + 0];

            // Add the highpass correction
            even += highpass[column];
            //			even = DivideByShift(even, 1);

            // Place the even result in the even column
            *(colptr++) = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowpass[column - 1];
            odd += lowpass[column + 1];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowpass[column + 0];

            // Subtract the highpass correction
            odd -= highpass[column];
            //			odd = DivideByShift(odd, 1);

            // Place the odd result in the odd column
            *(colptr++) = SATURATE(odd);
        }

        // Should have exited the loop at the column for right border processing
        assert(column == last_column);

        // Process the last two output points with special filters for the right border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowpass[column + 0];
        even += 4 * lowpass[column - 1];
        even -= 1 * lowpass[column - 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highpass[column];
        //		even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowpass[column + 0];
        odd -=  4 * lowpass[column - 1];
        odd +=  1 * lowpass[column - 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highpass[column];
        //		odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(colptr++) = SATURATE(odd);

        // Advance to the next row
        lowpass += lowpass_pitch;
        highpass += highpass_pitch;
        output += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state
}

#endif




#if 0
static void InvertHorizontalQuantSlow16s8sTo16s(PIXEL   *lowpass, int lowpass_quantization, int lowpass_pitch,
        PIXEL8S *highpass, int highpass_quantization, int highpass_pitch,
        PIXEL   *output, int output_pitch, ROI roi)
{
    int row, column;

    // Convert pitch from bytes to pixels
    lowpass_pitch /= sizeof(PIXEL);
    highpass_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        PIXEL *outptr = output;
        const int column_step = 1;
        int last_column = roi.width - column_step;
        int32_t even;
        int32_t odd;

        column = 0;

        // Process the first two output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowpass[column + 0];
        even -=  4 * lowpass[column + 1];
        even +=  1 * lowpass[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += (highpass[column]) * highpass_quantization;
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(outptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowpass[column + 0];
        odd += 4 * lowpass[column + 1];
        odd -= 1 * lowpass[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= (highpass[column]) * highpass_quantization;
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(outptr++) = SATURATE(odd);

        column++;

        for (; column < last_column; column += column_step)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter

            // Apply the even reconstruction filter to the lowpass band
            even += lowpass[column - 1];
            even -= lowpass[column + 1];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowpass[column + 0];

            // Add the highpass correction
            even += (highpass[column]) * highpass_quantization;
            even = DivideByShift(even, 1);

            // Place the even result in the even column
            *(outptr++) = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowpass[column - 1];
            odd += lowpass[column + 1];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowpass[column + 0];

            // Subtract the highpass correction
            odd -= (highpass[column]) * highpass_quantization;
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd column
            *(outptr++) = SATURATE(odd);
        }

        // Should have exited the loop with the column equal to the last column
        assert(column == last_column);

        // Process the last two output points with special filters for the right border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowpass[column + 0];
        even += 4 * lowpass[column - 1];
        even -= 1 * lowpass[column - 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += (highpass[column]) * highpass_quantization;
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(outptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowpass[column + 0];
        odd -=  4 * lowpass[column - 1];
        odd +=  1 * lowpass[column - 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= (highpass[column]) * highpass_quantization;
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(outptr++) = SATURATE(odd);

        // Advance to the next row
        lowpass += lowpass_pitch;
        highpass += highpass_pitch;
        output += output_pitch;
    }
}

static void InvertHorizontalQuantSlow8s(PIXEL8S *lowpass, int lowpass_quantization, int lowpass_pitch,
                                        PIXEL8S *highpass, int highpass_quantization, int highpass_pitch,
                                        PIXEL   *output, int output_pitch, ROI roi)
{
    int row, column;

    // Convert pitch from bytes to pixels
    lowpass_pitch /= sizeof(PIXEL8S);
    highpass_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL);

    for (row = 0; row < roi.height; row++)
    {
        PIXEL *outptr = output;
        const int column_step = 1;
        int last_column = roi.width - column_step;
        int32_t even;
        int32_t odd;

        column = 0;

        // Process the first two output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowpass[column + 0] * lowpass_quantization;
        even -=  4 * lowpass[column + 1] * lowpass_quantization;
        even +=  1 * lowpass[column + 2] * lowpass_quantization;
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += (highpass[column]) * highpass_quantization;
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(outptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowpass[column + 0] * lowpass_quantization;
        odd += 4 * lowpass[column + 1] * lowpass_quantization;
        odd -= 1 * lowpass[column + 2] * lowpass_quantization;
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= (highpass[column]) * highpass_quantization;
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(outptr++) = SATURATE(odd);

        column++;

        for (; column < last_column; column += column_step)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter

            // Apply the even reconstruction filter to the lowpass band
            even += lowpass[column - 1] * lowpass_quantization;
            even -= lowpass[column + 1] * lowpass_quantization;
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += (lowpass[column + 0]) * lowpass_quantization;

            // Add the highpass correction
            even += (highpass[column]) * highpass_quantization;
            even = DivideByShift(even, 1);

            // Place the even result in the even column
            *(outptr++) = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowpass[column - 1] * lowpass_quantization;
            odd += lowpass[column + 1] * lowpass_quantization;
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += (lowpass[column + 0]) * lowpass_quantization;

            // Subtract the highpass correction
            odd -= (highpass[column]) * highpass_quantization;
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd column
            *(outptr++) = SATURATE(odd);
        }

        // Should have exited the loop with the column equal to the last column
        assert(column == last_column);

        // Process the last two output points with special filters for the right border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowpass[column + 0] * lowpass_quantization;
        even += 4 * lowpass[column - 1] * lowpass_quantization;
        even -= 1 * lowpass[column - 2] * lowpass_quantization;
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += (highpass[column]) * highpass_quantization;
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(outptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowpass[column + 0] * lowpass_quantization;
        odd -=  4 * lowpass[column - 1] * lowpass_quantization;
        odd +=  1 * lowpass[column - 2] * lowpass_quantization;
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= (highpass[column]) * highpass_quantization;
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(outptr++) = SATURATE(odd);

        // Advance to the next row
        lowpass += lowpass_pitch;
        highpass += highpass_pitch;
        output += output_pitch;
    }
}
#endif


#if 0 //HACKDAN
// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s8sTo16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
                                   int lowpass_quantization,	// lowpass quantization factor
                                   PIXEL8S *highpass,			// Row of horizontal highpass coefficients
                                   int highpass_quantization,	// highpass quantization factor
                                   PIXEL *output,				// Row of reconstructed results
                                   int width)					// Length of each row of horizontal coefficients
{
    // Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S
    const int column_step = 8;
    const int last_column = width - 1;
    int post_column = last_column - (last_column % column_step);
    int column;

    __m64 low1_pi16;	// Lowpass coefficients
    __m64 low2_pi16;
    __m64 high_pi8;		// Highpass coefficients
    __m64 high1_pi16;	// Lower four highpass coefficients
    __m64 high2_pi16;	// Upper four highpass coefficients
    __m64 sign_pi8;
    __m64 quantization = _mm_set_pi16(highpass_quantization, highpass_quantization,
                                      highpass_quantization, highpass_quantization);

    // The fast loop computes output points starting at the third column
    __m64 *outptr = (__m64 *)&output[2];

    PIXEL *colptr;

    int32_t even;
    int32_t odd;
    //int32_t lsb;

    // Adjust the end of the fast loop if necessary
    if (post_column == last_column)
        post_column -= column_step;

    // Start processing at the beginning of the row
    column = 0;

    // Process the first two output points with special filters for the left border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 11 * lowpass[column + 0];
    even -=  4 * lowpass[column + 1];
    even +=  1 * lowpass[column + 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highpass[column] * highpass_quantization;
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    output[0] = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 5 * lowpass[column + 0];
    odd += 4 * lowpass[column + 1];
    odd -= 1 * lowpass[column + 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highpass[column] * highpass_quantization;
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    output[1] = SATURATE(odd);

    // Preload the first four lowpass coefficients
    low1_pi16 = *((__m64 *)&lowpass[column]);

    // Preload the eight highpass coefficients
    high_pi8 = *((__m64 *)&highpass[column]);

    // Unpack the first four highpass coefficients
    sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), high_pi8);
    high1_pi16 = _mm_unpacklo_pi8(high_pi8, sign_pi8);

    // Undo quantization
    high1_pi16 = _mm_mullo_pi16(high1_pi16, quantization);

    // The reconstruction filters use pixels starting at the first column
    for (; column < post_column; column += column_step)
    {
        __m64 even_pi16;	// Result of convolution with even filter
        __m64 odd_pi16;		// Result of convolution with odd filter
        __m64 temp_pi16;
        __m64 out_pi16;		// Reconstructed data
        __m64 mask_pi16;
        __m64 half_pi16;
        __m64 lsb_pi16;
        __m64 sign_pi16;
        //		__m64 high_pi16;

        // Preload the next four lowpass coefficients
        low2_pi16 = *((__m64 *)&lowpass[column + 4]);


        // Compute the first two even and two odd output points //

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift the highpass correction by one column
        high1_pi16 = _mm_srli_si64(high1_pi16, 16);

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;


        // Compute the second two even and two odd output points //

        // Unpack the second four highpass coefficients
        high2_pi16 = _mm_unpackhi_pi8(high_pi8, sign_pi8);

        // Undo quantization
        high2_pi16 = _mm_mullo_pi16(high2_pi16, quantization);

        // Shift in the new pixels for the next stage of the loop
        low1_pi16 = _mm_srli_si64(low1_pi16, 32);
        temp_pi16 = _mm_slli_si64(low2_pi16, 32);
        low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift in the next two highpass coefficients
        high1_pi16 = _mm_srli_si64(high1_pi16, 2 * 16);
        high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;

        // The second four lowpass coefficients will be the current values
        low1_pi16 = low2_pi16;

        // The second four highpass coefficients will be the current values
        high1_pi16 = high2_pi16;


        // Compute the next four even and odd output points //


        // Preload the next four lowpass coefficients
        low2_pi16 = *((__m64 *)&lowpass[column + 8]);

        // Compute the third two even and two odd output points //

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift the highpass correction by one column
        high1_pi16 = _mm_srli_si64(high1_pi16, 16);

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;


        // Compute the fourth two even and two odd output points //

        // Load the second eight highpass coefficients
        high_pi8 = *((__m64 *)&highpass[column + 8]);
        sign_pi8 = _mm_cmpgt_pi8(_mm_setzero_si64(), high_pi8);

        // Unpack the third four highpass coefficients
        high2_pi16 = _mm_unpacklo_pi8(high_pi8, sign_pi8);

        // Undo quantization
        high2_pi16 = _mm_mullo_pi16(high2_pi16, quantization);

        // Shift in the new pixels for the next stage of the loop
        low1_pi16 = _mm_srli_si64(low1_pi16, 32);
        temp_pi16 = _mm_slli_si64(low2_pi16, 32);
        low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift in the next highpass coefficient
        high1_pi16 = _mm_srli_si64(high1_pi16, 2 * 16);
        high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;

        // The second four lowpass coefficients will be the current values
        low1_pi16 = low2_pi16;

        // The second four highpass coefficients will be the current values
        high1_pi16 = high2_pi16;

    }

    // Should have exited the loop with the column equal to the post processing column
    assert(column == post_column);

    // The fast processing loop is one column behind the actual column
    column++;

    // Process the rest of the columns up to the last column in the row
    colptr = (PIXEL *)outptr;

    for (; column < last_column; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even += lowpass[column - 1];
        even -= lowpass[column + 1];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);
        even += lowpass[column + 0];

        // Add the highpass correction
        even += highpass[column] * highpass_quantization;
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowpass[column - 1];
        odd += lowpass[column + 1];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);
        odd += lowpass[column + 0];

        // Subtract the highpass correction
        odd -= highpass[column] * highpass_quantization;
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(colptr++) = SATURATE(odd);
    }

    // Should have exited the loop at the column for right border processing
    assert(column == last_column);

    // Process the last two output points with special filters for the right border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 5 * lowpass[column + 0];
    even += 4 * lowpass[column - 1];
    even -= 1 * lowpass[column - 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highpass[column] * highpass_quantization;
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    *(colptr++) = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 11 * lowpass[column + 0];
    odd -=  4 * lowpass[column - 1];
    odd +=  1 * lowpass[column - 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highpass[column] * highpass_quantization;
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    *(colptr++) = SATURATE(odd);

    //_mm_empty();	// Clear the mmx register state

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}
#endif //HACKDAN


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void InvertHorizontalRow16s8sTo16sBuffered(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
        int lowpass_quantization,	// lowpass quantization factor
        PIXEL8S *highpass,			// Row of horizontal highpass coefficients
        int highpass_quantization,	// highpass quantization factor
        PIXEL *output,				// Row of reconstructed results
        int width,					// Length of each row of horizontal coefficients
        PIXEL *buffer)				// Buffer to hold the dequantized values
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s8sTo16sBuffered(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
        int lowpass_quantization,	// lowpass quantization factor
        PIXEL8S *highpass_data,			// Row of horizontal highpass coefficients
        int highpass_quantization,	// highpass quantization factor
        PIXEL *output,				// Row of reconstructed results
        int width,					// Length of each row of horizontal coefficients
        PIXEL *buffer)				// Buffer to hold the dequantized values
{
#if _DECODE_LOWPASS_16S
    const int column_step = 4;
    const int last_column = width - 1;
    int post_column = last_column - (last_column % column_step);
    int column;

    PIXEL *highline = buffer;

    __m64 low1_pi16;	// Lowpass coefficients
    __m64 low2_pi16;
    __m64 high1_pi16;	// Lower four highpass coefficients
    __m64 high2_pi16;	// Upper four highpass coefficients

    // The fast loop computes output points starting at the third column
    __m64 *outptr = (__m64 *)&output[2];

    PIXEL *colptr;

    int32_t even;
    int32_t odd;
    //int32_t lsb;

    PIXEL *highpass = (PIXEL *)highpass_data;

    // Adjust the end of the fast loop if necessary
    if (post_column == last_column)
        post_column -= column_step;

    // Undo quantization for the highpass row
#if _DEQUANTIZE_IN_FSM
    highline = highpass;
#else
    DequantizeBandRow16s(highpass, width, highpass_quantization, highline);
#endif

    // Start processing at the beginning of the row
    column = 0;

    // Process the first two output points with special filters for the left border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 11 * lowpass[column + 0];
    even -=  4 * lowpass[column + 1];
    even +=  1 * lowpass[column + 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    output[0] = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 5 * lowpass[column + 0];
    odd += 4 * lowpass[column + 1];
    odd -= 1 * lowpass[column + 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    output[1] = SATURATE(odd);

#if (1 && XMMOPT)

    // Preload the first four lowpass coefficients
    low1_pi16 = *((__m64 *)&lowpass[column]);

    // Preload the first four highpass coefficients
    high1_pi16 = *((__m64 *)&highline[column]);

    // The reconstruction filters use pixels starting at the first column
    for (; column < post_column; column += column_step)
    {
        __m64 even_pi16;	// Result of convolution with even filter
        __m64 odd_pi16;		// Result of convolution with odd filter
        __m64 temp_pi16;
        __m64 out_pi16;		// Reconstructed data
        __m64 mask_pi16;
        __m64 half_pi16 = _mm_set1_pi16(4);
        __m64 lsb_pi16;
        __m64 sign_pi16;
        //__m64 high_pi16;

        // Preload the next four lowpass coefficients
        low2_pi16 = *((__m64 *)&lowpass[column + 4]);


        // Compute the first two even and two odd output points //

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift the highpass correction by one column
        high1_pi16 = _mm_srli_si64(high1_pi16, 16);

        // Prescale for 8bit output - DAN 4/5/02
        //high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;


        // Compute the second two even and two odd output points //

        // Preload the highpass correction
        high2_pi16 = *((__m64 *)&highline[column + 4]);

        // Shift in the new pixels for the next stage of the loop
        low1_pi16 = _mm_srli_si64(low1_pi16, 32);
        temp_pi16 = _mm_slli_si64(low2_pi16, 32);
        low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);


        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift in the next two highpass coefficients
        high1_pi16 = _mm_srli_si64(high1_pi16, 2 * 16);
        high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

        // Prescale for 8bit output - DAN 4/5/02
        //high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;

        // The second four lowpass coefficients will be the current values
        low1_pi16 = low2_pi16;

        // The second four highpass coefficients will be the current values
        high1_pi16 = high2_pi16;
    }

    // Should have exited the loop with the column equal to the post processing column
    assert(column == post_column);

#endif

    // The fast processing loop is one column behind the actual column
    column++;

    // Process the rest of the columns up to the last column in the row
    colptr = (PIXEL *)outptr;

    for (; column < last_column; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even += lowpass[column - 1];
        even -= lowpass[column + 1];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);
        even += lowpass[column + 0];

        // Add the highpass correction
        even += highline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowpass[column - 1];
        odd += lowpass[column + 1];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);
        odd += lowpass[column + 0];

        // Subtract the highpass correction
        odd -= highline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(colptr++) = SATURATE(odd);
    }

    // Should have exited the loop at the column for right border processing
    assert(column == last_column);

    // Process the last two output points with special filters for the right border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 5 * lowpass[column + 0];
    even += 4 * lowpass[column - 1];
    even -= 1 * lowpass[column - 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    *(colptr++) = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 11 * lowpass[column + 0];
    odd -=  4 * lowpass[column - 1];
    odd +=  1 * lowpass[column - 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    *(colptr++) = SATURATE(odd);

    //_mm_empty();	// Clear the mmx register state

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s8sTo16sBuffered(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
        int lowpass_quantization,	// lowpass quantization factor
        PIXEL8S *highpass_data,		// Row of horizontal highpass coefficients
        int highpass_quantization,	// highpass quantization factor
        PIXEL *output,				// Row of reconstructed results
        int width,					// Length of each row of horizontal coefficients
        PIXEL *buffer)				// Buffer to hold the dequantized values
{
#if _DECODE_LOWPASS_16S
    const int column_step = 8;
    const int last_column = width - 1;
    int post_column = last_column - (last_column % column_step);
    int column;

    PIXEL *highline = buffer;

    __m128i low1_epi16;		// Lowpass coefficients
    __m128i low2_epi16;
    __m128i high1_epi16;	// Current eight highpass coefficients
    __m128i high2_epi16;	// Next eight highpass coefficients

    __m128i half_epi16 = _mm_set1_epi16(4);

#if _UNALIGNED
    // The fast loop computes output points starting at the third column
    __m128i *outptr = (__m128i *)&output[2];
#else
    // The fast loop merges values from different phases to allow aligned stores
    __m128i *outptr = (__m128i *)&output[0];

    // Two 16-bit coefficients from the previous loop iteration
    //short remainder[2];
#endif

    PIXEL *colptr;

    int32_t even;
    int32_t odd;
    //int32_t lsb;

    PIXEL *highpass = (PIXEL *)highpass_data;

    // Adjust the end of the fast loop if necessary
    if (post_column == last_column)
        post_column -= column_step;

    // Undo quantization for the highpass row
#if _DEQUANTIZE_IN_FSM
    highline = highpass;
#else
    DequantizeBandRow16s(highpass, width, highpass_quantization, highline);
#endif

    // Start processing at the beginning of the row
    column = 0;

    // Process the first two output points with special filters for the left border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 11 * lowpass[column + 0];
    even -=  4 * lowpass[column + 1];
    even +=  1 * lowpass[column + 2];
    even += 4;
    even >>= 3;

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

#if _UNALIGNED
    // Place the even result in the even column
    output[0] = SATURATE(even);
#else
    // The output value will be stored later
    //remainder[0] = SATURATE(even);
#endif

    // Apply the odd reconstruction filter to the lowpass band
    odd += 5 * lowpass[column + 0];
    odd += 4 * lowpass[column + 1];
    odd -= 1 * lowpass[column + 2];
    odd += 4;
    odd >>= 3;

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

#if _UNALIGNED
    // Place the odd result in the odd column
    output[1] = SATURATE(odd);
#else
    // The output value will be stored later
    //remainder[1] = SATURATE(odd);
#endif

    /*
    	colptr = &output[2];
    	for (column = 2; column < 8; column++)
    	{
    		int32_t even = 0;		// Result of convolution with even filter
    		int32_t odd = 0;		// Result of convolution with odd filter

    		// Apply the even reconstruction filter to the lowpass band
    		even += lowpass[column - 1];
    		even -= lowpass[column + 1];
    		even += ROUNDING(even,8);
    		even = DivideByShift(even, 3);
    		even += lowpass[column + 0];

    		// Add the highpass correction
    		even += highline[column];
    		even = DivideByShift(even, 1);

    		// Place the even result in the even column
    		*(colptr++) = SATURATE(even);

    		// Apply the odd reconstruction filter to the lowpass band
    		odd -= lowpass[column - 1];
    		odd += lowpass[column + 1];
    		odd += ROUNDING(odd,8);
    		odd = DivideByShift(odd, 3);
    		odd += lowpass[column + 0];

    		// Subtract the highpass correction
    		odd -= highline[column];
    		odd = DivideByShift(odd, 1);

    		// Place the odd result in the odd column
    		*(colptr++) = SATURATE(odd);
    	}
    */

#if (1 && _FASTLOOP && XMMOPT)

    // Preload the first eight lowpass coefficients
    low1_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);
    //	low1_epi16 = _mm_adds_epi16(low1_epi16, overflowprotect_epi16);

    // Preload the first eight highpass coefficients
    high1_epi16 = _mm_load_si128((__m128i *)&highline[column]);

    // The reconstruction filters use pixels starting at the first column
    for (; column < post_column; column += column_step)
    {
        __m128i even_epi16;		// Result of convolution with even filter
        __m128i odd_epi16;		// Result of convolution with odd filter
        __m128i temp_epi16;
        __m128i out_epi16;		// Reconstructed data
        //__m128i high_epi16;
        uint32_t temp;		// Temporary register for last two values


        // Preload the next eight lowpass coefficients
        low2_epi16 = _mm_load_si128((__m128i *)&lowpass[column + 8]);

        //		low2_epi16 = _mm_adds_epi16(low2_epi16, overflowprotect_epi16);

        // Compute the first two even and two odd output points //

        // Apply the even reconstruction filter to the lowpass band
        /*		even_epi16 = low1_epi16;
        		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
        		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

        #if 1
        		// Apply the rounding adjustment
        		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		even_epi16 = _mm_srai_epi16(even_epi16, 3);
        */
        // better math.
        even_epi16 = low1_epi16;
        temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
        even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
        even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

        // Shift the highpass correction by one column
        high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

        // Prescale for 8bit output - DAN 4/5/02
        //high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

        // Add the highpass correction and divide by two
        even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        /*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
        		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

        #if 1
        		// Apply the rounding adjustment
        		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        */
        // Apply the odd reconstruction filter to the lowpass band
        // better math.
        odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        temp_epi16 = low1_epi16;
        odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
        odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

        // Subtract the highpass correction and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the first four even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
        //out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
        // Store the first eight output values
        _mm_storeu_si128(outptr++, out_epi16);
#else
        // Combine the new output values with the two values from the previous phase
        out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
        temp = _mm_cvtsi128_si32(out_epi16);
        out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
        out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

        // Store eight output values
        _mm_store_si128(outptr++, out_epi16);

        // Save the remaining two output values
        //*((int *)remainder) = temp;
        even = (short)temp;
        odd = (short)(temp >> 16);
#endif

        // Compute the second four even and four odd output points //

        // Preload the highpass correction
        high2_epi16 = _mm_load_si128((__m128i *)&highline[column + 8]);

        // Shift in the new pixels for the next stage of the loop
        low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
        temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
        low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

        /*		// Apply the even reconstruction filter to the lowpass band
        		even_epi16 = low1_epi16;
        		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
        		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

        #if 1
        		// Apply the rounding adjustment
        		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		even_epi16 = _mm_srai_epi16(even_epi16, 3);
        */
        // better math.
        even_epi16 = low1_epi16;
        temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
        even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
        even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);


        // Shift in the next four highpass coefficients
        high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
        temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
        high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

        // Prescale for 8bit output - DAN 4/5/02
        //high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

        // Add the highpass correction and divide by two
        even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        /*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
        		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

        #if 1
        		// Apply the rounding adjustment
        		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        */

        // Apply the odd reconstruction filter to the lowpass band
        // better math.
        odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        temp_epi16 = low1_epi16;
        odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);

        odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
        // Subtract the highpass correction and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the second four even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
        //out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
        // Store the first eight output values
        _mm_storeu_si128(outptr++, out_epi16);
#else
        // Combine the new output values with the two values from the previous phase
        out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
        temp = _mm_cvtsi128_si32(out_epi16);
        out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
        out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

        // Store eight output values
        _mm_store_si128(outptr++, out_epi16);

        // Save the remaining two output values
        even = (short)temp;
        odd = (short)(temp >> 16);
#endif

        // Prepare for the next loop iteration //

        // The second eight lowpass coefficients will be the current values
        low1_epi16 = low2_epi16;

        // The second eight highpass coefficients will be the current values
        high1_epi16 = high2_epi16;
    }

    // Should have exited the loop with the column equal to the post processing column
    assert(column == post_column);

#endif

    // The fast processing loop is one column behind the actual column
    column++;

    // Get the pointer to the next output value
    colptr = (PIXEL *)outptr;

#if _UNALIGNED
    // The last two output points have already been stored
#else
    // Store the last two output points produced by the loop
    *(colptr++) = SATURATE(even);
    *(colptr++) = SATURATE(odd);
#endif

    // Process the rest of the columns up to the last column in the row
    for (; column < last_column; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even = lowpass[column - 1];
        even -= lowpass[column + 1];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowpass[column + 0];

        // Add the highpass correction
        even += highpass[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        //even >>= _INVERSE_TEMPORAL_PRESCALE;
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd = -lowpass[column - 1];
        odd += lowpass[column + 1];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowpass[column + 0];

        // Subtract the highpass correction
        odd -= highpass[column];
        odd = DivideByShift(odd, 1);


        // Place the odd result in the odd column
        //odd >>= _INVERSE_TEMPORAL_PRESCALE;
        *(colptr++) = SATURATE(odd);
    }

    // Should have exited the loop at the column for right border processing
    assert(column == last_column);

    // Process the last two output points with special filters for the right border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 5 * lowpass[column + 0];
    even += 4 * lowpass[column - 1];
    even -= 1 * lowpass[column - 2];
    even += 4;
    even >>= 3;

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    *(colptr++) = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 11 * lowpass[column + 0];
    odd -=  4 * lowpass[column - 1];
    odd +=  1 * lowpass[column - 2];
    odd += 4;
    odd >>= 3;

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    *(colptr++) = SATURATE(odd);

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void InvertHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
                            //int lowpass_quantization,	// lowpass quantization factor
                            PIXEL *highpass,			// Row of horizontal highpass coefficients
                            //int highpass_quantization,// highpass quantization factor
                            PIXEL *output,				// Row of reconstructed results
                            int width)					// Length of each row of horizontal coefficients
//PIXEL *buffer)			// Buffer to hold the dequantized values
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

void InvertHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
                            //int lowpass_quantization,	// lowpass quantization factor
                            PIXEL *highpass,			// Row of horizontal highpass coefficients
                            //int highpass_quantization,// highpass quantization factor
                            PIXEL *output,				// Row of reconstructed results
                            int width)					// Length of each row of horizontal coefficients
//PIXEL *buffer)			// Buffer to hold the dequantized values
{
    int InvertHorizontalRow16sNotMMX_yet = 0;
    assert(InvertHorizontalRow16sNotMMX_yet);
}
#endif //_PROCESSOR_GENERIC



#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif
/***SSE2 Only***/

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
                            //int lowpass_quantization,	// lowpass quantization factor
                            PIXEL *highpass,			// Row of horizontal highpass coefficients
                            //int highpass_quantization,// highpass quantization factor
                            PIXEL *output,				// Row of reconstructed results
                            int width)					// Length of each row of horizontal coefficients
//PIXEL *buffer)			// Buffer to hold the dequantized values
{
    const int column_step = 8;
    const int last_column = width - 1;
    int post_column = last_column - (last_column % column_step);
    int column;

    __m128i low1_epi16;		// Lowpass coefficients
    __m128i low2_epi16;
    __m128i high1_epi16;	// Current eight highpass coefficients
    __m128i high2_epi16;	// Next eight highpass coefficients

    // The fast loop merges values from different phases to allow aligned stores
    __m128i *outptr = (__m128i *)&output[0];
    __m128i half_epi16 = _mm_set1_epi16(4);

    PIXEL *colptr;

    int32_t even;
    int32_t odd;

    // Adjust the end of the fast loop if necessary
    if (post_column == last_column)
        post_column -= column_step;

    // Assume that quantization has already been performed by the decoder
    //DequantizeBandRow16s(highpass_data, width, highpass_quantization, highpass);

    // Start processing at the beginning of the row
    column = 0;

    // Process the first two output points with special filters for the left border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 11 * lowpass[column + 0];
    even -=  4 * lowpass[column + 1];
    even +=  1 * lowpass[column + 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highpass[column];
    even = DivideByShift(even, 1);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 5 * lowpass[column + 0];
    odd += 4 * lowpass[column + 1];
    odd -= 1 * lowpass[column + 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highpass[column];
    odd = DivideByShift(odd, 1);

    //even = 100;		//***DEBUG***
    //odd = 100;		//***DEBUG***

#if (1 && XMMOPT)

    // Preload the first eight lowpass coefficients
    low1_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);

    // Preload the first eight highpass coefficients
    high1_epi16 = _mm_load_si128((__m128i *)&highpass[column]);

    //low1_epi16 = _mm_set1_epi16(200);	//***DEBUG***
    //high1_epi16 = _mm_set1_epi16(0);	//***DEBUG***

    // The reconstruction filters use pixels starting at the first column
    for (; column < post_column; column += column_step)
    {
        __m128i even_epi16;		// Result of convolution with even filter
        __m128i odd_epi16;		// Result of convolution with odd filter
        __m128i temp_epi16;
        __m128i out_epi16;		// Reconstructed data

        uint32_t temp;		// Temporary register for last two values


        // Preload the next eight lowpass coefficients
        low2_epi16 = _mm_load_si128((__m128i *)&lowpass[column + 8]);

        //low2_epi16 = _mm_set1_epi16(200);	//***DEBUG***


        /***** Compute the first two even and two odd output points *****/

        // Apply the even reconstruction filter to the lowpass band
        /*		even_epi16 = low1_epi16;
        		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
        		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

        #if 1
        		// Apply the rounding adjustment
        		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		even_epi16 = _mm_srai_epi16(even_epi16, 3);
        */
        // better math.
        even_epi16 = low1_epi16;
        temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
        even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
        even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);


        // Shift the highpass correction by one column
        high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

        // Add the highpass correction and divide by two
        even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        /*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
        		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

        #if 1
        		// Apply the rounding adjustment
        		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        */
        // better math.
        odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        temp_epi16 = low1_epi16;
        odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
        odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

        // Subtract the highpass correction and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the first four even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

        // Combine the new output values with the two values from the previous phase
        out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
        temp = _mm_cvtsi128_si32(out_epi16);
        out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
        out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

        // Store eight output values
        _mm_store_si128(outptr++, out_epi16);

        // Save the remaining two output values
        even = (short)temp;
        odd = (short)(temp >> 16);


        /***** Compute the second four even and four odd output points *****/

        // Preload the highpass correction
        high2_epi16 = _mm_load_si128((__m128i *)&highpass[column + 8]);

        //high2_epi16 = _mm_set1_epi16(0);	//***DEBUG***

        // Shift in the new pixels for the next stage of the loop
        low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
        temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
        low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

        // Apply the even reconstruction filter to the lowpass band
        /*		even_epi16 = low1_epi16;
        		temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		temp_epi16 = _mm_srli_si128(temp_epi16, 1*2);
        		even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

        #if 1
        		// Apply the rounding adjustment
        		even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		even_epi16 = _mm_srai_epi16(even_epi16, 3);
        */
        // better math.
        even_epi16 = low1_epi16;
        temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
        even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
        even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

        // Shift in the next four highpass coefficients
        high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
        temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
        high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

        // Add the highpass correction and divide by two
        even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        /*		odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
        		odd_epi16 = _mm_srli_si128(odd_epi16, 1*2);
        		temp_epi16 = _mm_srli_si128(low1_epi16, 2*2);
        		odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
        		odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

        #if 1
        		// Apply the rounding adjustment
        		odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
        #endif
        		// Divide by eight
        		odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        */
        // better math.
        odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        temp_epi16 = low1_epi16;
        odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
        temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
        odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);


        // Subtract the highpass correction and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the second four even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

        // Combine the new output values with the two values from the previous phase
        out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
        temp = _mm_cvtsi128_si32(out_epi16);
        out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
        out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

        // Store eight output values
        _mm_store_si128(outptr++, out_epi16);

        // Save the remaining two output values
        even = (short)temp;
        odd = (short)(temp >> 16);


        /***** Prepare for the next loop iteration *****/

        // The second eight lowpass coefficients will be the current values
        low1_epi16 = low2_epi16;

        // The second eight highpass coefficients will be the current values
        high1_epi16 = high2_epi16;
    }

    // Should have exited the loop with the column equal to the post processing column
    assert(column == post_column);

#endif

    // The fast processing loop is one column behind the actual column
    column++;

    // Get the pointer to the next output value
    colptr = (PIXEL *)outptr;

    // Store the last two output points produced by the loop
    *(colptr++) = SATURATE(even);
    *(colptr++) = SATURATE(odd);

    // Process the rest of the columns up to the last column in the row
    for (; column < last_column; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even += lowpass[column - 1];
        even -= lowpass[column + 1];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);
        even += lowpass[column + 0];

        // Add the highpass correction
        even += highpass[column];
        even = DivideByShift(even, 1);

        //even = 100;		//***DEBUG***

        // Place the even result in the even column
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowpass[column - 1];
        odd += lowpass[column + 1];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);
        odd += lowpass[column + 0];

        // Subtract the highpass correction
        odd -= highpass[column];
        odd = DivideByShift(odd, 1);

        //odd = 100;		//***DEBUG***

        // Place the odd result in the odd column
        *(colptr++) = SATURATE(odd);
    }

    // Should have exited the loop at the column for right border processing
    assert(column == last_column);

    // Process the last two output points with special filters for the right border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 5 * lowpass[column + 0];
    even += 4 * lowpass[column - 1];
    even -= 1 * lowpass[column - 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highpass[column];
    even = DivideByShift(even, 1);

    //even = 100;		//***DEBUG***

    // Place the even result in the even column
    *(colptr++) = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 11 * lowpass[column + 0];
    odd -=  4 * lowpass[column - 1];
    odd +=  1 * lowpass[column - 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highpass[column];
    odd = DivideByShift(odd, 1);

    //odd = 100;		//***DEBUG***

    // Place the odd result in the odd column
    *(colptr++) = SATURATE(odd);
}

#endif //P4



void BypassHorizontalRow16s(PIXEL *lowpass,  			// Row of horizontal lowpass coefficients
                            //int lowpass_quantization,	// lowpass quantization factor
                            PIXEL *highpass,			// Row of horizontal highpass coefficients
                            //int highpass_quantization,// highpass quantization factor
                            PIXEL *output,				// Row of reconstructed results
                            int width)					// Length of each row of horizontal coefficients
//PIXEL *buffer)			// Buffer to hold the dequantized values
{
    const int column_step = 8;
    const int last_column = width;
    int post_column = last_column - (last_column % column_step);
    int column;

    __m128i low_epi16;		// Lowpass coefficients

    // The fast loop merges values from different phases to allow aligned stores
    PIXEL *colptr = &output[0];

    // Start processing at the beginning of the row
    column = 0;


#if (1 && XMMOPT)

    if (ISALIGNED16(lowpass) && ISALIGNED16(colptr))
    {
        for (; column < post_column; column += 8)
        {
            low_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);
            low_epi16 = _mm_srai_epi16(low_epi16, 1);
            _mm_store_si128((__m128i *)&colptr[column], low_epi16);
        }
    }
    else
    {
        for (; column < post_column; column += 8)
        {
            low_epi16 = _mm_loadu_si128((__m128i *)&lowpass[column]);
            low_epi16 = _mm_srai_epi16(low_epi16, 1);
            _mm_storeu_si128((__m128i *)&colptr[column], low_epi16);
        }
    }

#endif

    // Process the rest of the columns up to the last column in the row
    for (; column < last_column; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        //int32_t odd = 0;		// Result of convolution with odd filter

        even = lowpass[column + 0];
        even = DivideByShift(even, 1);
        // Place the even result in the even column
        colptr[column] = SATURATE(even);
    }
}



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void InvertHorizontalRow8sBuffered(PIXEL8S *lowpass,			// Row of horizontal lowpass coefficients
                                   int lowpass_quantization,	// Lowpass quantization factor
                                   PIXEL8S *highpass,			// Row of horizontal highpass coefficients
                                   int highpass_quantization,	// Highpass quantization factor
                                   PIXEL   *output,				// Row of reconstructed results
                                   int width,					// Length of each row of horizontal coefficients
                                   PIXEL *buffer)				// Buffer to hold the dequantized values
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow8sBuffered(PIXEL8S *lowpass_data,			// Row of horizontal lowpass coefficients
                                   int lowpass_quantization,	// Lowpass quantization factor
                                   PIXEL8S *highpass_data,			// Row of horizontal highpass coefficients
                                   int highpass_quantization,	// Highpass quantization factor
                                   PIXEL   *output,				// Row of reconstructed results
                                   int width,					// Length of each row of horizontal coefficients
                                   PIXEL *buffer)				// Buffer to hold the dequantized values
{
    // Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S
    const int column_step = 4;
    const int last_column = width - 1;
    int post_column = last_column - (last_column % column_step);
    int column;

    __m64 low1_pi16;	// Lower four lowpass coefficients
    __m64 low2_pi16;	// Upper four lowpass coefficients
    __m64 high1_pi16;	// Lower four highpass coefficients
    __m64 high2_pi16;	// Upper four highpass coefficients

    PIXEL *lowline = buffer;
    PIXEL *highline = buffer + width;

    // The fast loop computes output points starting at the third column
    __m64 *outptr = (__m64 *)&output[2];

    PIXEL *colptr;

    int32_t even;
    int32_t odd;
    //int32_t lsb;

    PIXEL *lowpass = (PIXEL *)lowpass_data;
    PIXEL *highpass = (PIXEL *)highpass_data;

    // Adjust the end of the fast loop if necessary
    if (post_column == last_column)
        post_column -= column_step;

    // Align the highpass buffer to a 16 byte boundary
    highline = (PIXEL *)ALIGN16(highline);

    // Undo quantization for the lowpass and highpass bands
#if _DEQUANTIZE_IN_FSM
    lowline = lowpass;
    highline = highpass;
#else
    DequantizeBandRow16s(lowpass, width, lowpass_quantization, lowline);
    DequantizeBandRow16s(highpass, width, highpass_quantization, highline);
#endif

    // Start processing at the beginning of the row
    column = 0;

    // Process the first two output points with special filters for the left border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 11 * lowline[column + 0];
    even -=  4 * lowline[column + 1];
    even +=  1 * lowline[column + 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    output[0] = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 5 * lowline[column + 0];
    odd += 4 * lowline[column + 1];
    odd -= 1 * lowline[column + 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    output[1] = SATURATE(odd);

#if (1 && XMMOPT)

    // Preload the first four lowpass coefficients
    low1_pi16 = *((__m64 *)&lowline[column]);

    // Preload the first four highpass coefficients
    high1_pi16 = *((__m64 *)&highline[column]);

    // The reconstruction filters use pixels starting at the first column
    for (; column < post_column; column += column_step)
    {
        __m64 even_pi16;	// Result of convolution with even filter
        __m64 odd_pi16;		// Result of convolution with odd filter
        __m64 temp_pi16;
        __m64 out_pi16;		// Reconstructed data
        __m64 mask_pi16;
        __m64 half_pi16 = _mm_set1_pi16(4);
        __m64 lsb_pi16;
        __m64 sign_pi16;
        //		__m64 high_pi16;

        // Preload the next four lowpass coefficients
        low2_pi16 = *((__m64 *)&lowline[column + 4]);


        // Compute the first two even and two odd output points //

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift the highpass correction by one column
        high1_pi16 = _mm_srli_si64(high1_pi16, 16);

        // Prescale for 8bit output - DAN 4/5/02
        //		high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);


        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;

        // Compute the second two even and two odd output points //

        // Preload the highpass correction
        high2_pi16 = *((__m64 *)&highline[column + 4]);

        // Shift in the new pixels for the next stage of the loop
        low1_pi16 = _mm_srli_si64(low1_pi16, 32);
        temp_pi16 = _mm_slli_si64(low2_pi16, 32);
        low1_pi16 = _mm_or_si64(low1_pi16, temp_pi16);

        // Apply the even reconstruction filter to the lowpass band
        even_pi16 = low1_pi16;
        temp_pi16 = _mm_slli_pi16(low1_pi16, 3);
        temp_pi16 = _mm_shuffle_pi16(temp_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        even_pi16 = _mm_adds_pi16(even_pi16, temp_pi16);
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        even_pi16 = _mm_subs_pi16(even_pi16, temp_pi16);

        // Apply the rounding adjustment
        even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
        // Divide by eight
        even_pi16 = _mm_srai_pi16(even_pi16, 3);

        // Shift in the next two highpass coefficients
        high1_pi16 = _mm_srli_si64(high1_pi16, 2 * 16);
        high1_pi16 = _mm_or_si64(high1_pi16, _mm_slli_si64(high2_pi16, 16));

        // Prescale for 8bit output - DAN 4/5/02
        //		high_pi16 = _mm_slli_pi16(high1_pi16, prescale);

        // Add the highpass correction
        even_pi16 = _mm_adds_pi16(even_pi16, high1_pi16);
        even_pi16 = _mm_srai_pi16(even_pi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_pi16 = _mm_slli_pi16(low1_pi16, 3);
        odd_pi16 = _mm_shuffle_pi16(odd_pi16, _MM_SHUFFLE(0, 3, 2, 1));
        temp_pi16 = _mm_shuffle_pi16(low1_pi16, _MM_SHUFFLE(1, 0, 3, 2));
        odd_pi16 = _mm_adds_pi16(odd_pi16, temp_pi16);
        odd_pi16 = _mm_subs_pi16(odd_pi16, low1_pi16);

        // Apply the rounding adjustment
        odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);
        // Divide by eight
        odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

        // Subtract the highpass correction
        odd_pi16 = _mm_subs_pi16(odd_pi16, high1_pi16);
        odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

        // Interleave the even and odd results
        out_pi16 = _mm_unpacklo_pi16(even_pi16, odd_pi16);
        //out_pi16 = _mm_max_pi16(out_pi16, _mm_setzero_si64());
        *(outptr++) = out_pi16;

        // The second four lowpass coefficients will be the current values
        low1_pi16 = low2_pi16;

        // The second four highpass coefficients will be the current values
        high1_pi16 = high2_pi16;
    }

    // Should have exited the loop with the column equal to the post processing column
    assert(column == post_column);

#endif

    // The fast processing loop is one column behind the actual column
    column++;

    // Process the rest of the columns up to the last column in the row
    colptr = (PIXEL *)outptr;

    for (; column < last_column; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even += lowline[column - 1];
        even -= lowline[column + 1];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);
        even += (lowline[column + 0]);

        // Add the highpass correction
        even += highline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowline[column - 1];
        odd += lowline[column + 1];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);
        odd += (lowline[column + 0]);

        // Subtract the highpass correction
        odd -= highline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(colptr++) = SATURATE(odd);
    }

    // Should have exited the loop at the column for right border processing
    assert(column == last_column);

    // Process the last two output points with special filters for the right border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 5 * lowline[column + 0];
    even += 4 * lowline[column - 1];
    even -= 1 * lowline[column - 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    *(colptr++) = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 11 * lowline[column + 0];
    odd -=  4 * lowline[column - 1];
    odd +=  1 * lowline[column - 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    *(colptr++) = SATURATE(odd);

    //_mm_empty();	// Clear the mmx register state

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse horizontal transform to reconstruct a single row
void InvertHorizontalRow8sBuffered(PIXEL8S *lowpass_data,			// Row of horizontal lowpass coefficients
                                   int lowpass_quantization,	// Lowpass quantization factor
                                   PIXEL8S *highpass_data,			// Row of horizontal highpass coefficients
                                   int highpass_quantization,	// Highpass quantization factor
                                   PIXEL   *output,				// Row of reconstructed results
                                   int width,					// Length of each row of horizontal coefficients
                                   PIXEL *buffer)				// Buffer to hold the dequantized values
{
    // Need to implement this routine for 8-bit decoding

#if _DECODE_LOWPASS_16S
    const int column_step = 8;
    const int last_column = width - 1;
    int post_column = last_column - (last_column % column_step);
    int column;

    __m128i low1_epi16;		// Lower eight lowpass coefficients
    __m128i low2_epi16;		// Upper eight lowpass coefficients
    __m128i high1_epi16;	// Lower eight highpass coefficients
    __m128i high2_epi16;	// Upper eight highpass coefficients

    PIXEL *lowline = buffer;
    PIXEL *highline = buffer + width;

    // Some calculations can extend past the true length of the row
    //int row_length = ALIGN16(width);

#if _UNALIGNED
    // The fast loop computes output points starting at the third column
    __m128i *outptr = (__m128i *)&output[2];
#else
    // The fast loop merges values from different phases to allow aligned stores
    __m128i *outptr = (__m128i *)&output[0];
#endif

    // Two 16-bit coefficients from the previous loop iteration
    //short remainder[2];

    PIXEL *colptr;

    int32_t even;
    int32_t odd;
    //int32_t lsb;

    PIXEL *lowpass = (PIXEL *)lowpass_data;
    PIXEL *highpass = (PIXEL *)highpass_data;

    // Adjust the end of the fast loop if necessary
    if (post_column == last_column)
        post_column -= column_step;

    // Align the highpass buffer to a 16 byte boundary
    highline = (PIXEL *)ALIGN16(highline);

    // Check that both row buffers are properly aligned
    assert(ISALIGNED16(lowline));
    assert(ISALIGNED16(highline));

    // Undo quantization for the lowpass and highpass bands
#if _DEQUANTIZE_IN_FSM
    lowline = lowpass;
    highline = highpass;
#else
    DequantizeBandRow16s(lowpass, row_length, lowpass_quantization, lowline);
    DequantizeBandRow16s(highpass, row_length, highpass_quantization, highline);
#endif

    // Start processing at the beginning of the row
    column = 0;

    // Process the first two output points with special filters for the left border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 11 * lowline[column + 0];
    even -=  4 * lowline[column + 1];
    even +=  1 * lowline[column + 2];
    even += ROUNDING(even, 8);
    even = DivideByShift(even, 3);

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

#if _UNALIGNED
    // Place the even result in the even column
    output[0] = SATURATE(even);
#else
    // The output value will be stored later
    //remainder[0] = SATURATE(even);
#endif

    // Apply the odd reconstruction filter to the lowpass band
    odd += 5 * lowline[column + 0];
    odd += 4 * lowline[column + 1];
    odd -= 1 * lowline[column + 2];
    odd += ROUNDING(odd, 8);
    odd = DivideByShift(odd, 3);

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

#if _UNALIGNED
    // Place the odd result in the odd column
    output[1] = SATURATE(odd);
#else
    // The output value will be stored later
    //remainder[1] = SATURATE(odd);
#endif

#if (1 && _FASTLOOP && XMMOPT)

    // Preload the first four lowpass coefficients
    low1_epi16 = _mm_load_si128((__m128i *)&lowline[column]);

    // Preload the first four highpass coefficients
    high1_epi16 = _mm_load_si128((__m128i *)&highline[column]);

    // The reconstruction filters use pixels starting at the first column
    for (; column < post_column; column += column_step)
    {
        __m128i even_epi16;		// Result of convolution with even filter
        __m128i odd_epi16;		// Result of convolution with odd filter
        __m128i temp_epi16;
        __m128i out_epi16;		// Reconstructed data
        __m128i half_epi16 = _mm_set1_epi16(4);
        //__m128i high_epi16;
        uint32_t temp;		// Temporary register for last two values

        // Preload the next eight lowpass coefficients
        low2_epi16 = _mm_load_si128((__m128i *)&lowline[column + 8]);


        // Compute the first four even and four odd output points //

        // Apply the even reconstruction filter to the lowpass band
        even_epi16 = low1_epi16;
        temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
        temp_epi16 = _mm_srli_si128(temp_epi16, 1 * 2);
        even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
        temp_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

        // Apply the rounding adjustment
        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);

        // Divide by eight
        even_epi16 = _mm_srai_epi16(even_epi16, 3);

        // Shift the highpass correction by one column
        high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

        // Prescale for 8bit output - DAN 4/5/02
        //high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

        // Add the highpass correction and divide by two
        even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
        odd_epi16 = _mm_srli_si128(odd_epi16, 1 * 2);
        temp_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
        odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

        // Apply the rounding adjustment
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

        // Divide by eight
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

        // Subtract the highpass correction and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
        //out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
        // Store the first eight output values
        _mm_storeu_si128(outptr++, out_epi16);
#else
        // Combine the new output values with the two values from the previous phase
        out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
        temp = _mm_cvtsi128_si32(out_epi16);
        out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
        out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

        // Store eight output values
        _mm_store_si128(outptr++, out_epi16);

        // Save the remaining two output values
        even = (short)temp;
        odd = (short)(temp >> 16);
#endif

        // Compute the second four even and four odd output points //

        // Preload the highpass correction
        high2_epi16 = _mm_load_si128((__m128i *)&highline[column + 8]);

        // Shift in the new pixels for the next stage of the loop
        low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
        temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
        low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

        // Apply the even reconstruction filter to the lowpass band
        even_epi16 = low1_epi16;
        temp_epi16 = _mm_slli_epi16(low1_epi16, 3);
        temp_epi16 = _mm_srli_si128(temp_epi16, 1 * 2);
        even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);
        temp_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);

        // Apply the rounding adjustment
        even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);

        // Divide by eight
        even_epi16 = _mm_srai_epi16(even_epi16, 3);

        // Shift in the next four highpass coefficients
        high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
        temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
        high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

        // Prescale for 8bit output - DAN 4/5/02
        //high_epi16 = _mm_slli_epi16(high1_epi16, prescale);

        // Add the highpass correction and divide by two
        even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_epi16 = _mm_slli_epi16(low1_epi16, 3);
        odd_epi16 = _mm_srli_si128(odd_epi16, 1 * 2);
        temp_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
        odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);
        odd_epi16 = _mm_subs_epi16(odd_epi16, low1_epi16);

        // Apply the rounding adjustment
        odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

        // Divide by eight
        odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

        // Subtract the highpass correction and divide by two
        odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);
        //out_epi16 = _mm_max_epi16(out_epi16, _mm_setzero_si64());

#if _UNALIGNED
        // Store the first eight output values
        _mm_storeu_si128(outptr++, out_epi16);
#else
        // Combine the new output values with the two values from the previous phase
        out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
        temp = _mm_cvtsi128_si32(out_epi16);
        out_epi16 = _mm_insert_epi16(out_epi16, even, 0);
        out_epi16 = _mm_insert_epi16(out_epi16, odd, 1);

        // Store eight output values
        _mm_store_si128(outptr++, out_epi16);

        // Save the remaining two output values
        even = (short)temp;
        odd = (short)(temp >> 16);
#endif
        // The second four lowpass coefficients will be the current values
        low1_epi16 = low2_epi16;

        // The second four highpass coefficients will be the current values
        high1_epi16 = high2_epi16;
    }

    // Should have exited the loop with the column equal to the post processing column
    assert(column == post_column);

#endif

    // The fast processing loop is one column behind the actual column
    column++;

    // Get the pointer to the next output value
    colptr = (PIXEL *)outptr;

#if _UNALIGNED
    // The last two output points have already been stored
#else
    // Store the last two output points produced by the loop
    *(colptr++) = SATURATE(even);
    *(colptr++) = SATURATE(odd);
#endif

    // Process the rest of the columns up to the last column in the row
    for (; column < last_column; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter

        // Apply the even reconstruction filter to the lowpass band
        even += lowline[column - 1];
        even -= lowline[column + 1];
        even += 4; //DAN20050921
        even >>= 3;
        even += lowline[column + 0];

        // Add the highpass correction
        even += highline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd -= lowline[column - 1];
        odd += lowline[column + 1];
        odd += 4; //DAN20050921
        odd >>= 3;
        odd += lowline[column + 0];

        // Subtract the highpass correction
        odd -= highline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(colptr++) = SATURATE(odd);
    }

    // Should have exited the loop at the column for right border processing
    assert(column == last_column);

    // Process the last two output points with special filters for the right border
    even = 0;
    odd = 0;

    // Apply the even reconstruction filter to the lowpass band
    even += 5 * lowline[column + 0];
    even += 4 * lowline[column - 1];
    even -= 1 * lowline[column - 2];
    even += 4;
    even >>= 3;

    // Add the highpass correction
    even += highline[column];
    even = DivideByShift(even, 1);

    // Place the even result in the even column
    *(colptr++) = SATURATE(even);

    // Apply the odd reconstruction filter to the lowpass band
    odd += 11 * lowline[column + 0];
    odd -=  4 * lowline[column - 1];
    odd +=  1 * lowline[column - 2];
    odd += 4;
    odd >>= 3;

    // Subtract the highpass correction
    odd -= highline[column];
    odd = DivideByShift(odd, 1);

    // Place the odd result in the odd column
    *(colptr++) = SATURATE(odd);

#else
#error Have not implemented 8-bit lowpass coefficients
#endif
}

#endif

#if _DEBUG

//#if BUILD_PROSPECT

// Apply the inverse horizontal transform to reconstruct a single row using pixel duplication
void InvertHorizontalRowDuplicated16s(PIXEL *lowpass,				// Row of horizontal lowpass coefficients
                                      int lowpass_quantization,		// Lowpass quantization factor
                                      PIXEL8S *highpass_data,		// Row of horizontal highpass coefficients
                                      int highpass_quantization,	// highpass quantization factor
                                      PIXEL *output,				// Row of reconstructed results
                                      int width,					// Length of each row of horizontal coefficients
                                      PIXEL *buffer)				// Buffer to hold the dequantized values
{
    const int column_step = 8;
    const int last_column = width;
    int post_column = last_column - (last_column % column_step);
    int column;

    __m128i low1_epi16;		// Lowpass coefficients
    __m128i low2_epi16;
    __m128i *outptr = (__m128i *)&output[0];

    PIXEL *colptr;

    // Start processing at the beginning of the row
    column = 0;

#if (1 && XMMOPT)

    // Preload the first eight lowpass coefficients
    low1_epi16 = _mm_load_si128((__m128i *)&lowpass[column]);

    // Preload the first eight highpass coefficients
    //high1_epi16 = _mm_load_si128((__m128i *)&highline[column]);

    // The reconstruction filters use pixels starting at the first column
    for (; column < post_column; column += column_step)
    {
        __m128i even_epi16;		// Result of convolution with even filter
        __m128i odd_epi16;		// Result of convolution with odd filter
        __m128i temp_epi16;
        __m128i out_epi16;		// Reconstructed data


        // Preload the next eight lowpass coefficients
        low2_epi16 = _mm_load_si128((__m128i *)&lowpass[column + 8]);


        /***** Compute the first two even and two odd output points *****/

        // Apply the even reconstruction filter to the lowpass band
        even_epi16 = low1_epi16;
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_epi16 = low1_epi16;
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the first four even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

        // Store the first eight output values
        _mm_store_si128(outptr++, out_epi16);


        /***** Compute the second four even and four odd output points *****/

        // Preload the highpass correction
        //high2_epi16 = _mm_load_si128((__m128i *)&highline[column+8]);

        // Shift in the new pixels for the next stage of the loop
        low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
        temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
        low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

        // Apply the even reconstruction filter to the lowpass band
        even_epi16 = low1_epi16;
        even_epi16 = _mm_srai_epi16(even_epi16, 1);

        // Apply the odd reconstruction filter to the lowpass band
        odd_epi16 = low1_epi16;
        odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

        // Interleave the second four even and odd results
        out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

        // Store the first eight output values
        _mm_store_si128(outptr++, out_epi16);


        /***** Prepare for the next loop iteration *****/

        // The second eight lowpass coefficients will be the current values
        low1_epi16 = low2_epi16;

        // The second eight highpass coefficients will be the current values
        //high1_epi16 = high2_epi16;
    }

    // Should have exited the loop with the column equal to the post processing column
    assert(column == post_column);

#endif

    // Get the pointer to the next output value
    colptr = (PIXEL *)outptr;

    // Process the rest of the columns up to the last column in the row
    for (; column < last_column; column++)
    {
        int32_t even;
        int32_t odd;

        // Apply the even reconstruction filter to the lowpass band
        even = lowpass[column + 0];
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(colptr++) = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd = lowpass[column + 0];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(colptr++) = SATURATE(odd);
    }

    // Should have exited the loop at the column for right border processing
    assert(column == last_column);
}
//#endif //BUILD_PROSPECT

#endif


#if 1

// Apply the inverse spatial (horizontal and vertical) transform by
// performing the inverse horizontal transform as each row is output
// by the inverse vertical transform.

#if 0	//_PROCESSOR_DISPATCH		// This routine contains only MMX optimizations

__declspec(cpu_dispatch(Pentium_II, Pentium_III, Pentium_4, Generic))

void InvertSpatialQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
                          PIXEL8S *lowhigh_band, int lowhigh_pitch,
                          PIXEL8S *highlow_band, int highlow_pitch,
                          PIXEL8S *highhigh_band, int highhigh_pitch,
                          PIXEL *output_image, int output_pitch,
                          ROI roi, PIXEL *buffer, size_t buffer_size,
                          int quantization[])
{
    // Stub routine for processor specific dispatch
}

__declspec(cpu_specific(Pentium_II))

#endif


// Adapted from the 8s version above
void InvertSpatialQuantOverflowProtected16s(PIXEL *lowlow_band, int lowlow_pitch,
        PIXEL *lowhigh_band, int lowhigh_pitch,
        PIXEL *highlow_band, int highlow_pitch,
        PIXEL *highhigh_band, int highhigh_pitch,
        PIXEL *output_image, int output_pitch,
        ROI roi, PIXEL *buffer, size_t buffer_size,
        int quantization[])
{
    PIXEL *lowlow = (PIXEL *)lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;					// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int width = roi.width;
    int height = roi.height;
    int last_row = height - 1;
    int row, column;

    SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
    SCRATCH *scratch = &scratch_buffer;
    PIXEL *lowhigh_line[3];
    PIXEL *highlow_line;
    PIXEL *highhigh_line;

    //int lowlow_quantization = quantization[LL_BAND];
    //int highlow_quantization = quantization[HL_BAND];
    //int lowhigh_quantization = quantization[LH_BAND];
    //int highhigh_quantization = quantization[HH_BAND];

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of
    // vertical results and 5 rows of dequantized highpass coefficients
    assert(buffer_size >= (9 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Compute the positions of the dequantized highpass rows
    lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Apply the vertical border filter to the first row
    row = 0;

    // Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
    lowhigh_line[0] = lowhigh;
    lowhigh_line[1] = lowhigh + lowhigh_pitch;
    lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;

    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
    DequantizeBandRow16s(lowhigh + lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
    DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

    // Dequantize one row of coefficients each in the highlow and highhigh bands
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh_line[0][column];
        even -=  4 * lowhigh_line[1][column];
        even +=  1 * lowhigh_line[2][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh_line[0][column];
        odd += 4 * lowhigh_line[1][column];
        odd -= 1 * lowhigh_line[2][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
        DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
    }
#endif

    // Apply the inverse horizontal transform to the even and odd rows (without descaling)
    InvertHorizontalStrip16s(lowpass, lowpass_pitch, highpass, highpass_pitch,
                             output, (int)output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
        //		assert(0);
#if (0 && XMMOPT) //DANREMOVED
        int column_step = 4;
        int post_column = width - (width % column_step);
        __m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
        __m64 *even_highpass_ptr = (__m64 *)even_highpass;
        __m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
        __m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
        int quad_pitch;
#endif

        // Dequantize one row from each of the two highpass bands
#if _DEQUANTIZE_IN_FSM
        highlow_line = highlow;
        highhigh_line = highhigh;
#else
        DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
        DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

        // Start at the first column
        column = 0;

#if (0 && XMMOPT) //DANREMOVED

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
            __m64 *highlow_ptr = (__m64 *)&highlow_line[column];
            __m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
            __m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
            __m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
            __m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
            __m64 low0_pi16;
            __m64 low1_pi16;
            __m64 low2_pi16;
            __m64 high_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;
            __m64 addition_pi16;
            __m64 diff_pi16;

            __m64 additionA_pi32;
            __m64 additionB_pi32;
            __m64 diffA_pi32;
            __m64 diffB_pi32;
            __m64 evenA_pi32;
            __m64 oddA_pi32;
            __m64 evenB_pi32;
            __m64 oddB_pi32;
            __m64 lowA_pi32;
            __m64 lowB_pi32;
            __m64 highA_pi32;
            __m64 highB_pi32;
            __m64 low1A_pi32;
            __m64 low1B_pi32;

            // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
            __m64 half_pi32 = _mm_set1_pi32(4);
            __m64 zero = _mm_set1_pi16(0);


            /***** Compute the vertical inverse for the left two bands *****/

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            //even += lowlow[column + 0 * lowlow_pitch];
            low0_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            evenA_pi32 = _mm_unpackhi_pi16(zero, low0_pi16);
            evenA_pi32 = _mm_srai_pi32(evenA_pi32, 16); // presevere sign
            evenB_pi32 = _mm_unpacklo_pi16(zero, low0_pi16);
            evenB_pi32 = _mm_srai_pi32(evenB_pi32, 16); // presevere sign
            lowlow_ptr += quad_pitch;	// Advance to the next row

            //odd -= lowlow[column + 0 * lowlow_pitch];
            oddA_pi32 = _mm_sub_pi32(zero, evenA_pi32);
            oddB_pi32 = _mm_sub_pi32(zero, evenB_pi32);

            low1_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            low1A_pi32 = _mm_unpackhi_pi16(zero, low1_pi16);
            low1A_pi32 = _mm_srai_pi32(low1A_pi32, 16); // presevere sign
            low1B_pi32 = _mm_unpacklo_pi16(zero, low1_pi16);
            low1B_pi32 = _mm_srai_pi32(low1B_pi32, 16); // presevere sign
            lowlow_ptr += quad_pitch;	// Advance to the next row

            low2_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowA_pi32 = _mm_unpackhi_pi16(zero, low2_pi16);
            lowA_pi32 = _mm_srai_pi32(lowA_pi32, 16); // presevere sign
            lowB_pi32 = _mm_unpacklo_pi16(zero, low2_pi16);
            lowB_pi32 = _mm_srai_pi32(lowB_pi32, 16); // presevere sign


            //even_pi16 = _mm_subs_pi16(even_pi16, low_pi16);
            //even -= lowlow[column + 2 * lowlow_pitch];
            evenA_pi32 = _mm_sub_pi32(evenA_pi32, lowA_pi32);
            evenB_pi32 = _mm_sub_pi32(evenB_pi32, lowB_pi32);

            //odd_pi16 = _mm_adds_pi16(odd_pi16, low_pi16);
            //odd += lowlow[column + 2 * lowlow_pitch];
            oddA_pi32 = _mm_add_pi32(oddA_pi32, lowA_pi32);
            oddB_pi32 = _mm_add_pi32(oddB_pi32, lowB_pi32);


            //even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            //even += 4; //DAN20050921
            evenA_pi32 = _mm_add_pi32(evenA_pi32, half_pi32);
            evenB_pi32 = _mm_add_pi32(evenB_pi32, half_pi32);

            //odd += 4; //DAN20050921
            //odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            oddA_pi32 = _mm_add_pi32(oddA_pi32, half_pi32);
            oddB_pi32 = _mm_add_pi32(oddB_pi32, half_pi32);

            //even >>= 3;
            //even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            evenA_pi32 = _mm_srai_pi32(evenA_pi32, 3);
            evenB_pi32 = _mm_srai_pi32(evenB_pi32, 3);

            //odd >>= 3;
            //odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8
            oddA_pi32 = _mm_srai_pi32(oddA_pi32, 3);
            oddB_pi32 = _mm_srai_pi32(oddB_pi32, 3);

            //addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
            high_pi16 = *highlow_ptr;
            highA_pi32 = _mm_unpackhi_pi16(zero, high_pi16);
            highA_pi32 = _mm_srai_pi32(highA_pi32, 16); // presevere sign
            highB_pi32 = _mm_unpacklo_pi16(zero, high_pi16);
            highB_pi32 = _mm_srai_pi32(highB_pi32, 16); // presevere sign
            //addition_pi16 = _mm_adds_pi16(low8_pi16, high_pi16);
            additionA_pi32 = _mm_add_pi32(low1A_pi32, highA_pi32);
            additionB_pi32 = _mm_add_pi32(low1B_pi32, highB_pi32);


            //diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
            //diff_pi16 = _mm_subs_pi16(low8_pi16, high_pi16);
            diffA_pi32 = _mm_sub_pi32(low1A_pi32, highA_pi32);
            diffB_pi32 = _mm_sub_pi32(low1B_pi32, highB_pi32);

            // These can clip inapproxiately (signed shorts are no enough)
            //even_pi16 = _mm_adds_pi16(even_pi16, addition_pi16);
            //even += addition;
            evenA_pi32 = _mm_add_pi32(evenA_pi32, additionA_pi32);
            evenB_pi32 = _mm_add_pi32(evenB_pi32, additionB_pi32);

            //odd += diff;
            //odd_pi16 = _mm_adds_pi16(odd_pi16, diff_pi16);
            oddA_pi32 = _mm_add_pi32(oddA_pi32, diffA_pi32);
            oddB_pi32 = _mm_add_pi32(oddB_pi32, diffB_pi32);

            //even_pi16 = _mm_srai_pi16(even_pi16, 1); // divide by 2
            //even = DivideByShift(even, 1);
            evenA_pi32 = _mm_srai_pi32(evenA_pi32, 1);
            evenB_pi32 = _mm_srai_pi32(evenB_pi32, 1);

            //odd = DivideByShift(odd, 1);
            //odd_pi16 = _mm_srai_pi16(odd_pi16, 1);  // divide by 2
            oddA_pi32 = _mm_srai_pi32(oddA_pi32, 1);
            oddB_pi32 = _mm_srai_pi32(oddB_pi32, 1);

            even_pi16 = _mm_packs_pi32 (evenB_pi32, evenA_pi32);
            odd_pi16 = _mm_packs_pi32 (oddB_pi32, oddA_pi32);


            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            /**** Compute the vertical inverse for the right two bands *****/

            // Set the pitch for the lowpass band used in this section of code
            //quad_pitch = (lowhigh_pitch * sizeof(PIXEL))/sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters

            low0_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
            evenA_pi32 = _mm_unpackhi_pi16(zero, low0_pi16);
            evenA_pi32 = _mm_srai_pi32(evenA_pi32, 16); // presevere sign
            evenB_pi32 = _mm_unpacklo_pi16(zero, low0_pi16);
            evenB_pi32 = _mm_srai_pi32(evenB_pi32, 16); // presevere sign

            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            oddA_pi32 = _mm_sub_pi32(zero, evenA_pi32);
            oddB_pi32 = _mm_sub_pi32(zero, evenB_pi32);

            low2_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients
            lowA_pi32 = _mm_unpackhi_pi16(zero, low2_pi16);
            lowA_pi32 = _mm_srai_pi32(lowA_pi32, 16); // presevere sign
            lowB_pi32 = _mm_unpacklo_pi16(zero, low2_pi16);
            lowB_pi32 = _mm_srai_pi32(lowB_pi32, 16); // presevere sign

            //even_pi16 = _mm_subs_pi16(even_pi16, low_pi16);
            evenA_pi32 = _mm_sub_pi32(evenA_pi32, lowA_pi32);
            evenB_pi32 = _mm_sub_pi32(evenB_pi32, lowB_pi32);

            //odd_pi16 = _mm_adds_pi16(odd_pi16, low_pi16);
            oddA_pi32 = _mm_add_pi32(oddA_pi32, lowA_pi32);
            oddB_pi32 = _mm_add_pi32(oddB_pi32, lowB_pi32);



            low1_pi16 = *lowhigh_ptr2;
            low1A_pi32 = _mm_unpackhi_pi16(zero, low1_pi16);
            low1A_pi32 = _mm_srai_pi32(low1A_pi32, 16); // presevere sign
            low1B_pi32 = _mm_unpacklo_pi16(zero, low1_pi16);
            low1B_pi32 = _mm_srai_pi32(low1B_pi32, 16); // presevere sign

            //even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            evenA_pi32 = _mm_add_pi32(evenA_pi32, half_pi32);
            evenB_pi32 = _mm_add_pi32(evenB_pi32, half_pi32);

            //odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            oddA_pi32 = _mm_add_pi32(oddA_pi32, half_pi32);
            oddB_pi32 = _mm_add_pi32(oddB_pi32, half_pi32);

            //even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            evenA_pi32 = _mm_srai_pi32(evenA_pi32, 3);
            evenB_pi32 = _mm_srai_pi32(evenB_pi32, 3);

            //odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8
            oddA_pi32 = _mm_srai_pi32(oddA_pi32, 3);
            oddB_pi32 = _mm_srai_pi32(oddB_pi32, 3);


            high_pi16 = *highhigh_ptr;
            highA_pi32 = _mm_unpackhi_pi16(zero, high_pi16);
            highA_pi32 = _mm_srai_pi32(highA_pi32, 16); // presevere sign
            highB_pi32 = _mm_unpacklo_pi16(zero, high_pi16);
            highB_pi32 = _mm_srai_pi32(highB_pi32, 16); // presevere sign


            //addition_pi16 = _mm_adds_pi16(low8_pi16, high_pi16);
            additionA_pi32 = _mm_add_pi32(low1A_pi32, highA_pi32);
            additionB_pi32 = _mm_add_pi32(low1B_pi32, highB_pi32);

            //diff_pi16 = _mm_subs_pi16(low8_pi16, high_pi16);
            diffA_pi32 = _mm_sub_pi32(low1A_pi32, highA_pi32);
            diffB_pi32 = _mm_sub_pi32(low1B_pi32, highB_pi32);

            // These can clip inapproxiately (signed shorts are no enough)
            //even_pi16 = _mm_adds_pi16(even_pi16, addition_pi16);
            evenA_pi32 = _mm_add_pi32(evenA_pi32, additionA_pi32);
            evenB_pi32 = _mm_add_pi32(evenB_pi32, additionB_pi32);

            //odd_pi16 = _mm_adds_pi16(odd_pi16, diff_pi16);
            oddA_pi32 = _mm_add_pi32(oddA_pi32, diffA_pi32);
            oddB_pi32 = _mm_add_pi32(oddB_pi32, diffB_pi32);

            //even_pi16 = _mm_srai_pi16(even_pi16, 1); // divide by 2
            evenA_pi32 = _mm_srai_pi32(evenA_pi32, 1);
            evenB_pi32 = _mm_srai_pi32(evenB_pi32, 1);

            //odd_pi16 = _mm_srai_pi16(odd_pi16, 1);  // divide by 2
            oddA_pi32 = _mm_srai_pi32(oddA_pi32, 1);
            oddB_pi32 = _mm_srai_pi32(oddB_pi32, 1);

            even_pi16 = _mm_packs_pi32 (evenB_pi32, evenA_pi32);
            odd_pi16 = _mm_packs_pi32 (oddB_pi32, oddA_pi32);




            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
        }


        // test this row.
        /*	for (column=0; column < width; column++)
        	{
        		int32_t even = 0;		// Result of convolution with even filter
        		int32_t odd = 0;		// Result of convolution with odd filter
        		int32_t addition, diff;


        		// Compute the vertical inverse for the left two bands

        		// Apply the even reconstruction filter to the lowpass band
        		even += lowlow[column + 0 * lowlow_pitch];
        		even -= lowlow[column + 2 * lowlow_pitch];
        		even += 4; //DAN20050921
        		even >>= 3;
        		addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
        		even += addition;

        		// Add the highpass correction
        		//even += highlow_line[column];
        		even = DivideByShift(even, 1);

        		// Place the even result in the even row
        		assert(even_lowpass[column] == SATURATE(even));

        		// Apply the odd reconstruction filter to the lowpass band
        		odd -= lowlow[column + 0 * lowlow_pitch];
        		odd += lowlow[column + 2 * lowlow_pitch];
        		odd += 4; //DAN20050921
        		odd >>= 3;
        		diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
        		odd += diff;

        		// Subtract the highpass correction
        		//odd -= highlow_line[column];
        		odd = DivideByShift(odd, 1);

        		// Place the odd result in the odd row
        		assert(odd_lowpass[column] == SATURATE(odd));


        		// Compute the vertical inverse for the right two bands

        		even = 0;
        		odd = 0;

        		// Apply the even reconstruction filter to the lowpass band
        		even += lowhigh_line[0][column];
        		even -= lowhigh_line[2][column];
        		even += 4; //DAN20050921
        		even >>= 3;
        		addition = (lowhigh_line[1][column]+highhigh_line[column]);
        		even += addition;

        		// Add the highpass correction
        		//even += highhigh_line[column];
        		even = DivideByShift(even, 1);

        		// Place the even result in the even row
        		assert(even_highpass[column] == SATURATE(even));


        		// Apply the odd reconstruction filter to the lowpass band
        		odd -= lowhigh_line[0][column];
        		odd += lowhigh_line[2][column];
        		odd += 4; //DAN20050921
        		odd >>= 3;
        		diff = (lowhigh_line[1][column] - highhigh_line[column]);
        		odd += diff;

        		// Subtract the highpass correction
        		//odd -= highhigh_line[column];
        		odd = DivideByShift(odd, 1);

        		// Place the odd result in the odd row
        		assert(odd_highpass[column] == SATURATE(odd));
        	}
        */
        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter
            int32_t addition, diff;


            /***** Compute the vertical inverse for the left two bands *****/

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += 4; //DAN20050921
            even >>= 3;
            addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
            even += addition;

            // Add the highpass correction
            //even += highlow_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += 4; //DAN20050921
            odd >>= 3;
            diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
            odd += diff;

            // Subtract the highpass correction
            //odd -= highlow_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            /***** Compute the vertical inverse for the right two bands *****/

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_line[0][column];
            even -= lowhigh_line[2][column];
            even += 4; //DAN20050921
            even >>= 3;
            addition = (lowhigh_line[1][column] + highhigh_line[column]);
            even += addition;

            // Add the highpass correction
            //even += highhigh_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_line[0][column];
            odd += lowhigh_line[2][column];
            odd += 4; //DAN20050921
            odd >>= 3;
            diff = (lowhigh_line[1][column] - highhigh_line[column]);
            odd += diff;

            // Subtract the highpass correction
            //odd -= highhigh_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, (int)output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            PIXEL *temp = lowhigh_line[0];
            lowhigh_line[0] = lowhigh_line[1];
            lowhigh_line[1] = lowhigh_line[2];
            lowhigh_line[2] = temp;

            // Undo quantization for the next row in the lowhigh band
#if _DEQUANTIZE_IN_FSM
            lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;
#else
            DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
#endif
        }
    }

#if (0 && XMMOPT) //DANREMOVED
    //_mm_empty();	// Clear the mmx register state

    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh_line[2][column];
        even += 4 * lowhigh_line[1][column];
        even -= 1 * lowhigh_line[0][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh_line[2][column];
        odd -=  4 * lowhigh_line[1][column];
        odd +=  1 * lowhigh_line[0][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);
}

// Adapted from the 8s version above
void InvertSpatialQuant16s(PIXEL *lowlow_band, int lowlow_pitch,
                           PIXEL *lowhigh_band, int lowhigh_pitch,
                           PIXEL *highlow_band, int highlow_pitch,
                           PIXEL *highhigh_band, int highhigh_pitch,
                           PIXEL *output_image, int output_pitch,
                           ROI roi, PIXEL *buffer, size_t buffer_size,
                           int quantization[])
{
    PIXEL *lowlow = (PIXEL *)lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;					// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int width = roi.width;
    int height = roi.height;
    int last_row = height - 1;
    int row, column;

    SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
    SCRATCH *scratch = &scratch_buffer;
    PIXEL *lowhigh_line[3];
    PIXEL *highlow_line;
    PIXEL *highhigh_line;

    //int lowlow_quantization = quantization[LL_BAND];
    //int highlow_quantization = quantization[HL_BAND];
    //int lowhigh_quantization = quantization[LH_BAND];
    //int highhigh_quantization = quantization[HH_BAND];

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of
    // vertical results and 5 rows of dequantized highpass coefficients
    assert(buffer_size >= (9 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Compute the positions of the dequantized highpass rows
    lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Apply the vertical border filter to the first row
    row = 0;

    // Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
    lowhigh_line[0] = lowhigh;
    lowhigh_line[1] = lowhigh + lowhigh_pitch;
    lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;

    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
    DequantizeBandRow16s(lowhigh + lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
    DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

    // Dequantize one row of coefficients each in the highlow and highhigh bands
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even >>= 1;//DAN20050913 - DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh_line[0][column];
        even -=  4 * lowhigh_line[1][column];
        even +=  1 * lowhigh_line[2][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even >>= 1;//DAN20050913 - DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh_line[0][column];
        odd += 4 * lowhigh_line[1][column];
        odd -= 1 * lowhigh_line[2][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
        DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
    }
#endif

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 8;
        int post_column = width - (width % column_step);
        __m128i *even_lowpass_ptr  = (__m128i *)even_lowpass;
        __m128i *even_highpass_ptr = (__m128i *)even_highpass;
        __m128i *odd_lowpass_ptr   = (__m128i *)odd_lowpass;
        __m128i *odd_highpass_ptr  = (__m128i *)odd_highpass;
        int oct_pitch;
#endif

        // Dequantize one row from each of the two highpass bands
#if _DEQUANTIZE_IN_FSM
        highlow_line = highlow;
        highhigh_line = highhigh;
#else
        DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
        DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m128i *lowlow_ptr = (__m128i *)(lowlow + column);
            __m128i *highlow_ptr = (__m128i *)(highlow_line + column);
            __m128i *lowhigh1_ptr = (__m128i *)(lowhigh_line[0] + column);
            __m128i *lowhigh2_ptr = (__m128i *)(lowhigh_line[1] + column);
            __m128i *lowhigh3_ptr = (__m128i *)(lowhigh_line[2] + column);
            __m128i *highhigh_ptr = (__m128i *)(highhigh_line + column);
            __m128i quad_epi16, quad8_epi16, even_epi16, odd_epi16;
            __m128i half_epi16 = _mm_set1_epi16(4); // used for rounding
            __m128i zero_epi16 = _mm_set1_epi16(0);

            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            oct_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters
            quad_epi16 = _mm_loadu_si128(lowlow_ptr);   // get 8 lowpass coefficients
            lowlow_ptr += oct_pitch;                    // advance to next row

            even_epi16 = quad_epi16;
            odd_epi16 = _mm_subs_epi16(zero_epi16, quad_epi16);

            quad8_epi16 = _mm_loadu_si128(lowlow_ptr);  // get 8 lowpass coefficients
            lowlow_ptr += oct_pitch;                    // advance to next row

            quad_epi16 = _mm_loadu_si128(lowlow_ptr);   // get 8 lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16); // rounding
            even_epi16 = _mm_srai_epi16(even_epi16, 3);          // divide by 8
            even_epi16 = _mm_adds_epi16(even_epi16, quad8_epi16);

            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);   // rounding
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);            // divide by 8
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad8_epi16);

            // Add the highpass correction to the even result and divide by 2
            quad_epi16 = _mm_loadu_si128(highlow_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by 2
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            _mm_storeu_si128(even_lowpass_ptr++, even_epi16);
            _mm_storeu_si128(odd_lowpass_ptr++, odd_epi16);


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            oct_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters
            quad_epi16 = _mm_loadu_si128(lowhigh1_ptr);     // get 8 lowpass coefficients
            even_epi16 = quad_epi16;
            odd_epi16 = _mm_subs_epi16(zero_epi16, quad_epi16);
            quad_epi16 = _mm_loadu_si128(lowhigh3_ptr);     // get 8 lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16); // rounding
            even_epi16 = _mm_srai_epi16(even_epi16, 3);          // divide by 8

            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);   // rounding
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);            // divide by 8

            quad_epi16 = _mm_loadu_si128(lowhigh2_ptr); // get 8 lowpass coefficients
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            // Add the highpass correction to the even result and divide by 2
            quad_epi16 = _mm_loadu_si128(highhigh_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by 2
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            _mm_storeu_si128(even_highpass_ptr++, even_epi16);
            _mm_storeu_si128(odd_highpass_ptr++, odd_epi16);
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowlow[column + 1 * lowlow_pitch];

            // Add the highpass correction
            even += highlow_line[column];
            even >>= 1;//DAN20050913 - DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowlow[column + 1 * lowlow_pitch];

            // Subtract the highpass correction
            odd -= highlow_line[column];
            odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_line[0][column];
            even -= lowhigh_line[2][column];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowhigh_line[1][column];

            // Add the highpass correction
            even += highhigh_line[column];
            even >>= 1;//DAN20050913 - DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_line[0][column];
            odd += lowhigh_line[2][column];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowhigh_line[1][column];

            // Subtract the highpass correction
            odd -= highhigh_line[column];
            odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Apply the inverse horizontal transform to the even and odd rows and descale the results
        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, (int)output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            PIXEL *temp = lowhigh_line[0];
            lowhigh_line[0] = lowhigh_line[1];
            lowhigh_line[1] = lowhigh_line[2];
            lowhigh_line[2] = temp;

            // Undo quantization for the next row in the lowhigh band
#if _DEQUANTIZE_IN_FSM
            lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;
#else
            DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
#endif
        }
    }

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += 4; //DAN20050921
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even >>= 1;//DAN20050913 - DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += 4; //DAN20050921
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh_line[2][column];
        even += 4 * lowhigh_line[1][column];
        even -= 1 * lowhigh_line[0][column];
        even += 4; //DAN20050921
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even >>= 1;//DAN20050913 - DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh_line[2][column];
        odd -=  4 * lowhigh_line[1][column];
        odd +=  1 * lowhigh_line[0][column];
        odd += 4; //DAN20050921
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd >>= 1;//DAN20050913 - DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);
}

///universal decoder
// Spatial transform inversion with descaling
void InvertSpatialQuantDescale16s(PIXEL *lowlow_band, int lowlow_pitch,
                                  PIXEL *lowhigh_band, int lowhigh_pitch,
                                  PIXEL *highlow_band, int highlow_pitch,
                                  PIXEL *highhigh_band, int highhigh_pitch,
                                  PIXEL *output_image, int output_pitch,
                                  ROI roi, PIXEL *buffer, size_t buffer_size,
                                  int descale, int quantization[])
{
    PIXEL *lowlow = (PIXEL *)lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;					// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int width = roi.width;
    int height = roi.height;
    int last_row = height - 1;
    int row, column;

    SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
    SCRATCH *scratch = &scratch_buffer;
    PIXEL *lowhigh_line[3];
    PIXEL *highlow_line;
    PIXEL *highhigh_line;

    //int lowlow_quantization = quantization[LL_BAND];
    //int highlow_quantization = quantization[HL_BAND];
    //int lowhigh_quantization = quantization[LH_BAND];
    //int highhigh_quantization = quantization[HH_BAND];

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of
    // vertical results and 5 rows of dequantized highpass coefficients
    assert(buffer_size >= (9 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Compute the positions of the dequantized highpass rows
    lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Apply the vertical border filter to the first row
    row = 0;

    // Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
    lowhigh_line[0] = lowhigh;
    lowhigh_line[1] = lowhigh + lowhigh_pitch;
    lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;

    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
    DequantizeBandRow16s(lowhigh + lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
    DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

    // Dequantize one row of coefficients each in the highlow and highhigh bands
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        /***** Compute the vertical inverse for the left two bands *****/

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        /***** Compute the vertical inverse for the right two bands *****/

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh_line[0][column];
        even -=  4 * lowhigh_line[1][column];
        even +=  1 * lowhigh_line[2][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh_line[0][column];
        odd += 4 * lowhigh_line[1][column];
        odd -= 1 * lowhigh_line[2][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
        DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
    }
#endif

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
                                    highpass, highpass_pitch,
                                    output, (int)output_row_size,
                                    strip, descale);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 8;
        int post_column = width - (width % column_step);
        __m128i *even_lowpass_ptr  = (__m128i *)even_lowpass;
        __m128i *even_highpass_ptr = (__m128i *)even_highpass;
        __m128i *odd_lowpass_ptr   = (__m128i *)odd_lowpass;
        __m128i *odd_highpass_ptr  = (__m128i *)odd_highpass;
        int oct_pitch;
#endif

        // Dequantize one row from each of the two highpass bands
#if _DEQUANTIZE_IN_FSM
        highlow_line = highlow;
        highhigh_line = highhigh;
#else
        DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
        DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
#if 1 //use 32-bit math
            __m128i *lowlow_ptr   = (__m128i *)(lowlow + column);
            __m128i *lowhigh1_ptr = (__m128i *)(lowhigh_line[0] + column);
            __m128i *lowhigh2_ptr = (__m128i *)(lowhigh_line[1] + column);
            __m128i *lowhigh3_ptr = (__m128i *)(lowhigh_line[2] + column);
            __m128i *highlow_ptr  = (__m128i *)(highlow_line + column);
            __m128i *highhigh_ptr = (__m128i *)(highhigh_line + column);
            __m128i low0_epi16, low1_epi16, low2_epi16, high_epi16;
            __m128i even_epi32, odd_epi32;
            __m128i additionA_epi32, additionB_epi32;
            __m128i diffA_epi32, diffB_epi32;
            __m128i evenA_epi32, evenB_epi32;
            __m128i oddA_epi32, oddB_epi32;
            __m128i lowA_epi32, lowB_epi32;
            __m128i low1A_epi32, low1B_epi32;
            __m128i highA_epi32, highB_epi32;
            __m128i half_epi32 = _mm_set1_epi32(4); // used for rounding
            __m128i zero_epi16 = _mm_set1_epi16(0);

            oct_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            /***** Compute the vertical inverse for the left two bands *****/

            // Accumulate parallel sums for the even and odd filters.
            // Put 16 bit values in 32 bit containers, preserving sign.

            // even += lowlow[column + 0 * lowlow_pitch];
            low0_epi16 = _mm_loadu_si128(lowlow_ptr); // get 8 lowpass coefficients
            evenA_epi32 = _mm_unpackhi_epi16(zero_epi16, low0_epi16);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 16);
            evenB_epi32 = _mm_unpacklo_epi16(zero_epi16, low0_epi16);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 16);

            lowlow_ptr += oct_pitch; // advance to the next row

            // odd -= lowlow[column + 0 * lowlow_pitch];
            oddA_epi32  = _mm_sub_epi32(zero_epi16, evenA_epi32);
            oddB_epi32  = _mm_sub_epi32(zero_epi16, evenB_epi32);

            low1_epi16 = _mm_loadu_si128(lowlow_ptr); // get 8 lowpass coefficients
            low1A_epi32 = _mm_unpackhi_epi16(zero_epi16, low1_epi16);
            low1A_epi32 = _mm_srai_epi32(low1A_epi32, 16);
            low1B_epi32 = _mm_unpacklo_epi16(zero_epi16, low1_epi16);
            low1B_epi32 = _mm_srai_epi32(low1B_epi32, 16);
            lowlow_ptr += oct_pitch; // advance to the next row

            low2_epi16 = _mm_loadu_si128(lowlow_ptr); // get 8 lowpass coefficients
            lowA_epi32 = _mm_unpackhi_epi16(zero_epi16, low2_epi16);
            lowA_epi32 = _mm_srai_epi32(lowA_epi32, 16);
            lowB_epi32 = _mm_unpacklo_epi16(zero_epi16, low2_epi16);
            lowB_epi32 = _mm_srai_epi32(lowB_epi32, 16);

            // even -= lowlow[column + 2 * lowlow_pitch];
            // even = (even + 4) / 8;
            evenA_epi32 = _mm_sub_epi32(evenA_epi32, lowA_epi32);
            evenA_epi32 = _mm_add_epi32(evenA_epi32, half_epi32); // rounding
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 3);         // divide by 8
            evenB_epi32 = _mm_sub_epi32(evenB_epi32, lowB_epi32);
            evenB_epi32 = _mm_add_epi32(evenB_epi32, half_epi32); // rounding
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 3);         // divide by 8

            // odd += lowlow[column + 2 * lowlow_pitch];
            // odd = (odd + 4) / 8;
            oddA_epi32 = _mm_add_epi32(oddA_epi32, lowA_epi32);
            oddA_epi32 = _mm_add_epi32(oddA_epi32, half_epi32); // rounding
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 3);         // divide by 8
            oddB_epi32 = _mm_add_epi32(oddB_epi32, lowB_epi32);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, half_epi32); // rounding
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 3);         // divide by 8

            // addition = (lowlow[column + 1 * lowlow_pitch] + highlow_line[column]);
            high_epi16 = _mm_loadu_si128(highlow_ptr);
            highA_epi32 = _mm_unpackhi_epi16(zero_epi16, high_epi16);
            highA_epi32 = _mm_srai_epi32(highA_epi32, 16);
            highB_epi32 = _mm_unpacklo_epi16(zero_epi16, high_epi16);
            highB_epi32 = _mm_srai_epi32(highB_epi32, 16);
            additionA_epi32 = _mm_add_epi32(low1A_epi32, highA_epi32);
            additionB_epi32 = _mm_add_epi32(low1B_epi32, highB_epi32);

            // diff = (lowlow[column + 1 * lowlow_pitch] - highlow_line[column]);
            diffA_epi32 = _mm_sub_epi32(low1A_epi32, highA_epi32);
            diffB_epi32 = _mm_sub_epi32(low1B_epi32, highB_epi32);

            // even = (even + addition) >> 1;
            evenA_epi32 = _mm_add_epi32(evenA_epi32, additionA_epi32);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 1);
            evenB_epi32 = _mm_add_epi32(evenB_epi32, additionB_epi32);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 1);

            // odd = (odd + diff) >> 1;
            oddA_epi32 = _mm_add_epi32(oddA_epi32, diffA_epi32);
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 1);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, diffB_epi32);
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 1);

            even_epi32 = _mm_packs_epi32(evenB_epi32, evenA_epi32);
            odd_epi32 = _mm_packs_epi32(oddB_epi32, oddA_epi32);

            // Store the even and odd groups of horizontal lowpass coefficients
            _mm_storeu_si128(even_lowpass_ptr++, even_epi32);
            _mm_storeu_si128(odd_lowpass_ptr++, odd_epi32);

            /**** Compute the vertical inverse for the right two bands *****/

            // Accumulate parallel sums for the even and odd filters.
            // Put 16 bit coefficients into 32 bit containers, preserving sign.

            low0_epi16 = _mm_loadu_si128(lowhigh1_ptr); // get 8 lowpass coefficients
            evenA_epi32 = _mm_unpackhi_epi16(zero_epi16, low0_epi16);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 16);
            evenB_epi32 = _mm_unpacklo_epi16(zero_epi16, low0_epi16);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 16);

            oddA_epi32 = _mm_sub_epi32(zero_epi16, evenA_epi32);
            oddB_epi32 = _mm_sub_epi32(zero_epi16, evenB_epi32);

            low2_epi16 = _mm_loadu_si128(lowhigh3_ptr); // get 8 lowpass coefficients
            lowA_epi32 = _mm_unpackhi_epi16(zero_epi16, low2_epi16);
            lowA_epi32 = _mm_srai_epi32(lowA_epi32, 16);
            lowB_epi32 = _mm_unpacklo_epi16(zero_epi16, low2_epi16);
            lowB_epi32 = _mm_srai_epi32(lowB_epi32, 16);

            evenA_epi32 = _mm_sub_epi32(evenA_epi32, lowA_epi32);
            evenB_epi32 = _mm_sub_epi32(evenB_epi32, lowB_epi32);
            oddA_epi32 = _mm_add_epi32(oddA_epi32, lowA_epi32);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, lowB_epi32);



            low1_epi16 = _mm_loadu_si128(lowhigh2_ptr); // get 8 coefficients
            low1A_epi32 = _mm_unpackhi_epi16(zero_epi16, low1_epi16);
            low1A_epi32 = _mm_srai_epi32(low1A_epi32, 16);
            low1B_epi32 = _mm_unpacklo_epi16(zero_epi16, low1_epi16);
            low1B_epi32 = _mm_srai_epi32(low1B_epi32, 16);

            evenA_epi32 = _mm_add_epi32(evenA_epi32, half_epi32); // rounding
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 3);         // divide by 8
            evenB_epi32 = _mm_add_epi32(evenB_epi32, half_epi32); // rounding
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 3);         // divide by 8

            oddA_epi32 = _mm_add_epi32(oddA_epi32, half_epi32);   // rounding
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 3);           // divide by 8
            oddB_epi32 = _mm_add_epi32(oddB_epi32, half_epi32);   // rounding
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 3);           // divide by 8



            high_epi16 = _mm_loadu_si128(highhigh_ptr);
            highA_epi32 = _mm_unpackhi_epi16(zero_epi16, high_epi16);
            highA_epi32 = _mm_srai_epi32(highA_epi32, 16);
            highB_epi32 = _mm_unpacklo_epi16(zero_epi16, high_epi16);
            highB_epi32 = _mm_srai_epi32(highB_epi32, 16);



            additionA_epi32 = _mm_add_epi32(low1A_epi32, highA_epi32);
            additionB_epi32 = _mm_add_epi32(low1B_epi32, highB_epi32);

            diffA_epi32 = _mm_sub_epi32(low1A_epi32, highA_epi32);
            diffB_epi32 = _mm_sub_epi32(low1B_epi32, highB_epi32);

            evenA_epi32 = _mm_add_epi32(evenA_epi32, additionA_epi32);
            evenA_epi32 = _mm_srai_epi32(evenA_epi32, 1);
            evenB_epi32 = _mm_add_epi32(evenB_epi32, additionB_epi32);
            evenB_epi32 = _mm_srai_epi32(evenB_epi32, 1);

            oddA_epi32 = _mm_add_epi32(oddA_epi32, diffA_epi32);
            oddA_epi32 = _mm_srai_epi32(oddA_epi32, 1);
            oddB_epi32 = _mm_add_epi32(oddB_epi32, diffB_epi32);
            oddB_epi32 = _mm_srai_epi32(oddB_epi32, 1);

            even_epi32 = _mm_packs_epi32(evenB_epi32, evenA_epi32);
            odd_epi32 = _mm_packs_epi32(oddB_epi32, oddA_epi32);

            // Store the even and odd groups of horizontal highpass coefficients
            _mm_storeu_si128(even_highpass_ptr++, even_epi32);
            _mm_storeu_si128(odd_highpass_ptr++, odd_epi32);

#else //use 16-bit math


            __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
            __m64 *highlow_ptr = (__m64 *)&highlow_line[column];
            __m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
            __m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
            __m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
            __m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
            __m64 quad_pi16;
            __m64 quad8_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;

            // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
            __m64 half_pi16 = _mm_set1_pi16(4);


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad8_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

            even_pi16 = _mm_adds_pi16(even_pi16, quad8_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad8_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highlow_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters

            quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

            quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highhigh_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
#endif
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            /***** Compute the vertical inverse for the left two bands *****/

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowlow[column + 1 * lowlow_pitch];

            // Add the highpass correction
            even += highlow_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowlow[column + 1 * lowlow_pitch];

            // Subtract the highpass correction
            odd -= highlow_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            /***** Compute the vertical inverse for the right two bands *****/

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_line[0][column];
            even -= lowhigh_line[2][column];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowhigh_line[1][column];

            // Add the highpass correction
            even += highhigh_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_line[0][column];
            odd += lowhigh_line[2][column];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowhigh_line[1][column];

            // Subtract the highpass correction
            odd -= highhigh_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Apply the inverse horizontal transform to the even and odd rows and descale the results
        InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
                                        highpass, highpass_pitch,
                                        output, (int)output_row_size,
                                        strip, descale);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            PIXEL *temp = lowhigh_line[0];
            lowhigh_line[0] = lowhigh_line[1];
            lowhigh_line[1] = lowhigh_line[2];
            lowhigh_line[2] = temp;

            // Undo quantization for the next row in the lowhigh band
#if _DEQUANTIZE_IN_FSM
            lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;
#else
            DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
#endif
        }
    }


#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh_line[2][column];
        even += 4 * lowhigh_line[1][column];
        even -= 1 * lowhigh_line[0][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh_line[2][column];
        odd -=  4 * lowhigh_line[1][column];
        odd +=  1 * lowhigh_line[0][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
                                    highpass, highpass_pitch,
                                    output, (int)output_row_size,
                                    strip, descale);
}

#endif


#if 0

// Adapted from the 8s version above
void InvertSpatialPrescaledQuant16s(PIXEL *lowlow_band, int lowlow_pitch,
                                    PIXEL *lowhigh_band, int lowhigh_pitch,
                                    PIXEL *highlow_band, int highlow_pitch,
                                    PIXEL *highhigh_band, int highhigh_pitch,
                                    PIXEL *output_image, int output_pitch,
                                    ROI roi, PIXEL *buffer, size_t buffer_size,
                                    int quantization[])
{
    PIXEL *lowlow = (PIXEL *)lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;					// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int width = roi.width;
    int height = roi.height;
    int last_row = height - 1;
    int row, column;

    SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
    SCRATCH *scratch = &scratch_buffer;
    PIXEL *lowhigh_line[3];
    PIXEL *highlow_line;
    PIXEL *highhigh_line;

    int lowlow_quantization = quantization[LL_BAND];
    int highlow_quantization = quantization[HL_BAND];
    int lowhigh_quantization = quantization[LH_BAND];
    int highhigh_quantization = quantization[HH_BAND];

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of
    // vertical results and 5 rows of dequantized highpass coefficients
    assert(buffer_size >= (9 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // Compute the positions of the dequantized highpass rows
    lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Apply the vertical border filter to the first row
    row = 0;

    // Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
    lowhigh_line[0] = lowhigh;
    lowhigh_line[1] = lowhigh + lowhigh_pitch;
    lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;

    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
    DequantizeBandRow16s(lowhigh + lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
    DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

    // Dequantize one row of coefficients each in the highlow and highhigh bands
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh_line[0][column];
        even -=  4 * lowhigh_line[1][column];
        even +=  1 * lowhigh_line[2][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh_line[0][column];
        odd += 4 * lowhigh_line[1][column];
        odd -= 1 * lowhigh_line[2][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
        DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
    }
#endif

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
                                    highpass, highpass_pitch,
                                    output, output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 4;
        int post_column = width - (width % column_step);
        __m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
        __m64 *even_highpass_ptr = (__m64 *)even_highpass;
        __m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
        __m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
        int quad_pitch;
#endif

        // Dequantize one row from each of the two highpass bands
#if _DEQUANTIZE_IN_FSM
        highlow_line = highlow;
        highhigh_line = highhigh;
#else
        DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
        DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
            __m64 *highlow_ptr = (__m64 *)&highlow_line[column];
            __m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
            __m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
            __m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
            __m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
            __m64 quad_pi16;
            __m64 quad8_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;

            // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
            __m64 half_pi16 = _mm_set1_pi16(4);


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad8_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

            even_pi16 = _mm_adds_pi16(even_pi16, quad8_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad8_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highlow_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters

            quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

            quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highhigh_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowlow[column + 1 * lowlow_pitch];

            // Add the highpass correction
            even += highlow_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowlow[column + 1 * lowlow_pitch];

            // Subtract the highpass correction
            odd -= highlow_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_line[0][column];
            even -= lowhigh_line[2][column];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowhigh_line[1][column];

            // Add the highpass correction
            even += highhigh_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_line[0][column];
            odd += lowhigh_line[2][column];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowhigh_line[1][column];

            // Subtract the highpass correction
            odd -= highhigh_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Apply the inverse horizontal transform to the even and odd rows and descale the results
        InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
                                        highpass, highpass_pitch,
                                        output, output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            PIXEL *temp = lowhigh_line[0];
            lowhigh_line[0] = lowhigh_line[1];
            lowhigh_line[1] = lowhigh_line[2];
            lowhigh_line[2] = temp;

            // Undo quantization for the next row in the lowhigh band
#if _DEQUANTIZE_IN_FSM
            lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;
#else
            DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
#endif
        }
    }

    //_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh_line[2][column];
        even += 4 * lowhigh_line[1][column];
        even -= 1 * lowhigh_line[0][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh_line[2][column];
        odd -=  4 * lowhigh_line[1][column];
        odd +=  1 * lowhigh_line[0][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStripDescale16s(lowpass, lowpass_pitch,
                                    highpass, highpass_pitch,
                                    output, output_row_size, strip);
}

#else

//universal decoder
// New version of InvertSpatialPrescaledQuant16s with better naming convention
void InvertSpatialQuant1x16s(PIXEL *lowlow_band, int lowlow_pitch,
                             PIXEL *lowhigh_band, int lowhigh_pitch,
                             PIXEL *highlow_band, int highlow_pitch,
                             PIXEL *highhigh_band, int highhigh_pitch,
                             PIXEL *output_image, int output_pitch,
                             ROI roi, PIXEL *buffer, size_t buffer_size,
                             int quantization[])
{
    PIXEL *lowlow = (PIXEL *)lowlow_band;
    PIXEL *lowhigh = lowhigh_band;
    PIXEL *highlow = highlow_band;
    PIXEL *highhigh = highhigh_band;
    PIXEL *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;					// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int width = roi.width;
    int height = roi.height;
    int last_row = height - 1;
    int row, column;

    SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
    SCRATCH *scratch = &scratch_buffer;
    PIXEL *lowhigh_line[3];
    PIXEL *highlow_line;
    PIXEL *highhigh_line;

    //int lowlow_quantization = quantization[LL_BAND];
    //int highlow_quantization = quantization[HL_BAND];
    //int lowhigh_quantization = quantization[LH_BAND];
    //int highhigh_quantization = quantization[HH_BAND];

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of
    // vertical results and 5 rows of dequantized highpass coefficients
    assert(buffer_size >= (9 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Compute the positions of the dequantized highpass rows
    lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL);
    highlow_pitch /= sizeof(PIXEL);
    highhigh_pitch /= sizeof(PIXEL);
    output_pitch /= sizeof(PIXEL);

    // Apply the vertical border filter to the first row
    row = 0;

    // Dequantize three rows of highpass coefficients in the lowhigh band
#if _DEQUANTIZE_IN_FSM
    lowhigh_line[0] = lowhigh;
    lowhigh_line[1] = lowhigh + lowhigh_pitch;
    lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;

    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
    DequantizeBandRow16s(lowhigh + lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
    DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

    // Dequantize one row of coefficients each in the highlow and highhigh bands
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh_line[0][column];
        even -=  4 * lowhigh_line[1][column];
        even +=  1 * lowhigh_line[2][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh_line[0][column];
        odd += 4 * lowhigh_line[1][column];
        odd -= 1 * lowhigh_line[2][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
        DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
    }
#endif

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip1x16s(lowpass, lowpass_pitch,
                               highpass, highpass_pitch,
                               output, (int)output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
        //assert(0);
#if (0 && XMMOPT) //DANREMOVED
        int column_step = 4;
        int post_column = width - (width % column_step);
        __m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
        __m64 *even_highpass_ptr = (__m64 *)even_highpass;
        __m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
        __m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
        int quad_pitch;
#endif

        // Dequantize one row from each of the two highpass bands
#if _DEQUANTIZE_IN_FSM
        highlow_line = highlow;
        highhigh_line = highhigh;
#else
        DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
        DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

        // Start at the first column
        column = 0;

#if (0 && XMMOPT) //DANREMOVED

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
            __m64 *highlow_ptr = (__m64 *)&highlow_line[column];
            __m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
            __m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
            __m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
            __m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
            __m64 quad_pi16;
            __m64 quad8_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;

            // Was 4 but 7 makes for more accurate rounding to prevent luma/chroma shifts -- DAN 6/2/03
            __m64 half_pi16 = _mm_set1_pi16(4);


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad8_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

            even_pi16 = _mm_adds_pi16(even_pi16, quad8_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad8_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highlow_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters

            quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


            even_pi16 = _mm_adds_pi16(even_pi16, half_pi16); // +4 rounding
            odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16); // +4 rounding
            even_pi16 = _mm_srai_pi16(even_pi16, 3); // divide by 8
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);  // divide by 8

            quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);


            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highhigh_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowlow[column + 1 * lowlow_pitch];

            // Add the highpass correction
            even += highlow_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowlow[column + 1 * lowlow_pitch];

            // Subtract the highpass correction
            odd -= highlow_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_line[0][column];
            even -= lowhigh_line[2][column];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowhigh_line[1][column];

            // Add the highpass correction
            even += highhigh_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_line[0][column];
            odd += lowhigh_line[2][column];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowhigh_line[1][column];

            // Subtract the highpass correction
            odd -= highhigh_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

        // Apply the inverse horizontal transform to the even and odd rows and descale the results
        InvertHorizontalStrip1x16s(lowpass, lowpass_pitch,
                                   highpass, highpass_pitch,
                                   output, (int)output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            PIXEL *temp = lowhigh_line[0];
            lowhigh_line[0] = lowhigh_line[1];
            lowhigh_line[1] = lowhigh_line[2];
            lowhigh_line[2] = temp;

            // Undo quantization for the next row in the lowhigh band
#if _DEQUANTIZE_IN_FSM
            lowhigh_line[2] = lowhigh + 2 * lowhigh_pitch;
#else
            DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
#endif
        }
    }

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
    highlow_line = highlow;
    highhigh_line = highhigh;
#else
    DequantizeBandRow16s(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow16s(highhigh, width, highhigh_quantization, highhigh_line);
#endif

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh_line[2][column];
        even += 4 * lowhigh_line[1][column];
        even -= 1 * lowhigh_line[0][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh_line[2][column];
        odd -=  4 * lowhigh_line[1][column];
        odd +=  1 * lowhigh_line[0][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip1x16s(lowpass, lowpass_pitch,
                               highpass, highpass_pitch,
                               output, (int)output_row_size, strip);
}

#endif



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void InvertSpatialPrescaledQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
                                   PIXEL8S *lowhigh_band, int lowhigh_pitch,
                                   PIXEL8S *highlow_band, int highlow_pitch,
                                   PIXEL8S *highhigh_band, int highhigh_pitch,
                                   PIXEL *output_image, int output_pitch,
                                   ROI roi, PIXEL *buffer, size_t buffer_size,
                                   int quantization[])
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse transform on coefficients that were prescaled
void InvertSpatialPrescaledQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
                                   PIXEL8S *lowhigh_band, int lowhigh_pitch,
                                   PIXEL8S *highlow_band, int highlow_pitch,
                                   PIXEL8S *highhigh_band, int highhigh_pitch,
                                   PIXEL *output_image, int output_pitch,
                                   ROI roi, PIXEL *buffer, size_t buffer_size,
                                   int quantization[])
{
    PIXEL *lowlow = (PIXEL *)lowlow_band;
    PIXEL8S *lowhigh = lowhigh_band;
    PIXEL8S *highlow = highlow_band;
    PIXEL8S *highhigh = highhigh_band;
    PIXEL *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int width = roi.width;
    int height = roi.height;
    int last_row = height - 1;
    int row, column;

    SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
    SCRATCH *scratch = &scratch_buffer;
    PIXEL *lowhigh_line[3];
    PIXEL *highlow_line;
    PIXEL *highhigh_line;

    int lowlow_quantization = quantization[LL_BAND];
    int highlow_quantization = quantization[HL_BAND];
    int lowhigh_quantization = quantization[LH_BAND];
    int highhigh_quantization = quantization[HH_BAND];

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of vertical
    // intermediate results and five rows of dequantized highpass coefficients
    assert(buffer_size >= (9 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // Compute the positions of the dequantized highpass rows
    lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL);

    // Apply the vertical border filter to the first row
    row = 0;

    // Undo quantization to highpass bands
    DequantizeBandRow(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
    DequantizeBandRow(lowhigh + lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
    DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

    DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh_line[0][column];
        even -=  4 * lowhigh_line[1][column];
        even +=  1 * lowhigh_line[2][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh_line[0][column];
        odd += 4 * lowhigh_line[1][column];
        odd -= 1 * lowhigh_line[2][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
        DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
    }
#endif

#if (_LOWPASS_PRESCALE > 0)
    // Apply the inverse horizontal transform to the prescaled even and odd rows
    InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
                                      highpass, highpass_pitch,
                                      output, output_row_size, strip);
#else
    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);
#endif

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 4;
        int post_column = width - (width % column_step);
        __m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
        __m64 *even_highpass_ptr = (__m64 *)even_highpass;
        __m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
        __m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
        int quad_pitch;
#endif

        // Undo quantization to highpass bands
        DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
        DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *lowlow_ptr = (__m64 *)&lowlow[column];
            __m64 *highlow_ptr = (__m64 *)&highlow_line[column];
            __m64 *lowhigh_ptr1 = (__m64 *)&lowhigh_line[0][column];
            __m64 *lowhigh_ptr2 = (__m64 *)&lowhigh_line[1][column];
            __m64 *lowhigh_ptr3 = (__m64 *)&lowhigh_line[2][column];
            __m64 *highhigh_ptr = (__m64 *)&highhigh_line[column];
            __m64 quad_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;	// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highlow_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters

            quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);
#if 1
            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);
#endif
            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highhigh_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowlow[column + 1 * lowlow_pitch];

            // Add the highpass correction
            even += highlow_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowlow[column + 1 * lowlow_pitch];

            // Subtract the highpass correction
            odd -= highlow_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_line[0][column];
            even -= lowhigh_line[2][column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowhigh_line[1][column];

            // Add the highpass correction
            even += highhigh_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_line[0][column];
            odd += lowhigh_line[2][column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowhigh_line[1][column];

            // Subtract the highpass correction
            odd -= highhigh_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

#if (_LOWPASS_PRESCALE > 0)
        // Apply the inverse horizontal transform to the prescaled even and odd rows
        InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
                                          highpass, highpass_pitch,
                                          output, output_row_size, strip);
#else
        // Apply the inverse horizontal transform to the even and odd rows and descale the results
        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, output_row_size, strip);
#endif

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            PIXEL *temp = lowhigh_line[0];
            lowhigh_line[0] = lowhigh_line[1];
            lowhigh_line[1] = lowhigh_line[2];
            lowhigh_line[2] = temp;

            // Undo quantization for the new row in the lowhigh band
            DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
        }
    }

    //_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
    DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh_line[2][column];
        even += 4 * lowhigh_line[1][column];
        even -= 1 * lowhigh_line[0][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh_line[2][column];
        odd -=  4 * lowhigh_line[1][column];
        odd +=  1 * lowhigh_line[0][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (_LOWPASS_PRESCALE > 0)
    // Apply the inverse horizontal transform to the prescaled even and odd rows
    InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
                                      highpass, highpass_pitch,
                                      output, output_row_size, strip);
#else
    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);
#endif
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse transform on coefficients that were prescaled
void InvertSpatialPrescaledQuant8s(PIXEL8S *lowlow_band, int lowlow_pitch,
                                   PIXEL8S *lowhigh_band, int lowhigh_pitch,
                                   PIXEL8S *highlow_band, int highlow_pitch,
                                   PIXEL8S *highhigh_band, int highhigh_pitch,
                                   PIXEL *output_image, int output_pitch,
                                   ROI roi, PIXEL *buffer, size_t buffer_size,
                                   int quantization[])
{
    PIXEL *lowlow = (PIXEL *)lowlow_band;
    PIXEL8S *lowhigh = lowhigh_band;
    PIXEL8S *highlow = highlow_band;
    PIXEL8S *highhigh = highhigh_band;
    PIXEL *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int width = roi.width;
    int height = roi.height;
    int last_row = height - 1;
    int row, column;

    SCRATCH scratch_buffer = SCRATCH_INITIALIZER(buffer, buffer_size);
    SCRATCH *scratch = &scratch_buffer;
    PIXEL *lowhigh_line[3];
    PIXEL *highlow_line;
    PIXEL *highhigh_line;

    //int lowlow_quantization = quantization[LL_BAND];
    int highlow_quantization = quantization[HL_BAND];
    int lowhigh_quantization = quantization[LH_BAND];
    int highhigh_quantization = quantization[HH_BAND];

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = width;

    // Check that the buffer is large enough to hold four rows of vertical
    // intermediate results and five rows of dequantized highpass coefficients
    assert(buffer_size >= (9 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    even_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_lowpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    odd_highpass = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Compute the positions of the dequantized highpass rows
    lowhigh_line[0] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[1] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    lowhigh_line[2] = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highlow_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);
    highhigh_line = (PIXEL *)AllocScratchBuffer(scratch, buffer_row_size);

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL);
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL);

    // Apply the vertical border filter to the first row
    row = 0;

    // Undo quantization to highpass bands
    DequantizeBandRow(lowhigh, width, lowhigh_quantization, lowhigh_line[0]);
    DequantizeBandRow(lowhigh + lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[1]);
    DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);

    DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowlow[column + 0 * lowlow_pitch];
        even -=  4 * lowlow[column + 1 * lowlow_pitch];
        even +=  1 * lowlow[column + 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowlow[column + 0 * lowlow_pitch];
        odd += 4 * lowlow[column + 1 * lowlow_pitch];
        odd -= 1 * lowlow[column + 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowhigh_line[0][column];
        even -=  4 * lowhigh_line[1][column];
        even +=  1 * lowhigh_line[2][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowhigh_line[0][column];
        odd += 4 * lowhigh_line[1][column];
        odd -= 1 * lowhigh_line[2][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (0 && DEBUG)
    if (logfile)
    {
        DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
        DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
    }
#endif

#if (_LOWPASS_PRESCALE > 0)
    // Apply the inverse horizontal transform to the prescaled even and odd rows
    InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
                                      highpass, highpass_pitch,
                                      output, (int)output_row_size, strip);
#else
    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);
#endif

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 8;
        int post_column = width - (width % column_step);
        __m128i *even_lowpass_ptr = (__m128i *)even_lowpass;
        __m128i *even_highpass_ptr = (__m128i *)even_highpass;
        __m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass;
        __m128i *odd_highpass_ptr = (__m128i *)odd_highpass;
        int quad_pitch;
#endif

        // Undo quantization to the highpass bands
        DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
        DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m128i *lowlow_ptr = (__m128i *)&lowlow[column];
            __m128i *highlow_ptr = (__m128i *)&highlow_line[column];
            __m128i *lowhigh_ptr1 = (__m128i *)&lowhigh_line[0][column];
            __m128i *lowhigh_ptr2 = (__m128i *)&lowhigh_line[1][column];
            __m128i *lowhigh_ptr3 = (__m128i *)&lowhigh_line[2][column];
            __m128i *highhigh_ptr = (__m128i *)&highhigh_line[column];
            __m128i quad_epi16;
            __m128i even_epi16;
            __m128i odd_epi16;


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters
            quad_epi16 = _mm_load_si128(lowlow_ptr);	// Get eight lowpass coefficients
            lowlow_ptr += quad_pitch;					// Advance to the next row

            even_epi16 = quad_epi16;
            odd_epi16 = _mm_setzero_si128();
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowlow_ptr);	// Get four lowpass coefficients
            lowlow_ptr += quad_pitch;					// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowlow_ptr);	// Get four lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            // Apply the rounding adjustment
            even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
            // Divide by eight
            even_epi16 = _mm_srai_epi16(even_epi16, 3);

            // Apply the rounding adjustment
            odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
            // Divide by eight
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_epi16 = _mm_load_si128(highlow_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            _mm_store_si128(even_lowpass_ptr++, even_epi16);
            _mm_store_si128(odd_lowpass_ptr++, odd_epi16);


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters

            quad_epi16 = _mm_load_si128(lowhigh_ptr1);	// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;				// Advance to the next row

            even_epi16 = quad_epi16;
            odd_epi16 = _mm_setzero_si128();
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowhigh_ptr2);	// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;				// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowhigh_ptr3);		// Get four lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);
#if 1
            // Apply the rounding adjustment
            even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
            // Divide by eight
            even_epi16 = _mm_srai_epi16(even_epi16, 3);

            // Apply the rounding adjustment
            odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
            // Divide by eight
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
#endif
            // Add the highpass correction to the even result and divide by two
            quad_epi16 = _mm_load_si128(highhigh_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            _mm_store_si128(even_highpass_ptr++, even_epi16);
            _mm_store_si128(odd_highpass_ptr++, odd_epi16);
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow[column + 0 * lowlow_pitch];
            even -= lowlow[column + 2 * lowlow_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowlow[column + 1 * lowlow_pitch];

            // Add the highpass correction
            even += highlow_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow[column + 0 * lowlow_pitch];
            odd += lowlow[column + 2 * lowlow_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowlow[column + 1 * lowlow_pitch];

            // Subtract the highpass correction
            odd -= highlow_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_line[0][column];
            even -= lowhigh_line[2][column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowhigh_line[1][column];

            // Add the highpass correction
            even += highhigh_line[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_line[0][column];
            odd += lowhigh_line[2][column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowhigh_line[1][column];

            // Subtract the highpass correction
            odd -= highhigh_line[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

#if (0 && DEBUG)
        if (logfile)
        {
            DumpArray16s("Lowpass Strip", lowpass, strip.width, strip.height, lowpass_pitch, logfile);
            DumpArray16s("Highpass Strip", highpass, strip.width, strip.height, highpass_pitch, logfile);
        }
#endif

#if (_LOWPASS_PRESCALE > 0)
        // Apply the inverse horizontal transform to the prescaled even and odd rows
        InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
                                          highpass, highpass_pitch,
                                          output, (int)output_row_size, strip);
#else
        // Apply the inverse horizontal transform to the even and odd rows and descale the results
        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, output_row_size, strip);
#endif

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            PIXEL *temp = lowhigh_line[0];
            lowhigh_line[0] = lowhigh_line[1];
            lowhigh_line[1] = lowhigh_line[2];
            lowhigh_line[2] = temp;

            // Undo quantization for the new row in the lowhigh band
            DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, width, lowhigh_quantization, lowhigh_line[2]);
        }
    }

    //_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
    DequantizeBandRow(highlow, width, highlow_quantization, highlow_line);
    DequantizeBandRow(highhigh, width, highhigh_quantization, highhigh_line);

    // Apply the vertical border filter to the last row
    for (column = 0; column < width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowlow[column + 0 * lowlow_pitch];
        even += 4 * lowlow[column - 1 * lowlow_pitch];
        even -= 1 * lowlow[column - 2 * lowlow_pitch];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highlow_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowlow[column + 0 * lowlow_pitch];
        odd -=  4 * lowlow[column - 1 * lowlow_pitch];
        odd +=  1 * lowlow[column - 2 * lowlow_pitch];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highlow_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowhigh_line[2][column];
        even += 4 * lowhigh_line[1][column];
        even -= 1 * lowhigh_line[0][column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highhigh_line[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowhigh_line[2][column];
        odd -=  4 * lowhigh_line[1][column];
        odd +=  1 * lowhigh_line[0][column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highhigh_line[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

#if (_LOWPASS_PRESCALE > 0)
    // Apply the inverse horizontal transform to the prescaled even and odd rows
    InvertHorizontalStripPrescaled16s(lowpass, lowpass_pitch,
                                      highpass, highpass_pitch,
                                      output, (int)output_row_size, strip);
#else
    // Apply the inverse horizontal transform to the even and odd rows and descale the results
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);
#endif
}

#endif



#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void InvertSpatial8sTo16s(PIXEL8S *lowlow_band, int lowlow_pitch,
                          PIXEL8S *lowhigh_band, int lowhigh_pitch,
                          PIXEL8S *highlow_band, int highlow_pitch,
                          PIXEL8S *highhigh_band, int highhigh_pitch,
                          PIXEL16S *output_image, int output_pitch,
                          ROI roi, PIXEL *buffer, int quantization[],
                          PIXEL *line_buffer)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse spatial (horizontal and vertical) transform by
// performing the inverse horizontal transform as each row is output
// by the inverse vertical transform and produce a 16-but result.
void InvertSpatial8sTo16s(PIXEL8S *lowlow_band, int lowlow_pitch,
                          PIXEL8S *lowhigh_band, int lowhigh_pitch,
                          PIXEL8S *highlow_band, int highlow_pitch,
                          PIXEL8S *highhigh_band, int highhigh_pitch,
                          PIXEL16S *output_image, int output_pitch,
                          ROI roi, PIXEL *buffer, int quantization[],
                          PIXEL *line_buffer)
{
    PIXEL8S *lowlow = lowlow_band;
    PIXEL8S *lowhigh = lowhigh_band;
    PIXEL8S *highlow = highlow_band;
    PIXEL8S *highhigh = highhigh_band;
    PIXEL16S *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int last_row = roi.height - 1;
    int row, column;

    PIXEL *llline1;		// Dequantized lowlow band row 1
    PIXEL *llline2;		// Dequantized lowlow band row 2
    PIXEL *llline3;		// Dequantized lowlow band row 3
    PIXEL *lhline1;		// Dequantized lowhigh band row 1
    PIXEL *lhline2;		// Dequantized lowhigh band row 2
    PIXEL *lhline3;		// Dequantized lowhigh band row 3
    PIXEL *hlline;		// Dequantized highlow band row
    PIXEL *hhline;		// Dequantized highhigh band row
    PIXEL *temp;

    int lowlow_quantization = quantization[LL_BAND];
    int highlow_quantization = quantization[HL_BAND];
    int lowhigh_quantization = quantization[LH_BAND];
    int highhigh_quantization = quantization[HH_BAND];

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL8S);
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL16S);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = roi.width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = roi.width;

    // Check that the buffer is large enough to hold four rows of highpass coefficients
    //assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Compute the positions of the dequantized highpass rows
    llline1 = line_buffer;
    llline2 = llline1 + lowlow_pitch;
    llline3 = llline2 + lowlow_pitch;
    lhline1 = llline3 + lowlow_pitch;
    lhline2 = lhline1 + lowhigh_pitch;
    lhline3 = lhline2 + lowhigh_pitch;
    hlline = lhline3 + lowhigh_pitch;
    hhline = hlline + highlow_pitch;

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // Apply the vertical border filter to the first row
    row = 0;

    // Undo quantization
    DequantizeBandRow(lowlow, roi.width, lowlow_quantization, llline1);
    DequantizeBandRow(lowlow + lowlow_pitch, roi.width, lowlow_quantization, llline2);
    DequantizeBandRow(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);

    DequantizeBandRow(lowhigh, roi.width, lowhigh_quantization, lhline1);
    DequantizeBandRow(lowhigh + lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
    DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

    DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);

    DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * llline1[column];
        even -=  4 * llline2[column];
        even +=  1 * llline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * llline1[column];
        odd += 4 * llline2[column];
        odd -= 1 * llline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lhline1[column];
        even -=  4 * lhline2[column];
        even +=  1 * lhline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lhline1[column];
        odd += 4 * lhline2[column];
        odd -= 1 * lhline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 4;
        int post_column = roi.width - (roi.width % column_step);
        __m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
        __m64 *even_highpass_ptr = (__m64 *)even_highpass;
        __m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
        __m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
        int quad_pitch;
#endif

        // Undo quantization to highpass bands
        DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
        DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *lowlow_ptr1 = (__m64 *)&llline1[column];
            __m64 *lowlow_ptr2 = (__m64 *)&llline2[column];
            __m64 *lowlow_ptr3 = (__m64 *)&llline3[column];
            __m64 *highlow_ptr = (__m64 *)&hlline[column];
            __m64 *lowhigh_ptr1 = (__m64 *)&lhline1[column];
            __m64 *lowhigh_ptr2 = (__m64 *)&lhline2[column];
            __m64 *lowhigh_ptr3 = (__m64 *)&lhline3[column];
            __m64 *highhigh_ptr = (__m64 *)&hhline[column];
            __m64 quad_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowlow_ptr1;	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowlow_ptr2;	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;	// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            quad_pi16 = *lowlow_ptr3;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highlow_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters

            quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highhigh_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < roi.width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += llline1[column];
            even -= llline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += llline2[column];

            // Add the highpass correction
            even += hlline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= llline1[column];
            odd += llline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += llline2[column];

            // Subtract the highpass correction
            odd -= hlline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lhline1[column];
            even -= lhline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lhline2[column];

            // Add the highpass correction
            even += hhline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lhline1[column];
            odd += lhline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lhline2[column];

            // Subtract the highpass correction
            odd -= hhline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

        // Apply the inverse horizontal transform to the even and odd rows
        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            temp = llline1;
            llline1 = llline2;
            llline2 = llline3;
            llline3 = temp;

            // Undo quantization for the new row in lowlow band
            DequantizeBandRow(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);

            temp = lhline1;
            lhline1 = lhline2;
            lhline2 = lhline3;
            lhline3 = temp;

            // Undo quantization for the new row in lowhigh band
            DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
        }
    }

    //_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
    DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
    DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

    // Apply the vertical border filter to the last row
    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * llline3[column];
        even += 4 * llline2[column];
        even -= 1 * llline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * llline3[column];
        odd -=  4 * llline2[column];
        odd +=  1 * llline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lhline3[column];
        even += 4 * lhline2[column];
        even -= 1 * lhline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lhline3[column];
        odd -=  4 * lhline2[column];
        odd +=  1 * lhline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);
}

#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

// Apply the inverse spatial (horizontal and vertical) transform by
// performing the inverse horizontal transform as each row is output
// by the inverse vertical transform and produce a 16-but result.
void InvertSpatial8sTo16s(PIXEL8S *lowlow_band, int lowlow_pitch,
                          PIXEL8S *lowhigh_band, int lowhigh_pitch,
                          PIXEL8S *highlow_band, int highlow_pitch,
                          PIXEL8S *highhigh_band, int highhigh_pitch,
                          PIXEL16S *output_image, int output_pitch,
                          ROI roi, PIXEL *buffer, int quantization[],
                          PIXEL *line_buffer)
{
    PIXEL8S *lowlow = lowlow_band;
    PIXEL8S *lowhigh = lowhigh_band;
    PIXEL8S *highlow = highlow_band;
    PIXEL8S *highhigh = highhigh_band;
    PIXEL16S *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int last_row = roi.height - 1;
    int row, column;

    PIXEL *llline1;		// Dequantized lowlow band row 1
    PIXEL *llline2;		// Dequantized lowlow band row 2
    PIXEL *llline3;		// Dequantized lowlow band row 3
    PIXEL *lhline1;		// Dequantized lowhigh band row 1
    PIXEL *lhline2;		// Dequantized lowhigh band row 2
    PIXEL *lhline3;		// Dequantized lowhigh band row 3
    PIXEL *hlline;		// Dequantized highlow band row
    PIXEL *hhline;		// Dequantized highhigh band row
    PIXEL *temp;

    int lowlow_quantization = quantization[LL_BAND];
    int highlow_quantization = quantization[HL_BAND];
    int lowhigh_quantization = quantization[LH_BAND];
    int highhigh_quantization = quantization[HH_BAND];

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL8S);
    lowhigh_pitch /= sizeof(PIXEL8S);
    highlow_pitch /= sizeof(PIXEL8S);
    highhigh_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL16S);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = roi.width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = roi.width;

    // Check that the buffer is large enough to hold four rows of highpass coefficients
    //assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Compute the positions of the dequantized highpass rows
    llline1 = line_buffer;
    llline2 = llline1 + lowlow_pitch;
    llline3 = llline2 + lowlow_pitch;
    lhline1 = llline3 + lowlow_pitch;
    lhline2 = lhline1 + lowhigh_pitch;
    lhline3 = lhline2 + lowhigh_pitch;
    hlline = lhline3 + lowhigh_pitch;
    hhline = hlline + highlow_pitch;

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Apply the vertical border filter to the first row
    row = 0;

    // Undo quantization
    DequantizeBandRow(lowlow, roi.width, lowlow_quantization, llline1);
    DequantizeBandRow(lowlow + lowlow_pitch, roi.width, lowlow_quantization, llline2);
    DequantizeBandRow(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);

    DequantizeBandRow(lowhigh, roi.width, lowhigh_quantization, lhline1);
    DequantizeBandRow(lowhigh + lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
    DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

    DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);

    DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * llline1[column];
        even -=  4 * llline2[column];
        even +=  1 * llline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * llline1[column];
        odd += 4 * llline2[column];
        odd -= 1 * llline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lhline1[column];
        even -=  4 * lhline2[column];
        even +=  1 * lhline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lhline1[column];
        odd += 4 * lhline2[column];
        odd -= 1 * lhline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 8;
        int post_column = roi.width - (roi.width % column_step);
        __m128i *even_lowpass_ptr = (__m128i *)even_lowpass;
        __m128i *even_highpass_ptr = (__m128i *)even_highpass;
        __m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass;
        __m128i *odd_highpass_ptr = (__m128i *)odd_highpass;
        int quad_pitch;
#endif

        // Undo quantization to highpass bands
        DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
        DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m128i *lowlow_ptr1 = (__m128i *)&llline1[column];
            __m128i *lowlow_ptr2 = (__m128i *)&llline2[column];
            __m128i *lowlow_ptr3 = (__m128i *)&llline3[column];
            __m128i *highlow_ptr = (__m128i *)&hlline[column];
            __m128i *lowhigh_ptr1 = (__m128i *)&lhline1[column];
            __m128i *lowhigh_ptr2 = (__m128i *)&lhline2[column];
            __m128i *lowhigh_ptr3 = (__m128i *)&lhline3[column];
            __m128i *highhigh_ptr = (__m128i *)&hhline[column];
            __m128i quad_epi16;
            __m128i even_epi16;
            __m128i odd_epi16;


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters
            quad_epi16 = _mm_load_si128(lowlow_ptr1);	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;					// Advance to the next row

            even_epi16 = quad_epi16;
            odd_epi16 = _mm_setzero_si128();
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowlow_ptr2);	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;					// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowlow_ptr3);	// Get four lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            // Apply the rounding adjustment
            even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
            // Divide by eight
            even_epi16 = _mm_srai_epi16(even_epi16, 3);

            // Apply the rounding adjustment
            odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
            // Divide by eight
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_epi16 = _mm_load_si128(highlow_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            _mm_store_si128(even_lowpass_ptr++, even_epi16);
            _mm_store_si128(odd_lowpass_ptr++, odd_epi16);


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters

            quad_epi16 = _mm_load_si128(lowhigh_ptr1);	// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;				// Advance to the next row

            even_epi16 = quad_epi16;
            odd_epi16 = _mm_setzero_si128();
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowhigh_ptr2);	// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;				// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowhigh_ptr3);	// Get four lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            // Apply the rounding adjustment
            even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
            // Divide by eight
            even_epi16 = _mm_srai_epi16(even_epi16, 3);

            // Apply the rounding adjustment
            odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
            // Divide by eight
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_epi16 = _mm_load_si128(highhigh_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            _mm_store_si128(even_highpass_ptr++, even_epi16);
            _mm_store_si128(odd_highpass_ptr++, odd_epi16);
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < roi.width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += llline1[column];
            even -= llline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += llline2[column];

            // Add the highpass correction
            even += hlline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= llline1[column];
            odd += llline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += llline2[column];

            // Subtract the highpass correction
            odd -= hlline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lhline1[column];
            even -= lhline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lhline2[column];

            // Add the highpass correction
            even += hhline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lhline1[column];
            odd += lhline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lhline2[column];

            // Subtract the highpass correction
            odd -= hhline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

        // Apply the inverse horizontal transform to the even and odd rows
        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, (int)output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            temp = llline1;
            llline1 = llline2;
            llline2 = llline3;
            llline3 = temp;

            // Undo quantization for the new row in lowlow band
            DequantizeBandRow(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);

            temp = lhline1;
            lhline1 = lhline2;
            lhline2 = lhline3;
            lhline3 = temp;

            // Undo quantization for the new row in lowhigh band
            DequantizeBandRow(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
        }
    }

    //_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
    DequantizeBandRow(highlow, roi.width, highlow_quantization, hlline);
    DequantizeBandRow(highhigh, roi.width, highhigh_quantization, hhline);

    // Apply the vertical border filter to the last row
    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * llline3[column];
        even += 4 * llline2[column];
        even -= 1 * llline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * llline3[column];
        odd -=  4 * llline2[column];
        odd +=  1 * llline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lhline3[column];
        even += 4 * lhline2[column];
        even -= 1 * lhline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lhline3[column];
        odd -=  4 * lhline2[column];
        odd +=  1 * lhline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);
}

#endif


#if _PROCESSOR_DISPATCH

__declspec(cpu_dispatch(Pentium_4, Generic))

void InvertSpatial16sTo16s(PIXEL16S *lowlow_band, int lowlow_pitch,
                           PIXEL16S *lowhigh_band, int lowhigh_pitch,
                           PIXEL16S *highlow_band, int highlow_pitch,
                           PIXEL16S *highhigh_band, int highhigh_pitch,
                           PIXEL16S *output_image, int output_pitch,
                           ROI roi, PIXEL *buffer, int quantization[],
                           PIXEL *line_buffer)
{
    // Stub routine for processor specific dispatch
}
#endif


#if _PROCESSOR_GENERIC

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Generic))
#endif

// Apply the inverse spatial (horizontal and vertical) transform by
// performing the inverse horizontal transform as each row is output
// by the inverse vertical transform and produce a 16-but result.
void InvertSpatial16sTo16s(PIXEL16S *lowlow_band, int lowlow_pitch,
                           PIXEL16S *lowhigh_band, int lowhigh_pitch,
                           PIXEL16S *highlow_band, int highlow_pitch,
                           PIXEL16S *highhigh_band, int highhigh_pitch,
                           PIXEL16S *output_image, int output_pitch,
                           ROI roi, PIXEL *buffer, int quantization[],
                           PIXEL *line_buffer)
{
    PIXEL16S *lowlow = lowlow_band;
    PIXEL16S *lowhigh = lowhigh_band;
    PIXEL16S *highlow = highlow_band;
    PIXEL16S *highhigh = highhigh_band;
    PIXEL16S *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *even_output;
    PIXEL *odd_output;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int last_row = roi.height - 1;
    int row, column;

    PIXEL *llline1;		// Dequantized lowlow band row 1
    PIXEL *llline2;		// Dequantized lowlow band row 2
    PIXEL *llline3;		// Dequantized lowlow band row 3
    PIXEL *lhline1;		// Dequantized lowhigh band row 1
    PIXEL *lhline2;		// Dequantized lowhigh band row 2
    PIXEL *lhline3;		// Dequantized lowhigh band row 3
    PIXEL *hlline;		// Dequantized highlow band row
    PIXEL *hhline;		// Dequantized highhigh band row
    PIXEL *temp;

    int lowlow_quantization = quantization[LL_BAND];
    int highlow_quantization = quantization[HL_BAND];
    int lowhigh_quantization = quantization[LH_BAND];
    int highhigh_quantization = quantization[HH_BAND];

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL16S);
    lowhigh_pitch /= sizeof(PIXEL16S);
    highlow_pitch /= sizeof(PIXEL16S);
    highhigh_pitch /= sizeof(PIXEL16S);
    output_pitch /= sizeof(PIXEL16S);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = roi.width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = roi.width;

    // Check that the buffer is large enough to hold four rows of highpass coefficients
    //assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Compute the positions of the dequantized highpass rows
    llline1 = line_buffer;
    llline2 = llline1 + lowlow_pitch;
    llline3 = llline2 + lowlow_pitch;
    lhline1 = llline3 + lowlow_pitch;
    lhline2 = lhline1 + lowhigh_pitch;
    lhline3 = lhline2 + lowhigh_pitch;
    hlline = lhline3 + lowhigh_pitch;
    hhline = hlline + highlow_pitch;

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = 2 * buffer_row_size;
    highpass_pitch = 2 * buffer_row_size;

    // Apply the vertical border filter to the first row
    row = 0;

    // Undo quantization
#if _DEQUANTIZE_IN_FSM
    llline1 = lowlow;
    llline2 = lowlow + lowlow_pitch;
    llline3 = lowlow + 2 * lowlow_pitch;

    lhline1 = lowhigh;
    lhline2 = lowhigh + lowhigh_pitch;
    lhline3 = lowhigh + 2 * lowhigh_pitch;

    hlline = highlow;
    hhline = highhigh;
#else
    DequantizeBandRow16s(lowlow, roi.width, lowlow_quantization, llline1);
    DequantizeBandRow16s(lowlow + lowlow_pitch, roi.width, lowlow_quantization, llline2);
    DequantizeBandRow16s(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);

    DequantizeBandRow16s(lowhigh, roi.width, lowhigh_quantization, lhline1);
    DequantizeBandRow16s(lowhigh + lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
    DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

    DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
    DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * llline1[column];
        even -=  4 * llline2[column];
        even +=  1 * llline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * llline1[column];
        odd += 4 * llline2[column];
        odd -= 1 * llline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lhline1[column];
        even -=  4 * lhline2[column];
        even +=  1 * lhline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lhline1[column];
        odd += 4 * lhline2[column];
        odd -= 1 * lhline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 4;
        int post_column = roi.width - (roi.width % column_step);
        __m64 *even_lowpass_ptr = (__m64 *)even_lowpass;
        __m64 *even_highpass_ptr = (__m64 *)even_highpass;
        __m64 *odd_lowpass_ptr = (__m64 *)odd_lowpass;
        __m64 *odd_highpass_ptr = (__m64 *)odd_highpass;
        int quad_pitch;
#endif

        // Undo quantization to highpass bands
#if _DEQUANTIZE_IN_FSM
        hlline = highlow;
        hhline = highhigh;
#else
        DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
        DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m64 *lowlow_ptr1 = (__m64 *)&llline1[column];
            __m64 *lowlow_ptr2 = (__m64 *)&llline2[column];
            __m64 *lowlow_ptr3 = (__m64 *)&llline3[column];
            __m64 *highlow_ptr = (__m64 *)&hlline[column];
            __m64 *lowhigh_ptr1 = (__m64 *)&lhline1[column];
            __m64 *lowhigh_ptr2 = (__m64 *)&lhline2[column];
            __m64 *lowhigh_ptr3 = (__m64 *)&lhline3[column];
            __m64 *highhigh_ptr = (__m64 *)&hhline[column];
            __m64 quad_pi16;
            __m64 even_pi16;
            __m64 odd_pi16;


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters
            quad_pi16 = *lowlow_ptr1;	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowlow_ptr2;	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;	// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            quad_pi16 = *lowlow_ptr3;	// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highlow_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            *(even_lowpass_ptr++) = even_pi16;
            *(odd_lowpass_ptr++) = odd_pi16;


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m64);

            // Accumulate parallel sums for the even and odd filters

            quad_pi16 = *lowhigh_ptr1;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            even_pi16 = quad_pi16;
            odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

            quad_pi16 = *lowhigh_ptr2;		// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;	// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_pi16 = _mm_slli_pi16(quad_pi16, 3);

            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            quad_pi16 = *lowhigh_ptr3;		// Get four lowpass coefficients

            even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
            odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

            // Apply the rounding adjustment
            even_pi16 = _mm_adds_pi16(even_pi16, _mm_set1_pi16(4));
            // Divide by eight
            even_pi16 = _mm_srai_pi16(even_pi16, 3);

            // Apply the rounding adjustment
            odd_pi16 = _mm_adds_pi16(odd_pi16, _mm_set1_pi16(4));
            // Divide by eight
            odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_pi16 = *highhigh_ptr;
            even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
            even_pi16 = _mm_srai_pi16(even_pi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
            odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            *(even_highpass_ptr++) = even_pi16;
            *(odd_highpass_ptr++) = odd_pi16;
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < roi.width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += llline1[column];
            even -= llline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += llline2[column];

            // Add the highpass correction
            even += hlline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= llline1[column];
            odd += llline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += llline2[column];

            // Subtract the highpass correction
            odd -= hlline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lhline1[column];
            even -= lhline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lhline2[column];

            // Add the highpass correction
            even += hhline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lhline1[column];
            odd += lhline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lhline2[column];

            // Subtract the highpass correction
            odd -= hhline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

        // Apply the inverse horizontal transform to the even and odd rows
        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            temp = llline1;
            llline1 = llline2;
            llline2 = llline3;
            llline3 = temp;

            // Undo quantization for the new row in lowlow band
#if _DEQUANTIZE_IN_FSM
            llline3 = lowlow + 2 * lowlow_pitch;
#else
            DequantizeBandRow16s(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);
#endif

            temp = lhline1;
            lhline1 = lhline2;
            lhline2 = lhline3;
            lhline3 = temp;

            // Undo quantization for the new row in lowhigh band
#if _DEQUANTIZE_IN_FSM
            lhline3 = lowhigh + 2 * lowhigh_pitch;
#else
            DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
#endif
        }
    }

    //_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
    hlline = highlow;
    hhline = highhigh;
#else
    DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
    DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

    // Apply the vertical border filter to the last row
    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * llline3[column];
        even += 4 * llline2[column];
        even -= 1 * llline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * llline3[column];
        odd -=  4 * llline2[column];
        odd +=  1 * llline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lhline3[column];
        even += 4 * lhline2[column];
        even -= 1 * lhline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lhline3[column];
        odd -=  4 * lhline2[column];
        odd +=  1 * lhline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, output_row_size, strip);
}


#endif


#if _PROCESSOR_PENTIUM_4

#if _PROCESSOR_DISPATCH
__declspec(cpu_specific(Pentium_4))
#endif

void InvertSpatial16sTo16s(PIXEL16S *lowlow_band, int lowlow_pitch,
                           PIXEL16S *lowhigh_band, int lowhigh_pitch,
                           PIXEL16S *highlow_band, int highlow_pitch,
                           PIXEL16S *highhigh_band, int highhigh_pitch,
                           PIXEL16S *output_image, int output_pitch,
                           ROI roi, PIXEL *buffer, int quantization[],
                           PIXEL *line_buffer)
{
    PIXEL16S *lowlow = lowlow_band;
    PIXEL16S *lowhigh = lowhigh_band;
    PIXEL16S *highlow = highlow_band;
    PIXEL16S *highhigh = highhigh_band;
    PIXEL16S *output = output_image;
    PIXEL *even_lowpass;
    PIXEL *even_highpass;
    PIXEL *odd_lowpass;
    PIXEL *odd_highpass;
    PIXEL *lowpass;					// Strip of horizontal coefficients
    PIXEL *highpass;
    int lowpass_pitch;				// Distance between strip rows in bytes
    int highpass_pitch;
    ROI strip;						// Dimensions of the processing strip
    size_t buffer_row_size;
    size_t output_row_size = output_pitch;
    int buffer_half_pitch;
    int buffer_width;
    int buffer_pitch;
    int last_row = roi.height - 1;
    int row, column;

    PIXEL *llline1;		// Dequantized lowlow band row 1
    PIXEL *llline2;		// Dequantized lowlow band row 2
    PIXEL *llline3;		// Dequantized lowlow band row 3
    PIXEL *lhline1;		// Dequantized lowhigh band row 1
    PIXEL *lhline2;		// Dequantized lowhigh band row 2
    PIXEL *lhline3;		// Dequantized lowhigh band row 3
    PIXEL *hlline;		// Dequantized highlow band row
    PIXEL *hhline;		// Dequantized highhigh band row
    PIXEL *temp;

    //int lowlow_quantization = quantization[LL_BAND];
    //int highlow_quantization = quantization[HL_BAND];
    //int lowhigh_quantization = quantization[LH_BAND];
    //int highhigh_quantization = quantization[HH_BAND];

    // Convert pitch from bytes to pixels
    lowlow_pitch /= sizeof(PIXEL16S);
    lowhigh_pitch /= sizeof(PIXEL16S);
    highlow_pitch /= sizeof(PIXEL16S);
    highhigh_pitch /= sizeof(PIXEL16S);
    output_pitch /= sizeof(PIXEL16S);

    // Compute positions within the temporary buffer for each row of horizontal lowpass
    // and highpass intermediate coefficients computed by the vertical inverse transform
    buffer_row_size = roi.width * sizeof(PIXEL);
    buffer_row_size = ALIGN16(buffer_row_size);
    buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
    buffer_pitch = 2 * buffer_half_pitch;
    buffer_width = roi.width;

    // Check that the buffer is large enough to hold four rows of highpass coefficients
    //assert(buffer_size >= (4 * buffer_row_size));

    // Set the dimensions of the processing strip
    strip.width = buffer_width;
    strip.height = 2;

    // Compute the positions of the even and odd rows of coefficients
    even_lowpass = &buffer[0];
    even_highpass = &buffer[buffer_half_pitch];
    odd_lowpass = &buffer[2 * buffer_half_pitch];
    odd_highpass = &buffer[3 * buffer_half_pitch];

    // Compute the positions of the dequantized highpass rows
    llline1 = line_buffer;
    llline2 = llline1 + lowlow_pitch;
    llline3 = llline2 + lowlow_pitch;
    lhline1 = llline3 + lowlow_pitch;
    lhline2 = lhline1 + lowhigh_pitch;
    lhline3 = lhline2 + lowhigh_pitch;
    hlline = lhline3 + lowhigh_pitch;
    hhline = hlline + highlow_pitch;

    // Pointers into the strip of horizontal coefficients
    lowpass = even_lowpass;
    highpass = even_highpass;
    lowpass_pitch = (int)(2 * buffer_row_size);
    highpass_pitch = (int)(2 * buffer_row_size);

    // Apply the vertical border filter to the first row
    row = 0;

    // Undo quantization
#if _DEQUANTIZE_IN_FSM
    llline1 = lowlow;
    llline2 = lowlow + lowlow_pitch;
    llline3 = lowlow + 2 * lowlow_pitch;

    lhline1 = lowhigh;
    lhline2 = lowhigh + lowhigh_pitch;
    lhline3 = lowhigh + 2 * lowhigh_pitch;

    hlline = highlow;
    hhline = highhigh;
#else
    DequantizeBandRow16s(lowlow, roi.width, lowlow_quantization, llline1);
    DequantizeBandRow16s(lowlow + lowlow_pitch, roi.width, lowlow_quantization, llline2);
    DequantizeBandRow16s(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);

    DequantizeBandRow16s(lowhigh, roi.width, lowhigh_quantization, lhline1);
    DequantizeBandRow16s(lowhigh + lowhigh_pitch, roi.width, lowhigh_quantization, lhline2);
    DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);

    DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
    DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * llline1[column];
        even -=  4 * llline2[column];
        even +=  1 * llline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * llline1[column];
        odd += 4 * llline2[column];
        odd -= 1 * llline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lhline1[column];
        even -=  4 * lhline2[column];
        even +=  1 * lhline3[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lhline1[column];
        odd += 4 * lhline2[column];
        odd -= 1 * lhline3[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);

    // Advance to the next pair of even and odd output rows
    output += 2 * output_pitch;

    // Do not advance the lowpass row pointers until after the fast loop
    //lowlow += lowlow_pitch;
    //lowhigh += lowhigh_pitch;

    // Always advance the highpass row pointers
    highlow += highlow_pitch;
    highhigh += highhigh_pitch;

    // Advance the row index
    row++;

    // Process the middle rows using the interior reconstruction filters
    for (; row < last_row; row++)
    {
#if (1 && XMMOPT)
        int column_step = 8;
        int post_column = roi.width - (roi.width % column_step);
        __m128i *even_lowpass_ptr = (__m128i *)even_lowpass;
        __m128i *even_highpass_ptr = (__m128i *)even_highpass;
        __m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass;
        __m128i *odd_highpass_ptr = (__m128i *)odd_highpass;
        int quad_pitch;
#endif

        // Undo quantization to highpass bands
#if _DEQUANTIZE_IN_FSM
        hlline = highlow;
        hhline = highhigh;
#else
        DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
        DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

        // Start at the first column
        column = 0;

#if (1 && XMMOPT)

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m128i *lowlow_ptr1 = (__m128i *)&llline1[column];
            __m128i *lowlow_ptr2 = (__m128i *)&llline2[column];
            __m128i *lowlow_ptr3 = (__m128i *)&llline3[column];
            __m128i *highlow_ptr = (__m128i *)&hlline[column];
            __m128i *lowhigh_ptr1 = (__m128i *)&lhline1[column];
            __m128i *lowhigh_ptr2 = (__m128i *)&lhline2[column];
            __m128i *lowhigh_ptr3 = (__m128i *)&lhline3[column];
            __m128i *highhigh_ptr = (__m128i *)&hhline[column];
            __m128i quad_epi16;
            __m128i even_epi16;
            __m128i odd_epi16;


            // Compute the vertical inverse for the left two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowlow_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters
            quad_epi16 = _mm_load_si128(lowlow_ptr1);	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;					// Advance to the next row

            even_epi16 = quad_epi16;
            odd_epi16 = _mm_setzero_si128();
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowlow_ptr2);	// Get four lowpass coefficients
            //lowlow_ptr += quad_pitch;					// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowlow_ptr3);	// Get four lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            // Apply the rounding adjustment
            even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
            // Divide by eight
            even_epi16 = _mm_srai_epi16(even_epi16, 3);

            // Apply the rounding adjustment
            odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
            // Divide by eight
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_epi16 = _mm_load_si128(highlow_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal lowpass coefficients
            _mm_store_si128(even_lowpass_ptr++, even_epi16);
            _mm_store_si128(odd_lowpass_ptr++, odd_epi16);


            // Compute the vertical inverse for the right two bands //

            // Set the pitch for the lowpass band used in this section of code
            quad_pitch = (lowhigh_pitch * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters

            quad_epi16 = _mm_load_si128(lowhigh_ptr1);	// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;				// Advance to the next row

            even_epi16 = quad_epi16;
            odd_epi16 = _mm_setzero_si128();
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowhigh_ptr2);	// Get four lowpass coefficients
            //lowhigh_ptr += quad_pitch;				// Advance to the next row

            // Multiply the lowpass coefficients by eight
            quad_epi16 = _mm_slli_epi16(quad_epi16, 3);

            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            quad_epi16 = _mm_load_si128(lowhigh_ptr3);	// Get four lowpass coefficients

            even_epi16 = _mm_subs_epi16(even_epi16, quad_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, quad_epi16);

            // Apply the rounding adjustment
            even_epi16 = _mm_adds_epi16(even_epi16, _mm_set1_epi16(4));
            // Divide by eight
            even_epi16 = _mm_srai_epi16(even_epi16, 3);

            // Apply the rounding adjustment
            odd_epi16 = _mm_adds_epi16(odd_epi16, _mm_set1_epi16(4));
            // Divide by eight
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

            // Add the highpass correction to the even result and divide by two
            quad_epi16 = _mm_load_si128(highhigh_ptr);
            even_epi16 = _mm_adds_epi16(even_epi16, quad_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Subtract the highpass correction from the odd result and divide by two
            odd_epi16 = _mm_subs_epi16(odd_epi16, quad_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Store the even and odd groups of horizontal highpass coefficients
            _mm_store_si128(even_highpass_ptr++, even_epi16);
            _mm_store_si128(odd_highpass_ptr++, odd_epi16);
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);

#endif

        // Process the rest of the row
        for (; column < roi.width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += llline1[column];
            even -= llline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += llline2[column];

            // Add the highpass correction
            even += hlline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= llline1[column];
            odd += llline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += llline2[column];

            // Subtract the highpass correction
            odd -= hlline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lhline1[column];
            even -= lhline3[column];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lhline2[column];

            // Add the highpass correction
            even += hhline[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lhline1[column];
            odd += lhline3[column];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lhline2[column];

            // Subtract the highpass correction
            odd -= hhline[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[column] = SATURATE(odd);
        }

        // Apply the inverse horizontal transform to the even and odd rows
        InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                                 highpass, highpass_pitch,
                                 output, (int)output_row_size, strip);

        // Advance to the next input rows and skip the next output row
        lowlow += lowlow_pitch;
        lowhigh += lowhigh_pitch;
        highlow += highlow_pitch;
        highhigh += highhigh_pitch;
        output += 2 * output_pitch;

        if (row < last_row - 1)
        {
            temp = llline1;
            llline1 = llline2;
            llline2 = llline3;
            llline3 = temp;

            // Undo quantization for the new row in lowlow band
#if _DEQUANTIZE_IN_FSM
            llline3 = lowlow + 2 * lowlow_pitch;
#else
            DequantizeBandRow16s(lowlow + 2 * lowlow_pitch, roi.width, lowlow_quantization, llline3);
#endif

            temp = lhline1;
            lhline1 = lhline2;
            lhline2 = lhline3;
            lhline3 = temp;

            // Undo quantization for the new row in lowhigh band
#if _DEQUANTIZE_IN_FSM
            lhline3 = lowhigh + 2 * lowhigh_pitch;
#else
            DequantizeBandRow16s(lowhigh + 2 * lowhigh_pitch, roi.width, lowhigh_quantization, lhline3);
#endif
        }
    }

    //_mm_empty();	// Clear the mmx register state

#if (1 && XMMOPT)
    // Need to advance the lowpass pointer if using SIMD instructions
    lowlow += lowlow_pitch;
    lowhigh += lowhigh_pitch;
#endif

    // Should have exited the loop at the last row
    assert(row == last_row);

    // Undo quantization for the highlow and highhigh bands
#if _DEQUANTIZE_IN_FSM
    hlline = highlow;
    hhline = highhigh;
#else
    DequantizeBandRow16s(highlow, roi.width, highlow_quantization, hlline);
    DequantizeBandRow16s(highhigh, roi.width, highhigh_quantization, hhline);
#endif

    // Apply the vertical border filter to the last row
    for (column = 0; column < roi.width; column++)
    {
        int32_t even = 0;		// Result of convolution with even filter
        int32_t odd = 0;		// Result of convolution with odd filter


        // Compute the vertical inverse for the left two bands //

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * llline3[column];
        even += 4 * llline2[column];
        even -= 1 * llline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hlline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_lowpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * llline3[column];
        odd -=  4 * llline2[column];
        odd +=  1 * llline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hlline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_lowpass[column] = SATURATE(odd);


        // Compute the vertical inverse for the right two bands //

        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lhline3[column];
        even += 4 * lhline2[column];
        even -= 1 * lhline1[column];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += hhline[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even row
        even_highpass[column] = SATURATE(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lhline3[column];
        odd -=  4 * lhline2[column];
        odd +=  1 * lhline1[column];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= hhline[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd row
        odd_highpass[column] = SATURATE(odd);
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStrip16s(lowpass, lowpass_pitch,
                             highpass, highpass_pitch,
                             output, (int)output_row_size, strip);
}
#endif //P4 InvertSpatial16sTo16s

#if 1

// Slow version of InvertHorizontalStrip8s (the MMX instructions are not used)

// Apply the inverse horizontal transform to reconstruct a strip of rows
void InvertHorizontalStrip8s(PIXEL8S *lowpass_band,	// Horizontal lowpass coefficients
                             int lowpass_pitch,		// Distance between rows in bytes
                             PIXEL8S *highpass_band,// Horizontal highpass coefficients
                             int highpass_pitch,	// Distance between rows in bytes
                             PIXEL8S *output_image,	// Row of reconstructed results
                             int output_pitch,		// Distance between rows in bytes
                             ROI roi)			// Height and width of the strip
{
    int row, column;
    PIXEL8S *lowpass = lowpass_band;
    PIXEL8S *highpass = highpass_band;
    PIXEL8S *output = output_image;

    // Convert the pitch to units of pixels
    lowpass_pitch /= sizeof(PIXEL8S);
    highpass_pitch /= sizeof(PIXEL8S);
    output_pitch /= sizeof(PIXEL8S);

    for (row = 0; row < roi.height; row++)
    {
        PIXEL8S *outptr = output;
        const int column_step = 1;
        int last_column = roi.width - column_step;
        int32_t even;
        int32_t odd;

        column = 0;

        // Process the first two output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * lowpass[column + 0];
        even -=  4 * lowpass[column + 1];
        even +=  1 * lowpass[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highpass[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(outptr++) = SATURATE_8S(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * lowpass[column + 0];
        odd += 4 * lowpass[column + 1];
        odd -= 1 * lowpass[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highpass[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(outptr++) = SATURATE_8S(odd);

        column++;

        for (; column < last_column; column += column_step)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter

            // Apply the even reconstruction filter to the lowpass band
            even += lowpass[column - 1];
            even -= lowpass[column + 1];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);
            even += lowpass[column + 0];

            // Add the highpass correction
            even += highpass[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even column
            *(outptr++) = SATURATE_8S(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowpass[column - 1];
            odd += lowpass[column + 1];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);
            odd += lowpass[column + 0];

            // Subtract the highpass correction
            odd -= highpass[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd column
            *(outptr++) = SATURATE_8S(odd);
        }

        // Should have exited the loop with the column equal to the last column
        assert(column == last_column);

        // Process the last two output points with special filters for the right border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 5 * lowpass[column + 0];
        even += 4 * lowpass[column - 1];
        even -= 1 * lowpass[column - 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += highpass[column];
        even = DivideByShift(even, 1);

        // Place the even result in the even column
        *(outptr++) = SATURATE_8S(even);

        // Apply the odd reconstruction filter to the lowpass band
        odd += 11 * lowpass[column + 0];
        odd -=  4 * lowpass[column - 1];
        odd +=  1 * lowpass[column - 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= highpass[column];
        odd = DivideByShift(odd, 1);

        // Place the odd result in the odd column
        *(outptr++) = SATURATE_8S(odd);

        // Advance to the next row
        lowpass += lowpass_pitch;
        highpass += highpass_pitch;
        output += output_pitch;
    }
}
#endif






// Apply the inverse spatial filter to the top row and pack the results into 8-bit YUV
void
InvertSpatialTopRow16sToPackedYUV8u(PIXEL *lowlow_band[], int lowlow_band_pitch[],
                                    PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
                                    PIXEL *highlow_band[], int highlow_band_pitch[],
                                    PIXEL *highhigh_band[], int highhigh_band_pitch[],
                                    uint8_t *output, int output_pitch, int output_width,
                                    int format, int row, int luma_band_width,
                                    PIXEL *buffer, size_t buffer_size, int precision)
{
    int num_channels = CODEC_NUM_CHANNELS;

    PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *even_highpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_highpass[CODEC_MAX_CHANNELS];

    // Distance between strip rows in bytes
    int lowpass_pitch[CODEC_MAX_CHANNELS];
    int highpass_pitch[CODEC_MAX_CHANNELS];

    size_t output_row_size = output_pitch;

    // Set the dimensions of the processing strip
    ROI strip = {luma_band_width, 2};

    int channel;

    // Compute pointers into the buffers for temporary results
    for (channel = 0; channel < num_channels; channel++)
    {
        size_t buffer_row_size;
        int buffer_half_pitch;
        //int buffer_width;
        int buffer_pitch;

        int width = luma_band_width;

        // Compute positions within the temporary buffer for each row of horizontal lowpass
        // and highpass intermediate coefficients computed by the vertical inverse transform
        buffer_row_size = width * sizeof(PIXEL);
        buffer_row_size = ALIGN16(buffer_row_size);
        buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
        buffer_pitch = 2 * buffer_half_pitch;
        //buffer_width = width;

        // Check that the buffer is large enough to hold four rows of coefficients
        assert(buffer_size >= (4 * buffer_row_size));

        // Compute the positions of the even and odd rows of coefficients
        even_lowpass[channel] = &buffer[0];
        even_highpass[channel] = &buffer[buffer_half_pitch];
        odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
        odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

        // Pointers into the strip of horizontal coefficients
        lowpass_pitch[channel] = (int)(2 * buffer_row_size);
        highpass_pitch[channel] = (int)(2 * buffer_row_size);

        buffer = &buffer[4 * buffer_half_pitch];
        buffer_size -= 4 * buffer_row_size;
    }

    // This routine should be called for the first row
    assert(row == 0);

    for (channel = 0; channel < num_channels; channel++)
    {
        PIXEL *lowlow = lowlow_band[channel];
        PIXEL *lowhigh = lowhigh_band[channel];
        PIXEL *highlow = highlow_band[channel];
        PIXEL *highhigh = highhigh_band[channel];

        // Convert pitch from bytes to pixels
        int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
        int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
        //int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
        //int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

        int width = luma_band_width;

        // Start at the first column
        int column = 0;

        // Apply the vertical border filter to the first row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            /***** Compute the vertical inverse for the left two bands *****/

            // Apply the even reconstruction filter to the lowpass band
            even += 11 * lowlow[column + 0 * lowlow_pitch];
            even -=  4 * lowlow[column + 1 * lowlow_pitch];
            even +=  1 * lowlow[column + 2 * lowlow_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highlow[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 5 * lowlow[column + 0 * lowlow_pitch];
            odd += 4 * lowlow[column + 1 * lowlow_pitch];
            odd -= 1 * lowlow[column + 2 * lowlow_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highlow[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[channel][column] = SATURATE(odd);


            /***** Compute the vertical inverse for the right two bands *****/

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += 11 * lowhigh[column + 0 * lowhigh_pitch];
            even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
            even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highhigh[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
            odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
            odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highhigh[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[channel][column] = SATURATE(odd);
        }
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStripRGB16sToPackedYUV8u(even_lowpass, lowpass_pitch,
            even_highpass, highpass_pitch,
            output, (int)output_row_size, strip,
            precision);
}



// Apply the inverse spatial filter to the bottom row and pack the results into 8-bit YUV
void
InvertSpatialBottomRow16sToPackedYUV8u(PIXEL *lowlow_band[], int lowlow_band_pitch[],
                                       PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
                                       PIXEL *highlow_band[], int highlow_band_pitch[],
                                       PIXEL *highhigh_band[], int highhigh_band_pitch[],
                                       uint8_t *output, int output_pitch, int output_width,
                                       int format, int row, int luma_band_width,
                                       PIXEL *buffer, size_t buffer_size, int precision)
{
    int num_channels = CODEC_NUM_CHANNELS;

    PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *even_highpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_highpass[CODEC_MAX_CHANNELS];

    // Distance between strip rows in bytes
    int lowpass_pitch[CODEC_MAX_CHANNELS];
    int highpass_pitch[CODEC_MAX_CHANNELS];

    size_t output_row_size = output_pitch;

    // Set the dimensions of the processing strip
    ROI strip = {luma_band_width, 2};

    int channel;

    // Compute pointers into the buffers for temporary results
    for (channel = 0; channel < num_channels; channel++)
    {
        size_t buffer_row_size;
        int buffer_half_pitch;
        //int buffer_width;
        int buffer_pitch;

        int width = luma_band_width;

        // Compute positions within the temporary buffer for each row of horizontal lowpass
        // and highpass intermediate coefficients computed by the vertical inverse transform
        buffer_row_size = width * sizeof(PIXEL);
        buffer_row_size = ALIGN16(buffer_row_size);
        buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
        buffer_pitch = 2 * buffer_half_pitch;
        //buffer_width = width;

        // Check that the buffer is large enough to hold four rows of coefficients
        assert(buffer_size >= (4 * buffer_row_size));

        // Compute the positions of the even and odd rows of coefficients
        even_lowpass[channel] = &buffer[0];
        even_highpass[channel] = &buffer[buffer_half_pitch];
        odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
        odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

        // Pointers into the strip of horizontal coefficients
        lowpass_pitch[channel] = (int)(2 * buffer_row_size);
        highpass_pitch[channel] = (int)(2 * buffer_row_size);

        buffer = &buffer[4 * buffer_half_pitch];
        buffer_size -= 4 * buffer_row_size;
    }

    for (channel = 0; channel < num_channels; channel++)
    {
        PIXEL *lowlow = lowlow_band[channel];
        PIXEL *lowhigh = lowhigh_band[channel];
        PIXEL *highlow = highlow_band[channel];
        PIXEL *highhigh = highhigh_band[channel];

        // Convert pitch from bytes to pixels
        int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
        int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
        int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
        int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

        int width = luma_band_width;

        // Start at the first column
        int column = 0;

        // Compute the address of the first row for processing in each wavelet band
        lowlow += row * lowlow_pitch;
        lowhigh += row * lowhigh_pitch;
        highlow += row * highlow_pitch;
        highhigh += row * highhigh_pitch;

        // Apply the vertical border filter to the last row
        for (column = 0; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += 5 * lowlow[column + 0 * lowlow_pitch];
            even += 4 * lowlow[column - 1 * lowlow_pitch];
            even -= 1 * lowlow[column - 2 * lowlow_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highlow[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * lowlow[column + 0 * lowlow_pitch];
            odd -=  4 * lowlow[column - 1 * lowlow_pitch];
            odd +=  1 * lowlow[column - 2 * lowlow_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highlow[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[channel][column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += 5 * lowhigh[column + 0 * lowhigh_pitch];
            even += 4 * lowhigh[column - 1 * lowhigh_pitch];
            even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highhigh[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
            odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
            odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highhigh[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[channel][column] = SATURATE(odd);
        }
    }

    // Apply the inverse horizontal transform to the even and odd rows
    InvertHorizontalStripRGB16sToPackedYUV8u(even_lowpass, lowpass_pitch,
            even_highpass, highpass_pitch,
            output, (int)output_row_size, strip,
            precision);
}

// Adapted from InvertHorizontalStrip16sRGB2YUV
void InvertHorizontalStripRGB16sToPackedYUV8u(PIXEL *lowpass_band[],	// Horizontal lowpass coefficients
        int lowpass_pitch[],		// Distance between rows in bytes
        PIXEL *highpass_band[],	// Horizontal highpass coefficients
        int highpass_pitch[],	// Distance between rows in bytes
        uint8_t *output_image,		// Row of reconstructed results
        int output_pitch,		// Distance between rows in bytes
        ROI roi,					// Height and width of the strip
        int precision)			// Precision of the original video
{
    int num_channels = CODEC_NUM_CHANNELS;
    int height = roi.height;
    int width = roi.width;

    // Note that the u and v chroma values are swapped
    PIXEL *gg_lowpass_ptr = lowpass_band[0];
    PIXEL *rg_lowpass_ptr = lowpass_band[1];
    PIXEL *bg_lowpass_ptr = lowpass_band[2];
    PIXEL *gg_highpass_ptr = highpass_band[0];
    PIXEL *rg_highpass_ptr = highpass_band[1];
    PIXEL *bg_highpass_ptr = highpass_band[2];

    uint8_t *output = output_image;

    // Process 8 luma coefficients per loop iteration
    const int column_step = 8;

    // Need to process two luma coefficients up to the last column to allow for chroma output
    const int last_column = width;
    int post_column = last_column - (last_column % column_step);

    // Need at least four luma values of border processing up to the last column
    //const int post_border = 2;

    int channel;
    int row;

    // Compute the amount of scaling required to reduce the output precision
    int descale_shift = (precision - 8);

    int shift = 8;
    float scale;

    float fy_rmult, fy_gmult, fy_bmult, fy_offset;
    float fu_rmult, fu_gmult, fu_bmult, fu_offset;
    float fv_rmult, fv_gmult, fv_bmult, fv_offset;

    int color_space = COLOR_SPACE_BT_709; // This code is not active, should be  decoder->frame.colorspace;

    const float rgb2yuv709[3][4] =
    {
        {0.183f, 0.614f, 0.062f, 16.0f / 255.0f},
        {-0.101f, -0.338f, 0.439f, 128.0f / 255.0f},
        {0.439f, -0.399f, -0.040f, 128.0f / 255.0f}
    };
    const float rgb2yuv601[3][4] =
    {
        {0.257f, 0.504f, 0.098f, 16.0f / 255.0f},
        {-0.148f, -0.291f, 0.439f, 128.0f / 255.0f},
        {0.439f, -0.368f, -0.071f, 128.0f / 255.0f}
    };
    const float rgb2yuvVS601[3][4] =
    {
        {0.299f, 0.587f, 0.114f, 0},
        {-0.172f, -0.339f, 0.511f, 128.0f / 255.0f},
        {0.511f, -0.428f, -0.083f, 128.0f / 255.0f}
    };
    const float rgb2yuvVS709[3][4] =
    {
        {0.213f, 0.715f, 0.072f, 0},
        {-0.117f, -0.394f, 0.511f, 128.0f / 255.0f},
        {0.511f, -0.464f, -0.047f, 128.0f / 255.0f}
    };
    float rgb2yuv[3][4];
    //int yoffset = 16;

    switch (color_space & COLORSPACE_MASK)
    {
        case COLOR_SPACE_CG_601:
            memcpy(rgb2yuv, rgb2yuv601, 12 * sizeof(float));
            break;
        default:
            assert(0);
        case COLOR_SPACE_CG_709:
            memcpy(rgb2yuv, rgb2yuv709, 12 * sizeof(float));
            break;
        case COLOR_SPACE_VS_601:
            memcpy(rgb2yuv, rgb2yuvVS601, 12 * sizeof(float));
            break;
        case COLOR_SPACE_VS_709:
            memcpy(rgb2yuv, rgb2yuvVS709, 12 * sizeof(float));
            break;
    }

    //_mm_empty();

    scale = 64.0;

    fy_rmult = ((rgb2yuv[0][0]) * scale);
    fy_gmult = ((rgb2yuv[0][1]) * scale);
    fy_bmult = ((rgb2yuv[0][2]) * scale);
    fy_offset = ((rgb2yuv[0][3]) * 16384.0f);

    fu_rmult = ((rgb2yuv[1][0]) * scale);
    fu_gmult = ((rgb2yuv[1][1]) * scale);
    fu_bmult = ((rgb2yuv[1][2]) * scale);
    fu_offset = ((rgb2yuv[1][3]) * 16384.0f);

    fv_rmult = ((rgb2yuv[2][0]) * scale);
    fv_gmult = ((rgb2yuv[2][1]) * scale);
    fv_bmult = ((rgb2yuv[2][2]) * scale);
    fv_offset = ((rgb2yuv[2][3]) * 16384.0f);

    shift -= 2;


    // Convert the pitch to units of pixels
    for (channel = 0; channel < num_channels; channel++)
    {
        lowpass_pitch[channel] /= sizeof(PIXEL);
        highpass_pitch[channel] /= sizeof(PIXEL);
    }

    output_pitch /= sizeof(uint8_t);

    // Adjust the end of the fast loop if necessary for border processing
    //if (post_column > (last_column - post_border))  // DAN08112004 - ignore end row calc -- use SSE to edge.
    //	post_column -= column_step;

    // Check that there is enough margin to accommodate border processing
    //	assert(post_column <= (last_column - post_border));

    // Process each row of the strip
    for (row = 0; row < height; row++)
    {
#if (1 && XMMOPT)
        __m128i gg_low1_epi16;		// Lowpass coefficients
        __m128i gg_low2_epi16;
        __m128i bg_low1_epi16;
        __m128i bg_low2_epi16;
        __m128i rg_low1_epi16;
        __m128i rg_low2_epi16;

        __m128i gg_high1_epi16;		// Highpass coefficients
        __m128i gg_high2_epi16;
        __m128i bg_high1_epi16;
        __m128i bg_high2_epi16;
        __m128i rg_high1_epi16;
        __m128i rg_high2_epi16;

        // The fast loop merges values from different phases to allow aligned stores
        __m128i *outptr = (__m128i *)&output[0];

        const __m128i mask_epi32 = _mm_set1_epi32(0xffff);

        __m128i limiterRGB = _mm_set1_epi16(0x7fff - 0x00ff);
        __m128i limiter = _mm_set1_epi16(0x7fff - 0x3fff);

#endif
        uint8_t *colptr = (uint8_t *)&output[0];

        int32_t gg_even_value;
        int32_t bg_even_value;
        int32_t rg_even_value;
        int32_t gg_odd_value;
        int32_t bg_odd_value;
        int32_t rg_odd_value;


        // Start processing at the beginning of the row
        int column = 0;

        // Process the first two luma output points with special filters for the left border
        int32_t even = 0;
        int32_t odd = 0;


        __m128i rounding1_pi16 = _mm_set1_epi16(0); // for 6bit matm
        __m128i rounding2_pi16 = _mm_set1_epi16(0); // for 6bit matm

        if (descale_shift >= 2)
        {
            int mask = (1 << (descale_shift - 1)) - 1;
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 0);
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 1);
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 2);
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 3);
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 4);
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 5);
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 6);
            rounding1_pi16 = _mm_insert_epi16(rounding1_pi16, rand()&mask, 7);

            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 0);
            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 1);
            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 2);
            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 3);
            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 4);
            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 5);
            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 6);
            rounding2_pi16 = _mm_insert_epi16(rounding2_pi16, rand()&mask, 7);

            rounding1_pi16 = _mm_adds_epi16(rounding1_pi16, _mm_set1_epi16(10 * mask / 32)); //DAN20090601
            rounding2_pi16 = _mm_adds_epi16(rounding2_pi16, _mm_set1_epi16(10 * mask / 32));
        }



        // Apply the even reconstruction filter to the lowpass band
        even += 11 * gg_lowpass_ptr[column + 0];
        even -=  4 * gg_lowpass_ptr[column + 1];
        even +=  1 * gg_lowpass_ptr[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += gg_highpass_ptr[column];
        even = DivideByShift(even, 1);

        // Reduce the precision to eight bits
        even >>= descale_shift;

        // Save the value for use in the fast loop
        gg_even_value = even;

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * gg_lowpass_ptr[column + 0];
        odd += 4 * gg_lowpass_ptr[column + 1];
        odd -= 1 * gg_lowpass_ptr[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= gg_highpass_ptr[column];
        odd = DivideByShift(odd, 1);

        // Reduce the precision to eight bits
        odd >>= descale_shift;

        // Save the value for use in the fast loop
        gg_odd_value = odd;


        // Process the first two u chroma output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * bg_lowpass_ptr[column + 0];
        even -=  4 * bg_lowpass_ptr[column + 1];
        even +=  1 * bg_lowpass_ptr[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += bg_highpass_ptr[column];
        even = DivideByShift(even, 1);

        // Reduce the precision to eight bits
        even >>= descale_shift;

        // Save the value for use in the fast loop
        bg_even_value = even;

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * bg_lowpass_ptr[column + 0];
        odd += 4 * bg_lowpass_ptr[column + 1];
        odd -= 1 * bg_lowpass_ptr[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= bg_highpass_ptr[column];
        odd = DivideByShift(odd, 1);

        // Reduce the precision to eight bits
        odd >>= descale_shift;

        // Save the value for use in the fast loop
        bg_odd_value = odd;


        // Process the first two v chroma output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * rg_lowpass_ptr[column + 0];
        even -=  4 * rg_lowpass_ptr[column + 1];
        even +=  1 * rg_lowpass_ptr[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += rg_highpass_ptr[column];
        even = DivideByShift(even, 1);

        // Reduce the precision to eight bits
        even >>= descale_shift;

        // Save the value for use in the fast loop
        rg_even_value = even;

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * rg_lowpass_ptr[column + 0];
        odd += 4 * rg_lowpass_ptr[column + 1];
        odd -= 1 * rg_lowpass_ptr[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= rg_highpass_ptr[column];
        odd = DivideByShift(odd, 1);

        // Reduce the precision to eight bits
        odd >>= descale_shift;

        // Save the value for use in the fast loop
        rg_odd_value = odd;

#if (1 && XMMOPT)

        // Preload the first eight lowpass luma coefficients
        gg_low1_epi16 = _mm_load_si128((__m128i *)&gg_lowpass_ptr[0]);

        // Preload the first eight highpass luma coefficients
        gg_high1_epi16 = _mm_load_si128((__m128i *)&gg_highpass_ptr[0]);

        // Preload the first eight lowpass u chroma coefficients
        bg_low1_epi16 = _mm_load_si128((__m128i *)&bg_lowpass_ptr[0]);

        // Preload the first eight highpass u chroma coefficients
        bg_high1_epi16 = _mm_load_si128((__m128i *)&bg_highpass_ptr[0]);

        // Preload the first eight lowpass v chroma coefficients
        rg_low1_epi16 = _mm_load_si128((__m128i *)&rg_lowpass_ptr[0]);

        // Preload the first eight highpass v chroma coefficients
        rg_high1_epi16 = _mm_load_si128((__m128i *)&rg_highpass_ptr[0]);


        // The reconstruction filters use pixels starting at the first column
        for (; column < post_column; column += column_step)
        {
            __m128i g1_output_epi16;
            __m128i g2_output_epi16;
            __m128i r1_output_epi16;
            __m128i r2_output_epi16;
            __m128i b1_output_epi16;
            __m128i b2_output_epi16;

            __m128i gg1_output_epi16;
            __m128i gg2_output_epi16;
            __m128i rg1_output_epi16;
            __m128i rg2_output_epi16;
            __m128i bg1_output_epi16;
            __m128i bg2_output_epi16;

            __m128i y1_output_epi16;
            __m128i y2_output_epi16;
            __m128i u1_output_epi16;
            __m128i u2_output_epi16;
            __m128i v1_output_epi16;
            __m128i v2_output_epi16;

            __m128i urg_epi16;
            __m128i yuv1_epi16;
            __m128i yuv2_epi16;
            __m128i yuv1_epi8;
            __m128i yuv2_epi8;

            __m128i even_epi16;		// Result of convolution with even filter
            __m128i odd_epi16;		// Result of convolution with odd filter
            __m128i temp_epi16;
            __m128i temp_epi32;
            __m128i tempB_epi32;
            __m128i rgb_epi32;
            __m128i zero_epi128;
            __m128  temp_ps;
            __m128  rgb_ps;
            __m128	y1a_ps;
            __m128	y1b_ps;
            __m128	u1a_ps;
            __m128	u1b_ps;
            __m128	v1a_ps;
            __m128	v1b_ps;


            __m128i out_epi16;		// Reconstructed data
            //__m128i mask_epi16;
            //__m128i lsb_epi16;
            //__m128i sign_epi16;
            //__m128i high_epi16;

            __m128i low1_epi16;
            __m128i low2_epi16;
            __m128i high1_epi16;
            __m128i high2_epi16;

            //DAN031304 -- correct inverse filter
            __m128i half_epi16 = _mm_set1_epi16(4);
            __m128i offset_epi16 = _mm_set1_epi16(2048);

            uint32_t temp;		// Temporary register for last two values


            /***** Compute the first eight luma output values *****/

            // Preload the second eight lowpass coefficients
            gg_low2_epi16 = _mm_load_si128((__m128i *)&gg_lowpass_ptr[column + 8]);

            // Preload the second eight highpass coefficients
            gg_high2_epi16 = _mm_load_si128((__m128i *)&gg_highpass_ptr[column + 8]);

            // Move the current set of coefficients to working registers
            low1_epi16 = gg_low1_epi16;
            high1_epi16 = gg_high1_epi16;

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift the highpass correction by one column
            high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);


            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding1_pi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, gg_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, gg_odd_value, 1);

            // Save the eight luma values for packing later
            gg1_output_epi16 = out_epi16;

            // Save the remaining two output values
            gg_even_value = (short)temp;
            gg_odd_value = (short)(temp >> 16);


            /***** Compute the second eight luma output values *****/

            // Move the next set of coefficients to working registers
            low2_epi16 = gg_low2_epi16;
            high2_epi16 = gg_high2_epi16;

            // Shift in the new pixels for the next stage of the loop
            low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
            low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift in the next four highpass coefficients
            high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
            high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding2_pi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, gg_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, gg_odd_value, 1);

            // Save the eight luma values for packing later
            gg2_output_epi16 = out_epi16;

            // Save the remaining two output values
            gg_even_value = (short)temp;
            gg_odd_value = (short)(temp >> 16);

            // The second eight lowpass coefficients are used later in the loop
            gg_low1_epi16 = gg_low2_epi16;

            // The second eight highpass coefficients are used later in the loop
            gg_high1_epi16 = gg_high2_epi16;


            /***** Compute the first eight u chroma output values *****/

            // Preload the second eight lowpass coefficients
            bg_low2_epi16 = _mm_load_si128((__m128i *)&bg_lowpass_ptr[column + 8]);

            // Preload the second eight highpass coefficients
            bg_high2_epi16 = _mm_load_si128((__m128i *)&bg_highpass_ptr[column + 8]);

            // Move the current set of coefficients to working registers
            low1_epi16 = bg_low1_epi16;
            high1_epi16 = bg_high1_epi16;

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift the highpass correction by one column
            high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding1_pi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, bg_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, bg_odd_value, 1);

            // Save the eight u chroma values for packing later
            bg1_output_epi16 = out_epi16;

            // Save the remaining two output values
            bg_even_value = (short)temp;
            bg_odd_value = (short)(temp >> 16);


            /***** Compute the second eight u chroma output values *****/

            // Move the next set of coefficients to working registers
            low2_epi16 = bg_low2_epi16;
            high2_epi16 = bg_high2_epi16;

            // Shift in the new pixels for the next stage of the loop
            low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
            low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift in the next four highpass coefficients
            high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
            high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding2_pi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, bg_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, bg_odd_value, 1);

            // Save the eight u chroma values for packing later
            bg2_output_epi16 = out_epi16;

            // Save the remaining two output values
            bg_even_value = (short)temp;
            bg_odd_value = (short)(temp >> 16);

            // The second eight lowpass coefficients are the current values in the next iteration
            bg_low1_epi16 = bg_low2_epi16;

            // The second eight highpass coefficients are the current values in the next iteration
            bg_high1_epi16 = bg_high2_epi16;



            /***** Compute the first eight v chroma output values *****/

            // Preload the second eight lowpass coefficients
            rg_low2_epi16 = _mm_load_si128((__m128i *)&rg_lowpass_ptr[column + 8]);

            // Preload the second eight highpass coefficients
            rg_high2_epi16 = _mm_load_si128((__m128i *)&rg_highpass_ptr[column + 8]);

            // Move the current set of coefficients to working registers
            low1_epi16 = rg_low1_epi16;
            high1_epi16 = rg_high1_epi16;

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift the highpass correction by one column
            high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding1_pi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, rg_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, rg_odd_value, 1);

            // Save the eight u chroma values for packing later
            rg1_output_epi16 = out_epi16;

            // Save the remaining two output values
            rg_even_value = (short)temp;
            rg_odd_value = (short)(temp >> 16);


            /***** Compute the second eight v chroma output values *****/

            // Move the next set of coefficients to working registers
            low2_epi16 = rg_low2_epi16;
            high2_epi16 = rg_high2_epi16;

            // Shift in the new pixels for the next stage of the loop
            low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
            low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift in the next four highpass coefficients
            high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
            high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding2_pi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, rg_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, rg_odd_value, 1);

            // Save the eight u chroma values for packing later
            rg2_output_epi16 = out_epi16;

            // Save the remaining two output values
            rg_even_value = (short)temp;
            rg_odd_value = (short)(temp >> 16);

            // The second eight lowpass coefficients are the current values in the next iteration
            rg_low1_epi16 = rg_low2_epi16;

            // The second eight highpass coefficients are the current values in the next iteration
            rg_high1_epi16 = rg_high2_epi16;












            //r_output_epi16  = ((rg_output_epi16 - 32768)<<1)+gg_output_epi16
            //r_output_epi16  = ((rg_output_epi16>>3 - 32768>>3))+gg_output_epi16>>4


            g1_output_epi16 = gg1_output_epi16;

            r1_output_epi16 = rg1_output_epi16;//_mm_srli_epi16(rg1_output_epi16,2);
            //	r1_output_epi16 = _mm_subs_epi16(r1_output_epi16, value128_epi32);
            //	r1_output_epi16 = _mm_slli_epi16(r1_output_epi16,1);
            //	r1_output_epi16 = _mm_adds_epi16(r1_output_epi16, g1_output_epi16);

            b1_output_epi16 = bg1_output_epi16;//_mm_srli_epi16(bg1_output_epi16,2);
            //	b1_output_epi16 = _mm_subs_epi16(b1_output_epi16, value128_epi32);
            //	b1_output_epi16 = _mm_slli_epi16(b1_output_epi16,1);
            //	b1_output_epi16 = _mm_adds_epi16(b1_output_epi16, g1_output_epi16);


            r1_output_epi16 = _mm_adds_epi16(r1_output_epi16, limiterRGB);
            r1_output_epi16 = _mm_subs_epu16(r1_output_epi16, limiterRGB);

            g1_output_epi16 = _mm_adds_epi16(g1_output_epi16, limiterRGB);
            g1_output_epi16 = _mm_subs_epu16(g1_output_epi16, limiterRGB);

            b1_output_epi16 = _mm_adds_epi16(b1_output_epi16, limiterRGB);
            b1_output_epi16 = _mm_subs_epu16(b1_output_epi16, limiterRGB);


            zero_epi128 = _mm_setzero_si128();


            // Compute Y,U,V
            rgb_epi32 = _mm_unpacklo_epi16(r1_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            y1a_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
            u1a_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
            v1a_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);
            rgb_epi32 = _mm_unpackhi_epi16(r1_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            y1b_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
            u1b_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
            v1b_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);

            rgb_epi32 = _mm_unpacklo_epi16(g1_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
            y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
            u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
            v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
            rgb_epi32 = _mm_unpackhi_epi16(g1_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
            y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
            u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
            v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

            rgb_epi32 = _mm_unpacklo_epi16(b1_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
            y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
            u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
            v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
            rgb_epi32 = _mm_unpackhi_epi16(b1_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
            y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
            u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
            v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

            temp_ps = _mm_set_ps1(fy_offset);
            y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
            y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
            temp_ps = _mm_set_ps1(fu_offset);
            u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
            u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
            temp_ps = _mm_set_ps1(fv_offset);
            v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
            v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

            temp_epi32 = _mm_cvtps_epi32(y1a_ps);
            tempB_epi32 = _mm_cvtps_epi32(y1b_ps);
            y1_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
            y1_output_epi16 = _mm_adds_epi16(y1_output_epi16, limiter);
            y1_output_epi16 = _mm_subs_epu16(y1_output_epi16, limiter);
            y1_output_epi16 = _mm_srli_epi16(y1_output_epi16, shift);

            temp_epi32 = _mm_cvtps_epi32(u1a_ps);
            tempB_epi32 = _mm_cvtps_epi32(u1b_ps);
            u1_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
            u1_output_epi16 = _mm_adds_epi16(u1_output_epi16, limiter);
            u1_output_epi16 = _mm_subs_epu16(u1_output_epi16, limiter);
            u1_output_epi16 = _mm_srli_epi16(u1_output_epi16, shift);

            temp_epi32 = _mm_cvtps_epi32(v1a_ps);
            tempB_epi32 = _mm_cvtps_epi32(v1b_ps);
            v1_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
            v1_output_epi16 = _mm_adds_epi16(v1_output_epi16, limiter);
            v1_output_epi16 = _mm_subs_epu16(v1_output_epi16, limiter);
            v1_output_epi16 = _mm_srli_epi16(v1_output_epi16, shift);






            g2_output_epi16 = gg2_output_epi16;//_mm_srli_epi16(gg2_output_epi16,2);

            r2_output_epi16 = rg2_output_epi16;//_mm_srli_epi16(rg2_output_epi16,2);
            //	r2_output_epi16 = _mm_subs_epi16(r2_output_epi16, value128_epi32);
            //	r2_output_epi16 = _mm_slli_epi16(r2_output_epi16,1);
            //	r2_output_epi16 = _mm_adds_epi16(r2_output_epi16, g2_output_epi16);

            b2_output_epi16 = bg2_output_epi16;//_mm_srli_epi16(bg2_output_epi16,2);
            //	b2_output_epi16 = _mm_subs_epi16(b2_output_epi16, value128_epi32);
            //	b2_output_epi16 = _mm_slli_epi16(b2_output_epi16,1);
            //	b2_output_epi16 = _mm_adds_epi16(b2_output_epi16, g2_output_epi16);



            r2_output_epi16 = _mm_adds_epi16(r2_output_epi16, limiterRGB);
            r2_output_epi16 = _mm_subs_epu16(r2_output_epi16, limiterRGB);

            g2_output_epi16 = _mm_adds_epi16(g2_output_epi16, limiterRGB);
            g2_output_epi16 = _mm_subs_epu16(g2_output_epi16, limiterRGB);

            b2_output_epi16 = _mm_adds_epi16(b2_output_epi16, limiterRGB);
            b2_output_epi16 = _mm_subs_epu16(b2_output_epi16, limiterRGB);


            // Compute Y,U,V
            rgb_epi32 = _mm_unpacklo_epi16(r2_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            y1a_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
            u1a_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
            v1a_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);
            rgb_epi32 = _mm_unpackhi_epi16(r2_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            y1b_ps = _mm_mul_ps(_mm_set_ps1(fy_rmult), rgb_ps);
            u1b_ps = _mm_mul_ps(_mm_set_ps1(fu_rmult), rgb_ps);
            v1b_ps = _mm_mul_ps(_mm_set_ps1(fv_rmult), rgb_ps);

            rgb_epi32 = _mm_unpacklo_epi16(g2_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
            y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
            u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
            v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
            rgb_epi32 = _mm_unpackhi_epi16(g2_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_gmult), rgb_ps);
            y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_gmult), rgb_ps);
            u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_gmult), rgb_ps);
            v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

            rgb_epi32 = _mm_unpacklo_epi16(b2_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
            y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
            u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
            v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
            rgb_epi32 = _mm_unpackhi_epi16(b2_output_epi16, zero_epi128);
            rgb_ps = _mm_cvtepi32_ps(rgb_epi32);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fy_bmult), rgb_ps);
            y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fu_bmult), rgb_ps);
            u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
            temp_ps = _mm_mul_ps(_mm_set_ps1(fv_bmult), rgb_ps);
            v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

            temp_ps = _mm_set_ps1(fy_offset);
            y1a_ps = _mm_add_ps(y1a_ps, temp_ps);
            y1b_ps = _mm_add_ps(y1b_ps, temp_ps);
            temp_ps = _mm_set_ps1(fu_offset);
            u1a_ps = _mm_add_ps(u1a_ps, temp_ps);
            u1b_ps = _mm_add_ps(u1b_ps, temp_ps);
            temp_ps = _mm_set_ps1(fv_offset);
            v1a_ps = _mm_add_ps(v1a_ps, temp_ps);
            v1b_ps = _mm_add_ps(v1b_ps, temp_ps);

            temp_epi32 = _mm_cvtps_epi32(y1a_ps);
            tempB_epi32 = _mm_cvtps_epi32(y1b_ps);
            y2_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
            y2_output_epi16 = _mm_adds_epi16(y2_output_epi16, limiter);
            y2_output_epi16 = _mm_subs_epu16(y2_output_epi16, limiter);
            y2_output_epi16 = _mm_srli_epi16(y2_output_epi16, shift);

            temp_epi32 = _mm_cvtps_epi32(u1a_ps);
            tempB_epi32 = _mm_cvtps_epi32(u1b_ps);
            u2_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
            u2_output_epi16 = _mm_adds_epi16(u2_output_epi16, limiter);
            u2_output_epi16 = _mm_subs_epu16(u2_output_epi16, limiter);
            u2_output_epi16 = _mm_srli_epi16(u2_output_epi16, shift);

            temp_epi32 = _mm_cvtps_epi32(v1a_ps);
            tempB_epi32 = _mm_cvtps_epi32(v1b_ps);
            v2_output_epi16 = _mm_packs_epi32(temp_epi32, tempB_epi32);
            v2_output_epi16 = _mm_adds_epi16(v2_output_epi16, limiter);
            v2_output_epi16 = _mm_subs_epu16(v2_output_epi16, limiter);
            v2_output_epi16 = _mm_srli_epi16(v2_output_epi16, shift);


            // 4:4:4 to 4:2:2
            temp_epi16 = _mm_srli_si128(u1_output_epi16, 2);
            u1_output_epi16 = _mm_adds_epi16(u1_output_epi16, temp_epi16);
            u1_output_epi16 = _mm_srli_epi16(u1_output_epi16, 1);
            temp_epi16 = _mm_srli_si128(u2_output_epi16, 2);
            u2_output_epi16 = _mm_adds_epi16(u2_output_epi16, temp_epi16);
            u2_output_epi16 = _mm_srli_epi16(u2_output_epi16, 1);
            temp_epi16 = _mm_srli_si128(v1_output_epi16, 2);
            v1_output_epi16 = _mm_adds_epi16(v1_output_epi16, temp_epi16);
            v1_output_epi16 = _mm_srli_epi16(v1_output_epi16, 1);
            temp_epi16 = _mm_srli_si128(v2_output_epi16, 2);
            v2_output_epi16 = _mm_adds_epi16(v2_output_epi16, temp_epi16);
            v2_output_epi16 = _mm_srli_epi16(v2_output_epi16, 1);
            u1_output_epi16 = _mm_and_si128(u1_output_epi16, mask_epi32);
            u2_output_epi16 = _mm_and_si128(u2_output_epi16, mask_epi32);
            v1_output_epi16 = _mm_and_si128(v1_output_epi16, mask_epi32);
            v2_output_epi16 = _mm_and_si128(v2_output_epi16, mask_epi32);

            u1_output_epi16 = _mm_packs_epi32 (u1_output_epi16, u2_output_epi16);
            v1_output_epi16 = _mm_packs_epi32 (v1_output_epi16, v2_output_epi16);



            /***** Interleave the luma and chroma values *****/

            // Interleave the first four values from each chroma channel
            urg_epi16 = _mm_unpacklo_epi16(u1_output_epi16, v1_output_epi16);

            // Interleave the first eight chroma values with the first eight luma values
            yuv1_epi16 = _mm_unpacklo_epi16(y1_output_epi16, urg_epi16);
            yuv2_epi16 = _mm_unpackhi_epi16(y1_output_epi16, urg_epi16);

            // Pack the first sixteen bytes of luma and chroma
            yuv1_epi8 = _mm_packus_epi16(yuv1_epi16, yuv2_epi16);

            // Store the first sixteen bytes of output values
            _mm_store_si128(outptr++, yuv1_epi8);

            // Interleave the second four values from each chroma channel
            urg_epi16 = _mm_unpackhi_epi16(u1_output_epi16, v1_output_epi16);

            // Interleave the second eight chroma values with the second eight luma values
            yuv1_epi16 = _mm_unpacklo_epi16(y2_output_epi16, urg_epi16);
            yuv2_epi16 = _mm_unpackhi_epi16(y2_output_epi16, urg_epi16);

            // Pack the second sixteen bytes of luma and chroma
            yuv2_epi8 = _mm_packus_epi16(yuv1_epi16, yuv2_epi16);

            // Store the second sixteen bytes of output values
            _mm_store_si128(outptr++, yuv2_epi8);

        }

        // Should have exited the loop with the column equal to the post processing column
        //	assert(column == post_column);

        colptr = (uint8_t *)outptr;
#endif

        // Process the rest of the columns up to the last column in the row
        for (; column < last_column; column ++)
        {
            int re, ge, be;
            int ro, go, bo;
            int ye, yo, u, v;


            /***** First pair of luma output values *****/

            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += gg_lowpass_ptr[column - 1];
            even -= gg_lowpass_ptr[column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += gg_lowpass_ptr[column + 0];

            // Add the highpass correction
            even += gg_highpass_ptr[column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            //	even >>= descale_shift;

            // Save the luma result for later output in the correct order
            //	y1_even_value = even;
            ge = even;

            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= gg_lowpass_ptr[column - 1];
            odd += gg_lowpass_ptr[column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += gg_lowpass_ptr[column + 0];

            // Subtract the highpass correction
            odd -= gg_highpass_ptr[column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            //	odd >>= descale_shift;

            // Save the luma result for later output in the correct order
            //	y1_odd_value = odd;
            go = odd;


            /***** Pair of u chroma output values *****/

            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += bg_lowpass_ptr[column - 1];
            even -= bg_lowpass_ptr[column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += bg_lowpass_ptr[column + 0];

            // Add the highpass correction
            even += bg_highpass_ptr[column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            //	even >>= descale_shift;

            // Save the u chroma result for later output in the correct order
            //	bg_even_value = even;
            be = even;

            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= bg_lowpass_ptr[column - 1];
            odd += bg_lowpass_ptr[column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += bg_lowpass_ptr[column + 0];

            // Subtract the highpass correction
            odd -= bg_highpass_ptr[column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            //	odd >>= descale_shift;

            // Save the u chroma result for later output in the correct order
            //	bg_odd_value = odd;
            bo = odd;



            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += rg_lowpass_ptr[column - 1];
            even -= rg_lowpass_ptr[column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += rg_lowpass_ptr[column + 0];

            // Add the highpass correction
            even += rg_highpass_ptr[column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            //	even >>= descale_shift;

            // Save the v chroma result for later output in the correct order
            //	rg_even_value = even;
            re = even;

            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= rg_lowpass_ptr[column - 1];
            odd += rg_lowpass_ptr[column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += rg_lowpass_ptr[column + 0];

            // Subtract the highpass correction
            odd -= rg_highpass_ptr[column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            //	odd >>= descale_shift;

            // Save the v chroma result for later output in the correct order
            //	rg_odd_value = odd;
            ro = odd;


            // We use 16-bit fixed-point arithmetic to approximate the color conversion coefficients
            //
            // Floating point arithmetic is
            //
            ye = ((int)((fy_rmult * (float)re + fy_gmult * (float)ge + fy_bmult * (float)be)) >> (descale_shift + 6)) + 16;
            yo = ((int)((fy_rmult * (float)ro + fy_gmult * (float)go + fy_bmult * (float)bo)) >> (descale_shift + 6)) + 16;
            u  = ((int)((fu_rmult * (float)(re + ro) + fu_gmult * (float)(ge + go) + fu_bmult * (float)(be + bo))) >> (1 + descale_shift + 6)) + 128;
            v  = ((int)((fv_rmult * (float)(re + ro) + fv_gmult * (float)(ge + go) + fv_bmult * (float)(be + bo))) >> (1 + descale_shift + 6)) + 128;

            // Output the luma and chroma values in the correct order
            *(colptr++) = SATURATE_8U(ye);
            *(colptr++) = SATURATE_8U(u);
            *(colptr++) = SATURATE_8U(yo);
            *(colptr++) = SATURATE_8U(v);
        }

        // Should have exited the loop at the column for right border processing
        //	assert(column == last_column);
        /*

        		column = last_column - 1;
        		colptr -= 4;

        		// Process the last luma output points with special filters for the right border
        		even = 0;
        		odd = 0;

        		// Apply the even border filter to the lowpass band
        		even += 5 * gg_lowpass_ptr[column + 0];
        		even += 4 * gg_lowpass_ptr[column - 1];
        		even -= 1 * gg_lowpass_ptr[column - 2];
        		even += ROUNDING(even,8);
        		even = DivideByShift(even, 3);

        		// Add the highpass correction
        		even += gg_highpass_ptr[column];
        		even = DivideByShift(even, 1);

        		// Reduce the precision to eight bits
        		//even >>= descale_shift;

        		// Save the luma result for later output in the correct order
        		gg_even_value = even;

        		// Apply the odd border filter to the lowpass band
        		odd += 11 * gg_lowpass_ptr[column + 0];
        		odd -=  4 * gg_lowpass_ptr[column - 1];
        		odd +=  1 * gg_lowpass_ptr[column - 2];
        		odd += ROUNDING(odd,8);
        		odd = DivideByShift(odd, 3);

        		// Subtract the highpass correction
        		odd -= gg_highpass_ptr[column];
        		odd = DivideByShift(odd, 1);

        		// Reduce the precision to eight bits
        		//odd >>= descale_shift;

        		// Save the luma result for later output in the correct order
        		gg_odd_value = odd;

        		// Process the last u chroma output points with special filters for the right border
        		even = 0;
        		odd = 0;

        		// Apply the even border filter to the lowpass band
        		even += 5 * bg_lowpass_ptr[column + 0];
        		even += 4 * bg_lowpass_ptr[column - 1];
        		even -= 1 * bg_lowpass_ptr[column - 2];
        		even += ROUNDING(even,8);
        		even = DivideByShift(even, 3);

        		// Add the highpass correction
        		even += bg_highpass_ptr[column];
        		even = DivideByShift(even, 1);

        		// Reduce the precision to eight bits
        		//even >>= descale_shift;

        		// Save the u chroma result for later output in the correct order
        		bg_even_value = even;

        		// Apply the odd reconstruction filter to the lowpass band
        		odd += 11 * bg_lowpass_ptr[column + 0];
        		odd -=  4 * bg_lowpass_ptr[column - 1];
        		odd +=  1 * bg_lowpass_ptr[column - 2];
        		odd += ROUNDING(odd,8);
        		odd = DivideByShift(odd, 3);

        		// Subtract the highpass correction
        		odd -= bg_highpass_ptr[column];
        		odd = DivideByShift(odd, 1);

        		// Reduce the precision to eight bits
        		//odd >>= descale_shift;

        		// Save the u chroma result for later output in the correct order
        		bg_odd_value = odd;

        		// Process the last v chroma output points with special filters for the right border
        		even = 0;
        		odd = 0;

        		// Apply the even border filter to the lowpass band
        		even += 5 * rg_lowpass_ptr[column + 0];
        		even += 4 * rg_lowpass_ptr[column - 1];
        		even -= 1 * rg_lowpass_ptr[column - 2];
        		even += ROUNDING(even,8);
        		even = DivideByShift(even, 3);

        		// Add the highpass correction
        		even += rg_highpass_ptr[column];
        		even = DivideByShift(even, 1);

        		// Reduce the precision to eight bits
        		//even >>= descale_shift;

        		// Save the v chroma result for later output in the correct order
        		rg_even_value = even;

        		// Apply the odd reconstruction filter to the lowpass band
        		odd += 11 * rg_lowpass_ptr[column + 0];
        		odd -=  4 * rg_lowpass_ptr[column - 1];
        		odd +=  1 * rg_lowpass_ptr[column - 2];
        		odd += ROUNDING(odd,8);
        		odd = DivideByShift(odd, 3);

        		// Subtract the highpass correction
        		odd -= rg_highpass_ptr[column];
        		odd = DivideByShift(odd, 1);

        		// Reduce the precision to eight bits
        		//odd >>= descale_shift;

        		// Save the v chroma result for later output in the correct order
        		rg_odd_value = odd;

        		//DAN06052005 - Fix for PSNR errors in UV on right edge
        		colptr-=4;
        		colptr++; // Y fine
        		*(colptr++) = SATURATE_8U(bg_even_value);
        		colptr++; // Y2 fine
        		*(colptr++) = SATURATE_8U(rg_even_value);

        		// Output the last luma and chroma values in the correct order
        		*(colptr++) = SATURATE_8U(gg_even_value);
        		*(colptr++) = SATURATE_8U(bg_odd_value);
        		*(colptr++) = SATURATE_8U(gg_odd_value);
        		*(colptr++) = SATURATE_8U(rg_odd_value);
        */
        // Advance to the next row of coefficients in each channel
        gg_lowpass_ptr += lowpass_pitch[0];
        bg_lowpass_ptr += lowpass_pitch[1];
        rg_lowpass_ptr += lowpass_pitch[2];
        gg_highpass_ptr += highpass_pitch[0];
        bg_highpass_ptr += highpass_pitch[1];
        rg_highpass_ptr += highpass_pitch[2];

        // Advance the output pointer to the next row
        output += output_pitch;
    }

    //_mm_empty();	// Clear the mmx register state
}

void
InvertHorizontalStripYUV16sToPackedRGB32(HorizontalFilterParams)			// Target pixel format
{
    //int num_channels = CODEC_NUM_CHANNELS;
    int height = roi.height;
    int width = roi.width;

    // Note that the u and v chroma values are swapped
    PIXEL *y_lowpass_ptr = lowpass_band[0];
    PIXEL *u_lowpass_ptr = lowpass_band[2];
    PIXEL *v_lowpass_ptr = lowpass_band[1];

    PIXEL *y_highpass_ptr = highpass_band[0];
    PIXEL *u_highpass_ptr = highpass_band[2];
    PIXEL *v_highpass_ptr = highpass_band[1];

    int y_lowpass_pitch = lowpass_pitch[0];
    int u_lowpass_pitch = lowpass_pitch[2];
    int v_lowpass_pitch = lowpass_pitch[1];

    int y_highpass_pitch = highpass_pitch[0];
    int u_highpass_pitch = highpass_pitch[2];
    int v_highpass_pitch = highpass_pitch[1];

    uint8_t *output_row_ptr = output_image;

    // Process eight luma values per loop iteration
    const int column_step = 16;

    // Need to process two luma coefficients up to the last column to allow for chroma output
    const int last_column = width - 2;
    int post_column = width - (width % column_step);

    // Need enough luma and chroma values for border processing up to the last column
    const int post_border = 2;

    // Color conversion from YUV to RGB is done using the 709 color space
    int color_space = decoder->frame.colorspace;

    // Coefficients for color conversion (YUV to RGB)
    COLOR_CONVERSION conversion_data;
    COLOR_CONVERSION *conversion = &conversion_data;

    //TODO: Modify this routine to take the color conversion coefficients as an argument


    // Should the value for alpha be passed in the color conversion coefficients?
    const int alpha = 255;

    int ymult;
    int r_vmult;
    int g_umult;
    int g_vmult;
    int b_umult;
    int y_offset;
    int shift;

    int row;

    // The even and odd luma and chroma values yield two sets of RGBA values
    int r1, g1, b1;
    int r2, g2, b2;


    // Compute the shift that reduces the precision of the reconstructed values to 8 bits
    int descale_shift = (precision - 8);

    //TODO: Eliminate descaling in the inverse filter and performing descaling during color conversion

    int luma_offset;
    int chroma_offset;

    //TODO: Move the code for computing the coefficients outside of this routine
    ComputeColorCoefficientsYUVToRGB(&conversion_data, color_space);

    //TODO: Need to scale the precision of the color conversion coefficients to 8-bits if larger
    ymult = conversion->array[0][0];
    r_vmult = conversion->array[0][2];
    g_umult = conversion->array[1][1];
    g_vmult = conversion->array[1][2];
    b_umult = conversion->array[2][1];
    y_offset = conversion->array[0][3];

    // Store the scale of the coefficients
    shift = conversion->shift;

    // Adjust the luma offset for the scale of the coefficients
    //luma_offset = conversion->luma_offset << descale_shift;
    //chroma_offset = (128 << descale_shift);

    // Apply the luma and chroma offsets after descaling
    luma_offset = conversion->luma_offset;
    chroma_offset = 128;

    // Convert the lowpass and highpass pitch to units of pixels
    y_lowpass_pitch /= sizeof(PIXEL);
    u_lowpass_pitch /= sizeof(PIXEL);
    v_lowpass_pitch /= sizeof(PIXEL);

    y_highpass_pitch /= sizeof(PIXEL);
    u_highpass_pitch /= sizeof(PIXEL);
    v_highpass_pitch /= sizeof(PIXEL);

    // Convert the output pitch to units of pixels
    output_pitch /= sizeof(uint8_t);

    // Adjust the end of the fast loop if necessary for border processing
    // DAN08112004 - ignore end row calc -- use SSE to edge.
    while (post_column > (last_column - post_border))
    {
        post_column -= column_step;
    }

    // Check that there is enough margin to accommodate border processing
    assert(post_column <= (last_column - post_border));

    //*****DEBUG*****
    //post_column -= 16 * column_step;


    // Process each row of the strip
    for (row = 0; row < height; row++)
    {
#if (1 && XMMOPT)
        __m128i y_low1_epi16;		// Lowpass coefficients
        __m128i y_low2_epi16;
        __m128i u_low1_epi16;
        __m128i u_low2_epi16;
        __m128i v_low1_epi16;
        __m128i v_low2_epi16;

        __m128i y_high1_epi16;		// Highpass coefficients
        __m128i y_high2_epi16;
        __m128i u_high1_epi16;
        __m128i u_high2_epi16;
        __m128i v_high1_epi16;
        __m128i v_high2_epi16;

        // The fast loop merges values from different phases to allow aligned stores
        __m128i *output_ptr = (__m128i *)&output_row_ptr[0];

        __m128i limiterRGB = _mm_set1_epi16(0x7fff - 0x00ff);

#endif
        uint8_t *outptr = (uint8_t *)&output_row_ptr[0];

        int32_t y_even_value;
        int32_t u_even_value;
        int32_t v_even_value;
        int32_t y_odd_value;
        int32_t u_odd_value;
        int32_t v_odd_value;


        // Start processing at the beginning of the row
        int column = 0;

        // Process the first two luma output points with special filters for the left border
        int32_t even = 0;
        int32_t odd = 0;

        __m128i rounding1_epi16 = _mm_set1_epi16(0);	// for 6 bit matm
        __m128i rounding2_epi16 = _mm_set1_epi16(0);	// for 6 bit matm

        int chroma_column;

#if 0
        if (descale_shift)
        {
            //TODO: Change this code to set all values at once rather than using insert
            int mask = (1 << descale_shift) - 1;

            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 0);
            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 1);
            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 2);
            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 3);
            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 4);
            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 5);
            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 6);
            rounding1_epi16 = _mm_insert_epi16(rounding1_epi16, rand() & mask, 7);

            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 0);
            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 1);
            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 2);
            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 3);
            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 4);
            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 5);
            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 6);
            rounding2_epi16 = _mm_insert_epi16(rounding2_epi16, rand() & mask, 7);
        }
#endif

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * y_lowpass_ptr[column + 0];
        even -=  4 * y_lowpass_ptr[column + 1];
        even +=  1 * y_lowpass_ptr[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += y_highpass_ptr[column];
        even = DivideByShift(even, 1);

        // Reduce the precision to eight bits
        even >>= descale_shift;

        // Save the value for use in the fast loop
        y_even_value = even;

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * y_lowpass_ptr[column + 0];
        odd += 4 * y_lowpass_ptr[column + 1];
        odd -= 1 * y_lowpass_ptr[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= y_highpass_ptr[column];
        odd = DivideByShift(odd, 1);

        // Reduce the precision to eight bits
        odd >>= descale_shift;

        // Save the value for use in the fast loop
        y_odd_value = odd;


        // Process the first two u chroma output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * u_lowpass_ptr[column + 0];
        even -=  4 * u_lowpass_ptr[column + 1];
        even +=  1 * u_lowpass_ptr[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += u_highpass_ptr[column];
        even = DivideByShift(even, 1);

        // Reduce the precision to eight bits
        even >>= descale_shift;

        // Save the value for use in the fast loop
        u_even_value = even;

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * u_lowpass_ptr[column + 0];
        odd += 4 * u_lowpass_ptr[column + 1];
        odd -= 1 * u_lowpass_ptr[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= u_highpass_ptr[column];
        odd = DivideByShift(odd, 1);

        // Reduce the precision to eight bits
        odd >>= descale_shift;

        // Save the value for use in the fast loop
        u_odd_value = odd;


        // Process the first two v chroma output points with special filters for the left border
        even = 0;
        odd = 0;

        // Apply the even reconstruction filter to the lowpass band
        even += 11 * v_lowpass_ptr[column + 0];
        even -=  4 * v_lowpass_ptr[column + 1];
        even +=  1 * v_lowpass_ptr[column + 2];
        even += ROUNDING(even, 8);
        even = DivideByShift(even, 3);

        // Add the highpass correction
        even += v_highpass_ptr[column];
        even = DivideByShift(even, 1);

        // Reduce the precision to eight bits
        even >>= descale_shift;

        // Save the value for use in the fast loop
        v_even_value = even;

        // Apply the odd reconstruction filter to the lowpass band
        odd += 5 * v_lowpass_ptr[column + 0];
        odd += 4 * v_lowpass_ptr[column + 1];
        odd -= 1 * v_lowpass_ptr[column + 2];
        odd += ROUNDING(odd, 8);
        odd = DivideByShift(odd, 3);

        // Subtract the highpass correction
        odd -= v_highpass_ptr[column];
        odd = DivideByShift(odd, 1);

        // Reduce the precision to eight bits
        odd >>= descale_shift;

        // Save the value for use in the fast loop
        v_odd_value = odd;

#if (1 && XMMOPT)

        // Preload the first eight lowpass luma coefficients
        y_low1_epi16 = _mm_load_si128((__m128i *)&y_lowpass_ptr[0]);

        // Preload the first eight highpass luma coefficients
        y_high1_epi16 = _mm_load_si128((__m128i *)&y_highpass_ptr[0]);

        // Preload the first eight lowpass u chroma coefficients
        u_low1_epi16 = _mm_load_si128((__m128i *)&u_lowpass_ptr[0]);

        // Preload the first eight highpass u chroma coefficients
        u_high1_epi16 = _mm_load_si128((__m128i *)&u_highpass_ptr[0]);

        // Preload the first eight lowpass v chroma coefficients
        v_low1_epi16 = _mm_load_si128((__m128i *)&v_lowpass_ptr[0]);

        // Preload the first eight highpass v chroma coefficients
        v_high1_epi16 = _mm_load_si128((__m128i *)&v_highpass_ptr[0]);


        // The reconstruction filters use pixels starting at the first column
        for (; column < post_column; column += column_step)
        {
            __m128i y1_output_epi16;
            __m128i y2_output_epi16;
            __m128i u1_output_epi16;
            __m128i u2_output_epi16;
            __m128i y3_output_epi16;
            __m128i y4_output_epi16;
            __m128i v1_output_epi16;
            __m128i v2_output_epi16;

            __m128i even_epi16;		// Result of convolution with even filter
            __m128i odd_epi16;		// Result of convolution with odd filter

            __m128i temp_epi16;

            __m128i yy_epi16;
            __m128i uu_epi16;
            __m128i vv_epi16;

            __m128i out_epi16;		// Reconstructed data

            __m128i low1_epi16;
            __m128i low2_epi16;
            __m128i high1_epi16;
            __m128i high2_epi16;

            //DAN031304 -- correct inverse filter
            __m128i half_epi16 = _mm_set1_epi16(4);
            __m128i offset_epi16 = _mm_set1_epi16(2048);

            __m128i r1_epi16;
            __m128i g1_epi16;
            __m128i b1_epi16;

            __m128i r2_epi16;
            __m128i g2_epi16;
            __m128i b2_epi16;

            __m128i t1_epi16;
            __m128i t2_epi16;

            __m128i r_epi8;
            __m128i g_epi8;
            __m128i b_epi8;

            __m128i luma_offset_epi16 = _mm_set1_epi16(luma_offset);
            __m128i chroma_offset_epi16 = _mm_set1_epi16(chroma_offset);

            __m128i alpha_epi8 = _mm_set1_epi8(alpha);

            __m128i rg_epi8;
            __m128i ba_epi8;
            __m128i rgba_epi8;

            __m128i rounding_epi16 = _mm_set1_epi16(32);	// 6 bit half

            uint32_t temp;		// Temporary register for last two values

            // Chroma is 4:2:2 subsampled relative to the overall image
            chroma_column = column / 2;


            /***** Compute the first eight luma output values *****/

            // Preload the next eight lowpass coefficients
            y_low2_epi16 = _mm_load_si128((__m128i *)&y_lowpass_ptr[column + 8]);

            // Preload the next eight highpass coefficients
            y_high2_epi16 = _mm_load_si128((__m128i *)&y_highpass_ptr[column + 8]);

            // Move the current set of luma values to the working registers
            low1_epi16 = y_low1_epi16;
            high1_epi16 = y_high1_epi16;

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift the highpass correction by one column
            high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

            // Save the eight luma values for packing later
            y1_output_epi16 = out_epi16;

            // Save the remaining two output values
            y_even_value = (short)temp;
            y_odd_value = (short)(temp >> 16);


            /***** Compute the second eight luma output values *****/

            // Move the next set of luma values to the working registers
            low2_epi16 = y_low2_epi16;
            high2_epi16 = y_high2_epi16;

            // Shift in the new pixels for the next stage of the loop
            low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
            low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift in the next four highpass coefficients
            high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
            high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

            // Save the eight luma values for packing later
            y2_output_epi16 = out_epi16;

            // Save the remaining two output values
            y_even_value = (short)temp;
            y_odd_value = (short)(temp >> 16);

            // Use the second eight lowpass and highpass coefficients later in this loop
            y_low1_epi16 = y_low2_epi16;
            y_high1_epi16 = y_high2_epi16;


            /***** Compute the first eight u chroma output values *****/

            // Preload the next eight lowpass coefficients
            u_low2_epi16 = _mm_load_si128((__m128i *)&u_lowpass_ptr[chroma_column + 8]);

            // Preload the next eight highpass coefficients
            u_high2_epi16 = _mm_load_si128((__m128i *)&u_highpass_ptr[chroma_column + 8]);

            // Move the current set of chroma values to the working registers
            low1_epi16 = u_low1_epi16;
            high1_epi16 = u_high1_epi16;

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift the highpass correction by one column
            high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, u_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, u_odd_value, 1);

            // Save the eight u chroma values for packing later
            u1_output_epi16 = out_epi16;

            // Save the remaining two output values
            u_even_value = (short)temp;
            u_odd_value = (short)(temp >> 16);


            /***** Compute the second eight u chroma output values *****/

            // Move the next set of coefficients to working registers
            low2_epi16 = u_low2_epi16;
            high2_epi16 = u_high2_epi16;

            // Shift in the new pixels for the next stage of the loop
            low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
            low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift in the next four highpass coefficients
            high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
            high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, u_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, u_odd_value, 1);

            // Save the eight u chroma values for packing later
            u2_output_epi16 = out_epi16;

            // Save the remaining two output values
            u_even_value = (short)temp;
            u_odd_value = (short)(temp >> 16);

            // Use the second eight lowpass and highpass coefficients in the next iteration
            u_low1_epi16 = u_low2_epi16;
            u_high1_epi16 = u_high2_epi16;


            /***** Compute the third eight luma output values *****/

            // Preload the next eight lowpass coefficients
            y_low2_epi16 = _mm_load_si128((__m128i *)&y_lowpass_ptr[column + 16]);

            // Preload the second eight highpass coefficients
            y_high2_epi16 = _mm_load_si128((__m128i *)&y_highpass_ptr[column + 16]);

            // Move the current set of luma values to the working registers
            low1_epi16 = y_low1_epi16;
            high1_epi16 = y_high1_epi16;

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift the highpass correction by one column
            high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

            // Save the eight luma values for packing later
            y3_output_epi16 = out_epi16;

            // Save the remaining two output values
            y_even_value = (short)temp;
            y_odd_value = (short)(temp >> 16);


            /***** Compute the fourth eight luma output values *****/

            // Move the next set of luma values to the working registers
            low2_epi16 = y_low2_epi16;
            high2_epi16 = y_high2_epi16;

            // Shift in the new pixels for the next stage of the loop
            low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
            low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift in the next four highpass coefficients
            high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
            high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, y_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, y_odd_value, 1);

            // Save the eight luma values for packing later
            y4_output_epi16 = out_epi16;

            // Save the remaining two output values
            y_even_value = (short)temp;
            y_odd_value = (short)(temp >> 16);

            // Use the second eight lowpass and highpass coefficients in the next iteration
            y_low1_epi16 = y_low2_epi16;
            y_high1_epi16 = y_high2_epi16;


            /***** Compute the first eight v chroma output values *****/

            // Preload the next eight lowpass coefficients
            v_low2_epi16 = _mm_load_si128((__m128i *)&v_lowpass_ptr[chroma_column + 8]);

            // Preload the next eight highpass coefficients
            v_high2_epi16 = _mm_load_si128((__m128i *)&v_highpass_ptr[chroma_column + 8]);

            // Move the current set of coefficients to working registers
            low1_epi16 = v_low1_epi16;
            high1_epi16 = v_high1_epi16;

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift the highpass correction by one column
            high1_epi16 = _mm_srli_si128(high1_epi16, 1 * 2);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding1_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, v_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, v_odd_value, 1);

            // Save the eight v chroma values for packing later
            v1_output_epi16 = out_epi16;

            // Save the remaining two output values
            v_even_value = (short)temp;
            v_odd_value = (short)(temp >> 16);


            /***** Compute the second eight v chroma output values *****/

            // Move the next set of coefficients to working registers
            low2_epi16 = v_low2_epi16;
            high2_epi16 = v_high2_epi16;

            // Shift in the new pixels for the next stage of the loop
            low1_epi16 = _mm_srli_si128(low1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(low2_epi16, 4 * 2);
            low1_epi16 = _mm_or_si128(low1_epi16, temp_epi16);

            // Apply the even reconstruction filter to the lowpass band
            even_epi16 = low1_epi16;
            temp_epi16 = _mm_srli_si128(even_epi16, 2 * 2);
            even_epi16 = _mm_subs_epi16(even_epi16, temp_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            even_epi16 = _mm_adds_epi16(even_epi16, temp_epi16);

            // Shift in the next four highpass coefficients
            high1_epi16 = _mm_srli_si128(high1_epi16, 4 * 2);
            temp_epi16 = _mm_slli_si128(high2_epi16, 3 * 2);
            high1_epi16 = _mm_or_si128(high1_epi16, temp_epi16);

            // Add the highpass correction and divide by two
            even_epi16 = _mm_adds_epi16(even_epi16, offset_epi16);
            even_epi16 = _mm_adds_epi16(even_epi16, high1_epi16);
            even_epi16 = _mm_subs_epu16(even_epi16, offset_epi16);
            even_epi16 = _mm_srai_epi16(even_epi16, 1);

            // Apply the odd reconstruction filter to the lowpass band
            odd_epi16 = _mm_srli_si128(low1_epi16, 2 * 2);
            temp_epi16 = low1_epi16;
            odd_epi16 = _mm_subs_epi16(odd_epi16, temp_epi16);
            odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 3);
            temp_epi16 = _mm_srli_si128(low1_epi16, 1 * 2);
            odd_epi16 = _mm_adds_epi16(odd_epi16, temp_epi16);

            // Subtract the highpass correction and divide by two
            odd_epi16 = _mm_adds_epi16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_subs_epi16(odd_epi16, high1_epi16);
            odd_epi16 = _mm_subs_epu16(odd_epi16, offset_epi16);
            odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

            // Interleave the four even and four odd results
            out_epi16 = _mm_unpacklo_epi16(even_epi16, odd_epi16);

            // Reduce the precision to eight bits
            out_epi16 = _mm_adds_epi16(out_epi16, rounding2_epi16);
            out_epi16 = _mm_srli_epi16(out_epi16, descale_shift);

            // Combine the new output values with the two values from the previous phase
            out_epi16 = _mm_shuffle_epi32(out_epi16, _MM_SHUFFLE(2, 1, 0, 3));
            temp = _mm_cvtsi128_si32(out_epi16);
            out_epi16 = _mm_insert_epi16(out_epi16, v_even_value, 0);
            out_epi16 = _mm_insert_epi16(out_epi16, v_odd_value, 1);

            // Save the eight u chroma values for packing later
            v2_output_epi16 = out_epi16;

            // Save the remaining two output values
            v_even_value = (short)temp;
            v_odd_value = (short)(temp >> 16);

            // Use the second eight lowpass and highpass coefficients in the next iteration
            v_low1_epi16 = v_low2_epi16;
            v_high1_epi16 = v_high2_epi16;


            /***** Have computed 32 luma values and 16 of each chroma value *****/

#if (0 && DEBUG)
            u1_output_epi16 = chroma_offset_epi16;
            u2_output_epi16 = chroma_offset_epi16;
            v1_output_epi16 = chroma_offset_epi16;
            v2_output_epi16 = chroma_offset_epi16;
#endif

            /***** Compute the first set of eight RGBA output values *****/

            // Duplicate the first four chroma values
            uu_epi16 = _mm_unpacklo_epi16(u1_output_epi16, u1_output_epi16);
            vv_epi16 = _mm_unpacklo_epi16(v1_output_epi16, v1_output_epi16);

            // Convert YUV to eight RGB tuples
            yy_epi16 = _mm_subs_epi16(y1_output_epi16, luma_offset_epi16);

            // This code fixed overflow case where very bright pixels
            // with some color produced interim values larger than 32768

            yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
            yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
            uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
            uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
            vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
            vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

            uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
            vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

            yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
            yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
            yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

            // Calculate red
            t1_epi16 = _mm_set1_epi16(r_vmult);
            t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
            t1_epi16 = _mm_srai_epi16(t1_epi16, 1);		// 7 bits to 6 bits
            r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
            //r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
            r1_epi16 = _mm_adds_epi16(r1_epi16, rounding_epi16);
            r1_epi16 = _mm_srai_epi16(r1_epi16, 6);

            // Calculate green
            t1_epi16 = _mm_set1_epi16(g_vmult);
            t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
            t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
            g1_epi16 = _mm_subs_epi16(yy_epi16, t1_epi16);
            t1_epi16 = _mm_set1_epi16(g_umult);
            t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
            t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
            g1_epi16 = _mm_subs_epi16(g1_epi16, t1_epi16);
            g1_epi16 = _mm_adds_epi16(g1_epi16, rounding_epi16);
            g1_epi16 = _mm_srai_epi16(g1_epi16, 6);

            // Calculate blue
            t1_epi16 = _mm_set1_epi16(b_umult);
            t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
            b1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
            b1_epi16 = _mm_adds_epi16(b1_epi16, rounding_epi16);
            b1_epi16 = _mm_srai_epi16(b1_epi16, 6);


            /***** Compute the second set of eight RGBA output values *****/

            // Duplicate the second four chroma values
            uu_epi16 = _mm_unpackhi_epi16(u1_output_epi16, u1_output_epi16);
            vv_epi16 = _mm_unpackhi_epi16(v1_output_epi16, v1_output_epi16);

            // Convert YUV to eight RGB tuples
            yy_epi16 = _mm_subs_epi16(y2_output_epi16, luma_offset_epi16);

            yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
            yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
            uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
            uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
            vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
            vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

            uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
            vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

            // This code fixed overflow case where very bright pixels
            // with some color produced interim values larger than 32768
            yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
            yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
            yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

            // Calculate red
            t2_epi16 = _mm_set1_epi16(r_vmult);
            t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
            t2_epi16 = _mm_srai_epi16(t2_epi16, 1);		// 7 bits to 6 bits
            r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
            //r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
            r2_epi16 = _mm_adds_epi16(r2_epi16, rounding_epi16);
            r2_epi16 = _mm_srai_epi16(r2_epi16, 6);

            // Calculate green
            t2_epi16 = _mm_set1_epi16(g_vmult);
            t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
            t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
            g2_epi16 = _mm_subs_epi16(yy_epi16, t2_epi16);
            t2_epi16 = _mm_set1_epi16(g_umult);
            t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
            t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
            g2_epi16 = _mm_subs_epi16(g2_epi16, t2_epi16);
            g2_epi16 = _mm_adds_epi16(g2_epi16, rounding_epi16);
            g2_epi16 = _mm_srai_epi16(g2_epi16, 6);

            // Calculate blue
            t2_epi16 = _mm_set1_epi16(b_umult);
            t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
            b2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
            b2_epi16 = _mm_adds_epi16(b2_epi16, rounding_epi16);
            b2_epi16 = _mm_srai_epi16(b2_epi16, 6);


            /**** Pack and store the first sixteen RGBA tuples *****/

            // Pack the RGBA values
            r_epi8 = _mm_packus_epi16(b1_epi16, b2_epi16);		// Swapped with red
            g_epi8 = _mm_packus_epi16(g1_epi16, g2_epi16);
            b_epi8 = _mm_packus_epi16(r1_epi16, r2_epi16);		// Swapped with blue

            // Interleave the first eight red and green values
            rg_epi8 = _mm_unpacklo_epi8(r_epi8, g_epi8);

            // Interleave the first eight blue values with alpha
            ba_epi8 = _mm_unpacklo_epi8(b_epi8, alpha_epi8);

            // Interleave the first set of four RGBA tuples
            rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

            // Store the first set of four RGBA tuples
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);

            // Interleave the second set of four RGBA tuples
            rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

            // Store the second set of four RGBA tuples
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);

            // Interleave the second eight red and green values
            rg_epi8 = _mm_unpackhi_epi8(r_epi8, g_epi8);

            // Interleave the second eight blue values with alpha
            ba_epi8 = _mm_unpackhi_epi8(b_epi8, alpha_epi8);

            // Interleave the third set of four RGBA tuples
            rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

            // Store the third set of four RGBA tuples
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);

            // Interleave the fourth set of four RGBA tuples
            rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

            // Store the fourth set of four RGBA values
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);


            /***** Compute the third set of eight RGBA output values *****/

            // Duplicate the first four chroma values
            uu_epi16 = _mm_unpacklo_epi16(u2_output_epi16, u2_output_epi16);
            vv_epi16 = _mm_unpacklo_epi16(v2_output_epi16, v2_output_epi16);

            // Convert YUV to eight RGB tuples
            yy_epi16 = _mm_subs_epi16(y3_output_epi16, luma_offset_epi16);

            yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
            yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
            uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
            uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
            vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
            vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

            uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
            vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

            // This code fixed overflow case where very bright pixels
            // with some color produced interim values larger than 32768
            yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
            yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
            yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

            // Calculate red
            t1_epi16 = _mm_set1_epi16(r_vmult);
            t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
            t1_epi16 = _mm_srai_epi16(t1_epi16, 1);		// 7 bits to 6 bits
            r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
            //r1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
            r1_epi16 = _mm_adds_epi16(r1_epi16, rounding_epi16);
            r1_epi16 = _mm_srai_epi16(r1_epi16, 6);

            // Calculate green
            t1_epi16 = _mm_set1_epi16(g_vmult);
            t1_epi16 = _mm_mullo_epi16(vv_epi16, t1_epi16);
            t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
            g1_epi16 = _mm_subs_epi16(yy_epi16, t1_epi16);
            t1_epi16 = _mm_set1_epi16(g_umult);
            t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
            t1_epi16 = _mm_srai_epi16(t1_epi16, 2);		// 8 bits to 6 bits
            g1_epi16 = _mm_subs_epi16(g1_epi16, t1_epi16);
            g1_epi16 = _mm_adds_epi16(g1_epi16, rounding_epi16);
            g1_epi16 = _mm_srai_epi16(g1_epi16, 6);

            // Calculate blue
            t1_epi16 = _mm_set1_epi16(b_umult);
            t1_epi16 = _mm_mullo_epi16(uu_epi16, t1_epi16);
            b1_epi16 = _mm_adds_epi16(yy_epi16, t1_epi16);
            b1_epi16 = _mm_adds_epi16(b1_epi16, rounding_epi16);
            b1_epi16 = _mm_srai_epi16(b1_epi16, 6);


            /***** Compute the fourth set of eight RGBA output values *****/

            // Duplicate the second four chroma values
            uu_epi16 = _mm_unpackhi_epi16(u2_output_epi16, u2_output_epi16);
            vv_epi16 = _mm_unpackhi_epi16(v2_output_epi16, v2_output_epi16);

            // Convert YUV to eight RGB tuples
            yy_epi16 = _mm_subs_epi16(y4_output_epi16, luma_offset_epi16);

            yy_epi16 = _mm_adds_epi16(yy_epi16, limiterRGB); // Y to 0 to 255  -- DAN20101102
            yy_epi16 = _mm_subs_epu16(yy_epi16, limiterRGB);
            uu_epi16 = _mm_adds_epi16(uu_epi16, limiterRGB); // U to 0 to 255  -- DAN20101102
            uu_epi16 = _mm_subs_epu16(uu_epi16, limiterRGB);
            vv_epi16 = _mm_adds_epi16(vv_epi16, limiterRGB); // V to 0 to 255  -- DAN20101102
            vv_epi16 = _mm_subs_epu16(vv_epi16, limiterRGB);

            uu_epi16 = _mm_subs_epi16(uu_epi16, chroma_offset_epi16);
            vv_epi16 = _mm_subs_epi16(vv_epi16, chroma_offset_epi16);

            // This code fixed overflow case where very bright pixels
            // with some color produced interim values larger than 32768
            yy_epi16 = _mm_slli_epi16(yy_epi16, 7);
            yy_epi16 = _mm_mulhi_epi16(yy_epi16, _mm_set1_epi16(ymult));
            yy_epi16 = _mm_slli_epi16(yy_epi16, 1);

            // Calculate red
            t2_epi16 = _mm_set1_epi16(r_vmult);
            t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
            t2_epi16 = _mm_srai_epi16(t2_epi16, 1);		// 7 bits to 6 bits
            r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
            //r2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
            r2_epi16 = _mm_adds_epi16(r2_epi16, rounding_epi16);
            r2_epi16 = _mm_srai_epi16(r2_epi16, 6);

            // Calculate green
            t2_epi16 = _mm_set1_epi16(g_vmult);
            t2_epi16 = _mm_mullo_epi16(vv_epi16, t2_epi16);
            t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
            g2_epi16 = _mm_subs_epi16(yy_epi16, t2_epi16);
            t2_epi16 = _mm_set1_epi16(g_umult);
            t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
            t2_epi16 = _mm_srai_epi16(t2_epi16, 2);		// 8 bits to 6 bits
            g2_epi16 = _mm_subs_epi16(g2_epi16, t2_epi16);
            g2_epi16 = _mm_adds_epi16(g2_epi16, rounding_epi16);
            g2_epi16 = _mm_srai_epi16(g2_epi16, 6);

            // Calculate blue
            t2_epi16 = _mm_set1_epi16(b_umult);
            t2_epi16 = _mm_mullo_epi16(uu_epi16, t2_epi16);
            b2_epi16 = _mm_adds_epi16(yy_epi16, t2_epi16);
            b2_epi16 = _mm_adds_epi16(b2_epi16, rounding_epi16);
            b2_epi16 = _mm_srai_epi16(b2_epi16, 6);


            /**** Pack and store the second sixteen RGBA tuples *****/

            // Pack the RGBA values
            r_epi8 = _mm_packus_epi16(b1_epi16, b2_epi16);		// Swapped with red
            g_epi8 = _mm_packus_epi16(g1_epi16, g2_epi16);
            b_epi8 = _mm_packus_epi16(r1_epi16, r2_epi16);		// Swapped with blue

            // Interleave the first eight red and green values
            rg_epi8 = _mm_unpacklo_epi8(r_epi8, g_epi8);

            // Interleave the first eight blue values with alpha
            ba_epi8 = _mm_unpacklo_epi8(b_epi8, alpha_epi8);

            // Interleave the first set of four RGBA tuples
            rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

            // Store the first set of four RGBA tuples
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);

            // Interleave the second set of four RGBA tuples
            rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

            // Store the second set of four RGBA tuples
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);

            // Interleave the second eight red and green values
            rg_epi8 = _mm_unpackhi_epi8(r_epi8, g_epi8);

            // Interleave the second eight blue values with alpha
            ba_epi8 = _mm_unpackhi_epi8(b_epi8, alpha_epi8);

            // Interleave the third set of four RGBA tuples
            rgba_epi8 = _mm_unpacklo_epi16(rg_epi8, ba_epi8);

            // Store the third set of four RGBA tuples
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);

            // Interleave the fourth set of four RGBA tuples
            rgba_epi8 = _mm_unpackhi_epi16(rg_epi8, ba_epi8);

            // Store the fourth set of four RGBA values
            //*(output_ptr++) = rgba_epi8;
            _mm_storeu_si128(output_ptr++, rgba_epi8);
        }

        // Should have exited the loop with the column equal to the post processing column
        assert(column == post_column);

        outptr = (uint8_t *)output_ptr;
#endif
        // Have already computed the next luma and chroma output values

        // Process the rest of the columns up to the last column in the row
        for (; column < last_column; column++)
        {
            int y1_even_value;
            int y2_even_value;

            int y1_odd_value;
            int y2_odd_value;

            int u1_even_value;
            int v1_even_value;

            int u1_odd_value;
            int v1_odd_value;

            // Chroma is 4:2:2 subsampled relative to the overall image
            int chroma_column = column / 2;


            /***** First pair of even and odd luma values *****/

            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += y_lowpass_ptr[column - 1];
            even -= y_lowpass_ptr[column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += y_lowpass_ptr[column + 0];

            // Add the highpass correction
            even += y_highpass_ptr[column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the luma result for later output in the correct order
            y1_even_value = even;

            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= y_lowpass_ptr[column - 1];
            odd += y_lowpass_ptr[column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += y_lowpass_ptr[column + 0];

            // Subtract the highpass correction
            odd -= y_highpass_ptr[column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the luma result for later output in the correct order
            y1_odd_value = odd;


            /***** Even and odd pair of u chroma output values *****/

            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += u_lowpass_ptr[chroma_column - 1];
            even -= u_lowpass_ptr[chroma_column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += u_lowpass_ptr[chroma_column + 0];

            // Add the highpass correction
            even += u_highpass_ptr[chroma_column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the u chroma result for later output in the correct order
            u1_even_value = even;

            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= u_lowpass_ptr[chroma_column - 1];
            odd += u_lowpass_ptr[chroma_column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += u_lowpass_ptr[chroma_column + 0];

            // Subtract the highpass correction
            odd -= u_highpass_ptr[chroma_column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the u chroma result for later output in the correct order
            u1_odd_value = odd;


            /***** Even and odd pair of v chroma output values *****/

            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += v_lowpass_ptr[chroma_column - 1];
            even -= v_lowpass_ptr[chroma_column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += v_lowpass_ptr[chroma_column + 0];

            // Add the highpass correction
            even += v_highpass_ptr[chroma_column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the v chroma result for later output in the correct order
            v1_even_value = even;

            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= v_lowpass_ptr[chroma_column - 1];
            odd += v_lowpass_ptr[chroma_column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += v_lowpass_ptr[chroma_column + 0];

            // Subtract the highpass correction
            odd -= v_highpass_ptr[chroma_column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the v chroma result for later output in the correct order
            v1_odd_value = odd;

#if (0 && DEBUG)
            u1_even_value = 128;
            v1_even_value = 128;

            u1_odd_value = 128;
            v1_odd_value = 128;
#endif

            /***** Convert the first set of YUV values to RGBA *****/

            // Remove the luma and chroma offsets from the even and odd values
            y1_even_value -= luma_offset;
            u1_even_value -= chroma_offset;
            v1_even_value -= chroma_offset;

            y1_odd_value -= luma_offset;
            u1_odd_value -= chroma_offset;
            v1_odd_value -= chroma_offset;

            // Convert the even luma and chroma values to RGBA
            y1_even_value = (y1_even_value * ymult) >> 7;

            r1 = (y1_even_value                                   + r_vmult * v1_even_value +  64) >> 7;
            g1 = (y1_even_value * 2 -     g_umult * u1_even_value - g_vmult * v1_even_value + 128) >> 8;
            b1 = (y1_even_value     + 2 * b_umult * u1_even_value                           +  64) >> 7;

            // Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b1);
            *(outptr++) = SATURATE_8U(g1);
            *(outptr++) = SATURATE_8U(r1);
            *(outptr++) = alpha;

            // Convert the odd luma and chroma values to RGBA
            y1_odd_value = (y1_odd_value * ymult) >> 7;

            r2 = (y1_odd_value                                   + r_vmult * v1_even_value +  64) >> 7;
            g2 = (y1_odd_value * 2 -     g_umult * u1_even_value - g_vmult * v1_even_value + 128) >> 8;
            b2 = (y1_odd_value     + 2 * b_umult * u1_even_value                           +  64) >> 7;

            // Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b2);
            *(outptr++) = SATURATE_8U(g2);
            *(outptr++) = SATURATE_8U(r2);
            *(outptr++) = alpha;

            column++;

            /***** Second pair of even and odd luma values *****/

            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += y_lowpass_ptr[column - 1];
            even -= y_lowpass_ptr[column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += y_lowpass_ptr[column + 0];

            // Add the highpass correction
            even += y_highpass_ptr[column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the luma result for later output in the correct order
            y2_even_value = even;

            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= y_lowpass_ptr[column - 1];
            odd += y_lowpass_ptr[column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += y_lowpass_ptr[column + 0];

            // Subtract the highpass correction
            odd -= y_highpass_ptr[column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the luma result for later output in the correct order
            y2_odd_value = odd;


            /***** Convert the second set of YUV values to RGBA *****/

            // Remove the luma offsets from the even and odd values
            y2_even_value -= luma_offset;
            y2_odd_value -= luma_offset;

            // Convert the even luma and chroma values to RGBA
            y2_even_value = (y2_even_value * ymult) >> 7;

            r1 = (y2_even_value                                   + r_vmult * v1_odd_value +  64) >> 7;
            g1 = (y2_even_value * 2 -     g_umult * u1_odd_value  - g_vmult * v1_odd_value + 128) >> 8;
            b1 = (y2_even_value     + 2 * b_umult * u1_odd_value                           +  64) >> 7;

            // Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b1);
            *(outptr++) = SATURATE_8U(g1);
            *(outptr++) = SATURATE_8U(r1);
            *(outptr++) = alpha;

            // Convert the odd luma and chroma values to RGBA
            y2_odd_value = (y2_odd_value * ymult) >> 7;

            r2 = (y2_odd_value                                  + r_vmult * v1_odd_value +  64) >> 7;
            g2 = (y2_odd_value * 2 -     g_umult * u1_odd_value - g_vmult * v1_odd_value + 128) >> 8;
            b2 = (y2_odd_value     + 2 * b_umult * u1_odd_value                          +  64) >> 7;

            // Output the first RGBA tuple
            *(outptr++) = SATURATE_8U(b2);
            *(outptr++) = SATURATE_8U(g2);
            *(outptr++) = SATURATE_8U(r2);
            *(outptr++) = alpha;


        }

        // Should have exited the loop at the column for right border processing
        assert(column == last_column);

        {
            int last_y[4];
            int last_u[2];
            int last_v[2];

            // Apply the even reconstruction filter to the lowpass band
            even = 0;
            even += y_lowpass_ptr[column - 1];
            even -= y_lowpass_ptr[column + 1];
            even += 4; //DAN20050921
            even >>= 3;
            even += y_lowpass_ptr[column + 0];

            // Add the highpass correction
            even += y_highpass_ptr[column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the luma result for later output in the correct order
            last_y[0] = even - luma_offset;


            // Apply the odd reconstruction filter to the lowpass band
            odd = 0;
            odd -= y_lowpass_ptr[column - 1];
            odd += y_lowpass_ptr[column + 1];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += y_lowpass_ptr[column + 0];

            // Subtract the highpass correction
            odd -= y_highpass_ptr[column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the luma result for later output in the correct order
            last_y[1] = odd - luma_offset;

            column++;


            /***** Process the last column in the luma channel *****/

            // Compute the last column in the chroma channels
            chroma_column = (width / 2) - 1;

            // Process the last two output points with special filters for the right border
            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the luma lowpass band
            even += 5 * y_lowpass_ptr[column + 0];
            even += 4 * y_lowpass_ptr[column - 1];
            even -= 1 * y_lowpass_ptr[column - 2];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += y_highpass_ptr[column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the result for color conversion later
            last_y[2] = even - luma_offset;

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * y_lowpass_ptr[column + 0];
            odd -=  4 * y_lowpass_ptr[column - 1];
            odd +=  1 * y_lowpass_ptr[column - 2];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= y_highpass_ptr[column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the result for color conversion later
            last_y[3] = odd - luma_offset;


            /***** Process the last column in the u chroma channel *****/

            // Compute the last column in the chroma channels
            chroma_column = (width / 2) - 1;

            // Process the last two output points with special filters for the right border
            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the luma lowpass band
            even += 5 * u_lowpass_ptr[chroma_column + 0];
            even += 4 * u_lowpass_ptr[chroma_column - 1];
            even -= 1 * u_lowpass_ptr[chroma_column - 2];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += u_highpass_ptr[chroma_column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the result for color conversion later
            last_u[0] = even - chroma_offset;

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * u_lowpass_ptr[chroma_column + 0];
            odd -=  4 * u_lowpass_ptr[chroma_column - 1];
            odd +=  1 * u_lowpass_ptr[chroma_column - 2];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= u_highpass_ptr[chroma_column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the result for color conversion later
            last_u[1] = odd - chroma_offset;


            /***** Process the last column in the v chroma channel *****/

            // Process the last two output points with special filters for the right border
            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the luma lowpass band
            even += 5 * v_lowpass_ptr[chroma_column + 0];
            even += 4 * v_lowpass_ptr[chroma_column - 1];
            even -= 1 * v_lowpass_ptr[chroma_column - 2];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += v_highpass_ptr[chroma_column];
            even = DivideByShift(even, 1);

            // Reduce the precision to eight bits
            even >>= descale_shift;

            // Save the result for color conversion later
            last_v[0] = even - chroma_offset;

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * v_lowpass_ptr[chroma_column + 0];
            odd -=  4 * v_lowpass_ptr[chroma_column - 1];
            odd +=  1 * v_lowpass_ptr[chroma_column - 2];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= v_highpass_ptr[chroma_column];
            odd = DivideByShift(odd, 1);

            // Reduce the precision to eight bits
            odd >>= descale_shift;

            // Save the result for color conversion later
            last_v[1] = odd - chroma_offset;


            // Convert the even luma and chroma values to RGBA
            last_y[0] = (last_y[0] * ymult) >> 7;
            last_y[1] = (last_y[1] * ymult) >> 7;
            last_y[2] = (last_y[2] * ymult) >> 7;
            last_y[3] = (last_y[3] * ymult) >> 7;

            r1 = (last_y[0]                               + r_vmult * last_v[0] +  64) >> 7;
            g1 = (last_y[0] * 2 -     g_umult * last_u[0] - g_vmult * last_v[0] + 128) >> 8;
            b1 = (last_y[0]     + 2 * b_umult * last_u[0]                       +  64) >> 7;

            *(outptr++) = SATURATE_8U(b1);
            *(outptr++) = SATURATE_8U(g1);
            *(outptr++) = SATURATE_8U(r1);
            *(outptr++) = alpha;


            r1 = (last_y[1]                               + r_vmult * last_v[0] +  64) >> 7;
            g1 = (last_y[1] * 2 -     g_umult * last_u[0] - g_vmult * last_v[0] + 128) >> 8;
            b1 = (last_y[1]     + 2 * b_umult * last_u[0]                       +  64) >> 7;

            *(outptr++) = SATURATE_8U(b1);
            *(outptr++) = SATURATE_8U(g1);
            *(outptr++) = SATURATE_8U(r1);
            *(outptr++) = alpha;


            r1 = (last_y[2]                               + r_vmult * last_v[1] +  64) >> 7;
            g1 = (last_y[2] * 2 -     g_umult * last_u[1] - g_vmult * last_v[1] + 128) >> 8;
            b1 = (last_y[2]     + 2 * b_umult * last_u[1]                       +  64) >> 7;

            *(outptr++) = SATURATE_8U(b1);
            *(outptr++) = SATURATE_8U(g1);
            *(outptr++) = SATURATE_8U(r1);
            *(outptr++) = alpha;


            r1 = (last_y[3]                               + r_vmult * last_v[1] +  64) >> 7;
            g1 = (last_y[3] * 2 -     g_umult * last_u[1] - g_vmult * last_v[1] + 128) >> 8;
            b1 = (last_y[3]     + 2 * b_umult * last_u[1]                       +  64) >> 7;

            *(outptr++) = SATURATE_8U(b1);
            *(outptr++) = SATURATE_8U(g1);
            *(outptr++) = SATURATE_8U(r1);
            *(outptr++) = alpha;
        }

        // Advance to the next row of coefficients in each channel
        y_lowpass_ptr += y_lowpass_pitch;
        u_lowpass_ptr += u_lowpass_pitch;
        v_lowpass_ptr += v_lowpass_pitch;

        y_highpass_ptr += y_highpass_pitch;
        u_highpass_ptr += u_highpass_pitch;
        v_highpass_ptr += v_highpass_pitch;

        // Advance the output pointer to the next row
        output_row_ptr += output_pitch;
    }
}






// Apply the inverse spatial filter to the top row and convert the results to the output format
void
InvertSpatialTopRow16sToOutput(DECODER *decoder, int thread_index, PIXEL *lowlow_band[], int lowlow_band_pitch[],
                               PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
                               PIXEL *highlow_band[], int highlow_band_pitch[],
                               PIXEL *highhigh_band[], int highhigh_band_pitch[],
                               uint8_t *output, int output_pitch, int output_width,
                               int format, int colorspace, int row, int channel_width[],
                               PIXEL *buffer, size_t buffer_size, int precision,
                               HorizontalInverseFilterOutputProc horizontal_filter_proc)
{
    int num_channels = decoder->codec.num_channels;// = CODEC_NUM_CHANNELS;

    PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *even_highpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_highpass[CODEC_MAX_CHANNELS];

    // Distance between strip rows in bytes
    int lowpass_pitch[CODEC_MAX_CHANNELS];
    int highpass_pitch[CODEC_MAX_CHANNELS];

    size_t output_row_size = output_pitch;

    // The width of the first channel is the overall width
    int luma_band_width = channel_width[0];

    // Set the dimensions of the processing strip
    ROI strip = {luma_band_width, 2};

    int channel;

    // Compute pointers into the buffers for temporary results
    for (channel = 0; channel < num_channels; channel++)
    {
        size_t buffer_row_size;
        int buffer_half_pitch;
        //int buffer_width;
        int buffer_pitch;

        //int width = luma_band_width;
        int width = channel_width[channel];

        // Compute positions within the temporary buffer for each row of horizontal lowpass
        // and highpass intermediate coefficients computed by the vertical inverse transform
        buffer_row_size = width * sizeof(PIXEL);
        buffer_row_size = ALIGN16(buffer_row_size);
        buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
        buffer_pitch = 2 * buffer_half_pitch;
        //buffer_width = width;

        // Check that the buffer is large enough to hold four rows of coefficients
        assert(buffer_size >= (4 * buffer_row_size));

        // Compute the positions of the even and odd rows of coefficients
        even_lowpass[channel] = &buffer[0];
        even_highpass[channel] = &buffer[buffer_half_pitch];
        odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
        odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

        // Pointers into the strip of horizontal coefficients
        lowpass_pitch[channel] = (int)(2 * buffer_row_size);
        highpass_pitch[channel] = (int)(2 * buffer_row_size);

        buffer = &buffer[4 * buffer_half_pitch];
        buffer_size -= 4 * buffer_row_size;
    }

    // This routine should be called for the first row
    assert(row == 0);

    for (channel = 0; channel < num_channels; channel++)
    {
        PIXEL *lowlow = lowlow_band[channel];
        PIXEL *lowhigh = lowhigh_band[channel];
        PIXEL *highlow = highlow_band[channel];
        PIXEL *highhigh = highhigh_band[channel];

        // Convert pitch from bytes to pixels
        int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
        int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
        //int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
        //int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

        //int width = luma_band_width;
        int width = channel_width[channel];

        // Start at the first column
        int column = 0;

        // Apply the vertical border filter to the first row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            /***** Compute the vertical inverse for the left two bands *****/

            // Apply the even reconstruction filter to the lowpass band
            even += 11 * lowlow[column + 0 * lowlow_pitch];
            even -=  4 * lowlow[column + 1 * lowlow_pitch];
            even +=  1 * lowlow[column + 2 * lowlow_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highlow[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 5 * lowlow[column + 0 * lowlow_pitch];
            odd += 4 * lowlow[column + 1 * lowlow_pitch];
            odd -= 1 * lowlow[column + 2 * lowlow_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highlow[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[channel][column] = SATURATE(odd);


            /***** Compute the vertical inverse for the right two bands *****/

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += 11 * lowhigh[column + 0 * lowhigh_pitch];
            even -=  4 * lowhigh[column + 1 * lowhigh_pitch];
            even +=  1 * lowhigh[column + 2 * lowhigh_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highhigh[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 5 * lowhigh[column + 0 * lowhigh_pitch];
            odd += 4 * lowhigh[column + 1 * lowhigh_pitch];
            odd -= 1 * lowhigh[column + 2 * lowhigh_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highhigh[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[channel][column] = SATURATE(odd);
        }
    }

    // Apply the inverse horizontal transform to the even and odd rows
    horizontal_filter_proc(decoder, thread_index, even_lowpass, lowpass_pitch,
                           even_highpass, highpass_pitch,
                           output, (int)output_row_size, strip,
                           precision, format);
}

// Apply the inverse spatial filter to the middle row and convert the results to the output format
void
InvertSpatialMiddleRow16sToOutput(DECODER *decoder, int thread_index, PIXEL *lowlow_band[], int lowlow_band_pitch[],
                                  PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
                                  PIXEL *highlow_band[], int highlow_band_pitch[],
                                  PIXEL *highhigh_band[], int highhigh_band_pitch[],
                                  uint8_t *output, int output_pitch, int output_width,
                                  int format, int colorspace, int row, int channel_width[],
                                  PIXEL *buffer, size_t buffer_size, int precision,
                                  HorizontalInverseFilterOutputProc horizontal_filter_proc,
                                  int outputlines)
{
    int num_channels = decoder->codec.num_channels;//CODEC_NUM_CHANNELS;

    PIXEL *lowlow_band_row[CODEC_MAX_CHANNELS];
    PIXEL *lowhigh_band_row[CODEC_MAX_CHANNELS];
    PIXEL *highlow_band_row[CODEC_MAX_CHANNELS];
    PIXEL *highhigh_band_row[CODEC_MAX_CHANNELS];

    int lowlow_pitch[CODEC_MAX_CHANNELS];
    int lowhigh_pitch[CODEC_MAX_CHANNELS];
    int highlow_pitch[CODEC_MAX_CHANNELS];
    int highhigh_pitch[CODEC_MAX_CHANNELS];

    PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *even_highpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_highpass[CODEC_MAX_CHANNELS];

    // Distance between strip rows in bytes
    int lowpass_pitch[CODEC_MAX_CHANNELS];
    int highpass_pitch[CODEC_MAX_CHANNELS];

    size_t output_row_size = output_pitch;

    // The width of the first channel is the overall width
    int luma_band_width = channel_width[0];

    // Set the dimensions of the processing strip
    ROI strip = {luma_band_width, outputlines};

    int channel;
    int skip_highpass = 0;
    int lowpass_only = 0;

    if (decoder->channel_decodes > 1 &&
            (decoder->channel_blend_type == BLEND_STACKED_ANAMORPHIC || decoder->channel_blend_type == BLEND_LINE_INTERLEAVED)
            && decoder->frame.format == DECODED_FORMAT_YUYV)
    {
        lowpass_only = 1;
        strip.height = 1;
    }

    if ((decoder->channel_blend_type == BLEND_SIDEBYSIDE_ANAMORPHIC || decoder->channel_blend_type == BLEND_FREEVIEW) && decoder->frame.format == DECODED_FORMAT_YUYV)
        skip_highpass = 1;

    if (decoder->frame.resolution == DECODED_RESOLUTION_HALF_HORIZONTAL)
        skip_highpass = 1;



    // Compute pointers into the buffers for temporary results
    for (channel = 0; channel < num_channels; channel++)
    {
        size_t buffer_row_size;
        int buffer_half_pitch;
        //int buffer_width;
        int buffer_pitch;

        //int width = luma_band_width;
        int width = channel_width[channel];

        // Compute positions within the temporary buffer for each row of horizontal lowpass
        // and highpass intermediate coefficients computed by the vertical inverse transform
        buffer_row_size = width * sizeof(PIXEL);
        buffer_row_size = ALIGN16(buffer_row_size);
        buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
        buffer_pitch = 2 * buffer_half_pitch;
        //buffer_width = width;

        // Check that the buffer is large enough to hold four rows of coefficients
        assert(buffer_size >= (4 * buffer_row_size));

        // Compute the positions of the even and odd rows of coefficients
        even_lowpass[channel] = &buffer[0];
        even_highpass[channel] = &buffer[buffer_half_pitch];
        odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
        odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

        // Pointers into the strip of horizontal coefficients
        lowpass_pitch[channel] = (int)(2 * buffer_row_size);
        highpass_pitch[channel] = (int)(2 * buffer_row_size);

        // Convert pitch from bytes to pixels
        lowlow_pitch[channel] = lowlow_band_pitch[channel] / sizeof(PIXEL);
        lowhigh_pitch[channel] = lowhigh_band_pitch[channel] / sizeof(PIXEL);
        highlow_pitch[channel] = highlow_band_pitch[channel] / sizeof(PIXEL);
        highhigh_pitch[channel] = highhigh_band_pitch[channel] / sizeof(PIXEL);

        // Compute the address of the first row for processing in each wavelet band
        lowlow_band_row[channel] = lowlow_band[channel] + (row - 1) * lowlow_pitch[channel];
        lowhigh_band_row[channel] = lowhigh_band[channel] + (row - 1) * lowhigh_pitch[channel];
        highlow_band_row[channel] = highlow_band[channel] + row * highlow_pitch[channel];
        highhigh_band_row[channel] = highhigh_band[channel] + row * highhigh_pitch[channel];

        buffer = &buffer[4 * buffer_half_pitch];
        buffer_size -= 4 * buffer_row_size;
    }

    // This routine should not be called to process the first row
    assert(row > 0);

    for (channel = 0; channel < num_channels; channel++)
    {
        //int width = luma_band_width;
        int width = channel_width[channel];

        // Start at the first column
        int column = 0;

#if (1 && XMMOPT)

        const int column_step = 8;
        int post_column = width - (width % column_step);

        __m128i *even_lowpass_ptr = (__m128i *)even_lowpass[channel];
        __m128i *even_highpass_ptr = (__m128i *)even_highpass[channel];
        __m128i *odd_lowpass_ptr = (__m128i *)odd_lowpass[channel];
        __m128i *odd_highpass_ptr = (__m128i *)odd_highpass[channel];

        // Process groups of four coefficients along the row
        for (; column < post_column; column += column_step)
        {
            __m128i *lowlow_ptr = (__m128i *)&lowlow_band_row[channel][column];
            __m128i *highlow_ptr = (__m128i *)&highlow_band_row[channel][column];
            __m128i *lowhigh_ptr = (__m128i *)&lowhigh_band_row[channel][column];
            __m128i *highhigh_ptr = (__m128i *)&highhigh_band_row[channel][column];
            __m128i group_epi16;
            __m128i even_epi16;
            __m128i odd_epi16;
            __m128i mid_epi16;
            __m128i half_epi16 = _mm_set1_epi16(4); //DAN031604 4 to 6


            /***** Compute the vertical inverse for the left two bands *****/

            // Set the pitch for the lowpass band used in this section of code
            int group_pitch = (lowlow_pitch[channel] * sizeof(PIXEL)) / sizeof(__m128i);

            // Accumulate parallel sums for the even and odd filters

            if (lowpass_only == 1) // acceleration for 3D
            {
                group_epi16 = _mm_load_si128(lowlow_ptr);
                lowlow_ptr += group_pitch;
                group_epi16 = _mm_srai_epi16(group_epi16, 1);

                _mm_store_si128(even_lowpass_ptr++, group_epi16);
                //	_mm_store_si128(odd_lowpass_ptr++, group_epi16);

                group_epi16 = _mm_load_si128(lowhigh_ptr);
                lowhigh_ptr += group_pitch;
                group_epi16 = _mm_srai_epi16(group_epi16, 1);

                _mm_store_si128(even_highpass_ptr++, group_epi16);
                //	_mm_store_si128(odd_highpass_ptr++, group_epi16);
            }
            else
            {

                // Load eight lowpass coefficients and advance to the next row
                group_epi16 = _mm_load_si128(lowlow_ptr);
                lowlow_ptr += group_pitch;

                even_epi16 = group_epi16;
                odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), group_epi16);

                // Load eight lowpass coefficients and advance to the next row
                mid_epi16 = _mm_load_si128(lowlow_ptr);
                lowlow_ptr += group_pitch;

                // Load the last group of lowpass coefficients
                group_epi16 = _mm_load_si128(lowlow_ptr);

                even_epi16 = _mm_subs_epi16(even_epi16, group_epi16);
                odd_epi16 = _mm_adds_epi16(odd_epi16, group_epi16);

                even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
                odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

                even_epi16 = _mm_srai_epi16(even_epi16, 3);
                odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

                even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
                odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);

                // Add the highpass correction to the even result and divide by two
                group_epi16 = *highlow_ptr;
                even_epi16 = _mm_adds_epi16(even_epi16, group_epi16);
                even_epi16 = _mm_srai_epi16(even_epi16, 1);

                // Subtract the highpass correction from the odd result and divide by two
                odd_epi16 = _mm_subs_epi16(odd_epi16, group_epi16);
                odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

                // Store the even and odd groups of horizontal lowpass coefficients
                _mm_store_si128(even_lowpass_ptr++, even_epi16);
                _mm_store_si128(odd_lowpass_ptr++, odd_epi16);


                /***** Compute the vertical inverse for the right two bands *****/
                if (!skip_highpass) // side by side,
                {
                    // Set the pitch for the lowpass band used in this section of code
                    group_pitch = (lowhigh_pitch[channel] * sizeof(PIXEL)) / sizeof(__m128i);

                    // Accumulate parallel sums for the even and odd filters

                    // Load eight lowpass coefficients and advance to the next row
                    group_epi16 = _mm_load_si128(lowhigh_ptr);
                    lowhigh_ptr += group_pitch;

                    even_epi16 = group_epi16;
                    odd_epi16 = _mm_subs_epi16(_mm_setzero_si128(), group_epi16);

                    // Load eight lowpass coefficients and advance to the next row
                    mid_epi16 = _mm_load_si128(lowhigh_ptr);
                    lowhigh_ptr += group_pitch;

                    // Load the last group of lowpass coefficients
                    group_epi16 = _mm_load_si128(lowhigh_ptr);

                    even_epi16 = _mm_subs_epi16(even_epi16, group_epi16);
                    odd_epi16 = _mm_adds_epi16(odd_epi16, group_epi16);

                    even_epi16 = _mm_adds_epi16(even_epi16, half_epi16);
                    odd_epi16 = _mm_adds_epi16(odd_epi16, half_epi16);

                    even_epi16 = _mm_srai_epi16(even_epi16, 3);
                    odd_epi16 = _mm_srai_epi16(odd_epi16, 3);

                    even_epi16 = _mm_adds_epi16(even_epi16, mid_epi16);
                    odd_epi16 = _mm_adds_epi16(odd_epi16, mid_epi16);

                    // Add the highpass correction to the even result and divide by two
                    group_epi16 = *highhigh_ptr;
                    even_epi16 = _mm_adds_epi16(even_epi16, group_epi16);
                    even_epi16 = _mm_srai_epi16(even_epi16, 1);

                    // Subtract the highpass correction from the odd result and divide by two
                    odd_epi16 = _mm_subs_epi16(odd_epi16, group_epi16);
                    odd_epi16 = _mm_srai_epi16(odd_epi16, 1);

                    // Store the even and odd groups of horizontal highpass coefficients
                    _mm_store_si128(even_highpass_ptr++, even_epi16);
                    _mm_store_si128(odd_highpass_ptr++, odd_epi16);
                }
            }
        }

        // Should have exited the loop at the post processing column
        assert(column == post_column);
#endif

#if (0 && XMMOPT)

        // Fix the compiler errors so this loop can be used after the fast loop
        {
            const int column_step = 4;
            int post_column = width - (width % column_step);

            __m64 *even_lowpass_ptr = (__m64 *)&even_lowpass[channel][column];
            __m64 *even_highpass_ptr = (__m64 *)&even_highpass[channel][column];
            __m64 *odd_lowpass_ptr = (__m64 *)&odd_lowpass[channel][column];
            __m64 *odd_highpass_ptr = (__m64 *)&odd_highpass[channel][column];

            // Process groups of four coefficients along the row
            for (; column < post_column; column += column_step)
            {
                __m64 *lowlow_ptr = (__m64 *)&lowlow_band_row[channel][column];
                __m64 *highlow_ptr = (__m64 *)&highlow_band_row[channel][column];
                __m64 *lowhigh_ptr = (__m64 *)&lowhigh_band_row[channel][column];
                __m64 *highhigh_ptr = (__m64 *)&highhigh_band_row[channel][column];
                __m64 quad_pi16;
                __m64 even_pi16;
                __m64 odd_pi16;
                __m64 mid_pi16;
                __m64 half_pi16 = _mm_set1_pi16(4); //DAN031604 4 to 6


                /***** Compute the vertical inverse for the left two bands *****/

                // Set the pitch for the lowpass band used in this section of code
                int quad_pitch = (lowlow_pitch[channel] * sizeof(PIXEL)) / sizeof(__m64);

                // Accumulate parallel sums for the even and odd filters
                quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients
                lowlow_ptr += quad_pitch;	// Advance to the next row

                even_pi16 = quad_pi16;
                odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

                mid_pi16 = *lowlow_ptr;		// Get four lowpass coefficients
                lowlow_ptr += quad_pitch;	// Advance to the next row

                quad_pi16 = *lowlow_ptr;	// Get four lowpass coefficients

                even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

                even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

                even_pi16 = _mm_srai_pi16(even_pi16, 3);
                odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

                even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


                // Add the highpass correction to the even result and divide by two
                quad_pi16 = *highlow_ptr;
                even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
                even_pi16 = _mm_srai_pi16(even_pi16, 1);

                // Subtract the highpass correction from the odd result and divide by two
                odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
                odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

                // Store the even and odd groups of horizontal lowpass coefficients
                *(even_lowpass_ptr++) = even_pi16;
                *(odd_lowpass_ptr++) = odd_pi16;


                /***** Compute the vertical inverse for the right two bands *****/

                // Set the pitch for the lowpass band used in this section of code
                quad_pitch = (lowhigh_pitch[channel] * sizeof(PIXEL)) / sizeof(__m64);

                // Accumulate parallel sums for the even and odd filters
                quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
                lowhigh_ptr += quad_pitch;	// Advance to the next row

                even_pi16 = quad_pi16;
                odd_pi16 = _mm_subs_pi16(_mm_setzero_si64(), quad_pi16);

                mid_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients
                lowhigh_ptr += quad_pitch;	// Advance to the next row

                quad_pi16 = *lowhigh_ptr;	// Get four lowpass coefficients

                even_pi16 = _mm_subs_pi16(even_pi16, quad_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, quad_pi16);

                even_pi16 = _mm_adds_pi16(even_pi16, half_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, half_pi16);

                even_pi16 = _mm_srai_pi16(even_pi16, 3);
                odd_pi16 = _mm_srai_pi16(odd_pi16, 3);

                even_pi16 = _mm_adds_pi16(even_pi16, mid_pi16);
                odd_pi16 = _mm_adds_pi16(odd_pi16, mid_pi16);


                // Add the highpass correction to the even result and divide by two
                quad_pi16 = *highhigh_ptr;
                even_pi16 = _mm_adds_pi16(even_pi16, quad_pi16);
                even_pi16 = _mm_srai_pi16(even_pi16, 1);

                // Subtract the highpass correction from the odd result and divide by two
                odd_pi16 = _mm_subs_pi16(odd_pi16, quad_pi16);
                odd_pi16 = _mm_srai_pi16(odd_pi16, 1);

                // Store the even and odd groups of horizontal highpass coefficients
                *(even_highpass_ptr++) = even_pi16;
                *(odd_highpass_ptr++) = odd_pi16;
            }
            // Should have exited the loop at the post processing column
            assert(column == post_column);
        }
#endif

        // Process the rest of the row
        for (; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            /***** Compute the vertical inverse for the left two bands (first luma) *****/

            // Apply the even reconstruction filter to the lowpass band
            even += lowlow_band_row[channel][column + 0 * lowlow_pitch[channel]];
            even -= lowlow_band_row[channel][column + 2 * lowlow_pitch[channel]];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowlow_band_row[channel][column + 1 * lowlow_pitch[channel]];

            // Add the highpass correction
            even += highlow_band_row[channel][column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowlow_band_row[channel][column + 0 * lowlow_pitch[channel]];
            odd += lowlow_band_row[channel][column + 2 * lowlow_pitch[channel]];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowlow_band_row[channel][column + 1 * lowlow_pitch[channel]];

            // Subtract the highpass correction
            odd -= highlow_band_row[channel][column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[channel][column] = SATURATE(odd);


            /***** Compute the vertical inverse for the right two bands (first luma) *****/

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += lowhigh_band_row[channel][column + 0 * lowhigh_pitch[channel]];
            even -= lowhigh_band_row[channel][column + 2 * lowhigh_pitch[channel]];
            even += 4; //DAN20050921
            even >>= 3;
            even += lowhigh_band_row[channel][column + 1 * lowhigh_pitch[channel]];

            // Add the highpass correction
            even += highhigh_band_row[channel][column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd -= lowhigh_band_row[channel][column + 0 * lowhigh_pitch[channel]];
            odd += lowhigh_band_row[channel][column + 2 * lowhigh_pitch[channel]];
            odd += 4; //DAN20050921
            odd >>= 3;
            odd += lowhigh_band_row[channel][column + 1 * lowhigh_pitch[channel]];

            // Subtract the highpass correction
            odd -= highhigh_band_row[channel][column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[channel][column] = SATURATE(odd);
        }
    }

    // Apply the inverse horizontal transform to the even and odd rows
    horizontal_filter_proc(decoder, thread_index, even_lowpass, lowpass_pitch,
                           even_highpass, highpass_pitch,
                           output, (int)output_row_size, strip,
                           precision, format);

    //_mm_empty();	// Clear the mmx register state
}

// Apply the inverse spatial filter to the bottom row and convert the results to the output format
void
InvertSpatialBottomRow16sToOutput(DECODER *decoder, int thread_index, PIXEL *lowlow_band[], int lowlow_band_pitch[],
                                  PIXEL *lowhigh_band[], int lowhigh_band_pitch[],
                                  PIXEL *highlow_band[], int highlow_band_pitch[],
                                  PIXEL *highhigh_band[], int highhigh_band_pitch[],
                                  uint8_t *output, int output_pitch, int output_width,
                                  int format, int colorspace, int row, int channel_width[],
                                  PIXEL *buffer, size_t buffer_size, int precision, int odd_height,
                                  HorizontalInverseFilterOutputProc horizontal_filter_proc)
{
    int num_channels = decoder->codec.num_channels;//CODEC_NUM_CHANNELS;

    PIXEL *even_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *even_highpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_lowpass[CODEC_MAX_CHANNELS];
    PIXEL *odd_highpass[CODEC_MAX_CHANNELS];

    // Distance between strip rows in bytes
    int lowpass_pitch[CODEC_MAX_CHANNELS];
    int highpass_pitch[CODEC_MAX_CHANNELS];

    size_t output_row_size = output_pitch;

    // The width of the first channel is the overall width
    int luma_band_width = channel_width[0];

    // Set the dimensions of the processing strip
    ROI strip = {luma_band_width, 2};

    int channel;

    if (odd_height)
    {
        strip.height = 1;
    }

    // Compute pointers into the buffers for temporary results
    for (channel = 0; channel < num_channels; channel++)
    {
        size_t buffer_row_size;
        int buffer_half_pitch;
        //int buffer_width;
        int buffer_pitch;

        //int width = luma_band_width;
        int width = channel_width[channel];

        // Compute positions within the temporary buffer for each row of horizontal lowpass
        // and highpass intermediate coefficients computed by the vertical inverse transform
        buffer_row_size = width * sizeof(PIXEL);
        buffer_row_size = ALIGN16(buffer_row_size);
        buffer_half_pitch = (int)buffer_row_size / sizeof(PIXEL);
        buffer_pitch = 2 * buffer_half_pitch;
        //buffer_width = width;

        // Check that the buffer is large enough to hold four rows of coefficients
        assert(buffer_size >= (4 * buffer_row_size));

        // Compute the positions of the even and odd rows of coefficients
        even_lowpass[channel] = &buffer[0];
        even_highpass[channel] = &buffer[buffer_half_pitch];
        odd_lowpass[channel] = &buffer[2 * buffer_half_pitch];
        odd_highpass[channel] = &buffer[3 * buffer_half_pitch];

        // Pointers into the strip of horizontal coefficients
        lowpass_pitch[channel] = (int)(2 * buffer_row_size);
        highpass_pitch[channel] = (int)(2 * buffer_row_size);

        buffer = &buffer[4 * buffer_half_pitch];
        buffer_size -= 4 * buffer_row_size;
    }

    for (channel = 0; channel < num_channels; channel++)
    {
        PIXEL *lowlow = lowlow_band[channel];
        PIXEL *lowhigh = lowhigh_band[channel];
        PIXEL *highlow = highlow_band[channel];
        PIXEL *highhigh = highhigh_band[channel];

        // Convert pitch from bytes to pixels
        int lowlow_pitch = lowlow_band_pitch[channel] / sizeof(PIXEL);
        int lowhigh_pitch = lowhigh_band_pitch[channel] / sizeof(PIXEL);
        int highlow_pitch = highlow_band_pitch[channel] / sizeof(PIXEL);
        int highhigh_pitch = highhigh_band_pitch[channel] / sizeof(PIXEL);

        //int width = luma_band_width;
        int width = channel_width[channel];

        // Start at the first column
        int column = 0;

        // Compute the address of the first row for processing in each wavelet band
        lowlow += row * lowlow_pitch;
        lowhigh += row * lowhigh_pitch;
        highlow += row * highlow_pitch;
        highhigh += row * highhigh_pitch;

        // Apply the vertical border filter to the last row
        for (column = 0; column < width; column++)
        {
            int32_t even = 0;		// Result of convolution with even filter
            int32_t odd = 0;		// Result of convolution with odd filter


            // Compute the vertical inverse for the left two bands //

            // Apply the even reconstruction filter to the lowpass band
            even += 5 * lowlow[column + 0 * lowlow_pitch];
            even += 4 * lowlow[column - 1 * lowlow_pitch];
            even -= 1 * lowlow[column - 2 * lowlow_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highlow[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_lowpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * lowlow[column + 0 * lowlow_pitch];
            odd -=  4 * lowlow[column - 1 * lowlow_pitch];
            odd +=  1 * lowlow[column - 2 * lowlow_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highlow[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_lowpass[channel][column] = SATURATE(odd);


            // Compute the vertical inverse for the right two bands //

            even = 0;
            odd = 0;

            // Apply the even reconstruction filter to the lowpass band
            even += 5 * lowhigh[column + 0 * lowhigh_pitch];
            even += 4 * lowhigh[column - 1 * lowhigh_pitch];
            even -= 1 * lowhigh[column - 2 * lowhigh_pitch];
            even += ROUNDING(even, 8);
            even = DivideByShift(even, 3);

            // Add the highpass correction
            even += highhigh[column];
            even = DivideByShift(even, 1);

            // Place the even result in the even row
            even_highpass[channel][column] = SATURATE(even);

            // Apply the odd reconstruction filter to the lowpass band
            odd += 11 * lowhigh[column + 0 * lowhigh_pitch];
            odd -=  4 * lowhigh[column - 1 * lowhigh_pitch];
            odd +=  1 * lowhigh[column - 2 * lowhigh_pitch];
            odd += ROUNDING(odd, 8);
            odd = DivideByShift(odd, 3);

            // Subtract the highpass correction
            odd -= highhigh[column];
            odd = DivideByShift(odd, 1);

            // Place the odd result in the odd row
            odd_highpass[channel][column] = SATURATE(odd);
        }
    }

    // Apply the inverse horizontal transform to the even and odd rows
    horizontal_filter_proc(decoder, thread_index, even_lowpass, lowpass_pitch,
                           even_highpass, highpass_pitch,
                           output, (int)output_row_size, strip,
                           precision, format);
}

